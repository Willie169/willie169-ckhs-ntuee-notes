\documentclass[a4paper,12pt]{report}
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{3}
\input{/usr/share/LaTeX-ToolKit/template.tex}
\begin{document}
\title{Calculus}
\author{沈威宇}
\date{\temtoday}
\titletocdoc
\chapter{Calculus (微積分)}
\section{Limit (極限)}
\subsection{Limits of Real Sequences}
Below, we are discussing limits of sequences with domain $\mathbb{N}$ and codomain $\mathbb{R}$. For sequences $\langle a_n\rangle_{i=l}^\infty$ in $\mathbb{R}$, its limit is the same as the limit of another sequence $\langle b_n=a_{n+l-1}\rangle_{i=1}^\infty$.
\subsubsection{Definition}
For a real sequence \(\langle a_n\rangle\), the limit of \(\langle a_n\rangle\) (as $n$ approaches infinity), denoted as $\lim_{n \to \infty} a_n$ or $\lim_n a_n$, is defined as follows:
\[\lim_{n \to \infty} a_n = L \equiv \forall \epsilon > 0:\, \exists M \in\mathbb{N}\text{\ s.t.\ } n\in\mathbb{N}\land n \geq M\implies |a_n - L| < \epsilon.\]
In other words, as \(n\) becomes arbitrarily large, \(a_n\) gets arbitrarily close to \(L\).

If such $M$ exists, we say the limit exists or the sequence converges (收斂) to $L$; otherwise, we say the limit doesn't exist or the sequence diverge (發散).
\subsubsection{Infinite Limits}
\[\lim_{n\to \infty}a_n=\infty \equiv \forall M > 0, \exists M \in\mathbb{N} \text{\ s.t.\ } n\in\mathbb{N}\land n \geq M \implies a_n > M.\]
\[\lim_{n\to \infty}a_n=-\infty \equiv \forall M < 0, \exists M \in\mathbb{N} \text{\ s.t.\ } n\in\mathbb{N}\land n \geq M \implies a_n < M.\]
Note that if a limit equals to $\infty$ or $-\infty$, the limit doesn't exist.
\sssc{Preservation of equal to}
Given real sequences $\langle a_n\rangle$ and $\langle b_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$, $a_k=b_k$ and that $\lim_{n\to\infty}a_n$ exists, then $\lim_{n\to\infty}b_n$ exists and that:
\[\lim_{n\to\infty}a_n=\lim_{n\to\infty}b_n.\]
\sssc{Preservation of less than or equal to}
Given real sequences $\langle a_n\rangle$ and $\langle b_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$, $a_k\leq b_k$ and that both $\lim_{n\to\infty}a_n$ and $\lim_{n\to\infty}b_n$ exist, then:
\[\lim_{n\to\infty}a_n\leq\lim_{n\to\infty}b_n.\]
\sssc{Squeeze (夾擠) theorem or Sandwich (三明治) theorem}
Given real sequences $\langle a_n\rangle$, $\langle b_n\rangle$, and $\langle c_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$:
\[a_k\leq c_k\leq b_k\]
and
\[\lim_{n\to\infty}a_n=\lim_{n\to\infty}b_n=L,\]
then: 
\[\lim_{n\to\infty}c_n=L.\]
\subsubsection{Monotone Convergence Theorem (單調收斂定理) or Completeness of the Real Number (實數的完備性)}
\textit{Statement.}
\begin{enumerate}[label=(\Alph*)]
\item For a non-decreasing and bounded-above sequence of real numbers $\langle a_n\rangle_{n\in\mathbb {N}}$:
\[\lim_{n\to\infty}a_n=\sup_n a_n\]
\item For a non-increasing and bounded-below sequence of real numbers $\langle a_n\rangle_{n\in\mathbb {N}}$:
\[\lim_{n\to\infty}a_n=\inf_n a_n\]
\end{enumerate}
\begin{proof}\mbox{}\\
Let $\{a_{n}\}$ be the set of values of $\langle a_n\rangle_{n\in\mathbb {N}}$. By assumption, $\{a_n\}$ is non-empty and bounded-above by $\sup_n a_n$. Let $c=\sup_n a_n$.
\[\forall\epsilon>0:\,\exists M\in\mathbb {N}\text{\ s.t.\ }c\geq a_M>c-\epsilon,\]
since otherwise $c-\epsilon$ is a strictly smaller upper bound of $\langle a_n\rangle$, contradicting the definition of the supremum. 

Then since $\langle a_n\rangle$ is non-decreasing, and $c$ is an upper bound:
\[\forall\epsilon>0:\,\exists M\in\mathbb {N}\text{\ s.t.\ }\forall n\geq M:\,|c-a_n|=c-a_n\leq c-a_M=|c-a_M|<\epsilon.\]
The proof of the (B) part is analogous or follows from (A) by considering $\langle -a_{n}\rangle_{n\in \mathbb{N}}$.
\end{proof}
\textit{Statement.}

If $\langle a_n\rangle_{n\in\mathbb {N}}$ is a monotone sequence of real numbers, i.e., if 
$a_n\leq a_{n+1}$ for every $n\geq 1$ or $a_n\geq a_{n+1}$ for every $n\geq 1$, then this sequence has a finite limit if and only if the sequence is bounded.
\begin{proof}\mbox{}\\
"If"-direction: The proof follows directly from the proposition.

"Only If"-direction: By $(\epsilon,\delta)$-definition of limit, every sequence $\langle a_n\rangle_{n\in\mathbb {N}}$ with a finite limit $L$ is necessarily bounded.
\end{proof}
\subsection{Limits of Real Series}
\subsubsection{Definition}
Let:
\[S_n = \sum_{i=1}^n a_i,\]
where \(a_i\) are terms of a real sequence. The limit of \(S_n\), denoted as \(\lim_{n\to\infty}S_n\) or \(\sum_{i=1}^{\infty}a_i\), is defined as the following:
\[\sum_{i=1}^{\infty}a_i = L \equiv \forall \epsilon > 0:\, \exists M \in\mathbb{N}\text{\ s.t.\ } n \geq M\implies |S_n - L| < \epsilon.\]

If such $M$ exists, we say the limit exists or the series converges to $L$; otherwise, we say the limit doesn't exist or the series diverge.
\subsubsection{Absolute convergence and conditional convergence}
A series $S_n=\sum_{i=1}^{\infty}a_i$ converges absolutely to $L$ if $\exists\lim_{n\to\infty}\sum_{i=1}^{\infty}\abs{a_1}\land\lim_{n\to\infty}\sum_{i=1}^{\infty}\abs{a_1}=L$. If $S_n$ is convergent but not convergent absolutely, we say $S_n$ converges conditionally.
\sssc{Preservation of equal to}
Given real sequences $\langle a_n\rangle$ and $\langle b_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$:
\[\sum_{i=1}^ka_i=\sum_{i=1}^kb_i\]
and that $\sum_{i=1}^{\infty}a_i$ exists, then $\sum_{i=1}^{\infty}b_i$ exists and that
\[\sum_{i=1}^{\infty}a_i=\sum_{i=1}^{\infty}b_i.\]
\sssc{Preservation of less than or equal to}
Given real sequences $\langle a_n\rangle$ and $\langle b_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$:
\[\sum_{i=1}^ka_i\leq\sum_{i=1}^kb_i\]
and that both $\sum_{i=1}^{\infty}a_i$ and $\sum_{i=1}^{\infty}b_i$ exist, then
\[\sum_{i=1}^{\infty}a_i\leq\sum_{i=1}^{\infty}b_i.\]
\sssc{Squeeze theorem or Sandwich theorem}
Given real sequences $\langle a_n\rangle$, $\langle b_n\rangle$, and $\langle c_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$:
\[\sum_{i=1}^ka_i\leq\sum_{i=1}^kc_i\leq\sum_{i=1}^kb_i\]
and
\[\sum_{i=1}^{\infty}a_i=\sum_{i=1}^{\infty}b_i=L,\]
then: 
\[\sum_{i=1}^{\infty}c_i=L.\]
\subsection{Limits of Real Nets}
Below, we are discussing limits of nets in the set of real number.
\subsubsection{Definition}
For a real net $\langle x_a\rangle_{a\in A}$ in which $A$ is a directed set, the limit of $\langle x_a\rangle_{a\in A}$, denoted as $\lim_{a\in A} x_a$ or $\lim_a x_a$, is defined as follows:
\[\lim_ax_a = L \equiv \forall \epsilon > 0:\, \exists a_0 \in A\text{\ s.t.\ } a\in A\land a\ge a_0\implies |x_a - L| < \epsilon.\]

If such $a_0$ exists, we say the limit exists or the net converges to $L$; otherwise, we say the limit doesn't exist.
\subsubsection{Infinite Limits}
\[\lim_{a}x_a=\infty \equiv \forall M > 0, \exists a_0 \in A \text{\ s.t.\ } a\in A\land a\geq a_0 \implies x_a > M.\]
\[\lim_{a}x_a=-\infty \equiv \forall M < 0, \exists a_0 \in A \text{\ s.t.\ } a\in A\land a\geq a_0 \implies x_a < M.\]
Note that if a limit equals to $\infty$ or $-\infty$, the limit doesn't exist.
\sssc{Preservation of equal to}
Let $A$ be a directed set. Given real nets $\langle x_a\rangle_{a\in A}$ and $\langle b_n\rangle_{a\in A}$ which for all $k$ that is greater than or equal to a specific $j\in A$, $a_k=b_k$ and that $\lim_{a}x_a$ exists, then $\lim_{a}b_n$ exists and that:
\[\lim_{a}x_a=\lim_{a}b_n.\]
\sssc{Preservation of less than or equal to}
Let $A$ be a directed set. Given real nets $\langle x_a\rangle_{a\in A}$ and $\langle b_n\rangle_{a\in A}$ which for all $k$ that is greater than or equal to a specific $j\in A$, $a_k\leq b_k$ and that both $\lim_{a}x_a$ and $\lim_{a}b_n$ exist, then:
\[\lim_{a}x_a\leq\lim_{a}b_n.\]
\sssc{Squeeze theorem or Sandwich theorem}
Let $A$ be a directed set. Given real nets $\langle x_a\rangle_{a\in A}$, $\langle b_n\rangle_{a\in A}$, and $\langle c_n\rangle_{a\in A}$ which for all $k$ that is greater than or equal to a specific $j\in A$:
\[a_k\leq c_k\leq b_k\]
and
\[\lim_{a}x_a=\lim_{a}b_n=L,\]
then: 
\[\lim_{a}c_n=L.\]
\subsection{Limits of Functions with Real Domains}
\subsubsection{Definition at Finity}
Let \(I\) be an interval containing the point \(a\). Let \( f(x) \) be a function defined on \(I\), except possibly at \(a\) itself. The limit of \( f(x) \) as \( x \) approaches \( a \) is defined as follows:
\[\lim_{x \to a} f(x) = L \equiv \forall \epsilon > 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < |x - a| < \delta \implies |f(x) - L| < \epsilon.\]
In other words, as \(x\) becomes arbitrarily close to \(a\), \(f(x)\) gets arbitrarily close to \(L\).

If such $\detla$s exist, we say the limit exists; otherwise, we say the limit doesn't exist.
\subsubsection{Definition at Infinity}
Let \(I\) be a left-bounded, right-unbounded interval with the point \(a\) being its endpoint on the left. Let \( f(x) \) be a function defined on \(I\). The limit of \( f(x) \) as \( x \) approaches \( \infty \) is defined as follows:
\[\lim_{x \to \infty} f(x) = L \equiv \forall \epsilon > 0: \, \exists M > a \text{\ s.t.\ } x > M \implies |f(x) - L| < \epsilon.\]
In other words, as \(x\) becomes arbitrarily large, \(f(x)\) gets arbitrarily close to \(L\). We say $f(x)$ converge to $L$ as $x\to\infty$ if $\lim_{x \to \infty} f(x) = L$.

Let \(I\) be a right-bounded, left-unbounded interval with the point \(a\) being its endpoint on the right. Let \( f(x) \) be a function defined on \(I\). The limit of \( f(x) \) as \( x \) approaches \( -\infty \) is defined as follows:
\[\lim_{x \to -\infty} f(x) = L \equiv \forall \epsilon > 0: \, \exists M < a \text{\ s.t.\ } x < M \implies |f(x) - L| < \epsilon.\]
In other words, as \(x\) becomes arbitrarily small, \(f(x)\) gets arbitrarily close to \(L\). We say $f(x)$ converge to $L$ as $x\to-\infty$ if $\lim_{x \to -\infty} f(x) = L$.
\end{itemize}
\subsubsection{Horizontal asymptote (水平漸近線)}
\[ \qty(\lim_{x \to \infty} f(x)=L \lor\lim_{x \to -\infty} f(x)=L) \iff \qty(y=L\tx{ is a horizontal asymptote of $y=f(x)$}).\]
\subsubsection{Slant asymptote (斜漸近線)}
\[ \qty(\lim_{x \to \infty} f(x)-(mx+b)=0 \lor\lim_{x \to -\infty} f(x)-(mx+b)=0) \iff \qty(y=mx+b\tx{\ is a slant asymptote of $y=f(x)$}).\]
\subsubsection{One-side Limits}
\tb{Right-hand Limit (右極限)}: Let \(I\) be a left-open interval with the point \(a\) being its endpoint on the left. Let \( f(x) \) be a function defined on \(I\). The right-hand limit of \( f(x) \) as \( x \) approaches \( a \) is defined as follows:
\[\lim_{x \to a^+} f(x) = L \equiv \forall \epsilon > 0 :\,\exists \delta > 0 \text{\ s.t.\ } 0 < x - a < \delta \implies |f(x) - L| < \epsilon.\]
In other words, as \(x\) becomes arbitrarily close to \(a\) and is greater than \(a\), \(f(x)\) gets arbitrarily close to \(L\). For a function $f(x)$, $\lim_{x\to a^+}f(x)$ can also be denoted as $f(a^+)$.

\tb{Left-hand Limit (左極限)}: Let \(I\) be a right-open interval with the point \(a\) being its endpoint on the right. Let \( f(x) \) be a function defined on \(I\). The left-hand limit of \( f(x) \) as \( x \) approaches \( a \) is defined as follows:
\[\lim_{x \to a^-} f(x) = L \equiv \forall \epsilon > 0 :\,\exists \delta > 0 \text{\ s.t.\ } 0 < a - x < \delta \implies |f(x) - L| < \epsilon.\]
In other words, as \(x\) becomes arbitrarily close to \(a\) and is less than \(a\), \(f(x)\) gets arbitrarily close to \(L\). For a function $f(x)$, $\lim_{x\to a^-}f(x)$ can also be denoted as $f(a^-)$.
\subsubsection{Infinite Limits}
\[\lim_{x\to a}f(x)=\infty \equiv \forall N > 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < |x - a| < \delta \implies f(x) > N.\]
\[\lim_{x\to a^+}f(x)=\infty \equiv \forall N > 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < x - a < \delta \implies f(x) > N.\]
\[\lim_{x\to a^-}f(x)=\infty \equiv \forall N > 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < a - x < \delta \implies f(x) > N.\]
\[\lim_{x\to a}f(x)=-\infty \equiv \forall N < 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < |x - a| < \delta \implies f(x) < N.\]
\[\lim_{x\to a^+}f(x)=-\infty \equiv \forall N < 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < x - a < \delta \implies f(x) < N.\]
\[\lim_{x\to a^-}f(x)=-\infty \equiv \forall N < 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < a - x < \delta \implies f(x) < N.\]
\[\lim_{x\to\infty}f(x)=\infty \equiv \forall N > 0:\, \exists M > 0 \text{\ s.t.\ } x > M \implies f(x) > N.\]
\[\lim_{x\to\infty}f(x)=-\infty \equiv \forall N > 0:\, \exists M > 0 \text{\ s.t.\ } x > M \implies f(x) < N.\]
\[\lim_{x\to-\infty}f(x)=\infty \equiv \forall N > 0:\, \exists M < 0 \text{\ s.t.\ } x < M \implies f(x) > N.\]
\[\lim_{x\to-\infty}f(x)=-\infty \equiv \forall N > 0:\, \exists M < 0 \text{\ s.t.\ } x < M \implies f(x) < N.\]
Note that if a limit equals to $\infty$ or $-\infty$, the limit doesn't exist.
\sssc{Vertical asymptote (鉛直漸近線)}
\[\qty(\exists a\in\mathbb{R}\colon\abs{\lim_{x \to a^+} f(x)}=\infty\lor\abs{\lim_{x \to a^-} f(x)}=\infty)\iff \qty(x=a\tx{\ is a vertical asymptote of $y=f(x)$}).\]
\sssc{Preservation of equal to at finity}
Let \(I\) be an interval containing the point \(a\). Let $f(x)$ and $g(x)$ be functions defined on \(I\), except possibly at \(a\) itself, which for all $x\in I\land x\neq a$, $f(x)=g(x)$, and that $\lim_{x\to a}f(x)$ exists, then $\lim_{x\to a}g(x)$ exists and that
\[\lim_{x\to a}f(x)=\lim_{x\to a}g(x).\]
\sssc{Preservation of less than or equal to at finity}
Let \(I\) be an interval containing the point \(a\). Let $f(x)$ and $g(x)$ be functions defined on \(I\), except possibly at \(a\) itself, which for all $x\in I\land x\neq a$, $f(x)\leq g(x)$, and that both $\lim_{x\to a}f(x)$ and $\lim_{x\to a}g(x)$ exist, then
\[\lim_{x\to a}f(x)\leq\lim_{x\to a}g(x).\]
\subsubsection{Squeeze theorem or Sandwich theorem at finity}
Let \(I\) be an interval containing the point \(a\). Let $f(x)$, $g(x)$, and $h(x)$ be functions defined on \(I\), except possibly at \(a\) itself, which for all $x\in I\land x\neq a$:
\[f(x)\leq h(x)\leq g(x)\]
and
\[\lim_{x\to a}f(x)=\lim_{x\to a}g(x)=L,\]
then: 
\[\lim_{x\to a}h(x)=L.\]
\sssc{Preservation of equal to at finity of one-sided limit}
Let \(I\) be an interval \((a,b)\) in which $a<b$. Let $f(x)$ and $g(x)$ be functions defined on \(I\), which for all $x\in I$, $f(x)=g(x)$, and that $\lim_{x\to a^+}f(x)$ exists, then $\lim_{x\to a^+}g(x)$ exists and that
\[\lim_{x\to a^+}f(x)=\lim_{x\to a^+}g(x).\]

Let \(I\) be an interval \((b,a)\) in which $a>b$. Let $f(x)$ and $g(x)$ be functions defined on \(I\), which for all $x\in I$, $f(x)=g(x)$, and that $\lim_{x\to a^-}f(x)$ exists, then $\lim_{x\to a^-}g(x)$ exists and that
\[\lim_{x\to a^-}f(x)=\lim_{x\to a^-}g(x).\]
\sssc{Preservation of less than or equal to at finity of one-sided limit}
Let \(I\) be an interval \((a,b)\) in which $a<b$. Let $f(x)$ and $g(x)$ be functions defined on \(I\), which for all $x\in I$, $f(x)\leq g(x)$, and that both $\lim_{x\to a^+}f(x)$ and $\lim_{x\to a^+}g(x)$ exist, then
\[\lim_{x\to a^+}f(x)\leq\lim_{x\to a^+}g(x).\]

Let \(I\) be an interval \((b,a)\) in which $a>b$. Let $f(x)$ and $g(x)$ be functions defined on \(I\), which for all $x\in I$, $f(x)\leq g(x)$, and that both $\lim_{x\to a^-}f(x)$ and $\lim_{x\to a^-}g(x)$ exist, then
\[\lim_{x\to a^-}f(x)\leq\lim_{x\to a^-}g(x).\]
\subsubsection{Squeeze theorem or Sandwich theorem at finity of one-sided limit}
Let \(I\) be an interval \((a,b)\) in which $a<b$. Let $f(x)$, $g(x)$, and $h(x)$ be functions defined on \(I\), which for all $x\in I$:
\[f(x)\leq h(x)\leq g(x)\]
and
\[\lim_{x\to a^+}f(x)=\lim_{x\to a^+}g(x)=L,\]
then: 
\[\lim_{x\to a^+}h(x)=L.\]

Let \(I\) be an interval \((b,a)\) in which $b>a$. Let $f(x)$, $g(x)$, and $h(x)$ be functions defined on \(I\), which for all $x\in I$:
\[f(x)\leq h(x)\leq g(x)\]
and
\[\lim_{x\to a^-}f(x)=\lim_{x\to a^-}g(x)=L,\]
then: 
\[\lim_{x\to a^-}h(x)=L.\]
\sssc{Preservation of less than or equal to at infinity}
Let \(I\) be an interval $(a,\infty)$. Let $f(x)$ and $g(x)$ be functions defined on \(I\), which for all $x\in I$, $f(x)\leq g(x)$, and that both $\lim_{x\to\infty}f(x)$ and $\lim_{x\to\infty}g(x)$ exist, then
\[\lim_{x\to\infty}f(x)\leq\lim_{x\to\infty}g(x).\]

Let \(I\) be an interval $(-\infty,a)$. Let $f(x)$ and $g(x)$ be functions defined on \(I\), which for all $x\in I\land x\neq a$, $f(x)\leq g(x)$, and that both $\lim_{x\to-\infty}f(x)$ and $\lim_{x\to-\infty}g(x)$ exist, then
\[\lim_{x\to-\infty}f(x)\leq\lim_{x\to-\infty}g(x).\]
\subsubsection{Squeeze theorem or Sandwich theorem at infinity}
Let \(I\) be an interval $(a,\infty)$. Let $f(x)$, $g(x)$, and $h(x)$ be functions defined on \(I\), which for all $x\in I$:
\[f(x)\leq h(x)\leq g(x)\]
and
\[\lim_{x\to\infty}f(x)=\lim_{x\to\infty}g(x)=L,\]
then: 
\[\lim_{x\to\infty}h(x)=L.\]

Let \(I\) be an interval $(-\infty,a)$. Let $f(x)$, $g(x)$, and $h(x)$ be functions defined on \(I\), which for all $x\in I$:
\[f(x)\leq h(x)\leq g(x)\]
and
\[\lim_{x\to-\infty}f(x)=\lim_{x\to-\infty}g(x)=L,\]
then: 
\[\lim_{x\to-\infty}h(x)=L.\]
\sssc{Direct substitution property of rational functions}
If $f$ is a rational function and $a$ is in the domain of $f$, then
\[\lim_{x\to a}f(x)=f(a).\]
\sssc{Limits involving quotient functions}
Let \( a \) and \( b \) be real numbers, set
\[A=\left\{f\colon U\subseteq\mathbb{R}\to\mathbb{R} \middle | f(x) = x \lor \ln(f(x)) \in A \lor e^{f\left(x\right)}  \in A \right\},\]
and function $f\in A$. Then:
\[\lim_{x \to \infty} \frac{\left(f\left(x\right)\right)^a}{\left(f\left(x\right)\right)^b} = \infty, \quad a > b \]
\[ \lim_{x \to \infty} \frac{af\left(x\right)}{bf\left(x\right)} = \frac{a}{b}, \quad b \neq 0 \]
\[ \lim_{x \to \infty}\frac{n^{af\left(x\right)}}{bf\left(x\right)} = \infty, \quad a,b > 0 \land  n > 1 \]
\[ \lim_{x \to \infty}\frac{n^{af\left(x\right)}}{bf\left(x\right)} = 0, \quad a,b > 0 \land  0\leq n<1 \]
\[ \lim_{x \to \infty}\frac{af\left(x\right)}{b\log_n f\left(x\right)} = \infty, \quad a,b > 0 \land  n > 1 \]
\ssc{Limit of nets of fuctions}
\sssc{Pointwise convergence (逐點收斂)}
Let $V$ be a set and $Y$ be a topological space. A net of functions $\lange f_n\rangle_{n\in A}$ all having the same domain $X\subseteq V$ and codomain $Y$ is said to converge pointwise to a given function $f\colon X\to Y$, denoted as 
\[\lim_nf_n=f\text{\ pointwise},\]
if and only if
\[\forall x\in X\colon\lim_nf_n(x)=f(x).\]
The function $f$ is said to be the pointwise limit function of $\lange f_n\rangle$.
\sssc{Uniform convergence (一致收斂)}
Let $V$ be a set and $(Y,d)$ be a metric topological space. A net of functions $\lange f_n\rangle_{n\in A}$ all having the same domain $X\subseteq V$ and codomain $Y$ is said to converge uniformly to a given function $f\colon X\to Y$, denoted as 
\[\lim_nf_n=f\text{\ uniformly},\]
if and only if
\[\forall\varepsilon\in\mathbb{R}_{>0}\colon\exists N\in A\text{\ s.t.\ }\left(n\in A\land N\leq n\implies\sup_{x\in X}d(f_n(x),f(x))<\varepsilon\right).\]
The function $f$ is said to be the uniform limit function of $\lange f_n\rangle$.
\ssc{Limit Laws}
Given the limits of the functions involved exist,
\sssc{Sum Law}
The limit of a sum of functions is the sum of the limits of the functions.
\sssc{Difference Law}
The limit of a difference of functions is the difference of the limits of the functions.
\sssc{Constant Multiple Law}
The limit of a constant times a function is the constant times the limit of the function.
\sssc{Product Law}
The limit of a product of functions is the product of the limits of the functions.
\sssc{Quotient Law}
The limit of a quotient of functions is the quotient of the limits of the functions, provided that the limit of the denominator is not 0.
\sssc{Power Law}
The limit of the $n$th power of a function, in which $n$ is a positive integer, is the $n$th power of the limit of the function.
\sssc{Root Law}
The limit of the $n$th root of a function, in which $n$ is a positive integer, is the $n$th root of the limit of the function.
\sssc{The Uniqueness of Limits}
If a limit exists, it is unique.



\section{Continuity (連續性)}
\ssc{Continuity}
\sssc{Definition of continuity of real functions}
\begin{itemize}
\item For a point $a$ in the domain of a function $f$, if and only if $\exists\lim_{x\to a}f(x)$ and $\lim_{x\to a}f(x)=f(a)$, we say $f(x)$ is continuous (連續的) at $a$.
\item For a point $a$ in the domain of a function $f$, if and only if $\exists\lim_{x\to a^+}f(x)$ and $\lim_{x\to a^+}f(x)=f(a)$, we say $f(x)$ is continuous from the right at $a$; if and only if $\exists \lim_{x\to a^-} f(x)$ and $\lim_{x\to a^-} f(x)=f(a)$, we say $f(x)$ is continuous from the left at $a$.
\item For an open interval $I$ that is a subset of the domain of a function $f$, if and only if $f(x)$ is continuous at all points in $I$, we say $f(x)$ is continuous on $I$.
\item For an right-open interval $[a,b)$ that is a subset of the domain of a function $f$, if and only if $f(x)$ is continuous on $(a,b)$ and continuous from the right at $a$, we say $f(x)$ is continuous on $[a,b)$.
\item For an left-open interval $(a,b]$ that is a subset of the domain of a function $f$, if and only if $f(x)$ is continuous on $(a,b)$ and continuous from the left at $b$, we say $f(x)$ is continuous on $(a,b]$.
\item For an closed interval $[a,b]$ that is a subset of the domain of a function $f$, if and only if $f(x)$ is continuous on both $[a,b)$ and $(a,b]$, we say $f(x)$ is continuous on $[a,b]$.
\item if and only if $f(x)$ is continuous at all points in its domain, we say $f(x)$ is continuous.
\eit
\sssc{Definition of continuity of functions between topological spaces}
\begin{itemize}
\item A function $f\colon I\subeteq X\to Y$ where $X$ and $Y$ are topological spaces is continuous at a point $x\in I$ if and only if for any neighborhood $V$ of $f(x)$ in $Y$, there is a neighborhood $U$ of $x$ such that $f(U)\subseteq V$.
\item A function $f\colon I\subeteq X\to Y$ where $X$ and $Y$ are topological spaces is continuous if and only if for any open subset $V$ of $Y$, the preimage of $f$ on $V$ is an open subset of $X$.
\item A function $f\colon I\subeteq X\to Y$ where $X$ and $Y$ are topological spaces is continuous on a subset $J$ of $I$ if and only if for any open subset $V$ of $Y$, the joint set of the preimage of $f$ on $V$ and $J$ is open in the subspace topology of $X$ in $J$.
\eit
\sssc{Discontinuity (不連續（點）)}
A point is a discontinuity of a function $f$ if it is in the domain of $f$ but $f$ is not continuous on it.
\sssc{Type of discontinuity of real functions}
For a function $f$ with domain $U\subseteq\mathbb{R}$ and a point $a\in U$ that $f$ is discontinuous at, the discontinuity $a$ of $f$ can be classified as below:
\bit
\item \tb{Removable (可去) discontinuity}: If $\exists\lim_{x\to a}f(x)\land\lim_{x\to a}f(x)\neq f(a)$, we call $f(a)$ a removable discontinuity. A discontinuity that is not a removable discontinuity is called a non-removable discontinuity.
\item \tb{Jump (跳躍) discontinuity}: If $\exists\lim_{x\to a^-}f(x)\land\exists\lim_{x\to a^+}f(x)\land\lim_{x\to a^-}f(x)\neq\lim_{x\to a^+}f(x)$, we call $f(a)$ a jump discontinuity.
\item\tb{Infinite (無窮) discontinuity}: If at least one of $\lim_{x\to a^-}f(x)$ and $\lim_{x\to a^+}f(x)$ does not exist, and that those in $\lim_{x\to a^-}f(x)$ and $\lim_{x\to a^+}f(x)$ that do not exist are either $\infty$ or $-\infty$, we call $f(a)$ an infinite discontinuity.
\item\tb{Type I discontinuity}: A discontinuity of $f$ that is either a removable discontinuity or a jump discontinuity is called a type I discontinuity of $f$.
\item\tb{Essential (本質) discontinuity or type II discontinuity}: A discontinuity of $f$ that is not a type I discontinuity is called an essential discontinuity or a type II discontinuity of $f$.
\eit
\sssc{Singularity or singular point (奇點)}
A point is a singularity or a singular point of a function $f$ if it is in the closure of its domain but not in its domain, or it is a discontinuity of $f$.
\sssc{Arithmetic Laws}
If $f$ and $g$ are continuous at $a$ and $c$ is a constant, then the following functions are also continuous at $a$:
\[f+g;\quad f-g;\quad cf;\quad fg;\]
\[\frac{f}{g}\text{\ if\ }g(a)\neq 0.\]
\sssc{Composte Laws}
If $g$ is continuous at $a$ and $f$ is continuous at $g(a)$, then the composite function $f\circ g$ is continuous at $a$.
\sssc{Examples of continuous real functions}
The following types of functions are continuous at every number in their domains: algebraic functions, trigonometric functions, inverse trigonometric functions, exponential functions, logarithmic functions.
\ssc{Intermediate Value Theorem (IVT) (中間值定理)}
\sssc{Intermediate value theorem of real functions}
Let $f\colon I\subseteq\mathbb{R}\to\mathbb{R}$ be a function, then for any interval $[a,b]\subseteq I$ such that $f$ is continuous on $[a,b]$ and $f(a)\neq f(b)$,
\[k\in (f(a),f(b)) \implies \qty(\exists c\in (a,b) \text{\ s.t.\ }f(c)=k).\]
\sssc{Intermediate value theorem of functions between topological spaces}
Let $X$ and $Y$ be topological spaces and function $f\colon I\subseteq X\to Y$ be continuous on a subset $J$ of $I$, then for any connected subset $K$ of $J$, $f(K)$ is a connected subset of $Y$.

Let $X$ and $Y$ be topological spaces and function $f\colon I\subseteq X\to Y$ be continuous on a subset $J$ of $I$, then for any path-connected subset $K$ of $J$, $f(K)$ is a path-connected subset of $Y$.
\ssc{Piecewise continuity}
\sssc{Piecewise continuity of real functions}
Let $f\colon D\subseteq\mathbb{R}\to\mathbb{R}$ be a function. If there exists a family $\{[a_i,b_i]\mid i\in I\}$ of closed intervals such that:
\begin{itemize}
\item for every closed interval $V$, the set $\{i\in I\mid V\cap [a_i,b_i]\neq\varnothing\}$ is finite (some sources require instead that $n(I)$ is finite, which is stronger),
\item $D=\bigcup_{i\in I}[a_i,b_i]$,
\item function $f\big\vert_{a_i}^{b_i}\colon(a_i,b_i)\to Y$ is continuous for every $i\in I$, and
\item there exist finite $\lim_{x\to a_i^{\phantom{i}+}}f(x)$ and $\lim_{x\to b_i^{\phantom{i}-}}f(x)$ for every $i\in I$.
\end{itemize},
we say $f$ is piecewise continuous (on $\bigcup_{i\in I}[a_i,b_i]$).
\sssc{Piecewise continuity of functions between topological spaces}
Let $X$ and $Y$ be topological spaces, and $f\colon D\subseteq X\to Y$ be a function. If there exists a locally finite (some sources require instead finite, which is stronger) family $\{U_i\mid i\in I\}$ of closed subsets of $X$ such that:
\begin{itemize}
\item $D=\bigcup_{i\in I}U_i$, and
\item there exists a function $g_i\colon U_i\to Y$ that is continuous on $U_i$ such that $\forall x\in\operatorname{int}\left(U_i\right)f(x)=g_i(x)$ for every $i\in I$.
\end{itemize},
we say $f$ is piecewise continuous (on $\bigcup_{i\in I}U_i$).
\ssc{Uniform continuity (一致連續)}
\sssc{Uniform continuity of functions between metric spaces}
Let $(X,d_1)$ and $(Y,d_2)$ be metric spaces, and $f\colon D\subseteq X\to Y$ be a function. $f$ is called to be uniformly continuous if for every real number $\varepsilon >0$ there exists a real number $\delta >0$ such that $x,y\in D$ with $d_{1}(x,y)<\delta$ implies $d_{2}(f(x),f(y))<\varepsilon$.

Let $(X,d_1)$ and $(Y,d_2)$ be metric spaces, and $f\colon O\subseteq X\to Y$ be a function. $f$ is called to be uniformly continuous on $D\subseteq O$ if for every real number $\varepsilon >0$ there exists a real number $\delta >0$ such that $x,y\in D$ with $d_{1}(x,y)<\delta$ implies $d_{2}(f(x),f(y))<\varepsilon$.
\sssc{Uniform continuity of functions between topological vector spaces}
Let $X$ and $Y$ be topological vector spaces, and $f\colon D\subseteq X\to Y$ be a function. $f$ is called to be uniformly continuous if for every neighborhood $V$ of the zero vector in $Y$, there exists a neighborhood $U$ of the zero vector in $X$ such that $x,y\in D$ with $x-y\in U$ implies $f(x)-f(y)\in V$.

Let $X$ and $Y$ be topological vector spaces, and $f\colon O\subseteq X\to Y$ be a function. $f$ is called to be uniformly continuous on $D\subseteq O$ if for every neighborhood $V$ of the zero vector in $Y$, there exists a neighborhood $U$ of the zero vector in $X$ such that $x,y\in D$ with $x-y\in U$ implies $f(x)-f(y)\in V$.
\ssc{Absolute continuity (絕對連續) of functions from an interval to a metric space}
Let $(X, d)$ be a metric space and $I\subseteq\mathbb{R}$ be an interval. A function $f\colon I \to X$ is absolutely continuous on $I$ if for every positive number $\varepsilon$, there exists a positive number $\delta$ such that for any finite sequence of disjoint subintervals $[x_k, y_k]$ of $I$,
\[\sum _{k}\left|y_{k}-x_{k}\right|<\delta\]
implies
\[\sum _{k}d\left(f(y_{k}),f(x_{k})\right)<\varepsilon.\]
The collection of all absolutely continuous functions from $I$ into $X$ is denoted $AC(I; X)$.

Let $(X, d)$ be a metric space and $I\subseteq\mathbb{R}$ be an interval. A function $f\colon I \to X$ is absolutely continuous on $J\subseteq I$ if for every positive number $\varepsilon$, there exists a positive number $\delta$ such that for any finite sequence of disjoint subintervals $[x_k, y_k]$ of $J$,
\[\sum _{k}\left|y_{k}-x_{k}\right|<\delta\]
implies
\[\sum _{k}d\left(f(y_{k}),f(x_{k})\right)<\varepsilon.\]
\ssc{Lipschitz continuity (利普希茨連續)}
\sssc{(Golbal/regular) Lipschitz continuity of functions between metric spaces}
Let $(X,d_1)$ and $(Y,d_2)$ be metric spaces, and $f\colon D\subseteq X\to Y$ be a function. $f$ is called to be Lipschitz continuous if there exists a real constant $K$ such that $\forall x,y\in D$, $d_{2}(f(x),f(y))\leq Kd_{1}(x,y)$.

Let $(X,d_1)$ and $(Y,d_2)$ be metric spaces, and $f\colon O\subseteq X\to Y$ be a function. $f$ is called to be Lipschitz continuous on $D\subseteq O$ if there exists a real constant $K$ such that $\forall x,y\in D$, $d_{2}(f(x),f(y))\leq Kd_{1}(x,y)$.

If a function $f\colon D\subseteq X\to Y$ between metric spaces $(X,d_1)$ and $(Y,d_2)$ is such that there exists a real constant $K$ such that $\forall x,y\in D$, $d_{2}(f(x),f(y))\leq Kd_{1}(x,y)$, then, any such $K$ is sometimes called a Lipschitz constant (利普希茨常數) of the function $f$, $f$ is sometimes called to be $K$-Lipschitz, and the smallest such $K$ is sometimes called the best Lipschitz constant, Lipschitz constant, or the dilation of $f$.
\sssc{Short map}
A short map is a function between metric spaces that is $1$-Lipschitz.
\sssc{Contraction mapping, contraction map, contraction, contractive mapping, contractive map, or contractor (壓縮映射)}
A contraction mapping is a function $f$ from a metric space to itself such that there exists a real number $0\leq K<1$ such that $f$ is $K$-Lipschitz.
\sssc{Banach fixed-point theorem (巴拿赫不動點定理), contraction mapping theorem (壓縮映射定理), or Banach–Caccioppoli theorem}
For any contraction mapping $T$ over a non-empty complete metric space $X$, there must exist a unique fixed-point $x^*$ of $T$ in $X$. 

Furthermore, for any $x\in X$, for any sequence $\langle x_n\rangle_{n\in \mathbb {N}_0}$ defined as
\[\begin{cases}
&x_0=x\\
&x_n=T\qty(x_{n-1}),n\in\mathbb{N}
\end{cases},\]
\[\lim_{n\to \infty }x_{n}=x^{*}.\]
\ssc{Locally Lipschitz of functions between metric spaces}
Let $(X,d_1)$ and $(Y,d_2)$ be metric spaces, and $f\colon D\subseteq X\to Y$ be a function. $f$ is called to be locally Lipschitz if $\forall x\in D$, there exists a real constant $K$ and an open set $V\subseteq D$ with $x\in V$ such that $d_{2}(f(y),f(z))\leq Kd_{1}(y,z)$ for all $y,z\in V$.
\ssc{Relationships between different continuities}
Let $(X,d_1)$ and $(Y,d_2)$ be metric spaces, and $f\colon O\subseteq X\to Y$ be a function. $f$ is absolutely continuous and locally Lipschitz if it is Lipschitz continuous; $f$ is absolutely continuous on $D\subseteq O$ if it is Lipschitz continuous on $D\subseteq O$; $f$ is uniformly continuous if it is absolutely continuous; $f$ is uniformly  on $D\subseteq O$ if it is absolutely continuous on $D\subseteq O$.

Let $X$ and $Y$ be topological vector spaces, and $f\colon O\subseteq X\to Y$ be a function. $f$ is continuous if it is uniformly continuous; $f$ is continuous on $D\subseteq O$ if it is uniformly continuous on $D\subseteq O$.



\section{Derivative (導數)}
\ssc{Notation}
\sssc{Leibniz's notation (萊布尼茲符號) for derivative}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable $x$, that is,
\[y=f(x).\]
Then, the derivative of the function $f$ can be written as
\[\frac{\mathrm{d}y}{\mathrm{d}x},\quad\frac{\mathrm{d}}{\mathrm{d}x}y,\quad\frac{\mathrm{d}\qty(f(x))}{\mathrm{d}x},\quad\text{or\ }\frac{\mathrm{d}}{\mathrm{d}x}\qty(f(x)),\]
in which $\frac{\mathrm{d}}{\mathrm{d}x}$ is called a differential operator (微分運算子) or a derivative operator (導數運算子);

the $n$th derivative of the function $f$ can be written as
\[\frac{\mathrm{d}^ny}{\mathrm{d}x^n},\quad\frac{\mathrm{d}^n}{\mathrm{d}x^n}y,\quad\frac{\mathrm{d}^n\qty(f(x))}{\mathrm{d}x^n},\quad\tx{or\ }\frac{\mathrm{d}^n}{\mathrm{d}x^n}\qty(f(x)),\]
in which $\frac{\mathrm{d}^n}{\mathrm{d}x^n}$ is called a differential operator or a derivative operator.
\sssc{Leibniz's notation for partial derivative}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable vector $\mb{x}=(x_1,x_2,\dots x_n)$, that is,
\[y=f(\mb{x}).\]
Then, the partial derivative of the function $f$ with respect to $x_i$ can be written as
\[\frac{\partial y}{\partial x_i},\quad\frac{\partial }{\partial x_i}y,\quad\frac{\partial \qty(f(x))}{\partial x_i},\quad\text{or\ }\frac{\partial }{\partial x_i}\qty(f(x)),\]
in which $\frac{\partial}{\partial x_i}$ is called a partial differential operator (偏微分運算子) or a partial derivative operator (偏導數運算子);

the $n$th partial derivative of the function $f$ with respect to $x_i$ can be written as
\[\frac{\partial^ny}{\partial x_i^{\phantom{i}n}},\quad\frac{\partial^n}{\partial x_i^{\phantom{i}n}}y,\quad\frac{\partial^n\qty(f(x))}{\partial x_i^{\phantom{i}n}}\text{or\ }\frac{\partial^n}{\partial x_i^{\phantom{i}n}}\qty(f(x)),\]
in which $\frac{\partial^n}{\partial x_i^{\phantom{i}n}}$ is called a partial differential operator or a partial derivative operator;

the $n$th mixed partial derivative of the function $f$ $m_{i_1}$ times with respect to $x_{i_1}$, $m_{i_1}$ times with respect to $x_{i_2}$, $\dots $, $m_{i_k}$ times with respect to $x_{i_k}$, in which $\sum_{j=1}^km_{i_j}=n$, can be written as
\[\frac{\partial^ny}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}},\]
\[\frac{\partial^n}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}}y,\]
\[\frac{\partial^nf\qty(\mb{x})}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}},\quad \tx{or}\]
\[\frac{\partial^n}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}}f(\mb{x}),\]
in which $\frac{\partial^n}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}}$ is called a partial differential operator or a partial derivative operator.
\sssc{Lagrange's notation (拉格朗日符號) or Prime notation for derivative}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable $x$, that is,
\[y=f(x).\]
Then, the derivative of the function $f$ can be written as
\[y',\quad\tx{or\ }f'(x);\]
the $n$th derivative of the function $f$ can also be written as
\[y^{(n)},\quad\tx{or\ }f^{(n)}(x),\]
in which $^{(n)}$ can be replaced with $n$ primes ($'$) for usually $n<4$ (For example, $y''$ is equivalent to $y^{(2)}$, and $f''$ is equivalent to $f^{(2)}$.).
\sssc{Newton's notation (牛頓符號), dot notation, flyspeck notation, or fluxions for derivative}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable $t$, that is,
\[y=f(t),\]
where $t$ usually represents time.

Then, the derivative of the function $f$ can be written as
\[\dot{y},\]
the second derivative of the function $f$ can be written as
\[\ddot{y},\]
and so on.
\sssc{Subscript notation for partial derivative}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable vector $\mb{x}=(x_1,x_2,\dots x_n)$, that is,
\[y=f(\mb{x}).\]
Then, the partial derivative of the function $f$ with respect to $x_i$ can be written as
\[y_{x_i},\quad y'_{x_i},\quad f_{x_i},\quad \tx{or\ }f'_{x_i};\]
the $n$th partial derivative of the function $f$ with respect to $x_i$ can be written as below, in which subscript are $n$ $x_i$s
\[y_{x_ix_i\dots  x_i},\quad y^{(n)}_{\pht{(n)}x_ix_i\dots  x_i},\quad f_{x_ix_i\dots  x_i},\tx{or\ }\quad f^{(n)}_{\pht{(n)}x_ix_i\dots  x_i},\]
in which $^{(n)}$ can be replaced with $n$ primes ($'$) for usually $n<4$ (For example, $y''$ is equivalent to $y^{(2)}$, and $f''$ is equivalent to $f^{(2)}$.);

the $n$th mixed partial derivative of the function $f$ $m_{i_1}$ times with respect to $x_{i_1}$, $m_{i_1}$ times with respect to $x_{i_2}$, $\dots $, $m_{i_k}$ times with respect to $x_{i_k}$, in which $\sum_{j=1}^km_{i_j}=n$, can be written as below, in which subscript are $m_{i_j}$ $x_{i_j}$s for all $x_{i_j}$
\[y_{x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}},\quad y^{(n)}_{\pht{(n)}x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}},\]
\[f_{x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}},\quad \tx{or\ }f^{(n)}_{\pht{(n)}x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}.\]
\sssc{Euler's notation (歐拉符號) for derivative}
Given a function $f$ of an independent variable $x$, that is,
\[f(x).\]
Then, the derivative of the function $f$ can be written as
\[Df(x)\quad\tx{or\ }(Df)(x)\]
in which $Df$ is called a differential operator or a derivative operator;

the $n$th derivative of the function $f$ can be written as
\[D^nf(x)\quad\tx{or\ }(D^nf)(x)\]
in which $D^nf$ is called a differential operator or a derivative operator.
\sssc{Euler's notation for partial derivative}
Given a function $f$ of an independent variable vector $\mb{x}=(x_1,x_2,\dots x_n)$, that is,
\[f(\mb{x}).\]
Then, the partial derivative of the function $f$ with respect to $x_i$ can be written as
\[\partial_{x_i}f,\quad \tx{or\ }D_{x_i}f,\]
in which $\partial_{x_i}$ and $D_{x_i}$ are called partial differential operators or partial derivative operators;

the $n$th partial derivative of the function $f$ with respect to $x_i$ can be written as
\[\partial_{x_ix_i\dots  x_i}f,\quad\partial^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}f,\quad D_{x_ix_i\dots  x_i}f,\quad\tx{or\ }D^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}f,\]
in which subscript are $n$ $x_i$s, $^{(n)}$ can be replaced with $n$ primes ($'$) for usually $n<4$ (For example, $\partial''$ is equivalent to $\partial^{(2)}$, and $D''$ is equivalent to $D^{(2)}$.), and $\partial_{x_ix_i\dots  x_i}$, $\partial^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}$, $D_{x_ix_i\dots  x_i}$, and $D^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}$ are called partial differential operators or partial derivative operators;

the $n$th mixed partial derivative of the function $f$ $m_{i_1}$ times with respect to $x_{i_1}$, $m_{i_1}$ times with respect to $x_{i_2}$, $\dots $, $m_{i_k}$ times with respect to $x_{i_k}$, in which $\sum_{j=1}^km_{i_j}=n$, can be written as
\[\partial_{x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}f,\quad\partial^{(n)}_{\pht{(n)}x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}f,\]
\[ D_{x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}f,\quad \tx{or\ }D^{(n)}_{\pht{(n)}x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}f,\]
in which subscript are $m_{i_j}$ $x_{i_j}$s for all $x_{i_j}$, $^{(n)}$ can be replaced with $n$ primes ($'$) for usually $n<4$ (For example, $\partial''$ is equivalent to $\partial^{(2)}$, and $D''$ is equivalent to $D^{(2)}$.), and $\partial_{x_ix_i\dots  x_i}$, $\partial^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}$, $D_{x_ix_i\dots  x_i}$, and $D^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}$ are called partial differential operators or partial derivative operators.
\ssc{Ordinary Derivatives of Functions with Real Domain}
Let $W$ be a topological vector space. The ordinary derivative (常導數) or derivative (導數) $f'(x)$ of a function $f\colon U\subeteq\mathbb{R}\to W$ at $x\in U$ is defined as
\[f'(x)=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}\]
if the limit exists. If such limit exists, we say $f$ is differentiable (可微的) at $x$.

We define the (first(-order)) ordinary derivative function (常導函數) or derivative function (導函數) of $f$ as a function $f'$ with codomain $W$ such that for any $x\in U$ at which $f$ is differentiable, $f'$ maps $x$ to the derivative of $f$ at $x$.

The derivative of the $k$th(-order) ($k\in\mathbb{N}$) derivative function of $f$ at $x\in U$ is called the $(k+1)$th(-order) derivative of $f$ at $x\in U$. The derivative function of the $k$th(-order) ($k\in\mathbb{N}$) derivative function of $f$ is called the $k+1$th(-order) derivative function of $f$.

If for any $n\in\mathbb{N}$, the $n$th(-order) derivative of a function $f$ at a point $x$ in its domain exists, we say $f$ is infinitely differentiable at $x$.

If $f$ is differentiable at all point in $I\subeteq U$, we say $f$ is differentiable on $I$; if $f$ is differentiable on $U$, we say $f$ is differentiable. If $f^{(n-1)}$ exists and is differentiable at all point in $I\subeteq U$, we say $f$ is $n$-times differentiable on $I$; if $f^{(n-1)}$ exists and is differentiable on $U$, we say $f$ is $n$-times differentiable.

The operation of finding the derivative or derivative function is called ordinary differentiation (常微分) or differentiation (微分).

Specifically, the $0$th(-order) derivative of $f$ is $f$ itself.

The derivative of a $f$ at $x$ represents the slope (斜率) at $x$ or the lineal element at $x$ (a miniature tangent line at $x$).
\ssc{One-sided Derivative of Functions with Real Domain}
Let $W$ be a topological vector space and $f\colon U\subeteq\mathbb{R}\to W$ be a function.

The left-hand derivative of $f$ at $x\in U$, denoted as $f'_-(x)$, is defined as
\[f'_-(x)=\lim_{h\to 0^-}\frac{f(x+h)-f(x)}{h}\]
if the limit exists.

The right-hand derivative of $f$ at $x\in U$, denoted as $f'_+(x)$, is defined as
\[f'_+(x)=\lim_{h\to 0^+}\frac{f(x+h)-f(x)}{h}\]
if the limit exists.
\ssc{Partial derivatives of Functions with Real Vector Domain}
Let $W$ be a topological vector space and $f\colon U\subeteq\mathbb{R}^n\to W$ be a function, $\mb{x}$ be the independent variable vector of $f$, and $X$ be the set of all independent variables of $f$.

The (first(-order)) partial derivative (偏導數) $\pdv{f}{x_i}$ of $f$ with respect to $x_i\in X$ at $u\in U$ is defined as
\bma
\pdv{f}{x_i}&=\lim_{h\to 0}\frac{f(u+h\mb{e}_i)-f(u)}{h}\]
&=\frac{\mathrm{d}}{\mathrm{d}h}f(u+h\mb{e}_i)\big\vert_{h=0}
\end{aligned},\]
in which $\mb{e}_i\in\mathbb{R}^n$ is the unit vector in the direction of $x_i$.

The partial derivative of the $k$th(-order) ($k\in\mathbb{N}$) partial derivative function of $f$ with respect to $ x \in X$ with respect to $ x \in X$ at $u\in U$ is called the $k+1$th(-order) partial derivative of $f$ with respect to $ x$ at $u\in U$. The partial derivative function of the $k$th(-order) ($k\in\mathbb{N}$) partial derivative function of $f$ with respect to $ x \in X$ with respect to $ x \in X$ is called the $k+1$th(-order) partial derivative function of $f$ with respect to $ x$.

The partial derivative of the $k$th(-order) partial derivative function of $f$ with respect to $ x_1\in X$ with respect to $ x_2\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative of $f$ with respect to $ x_1, x_1,\dots  x_1$ ($k$ times) and $ x_2$ at $u\in U$. The partial derivative function of the $k$th(-order) partial derivative function of $f$ with respect to $ x_1\in X$ with respect to $ x_2\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_1,\dots  x_1$ ($k$ times) and $ x_2$.

The partial derivative of the $k$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k\in X$ with respect to $ x_{k+1}\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative of $f$ with respect to $ x_1, x_2,\dots  x_k, x_{k+1}$ at $u\in U$. The partial derivative function of the $k$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k\in X$ with respect to $ x_{k+1}\in X$ is called the $(k+1)$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k, x_{k+1}$.

The operation of finding the partial derivative or partial derivative function is called partial differentiation (偏微分).

Specifically, the $0$th(-order) partial derivative of $f$ is $f$ itself.
\ssc{Fréchet derivative (弗蘭歇導數)}
\sssc{Fréchet derivative}
Let $V$ and $W$ be normed vector spaces and $U$ be an open subset of $V$. A function $f\colon U\to W$ is Fréchet differentiable (弗蘭歇可微的) or differentiable at $x\in U$ if there exists a bounded linear operator $A\colon V\to W$ such that
\[\lim_{\|h\|_V\to 0}\frac{\|f(x+h)-f(x)-A(h)\|_W}{\|h\|_V}=0.\]
If there exists such an operator $A$, it is unique, so we define the (first(-order)) Fréchet derivative, ordinary derivative, or derivative of $f$ at $x$, denoted as $Df(x)$, as $A$.

We define the (first(-order)) Fréchet derivative function (弗蘭歇導函數), ordinary derivative function, or derivative function of $f$ as a function $Df$ with codomain $B(V,W)$, in which $B(V,W)$ is the space of all bounded linear operators from $V$ to $W$, such that for any $x\in U$ at which $f$ is Fréchet differentiable, $Df$ maps $x$ to the Fréchet derivative of $f$ at $x$.

The Fréchet derivative of the $k$th(-order) ($k\in\mathbb{N}$) Fréchet derivative function of $f$ at $x\in U$ is called the $k+1$th(-order) Fréchet derivative of $f$ at $x\in U$, denoted as $(D^{k+1}f)(x)$. The Fréchet derivative function of the $k$th(-order) ($k\in\mathbb{N}$) Fréchet derivative function of $f$ is called the $k+1$th(-order) Fréchet derivative function of $f$, denoted as $D^{k+1}f$.

If $f$ is Fréchet differentiable at all point in $I\subeteq U$, we say $f$ is Fréchet differentiable on $I$; if $f$ is Fréchet differentiable on $U$, we say $f$ is Fréchet differentiable. If $D^{(n-1)}f$ exists and is Fréchet differentiable at all point in $I\subeteq U$, we say $f$ is $n$-times Fréchet differentiable on $I$; if $D^{(n-1)}f$ exists and is Fréchet differentiable on $U$, we say $f$ is $n$-times Fréchet differentiable.

The operation of finding the Fréchet derivative or Fréchet derivative function is called Fréchet differentiation (弗蘭歇微分), ordinary differentiation, or differentiation.

Specifically, the $0$th(-order) Fréchet derivative of $f$ is $f$ itself.
\ssc{Smoothness (光滑性 or 平滑性)}
\sssc{Smoothness}
A function with real domain $f$ that has a $k$th derivative that is continuous on its domain is said to be of class $C^k$, denoted as $f\in C^k$, or be a $C^k$-function.

A function $f$ that has a $k$th derivative that is continuous on a subset $I$ of its domain is said to be of class $C^k$ on $I$ or of class $C^k(I)$, denoted as $f\in C^k(I)$.

Generally, the term smooth function refers to a $C^{\infty}$-function. However, it may also mean "sufficiently differentiable" for the problem under consideration.
\sssc{Piecewise smoothness of real functions}
Let $f\colon D\subseteq\mathbb{R}\to\mathbb{R}$ be a function. If there exists a family $\{[a_i,b_i]\mid i\in I\}$ of closed intervals such that:
\begin{itemize}
\item for every closed interval $V$, the set $\{i\in I\mid V\cap [a_i,b_i]\neq\varnothing\}$ is finite (some sources require instead that $n(I)$ is finite, which is stronger),
\item $D\subseteq\bigcup_{i\in I}[a_i,b_i]$,
\item function $f\big\vert_{a_i}^{b_i}\colon(a_i,b_i)\to Y$ is of class $C^k((a_i,b_i))$ for every $i\in I$, and
\item there exist finite $\lim_{x\to a_i^{\phantom{i}+}}f(x)$ and $\lim_{x\to b_i^{\phantom{i}-}}f(x)$ for every $i\in I$.
\end{itemize},
we say $f$ is of class piecewise $C^k$ (or of class piecewise $C^k\qty(\bigcup_{i\in I}[a_i,b_i])$); when $k=\infty$ or sufficiently large, we say $f$ is piecewise smooth (on $\bigcup_{i\in I}U_i$).
\sssc{Piecewise smoothness of functions between topological spaces}
Let $X$ and $Y$ be topological spaces, and $f\colon D\subseteq X\to Y$ be a function. If there exists a locally finite (some sources require instead finite, which is stronger) family $\{U_i\mid i\in I\}$ of closed subsets of $X$ such that:
\begin{itemize}
\item $D\subseteq\bigcup_{i\in I}U_i$, and
\item there exists a function $g_i\colon U_i\to Y$ that is of class $C^k\qty(U_i)$ such that $\forall x\in\operatorname{int}\left(U_i\right)f(x)=g_i(x)$ for every $i\in I$.
\end{itemize},
we say $f$ is of class piecewise $C^k$ (or of class piecewise $C^k\qty(\bigcup_{i\in I}U_i)$); when $k=\infty$ or sufficiently large, we say $f$ is piecewise smooth (on $\bigcup_{i\in I}U_i$).
\ssc{Gateaux Differentiation (加托微分)}
\sssc{Gateaux derivative (加托導數) and partial derivatives}
Let $V$ be a locally convex topological vector spaces (LCTVS), $W$ be a topological vector space, $U$ be an open subset of $V$, and $f\colon U\to W$ be a function.

The (first(-order)) Gateaux derivative $df(u;\,\psi)$ of $f$ at $u\in U$ in the direction $\psi \in V$ is defined to be
\[\begin{aligned}
df(u;\,\psi) &= \lim_{\tau\to 0}\frac{f(u+\tau \psi)-f(u)}{\tau}\\
&= \frac{\mathrm{d}}{\mathrm{d}\tau}f(u+\tau \psi)\big\vert_{\tau =0}
\end{aligned}\]
if the limit exists. If for any $\psi \in V$, the Gateaux derivative exists, then it is said that $f$ is Gateaux differentiable (加托可微的) at $u$.

We define the (first(-order)) Gateaux derivative function (加托導函數) of $f$ in the direction $\psi \in V$, denoted as $df$, as a function $df\colon U\to W$, such that for any $u\in U$ at which $f$ is Gateaux differentiable, $df$ maps $u$ to the Gateaux derivative of $f$ at $u$ in the direction $\psi \in V$.

The Gateaux derivative of the $k$th(-order) ($k\in\mathbb{N}$) Gateaux derivative function of $f$ in the direction $\psi \in V$ in the direction $\psi \in V$ at $u\in U$ is called the $k+1$th(-order) Gateaux derivative of $f$ in the direction $\psi$ at $u\in U$. The Gateaux derivative function of the $k$th(-order) ($k\in\mathbb{N}$) Gateaux derivative function of $f$ in the direction $\psi \in V$ in the direction $\psi \in V$ is called the $k+1$th(-order) Gateaux derivative function of $f$ in the direction $\psi$.

The Gateaux derivative of the $k$th(-order) Gateaux derivative function of $f$ in the direction $\psi_1\in V$ in the direction $\psi_2\in V$ at $u\in U$ is called the $(k+1)$th(-order) mixed Gateaux derivative of $f$ in the direction $\psi_1,\psi_1,\dots \psi_1$ ($k$ times) and $\psi_2$ at $u\in U$. The Gateaux derivative function of the $k$th(-order) Gateaux derivative function of $f$ in the direction $\psi_1\in V$ in the direction $\psi_2\in V$ is called the $(k+1)$th(-order) mixed Gateaux derivative function of $f$ in the direction $\psi_1,\psi_1,\dots \psi_1$ ($k$ times) and $\psi_2$.

The Gateaux derivative of the $k$th(-order) mixed Gateaux derivative function of $f$ in the direction $\psi_1,\psi_2,\dots \psi_k\in V$ in the direction $\psi_{k+1}\in V$ at $u\in U$ is called the $(k+1)$th(-order) mixed Gateaux derivative of $f$ in the direction $\psi_1,\psi_2,\dots \psi_k,\psi_{k+1}$ at $u\in U$. The Gateaux derivative function of the $k$th(-order) mixed Gateaux derivative function of $f$ in the direction $\psi_1,\psi_2,\dots \psi_k\in V$ in the direction $\psi_{k+1}\in V$ is called the $(k+1)$th(-order) mixed Gateaux derivative function of $f$ in the direction $\psi_1,\psi_2,\dots \psi_k,\psi_{k+1}$.

The operation of finding the Gateaux derivative or Gateaux derivative function is called Gateaux differentiation (加托微分).

Specifically, the $0$th(-order) Gateaux derivative of $f$ is $f$ itself.
\sssc{Partial derivative}
Let $V$ be a locally convex topological vector spaces (LCTVS), $W$ be a topological vector space, $U$ be an open subset of $V$, and $f\colon U\to W$ be a function, $\mb{x}$ be the independent variable vector of $f$, and $X$ be the set of all independent variables of $f$.

The (first(-order)) partial derivative of $f$ with respect to $x_i\in X$ at $u\in U$ is defined as the Gateaux derivative of $f$ in the direction of $x_i$ at $u$ if it exists.

The partial derivative of the $k$th(-order) ($k\in\mathbb{N}$) partial derivative function of $f$ with respect to $ x \in X$ with respect to $ x \in X$ at $u\in U$ is called the $k+1$th(-order) partial derivative of $f$ with respect to $ x$ at $u\in U$. The partial derivative function of the $k$th(-order) ($k\in\mathbb{N}$) partial derivative function of $f$ with respect to $ x \in X$ with respect to $ x \in X$ is called the $k+1$th(-order) partial derivative function of $f$ with respect to $ x$.

The partial derivative of the $k$th(-order) partial derivative function of $f$ with respect to $ x_1\in X$ with respect to $ x_2\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative of $f$ with respect to $ x_1, x_1,\dots  x_1$ ($k$ times) and $ x_2$ at $u\in U$. The partial derivative function of the $k$th(-order) partial derivative function of $f$ with respect to $ x_1\in X$ with respect to $ x_2\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_1,\dots  x_1$ ($k$ times) and $ x_2$.

The partial derivative of the $k$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k\in X$ with respect to $ x_{k+1}\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative of $f$ with respect to $ x_1, x_2,\dots  x_k, x_{k+1}$ at $u\in U$. The partial derivative function of the $k$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k\in X$ with respect to $ x_{k+1}\in X$ is called the $(k+1)$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k, x_{k+1}$.

The operation of finding the partial derivative or partial derivative function is called partial differentiation.

Specifically, the $0$th(-order) partial derivative of $f$ is $f$ itself.
\ssc{Differentiability and continuity}
For a point $a$ in the domain of $f$, $f$ is differentiable at $a$ if it is continuous at $a$.
\ssc{Antiderivative (反導函數), inverse derivative, primitive function, primitive integral, or indefinite integral (不定積分)}
An antiderivative of a continuous function $f$ is a differentiable function $F$ whose derivative is equal to the original function $f$, that is,
\[F'=f.\]
Suppose $f$ is a function of an independent variable $x$, then its antiderivative $F$ is denoted as
\[F=\int f\,\mathrm{d}x.\]
The process of solving for antiderivatives is called antidifferentiation (反微分) or indefinite integration (不定積分).
\subsection{Taylor series (泰勒級數) or Taylor expansion (泰勒展開)}
Assume that $F:\,\mathbb{R}\to\mathbb{R}$ is an infinitely differentiable function, and its derivatives of every order exist on $\mathbb{R}$, then the Taylor series of $F$ at $a$ is
\[F(x) = \sum_{n\in\mathbb{N}_0} \frac{F^{(n)}(a)}{n!}(x-a)^n,\]
that is,
\[F(x) = \sum^k_{n=0} \frac{F^{(n)}(a)}{n!}(x-a)^n+\int_0^1\frac{(1-t)^k}{k!}F^{(k+1)}(a+t(x-a))(x-a)^{k+1}\,\mathrm{d}t.\]
Also, the $k$th-order approximation of $f$ near $a$ is
\[F(x) \approx \sum^k_{n=0} \frac{F^{(n)}(a)}{n!}(x-a)^n,\]
and the first-order approximation near $a$ is
\[F(x) \approx F(0)+F'(a)(x-a).\]
The Taylor series of $F$ at $0$ is called Maclaurin series (馬克勞林級數) or Maclaurin expansion (馬克勞林展開).
\ssc{Real analyticity (實解析性) of real-codomain functions}
A real-codomain function $f$ is real analytic at a point $x_0$ in its domain, if it is infinitely differentiable at $x_0$ and that the Taylor expansion of $f$ at $x_0$ converges to $f(x)$ pointwise for any $x$ in a neighborhood of $x_0$.

A real-codomain function is called to be real analytic on an interval $I$ that is a subset of its domain if it is real analytic at any point in $I$.

A real-codomain function is called to be real analytic if it is real analytic at any point in its domain.
\ssc{Points in graph}
\sssc{Critical point (臨界點), equilibrium, equilibrium point (平衡點), or stationary point (駐點)}
Let $f$ be a function where the codomain of it has a zero element and \( c \) be a point in the domain of $f$ , if \( f'(c) = 0 \) or \( f' \) does not exist at \( c \), then \( c \) is a critical point, equilibrium, equilibrium point, or stationary point of \( f \).
\sssc{Relative extremum (相對極值), local extremum (局部極值), or extremum (極值)}
Let $f\colon D\subseteq X\to Y$ be a function with $X$ being a topological space and $Y$ being a preordered set. It is said that a relative maximum (相對極大值) or maximum (極大值) \( f(c) \) of \(f\) occurs at $c\in D$ if there exists an open subset $I\ni c$ of $X$ such that \( \forall x\in I\cap D\colon f(c) \geq f(x) \).

Let $f\colon D\subseteq X\to Y$ be a function with $X$ being a topological space and $Y$ being a preordered set. It is said that a relative minimum (相對極小值) or minimum (極小值) \( f(c) \) of \(f\) occurs at $c\in D$ if there exists an open subset $I\ni c$ of $X$ such that \( \forall x\in I\cap D\colon f(c) \leq f(x) \).

The relative maximum and relative minimum are collectively called the relative extreme.
\subsection{Absolute extremum (絕對極值 or 最值) or global extremum (全域極值)}
Let $f\colon D\to Y$ be a function with $Y$ be a preordered set. It is said that a absolute maximum (絕對極大值 or 最大值) \( f(c) \) of \(f\) occurs at $c\in D$ if \( \forall x\in D\colon f(c) \geq f(x) \).

Let $f\colon D\to Y$ be a function with $Y$ be a preordered set. It is said that a absolute minimum (絕對極小值 or 最小值) \( f(c) \) of \(f\) occurs at $c\in D$ if \( \forall x\in D\colon f(c) \leq f(x) \).

The absolute maximum and absolute minimum are collectively called the absolute extreme.
\sssc{Saddle point (鞍點)}
Let $f$ be a function where the codomain of it is a preordered set with a zero element and \( c \) be a point in the domain of $f$ , if \( f'(c) = 0 \) and $c$ is not a local extremum of $f$, then $c$ is a saddle point of $f$.
\sssc{Concavity (凹性)}
Let $f\colon J\subseteq X\to Y$ with $X,Y$ being posets be differentiable on the open interval $I\subseteq J$. If $f'$ is strictly increasing on $I$, the graph of $f$ is said to concave upward on $I$; if $f'$ is strictly decreasing on $I$, the graph of $f$ is said to concave downward on $I$; if $f'$ is a constant on $I$, the graph of $f$ is said to be neither upward nor downward (or both upward and downward or undefined in some contexts) on $I$.
\sssc{Point of inflection or inflection point (反曲點 or 拐點)}
Let $f\colon J\subseteq X\to Y$ with $X,Y$ being posets be a continuous function and be differentiable on an open interval $I\subseteq J$, and let $a<b<c\land a,b,c\in I$. If the graph of $f$ is concave upward on interval $(a,b)$ and concave downward on interval $(b,c)$, or concave downward on interval $(a,b)$ and concave upward on interval $(b,c)$, then $(b,f(b))$ is called an inflection point of the graph of $f$.
\sssc{Corner or sharp corner}
A corner or sharp corner is a point $x$ on the graph of a real function $f$ such that $f$ is continuous but not differentiable at $x$ and that the left-hand derivative and the right-hand derivative of $f$ at $x$ both exist and are finite.
\sssc{Vertical tangent}
A vertical tangent is a point $x$ on the graph of a real function $f$ such that $f$ is continuous at $x$ and that the left-hand derivative and the right-hand derivative of $f$ at $x$ are both $\infty$ or are both $-\infty$.
\sssc{Cusp}
A cusp is a point $x$ on the graph of a real function $f$ such that:
\bit
\item $f$ is continuous at $x$,
\item at least one of the left-hand derivative and the right-hand derivative of $f$ at $x$ are $\infty$ or $-\infty$,
\item $x$ is not a vertical tangent of $f$, and
\item the left-hand derivative and the right-hand derivative of $f$ at $x$ are both either finite, $\infty$, or $-\infty$.
\eit
\ssc{Differential Equation (微分方程)}
\sssc{Differential Equation}
An equation containing the derivatives of one or more unknown functions or dependent variables, with respect to one or more independent variables, is said to be a differential equation (DE).

Unless otherwise specified, the unknown functions or dependent variables are in $\mathbb{R}^n$ with $n\in\mathbb{N}$, and the independent variables are in $\matbbb{R}$.
\sssc{Ordinary differential equation (ODE) (常微分方程)}
If a differential equation contains only ordinary derivatives of one or more unknown functions with respect to a single independent variable, it is said to be an ordinary differential equation (ODE).
\sssc{Partial differential equation (PDE) (偏微分方程)}
If a DE contains partial derivatives of one or more unknown functions of two or more independent variables is called a partial differential equation (PDE).
\sssc{Order of a DE}
The order of a differential equation is the order of the highest derivative in the equation.



\section{Definte Integration (定積分)}
\ssc{Notation}
The integral of a function $f$, called integrand (被積函數), with respect to $x$, called integration variable (積分變數), from $a$ to $b$, which $(a,b)$ is called the domain of integration (積分域) or interval of integration (積分區間) and $a,b$ are called limits of integration (積分極限 or 積分上下限), is denoted as
\[\int_a^bf\dd{x}.\]
The integral of a function $f$ with respect to $\omega$ over $\Omega$, called the domain of integration and which the limit points of $\Omega$ are called are called limits of integration (積分極限), is denoted as
\[\int_{\Omega}f\dd{\omega}.\]
\subsection{(Proper) Riemann integral (黎曼積分) and Darboux integral (達布積分)}
\sssc{Premise}
(Proper) Riemann integral and Darboux integral are two equivalant definitions of definite integral of functions over compact intervals of $\mathbb{R}$ to $\mathbb{R}$.
\subsubsection{Partition of an interval}
A partition $P(x, n)$ of a compact interval $[a,b]$ is a finite sequence of numbers of the form
\[P(x, n):=\{x_i\colon x_0=a\land x_n=b\land\forall 1\leq i<j\leq n\colon x_i<x_j\}_{i=0}^n.\]

Each $[x_i, x_{i+1}]$ is called a subinterval of the partition. The length of a closed interval $[c,d]$ is defined as $d-c$. The mesh or norm of a partition is defined as
\[\max_i\left(x_{i+1}-x_{i}\right)\]
for every integer $i\in [0,n-1]$.

A tagged partition $P(x,n,\xi)$ of a interval $(a,b)$ is a partition together with a choice of a sample point within each of all $n$ subintervals, that is, numbers $\{\xi_i\}_{i=0}^{n-1}$ with $\xi_i\in [x_i,x_{i+1}]$ for each integer $i\in [0,n-1]$. The mesh of a tagged partition is the same as that of an ordinary partition.

Suppose that two tagged partitions $P(x,n,\xi)$ and $Q(y,m,\zeta)$ are both partitions of the interval $[a,b]$. We say that $Q(y,m,\zeta)$ is a refinement of $P(x,n,\xi)$ if for each integer $i\in [0,n-1]$, there exists an integer $r(i)\in [0,m-1]$ such that $x_i = y_{r(i)}$ and that $\forall i\in [0,n-1]\colon\exists j\in [r(i),r(i + 1)] \text{\ s.t.\ }\xi_i = \zeta_j$. That is, a tagged partition breaks up some of the subintervals and adds sample points where necessary, "refining" the accuracy of the partition.

We can turn the set of all tagged partitions into a directed set by saying that one tagged partition is greater than or equal to another if the former is a refinement of the latter.
\subsubsection{Riemann sum}
Let $f$ be a real-valued function defined on a interval $[a,b]$. The Riemann sum of $f$ with respect to a tagged partition $P(x,n,\xi)$ of $[a,b]$ is defined to be
\[R(f,P):=\sum_{i=0}^{n-1}f(\xi_i)\left(x_{i+1}-x_i\right).\]
Each term in the sum is the product of the value of the function at a given point and the length of an interval. Consequently, each term represents the signed area of a rectangle with height $f(\xi_i)$ and width $x_{i + 1} − x_i$. Thus the Riemann sum is the signed area of all the rectangles.
\subsubsection{Darboux sum}
Let $f$ be a real-valued function defined on a interval $[a,b]$. Lower and upper Darboux sums of $f$ with respect to a partition $P(x,n)$ of $[a,b]$ are two specific Riemann sums of which the tags are chosen to be the infimum and supremum (respectively) of $f$ on each subinterval:
\[\begin{aligned}
L(f,P)&:=\sum_{i=0}^{n-1}\inf_{\xi\in [x_i,x_{i+1}]}f(\xi)(x_{i+1}-x_i),\\
U(f,P)&:=\sum_{i=0}^{n-1}\sup_{\xi\in [x_i,x_{i+1}]}f(\xi)(x_{i+1}-x_i).
\end{aligned}\] 
\subsubsection{Riemann integral}
Let $f$ be a real-valued function defined on a interval $[a,b]$. The Riemann integral of $f$ on $[a,b]$ exists and equals $s$ if for all $\varepsilon > 0$, there exists $\delta > 0$ such that for any tagged partition $P(x,n,\xi)$ whose mesh is less than $\delta$,
\[\abs{R(f,P)-s}<\varepsilon .\]
\subsubsection{Darboux integral}
Let $f$ be a real-valued function defined on a interval $[a,b]$. The Darboux integral of $f$ on $[a,b]$ exists and equals $s$ if for all $\varepsilon > 0$, there exists $\delta > 0$ such that for any partition $P$ whose mesh is less than $\delta$,
\[\abs{U(f,P)-s}<\varepsilon \land \abs{L(f,P)-s}<\varepsilon.\]
\sssc{Lebesgue-Vitali theorem (of characterization of the Riemann integrable functions)}
A function on bounded a compact interval $I$ is Riemann integrable (i.e. Darboux integrable) over $I$ if and only if it is continuous almost everywhere in $I$.
\ssc{Extensions of Riemann integral}
\sssc{Improper (Riemann) integral (瑕（黎曼）積分)}
An integral $\int _{a}^{b}f(x)\dd{x}$ is an improper integral if one or more of the below conditions occur:
\ben
\item $a=-\infty$,
\item $b=\infty$,
\item $f(x)$ is unbounded or undefined somewhere in $[a,b]$.
\een

The improper integrals are defined by limits as:
\bit
\item for $a=-\infty$:
\[\int _{-\infty }^bf(x)\dd{x}=\lim _{a\to -\infty }\int _{a}^{b}f(x)\dd{x},\]
\item for $b=\infty$:
\[\int _{a}^{\infty }f(x)\dd{x}=\lim _{b\to \infty }\int _{a}^{b}f(x)\dd{x},\]
\item for $f(x)$ that is unbounded or undefined at $a$:
\[\int_a^bf(x)\dd{x}=\lim_{c\to a^+}\int_c^bf(x)\dd{x},\]
\item for $f(x)$ that is unbounded or undefined at $b$:
\[\int_a^bf(x)\dd{x}=\lim_{c\to b^-}\int_a^cf(x)\dd{x},\]
\item for $f(x)$ that is unbounded or undefined at $c\in(a,b)$:
\[\int _{a}^{b}f(x)\dd{x}=\lim_{t\to c^-}\int _{a}^{t}f(x)\dd{x}+\lim_{t\to c^+}\int _{t}^{b}f(x)\dd{x},\]
\eit
in which if any of the terms diverge or is undefined, the improper integral diverges and is undefined; otherwise, the improper integral exists finitely and converges to a finite value.

$\lim _{a\to -\infty }\int _{a}^{b}f(x)\dd{x}$ converges absolutely to $L$ if $\exists\lim _{a\to -\infty }\int _{a}^{b}\abs{f(x)}\dd{x}\land\lim _{a\to -\infty }\int _{a}^{b}\abs{f(x)}\dd{x}=L$.

$\lim _{b\to \infty }\int _{a}^{b}f(x)\dd{x}$ converges absolutely to $L$ if $\exists\lim _{b\to \infty }\int _{a}^{b}f(x)\dd{x}\land\lim _{b\to \infty }\int _{a}^{b}f(x)\dd{x}=L$.

If an improper integral is convergent but not convergent absolutely, we say it converges conditionally.
\sssc{Cauchy principal value (柯西主值) or PV integral}
The Cauchy principal value or PV integral, denoted as p.v., is a weaker notion of convergence, defined by taking symmetric limits. 

The p.v. of $\int _{-\infty}^{\infty}f(x)\dd{x}$, denoted as $\text{p.v.\ }\int_{-\infty}^{\infty} f(x)\dd{x}$, is defined with:
\[\text{p.v.\ }\int_{-\infty}^{\infty} f(x)\dd{x}\coloneq\lim_{R\to\infty} \int_{-R}^{R} f(x)\dd{x},\]
if the limit exists.

The p.v. of $\int _{a}^{b}f(x)\dd{x}$, in which $f(x)$ is unbounded or undefined at $c\in (a,b)$, denoted as $\text{p.v.\ }\int_{a}^{b} f(x)\dd{x}$, is defined with:
\[\text{p.v.\ }\int_{a}^{b} f(x)\dd{x}\coloneq\lim_{\epsilon\to 0}\qty(\int_a^{c-\epsilon}f(x)\dd{x}+\int_{c+\epsilon}^bf(x)\dd{x}),\]
if the limit exists.

If an improper integral converges, the p.v. of it converges.
\subsection{Lebesgue integral (勒貝格積分)}
A definition of definite integral.
\sssc{Premise}
Let $(E,\Sigma,\mu)$ be a measure space. Below, we will define the Lebesgue integral of measurable functions on $E$ to $\mathbb{R}\cup\{-\infty,\infty\}$.
\subsubsection{Of an indicator functions}
The integral of an indicator function $1_S$ of a measurable subset $S$ of $E$ is defined to be
\[\int 1_{S}\,\mathrm{d}{\mu} =\mu (S).\]
\sssc{Of a nonnegative simple function}
A simple function $s$ is a finite real linear combinations of indicator functions of disjoint measurable subsets of $E$, that is,
\[s\colon\sum_ka_k1_{S_k},\]
where the coefficients $a_k$ are real numbers and $S_k$ are disjoint measurable sets. When the coefficients $a_k$ are positive real numbers, $s$ is called nonnegative.

The integral of a nonnegative simple function $s=\sum_ka_k1_{S_k}$ over $E$ is defined to be
\[\int_Es\,\mathrm{d}\mu=\sum_ka_k\int 1_{S_k}\,\mathrm{d}\mu=\sum_ka_k\mu(S_k),\]
where this sum can be finite or $\infty$.

The integral of a nonnegative simple function $s=\sum_ka_k1_{S_k}$ over a subset $B$ of $E$ is defined to be:
\[\int_Bs\,\mathrm{d}\mu=\sum_ka_k\mu \qty(S_k\cap B).\]
\subsubsection{Of a nonnegative measurable function}
Let $f$ be a nonnegative function on some measurable subset $B$ of $E$ into $\mathbb{R}\cup\{-\infty,\infty\}$, called a nonnegative measurable function. We define
\[\int_Bf\,\mathrm{d}\mu=\sup\left\{\int_Bs\,\mathrm{d}\mu\mid\forall x\in B\colon 0\leq s(x)\leq f(x)\land s\text{\ is a nonnegative simple function}\right\}.\]
\subsubsection{Of a measurable function}
Let $f$ be a function on some measurable subset $B$ of $E$ into $\mathbb{R}\cup\{-\infty,\infty\}$, called a measurable function. We first define
\[\begin{aligned}
f^{+}(x)&=
\begin{cases}
f(x),\quad&\text{if\ }f(x)>0\\
0,\quad &\text{otherwise}
\end{cases},\quad\tx{and}\\
f^{-}(x)&=
\begin{cases}
-f(x),\quad&\text{if\ }f(x)<0\\
0,\quad&\text{otherwise}
\end{cases}.
\end{aligned}\]
Note that both $f^+$ and $f^-$ are nonnegative and that
\[f=f^+-f^-,\quad |f|=f^++f^-.\]
Then we define the Lebesgue integral of $f$ to exist if
\[ \min \left(\int f^{+}\,\mathrm{d}\mu ,\int f^{-}\,\mathrm{d}\mu \right)<\infty.\]
In this case we define
\[ \int f\,\mathrm{d}\mu =\int f^{+}\,\mathrm{d}\mu -\int f^{-}\,\mathrm{d}\mu.\]
\sssc{Integrability}
Let $f$ be a function on some measurable subset $B$ of $E$ into $\mathbb{R}\cup\{-\infty,\infty\}$.

If
\[\int |f|\,\mathrm {d} \mu <\infty ,\]
we say that $f$ is Lebesgue integrable.
\sssc{$L^p$ spaces ($L^p$ 空間)}{{{

\ssc{Bochner integral (博赫納積分)}
\sssc{Premise}
Let $(E,\Sigma ,\mu )$ be a measure space and $X$ be a Banach space with norm $\|\cdot\|_X$. Below, we will define the Bochner integral of measurable functions on $E$ to $X$.
\subsubsection{Of an indicator functions}
The integral of an indicator function $1_S$ of a measurable subset $S$ of $E$ is defined to be
\[\int 1_{S}\,\mathrm{d}{\mu} =\mu (S).\]
\sssc{Of a simple function}{{{
\sssc{Of a measurable function}{{{

\sssc{Bochner spaces (博赫納空間)}
Let $(E,\Sigma,\mu)$ be a measure space and $X$ be a topological space. 

The Bochner space $L^p(E;X)$ with $p\in\mathbb{N}\cup\{\infty\}$ is defined to be the Kolmogorov quotient space {{{ of the space of all Bochner measurable functions $f(t)\colon E\to X$ such that the norm $\|f(t)\|_{L^p(E;X)}$ of it, defined with
\[\|f(t)\|_{L^p(E;X)}\coloneq\left(\int_E\|f(t)\|_X^{\phantom{X}p}\,\mathrm{d}\mu\right)^{1/p},\quad p\in\mathbb{N},\]
and
\[\|f(t)\|_{L^{\infty }(E;X)}\coloneq\operatorname{ess\,sup}_{t\in E}\|f(t)\|_{X},\]
is finite under the equivalence relation of equality almost everywhere.
\ssc{Fundamental theorem of calculus (FTC) (微積分基本定理) of real functions}
Below is the FTC for functions from a subset of $\mathbb{R}$ to $\mathbb{R}$.
\sssc{The First Theorem}
Let $F(x)$ be a function differentiable on $[a,b]$. Then:
\[\int_a^bF'(x)\dd{x}=F(b)-F(a).\]
\begin{proof}\mbox{}\\
{{{ Change to Lebesgue integral
By the definition of the Riemann integral:
\[
\int_a^b F'(x)\, \dd{x} = \lim_{n \to \infty} \sum_{i=1}^n F'(x_i^*) \Delta x_i,
\]
where \( \{x_i^*\} \) are sample points in the subintervals of a partition \( P = \{x_0, x_1, \dots, x_n\} \) of \([a, b]\), and \( \Delta x_i = x_i - x_{i-1} \).
By the Mean Value Theorem for derivatives, since \( F(x) \) is differentiable, there exists an adequately refined partition \( P = \{x_0, x_1, \dots, x_n\} \) such that on each subinterval \([x_{i-1}, x_i]\) there exists a point \( x_i^* \in [x_{i-1}, x_i] \) such that:
\[
F'(x_i^*) \cdot \Delta x_i = F(x_i) - F(x_{i-1}).
\]
Thus, the Riemann sum becomes:
\[
\sum_{i=1}^n F'(x_i^*) \Delta x_i = \sum_{i=1}^n \left(F(x_i) - F(x_{i-1})\right) = F(b) - F(a).
\]
\end{proof}
\sssc{The Second Theorem}
Let $f(x)$ be a function continuous on $[a,b]$. Then:
\[\dv{x}\int_a^xf(t)\dd{t}=f(x).\]
\begin{proof}
\[\dv{x}\qty(\int_a^xf(t)\,\dd{t})=\lim_{h\to 0}\frac{\int_a^{x+h}f(t)\,\dd{t}-\int_a^xf(t)\,\dd{t}}{h}\]
Using the additivity property of integrals:
\[\int_a^{x+h}f(t)\,\dd{t}-\int_a^xf(t)\,\dd{t}=\int_x^{x+h}f(t)\,\dd{t}\]
By the Mean Value Theorem for integrals, since \(f(t)\) is continuous on \([x,x+h]\), there exists a point \(c\in [x,x+h]\) such that:
\[\int_x^{x+h} f(t)\, \dd{t} = f(c) \cdot h.\]
Substituting into the difference quotient:
\[\frac{\int_x^{x+h}f(t)\,\dd{t}}{h} = f(c).\]
\[\lim_{h\to 0}\frac{\int_x^{x+h}f(t)\,\dd{t}}{h} = f(x).\]
\end{proof}
\ssc{Fundamental theorem of calculus of Banach-space valued functions}{{{



\section{Multivariable (多變數 or 多變量 or 多元) Calculus}
\subsection{Operators}
\begin{itemize}
\item Dot product (點積) operator: $\cdot$
\item Cross product (叉積) operator: $\times$
\item Gradient (梯度) operator: $\nabla$
\item Divergence (散度) operator: $\nabla \cdot$
\item Curl (旋度) operator: $\nabla \times$
\item Directional derivative (方向導數) operator: $\cdot\nabla$
\item Laplace (拉普拉斯) operator: $\nabla^2$或$\Delta$
\item Line or Path integral operator: $\int$
\item Surface integral operator: $\iint$
\item Volume integration operator: $\iiint$
\item Closed line integral operator: $\oint$
\item Closed surface Integral Operator: $\oiint$
\item $\int\mathbf{F}\cdot\mathrm{d}\mathbf{S}$ is used as a shorthand for $\int(\mathbf{F}\cdot\mathbf{\hat{n}})\,\mathrm{d}S$, where $\hat{n}$ is the outward pointing unit normal at almost each point on $S$.
\end{itemize}
\subsection{Convention}
If not otherwise specified:
\begin{itemize}
\item The domain of the funcitons or maps below are subsets of a Euclidean vector space. If not otherwise specified, the coordinates are the Cartesian coordinates, the norms are the Euclidean norms, and the measures are the Lebesgue measures.
\item $\mathbf{0}$ or $0$ refers to the zero tensor (零張量) in the interested Euclidean tensor space $V$, that is, it satisfies 
\[\forall\mathbf{v}\in V:\,\mathbf{v}+\mathbf{0}=\mathbf{v}.\]
\item Unit vector (單位向量): $\mathbf{e}_i$ is the unit vector in the $i$th direction, i.e., a vector with zero norm.
\item Independent variable vector: $\mathbf{x}=(x_1,x_2,\dots,x_n)$
\item Vector fields: $\mathbf{F}(\mathbf{x}) = \sum_{i=1}^n F_i(\mathbf{x}) \mathbf{e}_i$、$\mathbf{G}$
\item Scalar fields: $A(\mathbf{x})$、$B(\mathbf{x})$
\item Tensor fields: $f(\mathbf{x})$、$g(\mathbf{x})$
\item Three-dimensional tensor space field: $\mathbf{T}(\mathbf{x})$
\item The $i$th component of the map $f$: $f_i$
\end{itemize}
\subsection{Gradient}
\[
\nabla f = \begin{pmatrix}\qty(\pdv{f}{x_1})^T & \qty(\pdv{f}{x_2})^T & \dots  & \qty(\pdv{f}{x_n})^T\end{pmatrix}
\]
The gradient of a scalar field is a vector field, the gradient of a vector field is a second-order tensor (matrix) field, and the gradient of a $k$-order tensor field is a $k+1$-order tensor field. 

In particular, the gradient of a scalar field $A$ is
\[
\nabla A = \sum_{i=1}^n \pdv{A}{x_i}e_i.
\]
And the gradient of a vector field $\mathbf{F}$ is also called the Jacobian matrix (雅可比矩陣) of it and also denoted as $\mathbf{J}(\mathbf{F})$, $J(\mathbf{F})$, or $J_{\mathbf{F}}$, of which the $( i,j )$th entry is
\[\mathbf{J}_{ij}=\frac{\partial F_i}{\partial x_j}.\]
The determinant $\det\left(J_{\mathbf{F}}\right)$ of a Jacobian matrix is called a Jacobian determinant, or Jacobian for short.
\subsection{Divergence}
\[
\nabla \cdot f = \sum_{i=1}^n\frac{\partial f_i}{\partial x_i}
\]
The divergence of a vector field is a scalar field, the gradient of a second-order tensor (i.e. matrix) field is a vector field, and the divergence of a $k+1$-order tensor field is a $k$-order tensor field.
\subsection{Curl}
The curl is only defined on three-dimensional vector field.
\[
\nabla \times \mathbf{T} = 
\begin{pmatrix}
\mathbf{e}_1 & \mathbf{e}_2 & \mathbf{e}_3 \\
\frac{\partial}{\partial x_1} & \frac{\partial}{\partial x_2} & \frac{\partial}{\partial x_3} \\
T_1 & T_2 & T_3 \\
\end{pmatrix}
\]
The curl of a three-dimensional vector field is a three-dimensional vector field.
\subsection{Directional derivative}
\[(\mathbf{f}\cdot\nabla)\mathbf{g}=\sum_{i=1}^n f_i\pdv{g}{x_i}\]
\subsection{Laplace operator}
\[
\nabla^2 f = \nabla \cdot (\nabla f) = \sum_{i=1}^n\frac{\partial^2 f}{\partial x_i^{\phantom{i}2}}
\]
The Laplace operator applied to a tensor field is a tensor field of the same order and same dimension (but not necessarily the same field).
\subsection{Poisson's equation (卜瓦松 or 帕松 or 泊松方程)}
\[
\nabla^2 A = B(\mathbf{x})
\]
\subsection{Laplace's equation (拉普拉斯方程)}
\[
\nabla^2 A = 0
\]
A real function $A$ with real independent variables that is second-order differentiable for all independent variables is called a harmonic function if $A$ satisfies Laplace's equation.
\subsection{Multi-index notation (多重指標記號)}
Suppose there are \( n \) variables \( x_1, x_2, \dots, x_n \), then a multi-index $\alpha$ is a vector of \( n \) nonnegative integers: 
\[
\alpha = (\alpha_1, \alpha_2, \dots, \alpha_n), \quad \text{where } \alpha_i \in \mathbb{N}_0.
\]
Define: 
\begin{itemize}
\item Norm \( \|\alpha\| \): 
\[
\|\alpha\| = \alpha_1 + \alpha_2 + \dots  + \alpha_n.
\]
\item Factorial \( \alpha! \): 
\[
\alpha! = \alpha_1! \cdot \alpha_2! \cdot \dots  \cdot \alpha_n!.
\]
\item Power \( \mathbf{x}^\alpha \): 
If \( \mathbf{x} = (x_1, x_2, \dots, x_n) \), then
\[
\mathbf{x}^\alpha = x_1^{\alpha_1} \cdot x_2^{\alpha_2} \dots  x_n^{\alpha_n}.
\]
\item Higher-order mixed partial derivatives $D^\alpha f$: 
\[
D^\alpha f = \frac{\partial^{\|\alpha\|} f}{\partial x_1^{\alpha_1} \partial x_2^{\alpha_2} \dots  \partial x_n^{\alpha_n}}.
\]
\end{itemize}
\subsection{Higher-order derivative}
The $k$th order derivative of $\mathbf{F}:\,\mathbb{R}^n\to\mathbb{R}^m$, denoted as $\mathbf{F}^{(k)}(\mathbf{x})$ or $D^{k}\mathbf{F}(\mathbf{x})$, is a $(\mathbb{R}^n)^k\to\mathbb{R}$ function, where $(\mathbb{R}^n)^k$ is a Cartesian product of $k$ copies of $\mathbb{R}^n$ vector, that is,
\[D^{k}\mathbf{F}(\mathbf{x})=\sum_{\|\alpha\|=k} \left(D^\alpha \mathbf{F}(\mathbf{a})\right).\]
In particular, the first-order derivative of $\mathbf{F}$ is the gradient of it.
\subsection{Taylor expansion}
Assume that $\mathbf{F}:\,\mathbb{R}^n\to\mathbb{R}^m$ is an infinitely differentiable function, and its partial derivatives of every order exist on $\mathbb{R}^n$, then the Taylor expansion of $\mathbf{F}$ at $\mathbf{a}$ is
\[\mathbf{F}(\mathbf{x}) = \sum_{\|\alpha\|\in\mathbb{N}_0} \frac{D^\alpha \mathbf{F}(\mathbf{a})}{\alpha!} (\mathbf{x} - \mathbf{a})^\alpha,\]
that is,
\[\mathbf{F}(\mathbf{x}) = \sum_{\|\alpha\|\leq k} \frac{D^\alpha \mathbf{F}(\mathbf{a})}{\alpha!} (\mathbf{x} - \mathbf{a})^\alpha+\int_0^1\frac{(1-t)^k}{k!} D^{k+1}\mathbf{F}(\mathbf{a} + t(\mathbf{x} - \mathbf{a})) (\mathbf{x} - \mathbf{a})^{k+1} \, \mathrm{d}t.\]
Also, the $k$th-order approximation of $\mathbf{F}$ near $\mathbf{a}$ is
\[\mathbf{F}(\mathbf{x}) \approx \sum_{\|\alpha\|\leq k} \frac{D^\alpha \mathbf{F}(\mathbf{a})}{\alpha!} (\mathbf{x} - \mathbf{a})^\alpha,\]
and the first-order approximation near $\mathbf{a}$ is
\[\mathbf{F}(\mathbf{x}) \approx \mathbf{F}(\mathbf{a}) + \nabla \mathbf{F}(\mathbf{a}) \cdot (\mathbf{x} - \mathbf{a}).\]
\ssc{Line integral (線積分) or Path integral (路徑積分)}
\sssc{Scalar field line or path integral}
For a scalar field $A : \,U\subseteq \mathbb {R} ^{n}\to \mathbb {R}$ and the path $C \in U$, the line integral of $A$ is: 
\[\int _{C}A\,\mathrm {d} s=\int _{a}^{b}A(\mathbf{r}(t))\|\dv{t}\mathbf {r} (t)\|\,\mathrm {d} t,\]
where $\mathbf{r}:\, [a, b] \to C$ is a one-to-one parametric function with $\mathbf{r}(a)$ and $\mathbf{r}(b)$ being the two endpoints of the path $C$. 

$A$ is called the integral function, $C$ is called the integral path, and the result of the line integration does not depend on the parametric function $r$.
\sssc{Vector field line or path integral}
For a scalar field $\mathbf{F}: \,U\subseteq \mathbb {R} ^{n}\to \mathbb {R}^n$ and the path $C \in U$, the line integral of $\mathbf{F}$ is: 
\[\int _{C}\mathbf {F} (\mathbf {r} )\cdot \,\mathrm {d} \mathbf{r}=\int _{a}^{b}\mathbf {F} (\mathbf {r} (t))\cdot \dv{t}\mathbf {r} (t)\,\mathrm {d} t\]
where $\mathbf{r}:\, [a, b] \to C$ is a one-to-one parametric function with $\mathbf{r}(a)$ and $\mathbf{r}(b)$ being the two endpoints of the path $C$. 

$\mathbf{F}$ is called the integral function, $C$ is called the integral path, and the result of the line integration does not depend on the parametric function $\mathbf{r}$.
\sssc{Conservative field (保守場)}
A field $f$ whose domain is a subset $U$ of a Euclidean tensor space is called a conservative field if for all paths $C$ between point $a$ and $b$, the integral 
\[\int_Cf(\mathbf{x})\cdot\mathrm{d}\mathbf{x}\]
are the same.

This implies 
\begin{itemize}
\item For any closed path $C$, 
\[\int_Cf(\mathbf{x})\cdot\mathrm{d}\mathbf{x}=0.\]
\item If $\operatorname{dim}(U)=3$, then for any subset of $U$ where $f$ is smooth,
\[\nabla\times f=0.\]
\end{itemize}
\ssc{Fundamental theorem of multivariable calculus (多變數微積分基本定理)}
\sssc{Gradient theorem (梯度定理)}
Suppose $r$ is a oriented differentiable curve that starts at a point $\mathbf{p}$ and ends at a point $\mathbf{q}$. If $\mathbf{F}$ is a differentiable tensor field defined on a neighborhood of $\mathbf{F}$, then,
\[\int_r(\nabla\mathbf{F})\cdot\mathrm{d}\mathbf{r}=\mathbf{F}\left(\mathbf{q}\right)-\mathbf{F}\left(\mathbf{p}\right).\]
Gradient theorem is a special case of generalized Stokes theorem.
\sssc{Divergence theorem, Gauss's theorem, or Ostrogradsky's theorem (高斯散度定理)}
Suppose $V\subseteq\mathbb{R}^n$ is compact and has a piecewise smooth boundary $S$ (also indicated with $\partial V=S$). The closed, measurable set $\partial V$ is oriented by outward-pointing normals. If $F$ is a continuously differentiable vector field defined on a neighborhood of $V$, then,
\[\iiint_V\left(\nabla\cdot\mathbf {F}\right)\,\mathrm{d}V=\oiint_S\mathbf{F}\cdot\mathrm{d}\mathbf{S}\]
Divergence theorem is a special case of generalized Stokes theorem.
\sssc{Stokes' theorem (斯托克斯定理) or Kelvin–Stokes theorem}
Let $S$ be a positively oriented, piecewise smooth surface in $\mathbb{R}^3$ with boundary $\partial S\equiv L$. If a vector field $\mathbf{F}:\,\mathbb{R}^3\rightarrow\mathbb{R}^3$ is defined and has continuous first order partial derivatives in a region containing $S$, then,
\[\iint_S(\nabla\times\mathbf{F})\cdot \mathrm{d}\mathbf{S}=\oint_{L}\mathbf{F}\cdot\mathrm{d}\mathbf{L}\]
Stokes' theorem is a special case of generalized Stokes theorem.
\sssc{Green's theorem (格林定理或綠定理)}
Let $S$ be a positively oriented, piecewise smooth surface in $\mathbb{R}^2$ with boundary $\partial S\equiv L$. If scalar function $P,(x,y)\,Q(x,y)$ are defined and has continuous first order partial derivatives in a region containing $S$, then,
\[\oint_L (P\mathrm{d}x+Q\mathrm{d}y)=\iint_S\left(\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y}\right)\mathrm{d}x\mathrm{d}y\]
where the path of integration along C is counterclockwise.

Green's theorem is a special case of Stokes' theorem.
\sssc{Generalized Stokes theorem, Stokes–Cartan theorem, or fundamental theorem of multivariable calculus}
The generalized Stokes theorem says that the integral of a differential form $\omega$ over the boundary $\partial\Omega$ of some orientable manifold $\Omega$ is equal to the integral of its exterior derivative $\mathrm{d}\boldsymbol{\omega}$ over the whole of $\Omega$, i.e.,
\[\int _{\partial\Omega}\omega=\int_{\Omega}\mathrm{d}\boldsymbol{\omega}\]



\section{Differential theorems}
\ssc{Distributive over addition and subtraction}
Differentiation is distributive over addition and subtraction.
\ssc{Product rule (乘法定則)}
\[\dv{x}\qty(f(x)g(x))=f'(x)g(x)+f(x)g'(x).\]
\ssc{General Leibniz rule}
If $f$ and $g$ are $n$-times differentiable functions, then the product $fg$ is also n-times differentiable and its $n$th derivative is given by 
\[(fg)^{(n)}=\sum _{k=0}^{n}{n \choose k}f^{(n-k)}g^{(k)}.\] 
\ssc{Quotient rule (除法定則)}
\[\dv{x}\qty(\frac{f(x)}{g(x)})=\frac{f'(x)g(x)-f(x)g'(x)}{\qty(g(x))^2}.\]
\ssc{Chain rule (連鎖律)}
\[\dv{x}\qty((f\circ g)(x))=f'\qty(g(x))g'(x).\]
\ssc{Faà di Bruno's formula}
\bma
&\frac{\mathrm{d}^n}{\mathrm{d}x}f\left(g(x)\right)\\
=&\sum_{\sum_{i=1}^nim_i=n,\quad m_i\in\mathbb{N}_0}\frac{n!}{\prod_{j=1}^nm_j!}\cdot\\
&f^{\qty(\sum_{j=1}^nm_j)}\left(g(x)\right)\cdot\\
&\prod_{j=1}^n\left(\frac {g^{(j)}(x)}{j!}\right)^{m_j}.
\eam
\subsection{Mean Value Theorem, MVT (均值定理)}
Let $f:\, I\subseteq\mathbb{R}\to\mathbb{R}$ be a continuous function, and $f$ is differentiable on an interval $(a, b)\subseteq I$, then
\[\exists c\in (a, b)\text{\ s.t.\ }f'(c)=\frac{f(b)-f(a)}{b-a}\]
\subsection{Extreme Value Theorem, EVT (極值定理)}
Let function $f:\, I\subseteq\mathbb{R}\to\mathbb{R}$ be continuous on an interval $[a,b]$, then
\[\exists c,d \in [a, b] \text{\ s.t.\ }\qty(\forall x \in [a, b]\colon f(c)\geq f(x)\geq f(d))\]
\subsection{L'Hôpital's rule (羅必達法則) or Bernoulli's rule}
Let \(I\) be an interval containing the point \(a\). Let \( f(x) \) and \( g(x) \) be functions defined on \(I\), except possibly at \(a\) itself. Let \( f(x) \) and \( g(x) \) be differentiable at all points except $a$ in $I$. If $\lim_{x\to a}f(x)=\lim_{x\to a}g(x)\in\{0,\infty,-\infty\}$, and $\exists \lim_{x\to a}\frac{f'(x)}{g'(x)}$, then:
\[\lim_{x\to a}\frac{f(x)}{g(x)}=\lim_{x\to a}\frac{f'(x)}{g'(x)}\]
\subsection{Relative extreme theorem}
A point in $I$ where a relative extreme of $f:\,I\subseteq\mathbb{R}\to\mathbb{R}$ occurs must be a critical point.
\subsection{Concavity theorem}
Let $f:\,J\subseteq\mathbb{R}\to\mathbb{R}$ be differentiable on the open interval $I\subseteq J$. If $\forall x\in I:\,f''>0$, then the graph of $f$ is concave upward on $I$; if $\forall x\in I:\,f''<0$, then the graph of $f$ is concave downward on $I$.
\subsection{Inflection point theorem}
If $(c,f(c))$ is an inflection point of $f$, then $f''(c)=0$ or $f''$ does not exist at $c$.
\subsection{Lagrange multiplier (method) (拉格朗日乘數 or 乘子（法）)}
The Lagrange multiplier method is a method for finding the points where extremes occur of a differentiable function under constraints.
\sssc{Univariate form}
Let $f:\,\mathbb{R} \rightarrow \mathbb{R}$ and $g:\,\mathbb{R} \rightarrow \mathbb{R}$ . We want to find the points where extremes of \( f(x) \) under the constraint \( g(x) = \mathbf{0} \) occur. 

First, construct the Lagrangian function \( \mathcal{L}(x,\lambda) \):
\[\mathcal{L}(x,\lambda) = f(x) - \lambda \cdot g(x),\]
where \( \lambda\in\mathbb{R} \) is the Lagrange multiplier (拉格朗日乘數 or 乘子).

Find the derivative of $\mathcal{L}$ and set it to zero:
\[
\dv{\mathcal{L}}{x} = 0
\]
Solve the equation to find \( x \) and \( \lambda \) . 

\text{Statement:} Let $A$ be the set of all solutions for \( x \) such that $\dv{\mathcal{L}}{x} = 0$, and $B$ be the set of all points where extremes of \( f(x) \) under the constraint \( g(x) = \mathbf{0} \) occur. We claim that $B\subseteq A$.
\sssc{Multivariate form}
Let \( \mathbf{x} = (x_1, x_2, \dots, x_n) \) be the independent variable vector and $\mathbf{0}$ be the zero vector. Now we have $f:\,\mathbb{R}^n \rightarrow \mathbb{R}$ and $g:\,\mathbb{R}^n \rightarrow \mathbb{R}^c$. We want to find the points where extremes of \( f(\mathbf{x}) \) under the constraint \( g(\mathbf{x}) = \mathbf{0}\) occur. 

First, construct the Lagrangian function \( \mathcal{L}(\mathbf{x},\lambda) \):
\[
\mathcal{L}(\mathbf{x},\lambda) = f(\mathbf{x}) - \lambda \cdot g(\mathbf{x}),
\]
where \( \lambda\in\mathbb{R}^c \) is the Lagrange multiplier vector.

Find the gradient of $\mathcal{L}$ and set it to zero:
\[
\nabla \mathcal{L} = \mathbf{0}
\]
Solve the equation to find \( \mathbf{x} \) and \( \lambda \) . 

\text{Statement:} Let $A$ be the set of all solutions for \( \mathbf{x} \) such that $\nabla \mathcal{L} = \mathbf{0}$, and $B$ be the set of all points where extremes of \( f(\mathbf{x}) \) under the constraint \( g(\mathbf{x}) = \mathbf{0}\) occur. We claim that $B\subseteq A$.
\begin{proof}\mbox{}\\
Consider $\mathbf{x}^*\in B$. It must satisfy the constraint:
\[g(\mathbf{x}^*) = \mathbf{0}.\]
Any feasible point $\mathbf{x}$ near $\mathbf{x}^*$ must satisfy the constraint. We can represent $\mathbf{x}$ as:
\[\mathbf{x} = \mathbf{x}^* + \delta\mathbf{x},\]
where $\delta\mathbf{x}$ is a differential change tangent to the manifold defined by $g(\mathbf{x})$, that is, it lies in the kernel of $\nabla g(\mathbf{x}^*)$, that is,
\[g(\mathbf{x}^* + \delta\mathbf{x}) = \mathbf{0}.\]
Find the first-order approximation of $f$ at $\mathbf{x}^*$:
\[f(\mathbf{x}^*+ \delta\mathbf{x}) \approx f(\mathbf{x}^*) + \nabla f(\mathbf{x}^*) \cdot \delta\mathbf{x} + O(\|\delta\mathbf{x}\|^2)\]
Find the first-order approximation of $g$ at $\mathbf{x}^*$:
\[g(\mathbf{x}^*+ \delta\mathbf{x}) \approx g(\mathbf{x}^*) + \nabla g(\mathbf{x}^*) \cdot \delta\mathbf{x} + O(\|\delta\mathbf{x}\|^2)\]
Since $\mathbf{x}^*\in B$, for any feasible $\delta\mathbf{x}$ we must have:
\[\nabla f(\mathbf{x}^*) \cdot \delta\mathbf{x} = 0.\]
Since $g(\mathbf{x}^*) = \mathbf{0}$, we have
\[\nabla g(\mathbf{x}^*) \cdot \delta\mathbf{x} = O(\|\delta\mathbf{x}\|^2).\]
Because \( \delta\mathbf{x} \in \ker(\nabla g(\mathbf{x}^)) \), \( \nabla f(\mathbf{x}^) \) can be expressed as a linear combination of \( \nabla g(\mathbf{x}^) \) . This means that there exists a vector to $\lambda$ such that:
\[\nabla\mathcal{L} = \nabla \qty(f(\mathbf{x}) - \lambda \cdot g(\mathbf{x})) = \mathbf{0} \]
\end{proof}
\ssc{Generalized Schwarz's theorem or Clairaut's theorem on equality of mixed partials}
For a function $f\colon\Omega\subseteq\mathbb{R}^n\to\mathbb{R}$, if $\mathbf{p}\in\Omega$ such that $f$ has continuous $m$th partial derivative with respect to $x_h$ for any $h\in\{1,2,\dots n\}$ on some neighborhood $N\subseteq\Omega$ of $\mathbf{p}$, then all $r$th mixed partial derivatives \[\frac{\partial^r f(\mathbf{p}}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}}\]
with given constants $t_q$ for any $q\in\{1,2,\dots n\}$ in which $0<r<m$, $\sum_{j=1}^km_{i_j}=r$, and
\[\forall q\in\{1,2,\dots n\}\colon\sum_{i_j=q}m_{i_j}=t_q,\]
are equivalent.
\ssc{Recurrent helper function}
If a function $y=f(x)$ satisfy that $y'=g\qty(f(x))$ and that $f$ and $g$ are sufficiently smooth such that all needed derivatives exist. We can define functions $F_n(y)$ as
\[\begin{cases}
&F_0(y)=y\\
&F_n(y)=g(y)F_{n-1}'(y).
\end{cases}\]
Then the $n$th derivative of $y=f(x)$ is $F_n(y)$, where $n\in\mathbb{N}$.



\section{Integral theorems}
\ssc{Distributive over addition and subtraction}
Integration is distributive over addition and subtraction.
\subsection{Integration by substitution (代換積分法), integration by change of variables (換元積分法), u-substitution (u-代換), reverse chain rule, substitution theroem (代換定理), change of variables theorem (換元定理), or transformation theorem (變換定理)}
\subsubsection{Univariate form}
Let $g:\,I\subseteq\mathbb{R}\to\mathbb{R}$ be injective and differentiable on $[a,b]\subseteq I$, with $g'$ being integrable on $[a,b]$, and $f:\,K\supseteq g([a,b])\to\mathbb{R}$ be integrable on $g([a,b])$. Then:
\[\int_a^bf\circ g(x)\cdot g'(x)\,\mathrm{d}x=\int_{g(a)}^{g(b)}f(u)\,\mathrm{d}u,\]
and for $K=g([a,b])$:
\[\int f\circ g(x)\cdot g'(x)\,\mathrm{d}x=\int f(u)\,\mathrm{d}u.\]
\begin{proof}\mbox{}\\
Consider the interval \([a, b]\) partitioned as
\[P = \{a = x_0 < x_1 < \dots  < x_n = b\}.\]
For each subinterval \([x_{i-1}, x_i]\), let \(\xi_i \in [x_{i-1}, x_i]\) be a sample point. The Riemann sum for the left-hand side of the integral is:
\[S_P = \sum_{i=1}^n f(g(\xi_i)) g'(\xi_i) (x_i - x_{i-1}).\]
Since \(g\) is injective and differentiable, it is either strictly increasing or strictly decreasing on \([a, b]\). Assume \(g\) is strictly increasing (the proof for \(g\) strictly decreasing follows similarly).

Under this assumption, \(g\) maps \([a, b]\) to \([g(a), g(b)]\) (with \(g(a) < g(b)\)). Let \([g(a), g(b)]\) be partitioned as
\[Q = \{g(a) = u_0 < u_1 < \dots  < u_m = g(b)\},\]
where \(u_i = g(x_i)\). For \(g\) increasing, \((u_i - u_{i-1}) = g(x_i) - g(x_{i-1})\).

The Riemann sum for the right-hand side of the integral is:
\[T_Q = \sum_{i=1}^n f(u_i) (u_i - u_{i-1}).\]
Since \(u_i = g(x_i)\) and \(g'(\xi_i) \approx \frac{g(x_i) - g(x_{i-1})}{x_i - x_{i-1}}\), we rewrite:
\[ g'(\xi_i) (x_i - x_{i-1}) \approx g(x_i) - g(x_{i-1}) = u_i - u_{i-1}. \]
Thus, the left-hand Riemann sum \(S_P\) becomes:
\[ S_P = \sum_{i=1}^n f(g(\xi_i)) (u_i - u_{i-1}),\]
which matches the structure of the right-hand Riemann sum \(T_Q\) if we let \(\xi_i = g^{-1}(u_i)\).

As the partition \(P\) of \([a, b]\) gets finer, the Riemann sum \(S_P\) converges to \(\int_a^b f(g(x)) g'(x) \, \mathrm{d}x\). Similarly, as the partition \(Q\) of \([g(a), g(b)]\) gets finer, the Riemann sum \(T_Q\) converges to \(\int_{g(a)}^{g(b)} f(u) \, \mathrm{d}u\).
\end{proof}
\subsubsection{Multivariate form}
Let $\mathbf{T}:\,I\subseteq\mathbb{R}^n\to\mathbb{R}^n$ be injective and differentiable on $D\subseteq I$, with all elements of its gradient (i.e. Jacobian matrix) $\nabla\mathbf{T}$ being continuous on $D$, and $f:\,K\supseteq\mathbf{T}(D)\to\mathbb{R}$ be integrable on $\mathbf{T}(D)$. Then:
\[\int_{\mathbf{T}(D)}f(x_1\,x_2\,\dots\,x_n)\cdot\,\mathrm{d}x_1\,\mathrm{d}x_2\,\dots\,\mathrm{d}x_n=\int_D f(u_1\,u_2\,\dots\,u_n)\abs{\det\left(\nabla\mathbf{T}\right)}\,\mathrm{d}u_1\,\mathrm{d}u_2\,\dots\,\mathrm{d}u_n,\]
and for $K=\mathbf{T}(D)$:
\[\int f(x_1\,x_2\,\dots\,x_n)\cdot\,\mathrm{d}x_1\,\mathrm{d}x_2\,\dots\,\mathrm{d}x_n=\int f(u_1\,u_2\,\dots\,u_n)\abs{\det\left(\nabla\mathbf{T}\right)}\,\mathrm{d}u_1\,\mathrm{d}u_2\,\dots\,\mathrm{d}u_n.\]
\subsubsection{Measure theory form}
Let $X$ be a locally compact Hausdorff space equipped with a finite Radon measure $μ$, and let $Y$ be a \text{\textsigma}-compact Hausdorff space with a \text{\textsigma}-finite Radon measure $\rho$. Let $\phi:\,X\to Y$ be an absolutely continuous function, (which implies that $\mu(E)=0\implies\rho(\phi(E))=0$). Then there exists a real-valued Borel measurable function $w$ on $X$ such that for every Lebesgue integrable function $f:\,Y\to\mathbb{R}$, the function $(f\circ\phi)\cdot w$ is Lebesgue integrable on $X$, and for every open subset $U$ of $X$
\[\int_{\phi(U)}f(y)\,\mathrm{d}\rho(y)=\int_U(f\circ\phi)(x)\cdot w(x)\,\mathrm{d}\mu(x).\]
Furthermore, there exists some Borel measurable function $g$ such that 
\[w(x)=(g\circ\phi)(x).\]
\subsection{Integration by parts (IBP) (分部積分法) or partial integration (部分積分法)}
\subsubsection{Theorem}
\[\frac{\mathrm{d}}{\mathrm{d}x}\prod_{i=1}^nf_i(x)=\sum_{j=1}^n\left(\frac{\mathrm{d}f_j(x)}{\mathrm{d}x}\frac{\prod_{\substack{i=1\\i\neq j}}^n f_i(x)}{f_j(x)}\right)\]
For example,
\[\int_{\Omega} u\dd{v} = \qty(u v)\big\vert_{\Omega} - \int_{\Omega} v\dd{u}.\]
\subsubsection{Application}
Integration by parts is a heuristic rather than a purely mechanical process for solving integrals; given a single function to integrate, the typical strategy is to carefully separate this single function into a product of two functions such that the residual integral from the integration by parts formula is easier to evaluate than the single function.

The DETAIL rule or the LIATE rule is a rule of thumb for integration by parts. It involves choosing as u the function that comes first in the following list:
\begin{itemize}
\item L: Logarithmic function
\item I: Inverse trigonometric function
\item A: Algebraic function
\item T: Trigonometric function
\item E: Exponential function
\end{itemize}
\ssc{Leibniz integral rule (for differentiation under the integral sign) (（積分符號內取微分的）萊布尼茲積分法則)}
\sssc{Basic form for constant limits}
Let $a,b\in\mathbb{R}$, $f(x,t)$ be a function with domain $\mathbb{R}^2$, and the following integral exists. Then:
\[\begin{aligned}
&\dv{}{x}\qty(\int_a^bf(x,t)\dd{t})\\
=&\int_a^b\pdv{}{x}f(x,t)\dd{t}
\end{aligned}\]
\sssc{Basic form for variable limits}
Let $a(x),b(x)\in\mathbb{R}$, $f(x,t)$ be a function with domain $\mathbb{R}^2$, and the following integral exists. Then:
\[\begin{aligned}
&\dv{}{x}\qty(\int_{a(x)}^{b(x)}f(x,t)\dd{t})\\
=&f\qty(x,b(x))\cdot\dv{b(x)}{x}-f\qty(x,a(x))\cdot\dv{a(x)}{x}+\int_{a(x)}^{b(x)}\pdv{}{x}f(x,t)\dd{t}
\end{aligned}\]
\sssc{Measure theory form for const limits}
Let $X$ be an open subset of $\mathbb{R}$, and $\Omega$ be a measure space. Suppose $f\colon X\times\Omega\to\mathbb{R}$ satisfies the following conditions:
\ben
\item $f(x,\omega)$ is a Lebesgue-integrable function of $\omega$ for each $x\in X$.
\item For almost all $\omega\in\Omega$, the partial derivative $\pdv{f}{x}$ exists for all $x\in X$.
\item There is an integrable function $\theta\colon\Omega\to\mathbb{R}$ such that $\abs{\pdv{f}{x}\qty(x,\omega)}\leq\theta(\omega)$ for all $x\in X$ and almost all $\omegq\in\Omega$.
\een
Then, for all $x\in X$,
\[\dv{}{x}\int_{\Omega}f(x,\omega)\dd{\omega}=\int_{\Omega}\pdv{f}{x}\qty(x,\omega)\dd{\omega}.\]
\ssc{Fubini's theorem (富比尼定理)}
If a function is Lebesgue integrable on $X\times Y$, then:
\[\iint_{X\times Y}f(x,y)\dd{(x,y)}=\int_X\qty(\int_Yf(x,y)\dd{y))\dd{x}=\int_Y\qty(\int_Xf(x,y)\dd{x})\dd{y}.\]
\ssc{(Lebesgue's) Dominated convergence theorem (DCT) (（勒貝格）控制/受制收斂定理)}
Let $\langle f_n\rangle_{n\in I}$ be a net of real or complex-valued measurable functions on a measure space $(S,\Sigma,\mu)$. If $f_n$ is almost everywhere pointwise convergent to a function $f$, and there is a Lebesgue-integrable function $g$ such that
\[\abs{f_n}\leq g\]
almost everywhere for all $n\in I$.

Then $f_n$ for all $n\in I$ and $f$ are in $L^1(\mu)$ and
\[\lim_n\int_Sf_n\dd{\mu}=\int_S\lim_nf_n\dd{\mu}=\int_Sf\dd{\mu},\]
and
\[\lim_n\int_S\abs{f_n-f}\dd{\mu}=0.\]



\sct{Integral Transform}
\ssc{Laplace Transform (拉普拉斯變換)}
\sssc{(Unilateral or One-sided) Laplace Transform (（單邊）拉普拉斯變換)}
The (unilateral or one-sided) Laplace transform is an integral transform that converts a function of a real variable (usually $t$, in the time domain) to a function of a complex variable (usually $s$, in the complex-valued frequency domain, also known as $s$-domain, or $s$-plane). The functions are often denoted in lowercase for the time-domain representation and uppercase for the frequency-domain.

The Laplace transform of a real function $f(t)$, denoted as $\mathcal{L}\{f(t)\}(s)$ or $F(s)$ is defined by the improper integral
\[\mathcal{L}\{f(t)\}(s) = F(s) = \int_0^{\infty} e^{-st} f(t)\dd{t}.\]

In the context of Laplace transform, convergence refers to absolute convergence, that is, we say $F(s)$ converges or $f(t)$ is Laplace-transformable if the improper integral
\[\int_0^{\infty} \abs{e^{-st} f(t)}\dd{t}\]
converges absolutely for some real $s$.

The set of values for which $F(s)$ converges, called region of convergence (ROC), is either of the form $\Re(s) > a$ or $\Re(s) \geq a$, where $a$ is an extended real constant, i.e. $-\infty\leq a\leq\infty$.
\sssc{Laplace transformability}
A function $f\colon\mathbb{R}\to\mathbb{R}$ is Laplace-transformable if it is piecewise continuous on $[0,\infty)$ and of exponential order.
\begin{proof}\mbox{}\\
Assume that a $f\colon D\subseteq [0,\infty)\to\mathbb{R}$ is piecewise continuous on $[0,\infty)$ and there exists $M>0$ and $T>0$ such that:
\[|f(t)|\leq Me^{\alpha t}\quad \forall t>T.\]

For $s>\alpha$, since $f(t)$ is piecewise continuous, there exist $t_0=0,t_1,\dots t_k\in\mathbb{R}$ such that:
\begin{itemize}
\item the integral
\[\int_{t_i}^{t_{i+1}} |f(t)| e^{-st}\dd{t}$\]
exists and is finite for every $i\in\mathbb{Z}\land 0\leq i\leq k-1$, and that
\item the family $\{[t_0,t_1],[t_1,t_2],\dots [t_{k-1},t_k]$ is locally finite, and that
\item $f(t)$ is continuous on $[t_k,\infty)$.
\end{itemize}

Rewrite $F(s)$ as:
\[\int_0^\infty |f(t)| e^{-st}\dd{t} = \sum_{i=0}^{k-1} \int_{t_i}^{t_{i+1}} |f(t)| e^{-st}\dd{t} + \int_{t_k}^\infty |f(t)| e^{-st}\dd{t}\]

$\sum_{i=0}^{k-1} \int_{t_i}^{t_{i+1}} |f(t)| e^{-st}\dd{t}$ is finite.

For the second integral, since $|f(t)| \le M e^{\alpha t}$, we have
\[\int_{t_k}^\infty |f(t)| e^{-st}\dd{t}\le \int_{t_k}^\infty M e^{\alpha t} e^{-st}\dd{t} = M \int_{t_k}^\infty e^{-(s-\alpha)t}\dd{t}.\]
Since $s>\alpha$, the integral converges, so the second integral is finite.
\end{proof}
\sssc{Linearity}
\[\mathcal{L}\{af(t)+bg(t)\}=a\mathcal{L}\{f(t)\}+b\mathcal{L}\{g(t)\}.\]
\sssc{First shifting theorem or Time shift}
\[\mathcal{L}\{f(t-a)u(t-a)\}=e^{-as}F(s), \quad a > 0,\]
where $u(t)$ is the unit step function.
\sssc{Second shifting theorem or Frequency shift}
\[\mathcal{L}\{e^{at} f(t)\}(s) = F(s-a).\]
\sssc{Differentiation in Time Domain}
\[\mathcal{L}\{f'(t)\}(s) = sF(s) - f\qty(0^+).\]
\[\mathcal{L}\{f^{(n)}(t)\}(s) = s^n F(s) - \sum_{i=0}^{n-1}s^{n-1-i}f^{(i)}\qty(0^+).\]
\begin{proof}
\[\mathcal{L}\{f'(t)\}(s) = \int_0^\infty e^{-st} f'(t)\dd{t}.\]
\[u = e^{-st} \quad \Rightarrow \quad \dd{u} = -s e^{-st} \dd{t}.\]
\[dv = f'(t)\dd{t} \quad \Rightarrow \quad v = f(t).\]
Integral by parts.
\[\int_0^\infty u\dd{v} = (u v)\big\vert_0^\infty - \int_0^\infty v\dd{u}.\]
\bma
\int_0^\infty e^{-st} f'(t)\dd{t}&=\qty(e^{-st}f(t))\big\vert_0^\infty+\int_0^\infty f(t)se^{-st}\dd{t}\\
&=-f\qty(0^+)+\int_0^\infty f(t)se^{-st}\dd{t}\\
&=s\mathcal{L}\{f(t)\}(s)-f\qty(0^+)
\end{proof}
\sssc{Integration in Time Domain}
\[\mathcal{L}\left\{\int_0^t f(\tau)\dd{\tau}\right\}(s) = \frac{1}{s} F(s).\]
\begin{proof}
\bma
\mathcal{L}\{\int_0^t f(\tau)\dd{\tau}\}(s) &= \int_0^{\infty} e^{-st} \int_0^t f(\tau)\dd{\tau}\dd{t}\\
&=\qty(-\frac{1}{s}e^{-st}\int_0^t f(\tau)\dd{\tau})\big\vert_0^\infty+\int_0^{\infty} \frac{1}{s}e^{-st}f(t)\dd{t}\\
&=\frac{1}{s}\int_0^{\infty} e^{-st}f(t)\dd{t}.
\eam
\end{proof}
\sssc{Differentiation in Frequency Domain}
\[\mathcal{L}\{t f(t)\}(s) = -\dv{}{s} F(s).\]
\[\mathcal{L}\{t^n f(t)\}(s) = (-1)^n \dv[n]{}{s} F(s).\]
\begin{proof}\mbox{}\\
By Leibniz integral rule,
\bma
-\dv{}{s} F(s)&=-\dv{}{s}\int_0^{\infty} e^{-st} f(t)\,\mathrm{d}t\\
&=-\int_0^{\infty} \pdv{}{s}\qty(e^{-st} f(t))\,\mathrm{d}t\\
&=-\int_0^{\infty} -te^{-st} f(t)\,\mathrm{d}t\\
&=\int_0^{\infty} te^{-st} f(t)\,\mathrm{d}t\\
&=\mathcal{L}\{t f(t)\}(s)
\eam
\end{proof}
\sssc{Scaling in Time Domain}
\[\mathcal{L}\{f(at)\}(s) = \frac{1}{a} F\left(\frac{s}{a}\right), \quad a>0.\]
\sssc{Convolution Theorem}
If $h(t) = (f * g)(t) = \int_0^t f(\tau)g(t-\tau)\dd{\tau}$, then
\[\mathcal{L}\{h(t)\}(s) = F(s)G(s).\]
\begin{proof}
\[\mathcal{L}\{h(t)\}(s)=\int_0^{\infty} e^{-st} \qty(\int_0^t f(\tau)g(t-\tau)\dd{\tau})\dd{t}\]
By Fubini's theorem,
\[\mathcal{L}\{h(t)\}(s)=\int_0^\infty\int_\tau^\infty e^{-st} f(\tau)g(t-\tau)\dd{t}\dd{\tau}\]
Let $u=t-\tau$. $\dd{t}=\dd{u}$.
\[\begin(aligned}
\mathcal{L}\{h(t)\}(s)&=\int_0^\infty f(\tau)\int_0^\infty e^{-s(u+\tau)} g(u)\dd{u}\dd{\tau}\\
&=\int_0^\infty f(\tau)e^{-s\tau}\int_0^\infty e^{-su} g(u)\dd{u}\dd{\tau}\\
&=F(s)G(s)
\end{algined}\]
\sssc{Initial Value Theorem}
If $f(t)$ and $f'(t)$ are Laplace-transformable:
\[\lim_{t \to 0^+} f(t) = \lim_{s \to \infty} s F(s).\]
\begin{proof}
\[s F(s) = \int_0^\infty s f(t) e^{-st} \dd{t}.\]
Let $u = st$, $\dd{t} = \frac{\dd{u}}{s}$.
\[s F(s) = \int_0^\infty f\qty(\frac{u}{s}) e^{-u} \dd{u}.\]
\[\lim_{s \to \infty}s F(s)=\int_0^\infty f\qty(\frac{u}{s}) e^{-u} \dd{u}.\]

We define a net of functions $\langle f_s\rangle_{s\in\mathbb{R}_{>s_0}}$, where $s_0$ is such that $F(s)$ converges for all $\Re(s)>s_0$.

For fixed $u \in\mathbb{R}_{>0}$, $\lim_{s\to\infty}\frac{u}{s} \to 0^+$, so $f_n\qty(\frac{u}{s})$ pointwise converges to $f(0^+)$.

For dominated convergence theorem, we require an integrable function $g(u)$ such that
\[\abs{f\qty(\frac{u}{s}) e^{-u}} \le g(u), \quad \forall s > 0.\]

Since $f(t)$ is Laplace-transformable, it is of exponential order, that is, there exists $\alpha>0$, $M>0$, and $T>0$ such that:
\[|f(t)|\leq Me^{\alpha t}\quad \forall t>T.\]
\[M e^{\alpha \frac{u}{s}} e^{-u} = M e^{-u\qty(1 - \frac{\alpha}{s})}\le M e^{-\frac{u}{2}}, \quad \forall s > 2\alpha.\]

By dominated convergence theorem, we obtain:
\[\lim_{s \to \infty}s F(s)=\lim_{n\to\infty
\int_0^\infty f(0^+) e^{-u} \dd{u}.\]

Evaluate the integral:
\[\int_0^\infty f(0^+) e^{-u} \dd{u} = f(0^+) \int_0^\infty e^{-u}\dd{u} = f(0^+).\]
\end{proof}
\sssc{Mellin's inverse formula, Bromwich integral, or Fourier–Mellin integral of Inverse Laplace transform (反拉普拉斯變換)}
The inverse Laplace transform of a complex function $F(s)$, denoted as $\mathcal{L}^{-1}\{F(s)\}(t)$ or $f(t)$, is defined as a real function such that
\[\mathcal{L}\{f(t)\}(s) = F(s),\]
where $\mathcal {L}$ denotes the Laplace transform.

Mellin's inverse formula, Bromwich integral, or Fourier–Mellin integral states that, the inverse Laplace transform of a complex function $F(s)$ is given by the line integral:
\[\mathcal{L}^{-1}\{F(s)\}(t)=f(t)=\frac{1}{2\pi i}\lim_{T\to\infty}\int_{\gamma-iT}^{\gamma+iT}e^{st}F(s)\dd{s},\]
where $\gamma$ is a real number such that it is greater than the real part of all singularities of $F$ and that $F$ is bounded on the line $s=\gamma$.
\sssc{(Bilateral or Two-sided) Laplace Transform (（雙邊）拉普拉斯變換)}
The (bilateral or two-sided) Laplace transform is an integral transform that converts a function of a real variable (usually $t$, in the time domain) to a function of a complex variable (usually $s$, in the complex-valued angular frequency domain, also known as $s$-domain or $s$-plane). The functions are often denoted in lowercase for the time-domain representation and uppercase for the frequency-domain.

The Laplace transform of a real function $f(t)$, denoted as $\mathcal{B}\{f(t)\}(s)$, is defined by the improper integral
\[\mathcal{B}\{f(t)\}(s) = \int_{-\infty}^{\infty} e^{-st} f(t)\,\mathrm{d}t.\]
\ssc{Fourier Transform (FT) (傅立葉變換)}
\sssc{Fourier Transform (FT)}
Fourier transform is an integral transform that converts a function of a real variable (usually $t$, in the time domain) to a function of another real variable (usually $\omega$, in the real-valued angular frequency domain). The functions are often denoted in lowercase for the time-domain representation and uppercase for the frequency-domain.

The Fourier transform, denoted as $\mathcal{F}\{f(t)\}(\omega)$ or $F(\omega)$, is defined by the improper integral
\[\mathcal{F}\{f(t)\}(\omega) = F(\omega) = \int_{-\infty}^{\infty} e^{-i\omega t} f(t)\,\mathrm{d}t.\]
\sssc{Inverse Fourier Transform (反傅立葉變換)}
The inverse Fourier transform of a complex function $F(s)$, denoted as $\mathcal{F}^{-1}\{F(s)\}(t)$ or $f(t)$, is defined as a real function such that
\[\mathcal{F}\{f(t)\}(s) = F(s),\]
where $\mathcal {F}$ denotes the Fourier transform.

The inverse Laplace transform of a complex function $F(s)$ is given by the line integral:
\[f(t) = \frac{1}{2\pi}\int_{-\infty}^{\infty} F(\omega) e^{i\omega t}\dd{\omega} .\]



\sct{Lists}
\ssc{List of Derivatives}
\sssc{Power function}
For any $x,n\in\mathbb{R}$ in the maximum possible domain:
\[\dv{x^n}{x}=nx^{n-1}.\]
\begin{proof}
    \[\lim_{h\to 0}\frac{(x+h)^n-x^n}{h}
\end{proof}
\ssc{List of Counterexamples}
\sssc{Dirichlet function (狄利克雷函數)}
The Dirichlet function is a function $f\colon\manthbb{R}\to\mathbb{R};$
\[f(x)=\begin{cases}1,\quad & x\in\mathbb{Q}\\
0,\quad & x\in\mathbb{R}\setminus\mathbb{Q}
\end{cases},\]
which is discontinuous at everywhere.
\sssc{Weierstrass function (魏爾施特拉斯函數)}
The Weierstrass function is a function $f\colon\mathbb{R}\to\mathbb{R};$
\[f(x)=\sum_{n=0}^{\infty}a^n\cos\left(b^n\pi x\right),\]
in which $0<a<1$, $b$ is a positive odd integer, and $ab>1+\frac{3}{2}\pi$, which is continuous but differentiable nowhere.
\sssc{Differentiable but derivative not continuous}
The function $f\colon\mathbb{R}\to\mathbb{R};$
\[f(x)=\begin{cases}x^2\sin\qty(\frac{1}{x}),\quad&x\neq 0\\0,\quad&x=0\end{cases},\]
is differentiable but its derivative is not continuous at $0$. (Note that because $\{0\}$ has Lebesgue measure $0$, $f'\colon\mathbb{R}\to\mathbb{R}$ is continuous almost everywhere, that is, $f'$ is Riemann integrable on any closed interval.)
\begin{proof}
\[f'(x)=2x\sin\qty(\frac{1}{x})-x^2\cos\qty(\frac{1}{x}),\quad x\neq 0\]
\bma
f'(0)&=\lim_{h\to 0}\frac{f(h)}{h}\\
&=\lim_{h\to 0}h\sin\qty(\frac{1}{h})
\eam
For any $|h|>0$, we have $-|h|\leq h\sin\qty(\frac{1}{h})\leq |h|$. By the squeeze theorem, $\lim_{h\to 0}-|h|=\lim_{h\to 0}|h|=0$ implies $\lim_{h\to 0}h\sin\qty(\frac{1}{h})=0$.
\bma
\lim_{x\to 0}f'(x)&=2\lim_{x\to 0}x\sin\qty(\frac{1}{x})-\lim_{x\to 0}\cos\qty(\frac{1}{x})\\
&=-\lim_{x\to 0}\cos\qty(\frac{1}{x})\\
\eam
$\lim_{x\to 0}\cos\qty(\frac{1}{x})$ doesn't exist, so $\lim_{x\to 0}f'(x)$ doesn't exist.
\end{proof}
\sssc{Differentiable at one point and discontinuous everywhere else}
The function $f\colon\manthbb{R}\to\mathbb{R};$
\[f(x)=\begin{cases}1,\quad & x^2\in\mathbb{Q}\\
0,\quad & x\in\mathbb{R}\setminus\mathbb{Q}
\end{cases}\]
which is differentiable at $0$ with $f'(0)=0$ and discontinuous everywhere else.
\ssc{List of Integrals}
\sssc{Rational function}
\[\int\frac{f'(x)}{f(x)}\,\mathrm{d}x=\ln|f(x)|+C.\]
\[\int\frac{1}{x^2+a^2}\,\mathrm{d}x=\frac{1}{a}\arctan\frac{x}{a}+C.\]
\[\int\frac{1}{x^2-a^2}\,\mathrm{d}x=\frac{1}{2a}\ln\frac{x-a}{x+a}+C.\]
\[\int\frac{1}{a^2-x^2}\,\mathrm{d}x=\frac{1}{2a}\ln\frac{a+x}{a+x}+C.\]
\[\int\frac{1}{ax+b}\,\mathrm{d}x=\frac{1}{a}\ln|ax+b|+C.\]
\[\int(ax+b)^n\,\mathrm{d}x=\frac{(ax+b)^{n-1}}{a(n+1)}+C,\quad n\neq -1.\]
\[\int\frac{x}{ax+b}\,\mathrm{d}x=\frac{x}{a}-\frac{b}{a^2}\ln|ax+b|+C.\]
\[\int\frac{x}{(ax+b)^2}\,\mathrm{d}x=\frac{b}{a^2(ax+b)}+\frac{1}{a^2}\ln|ax+b|+C.\]
\[\int x(ax+b)^n\,\mathrm{d}x=\frac{a(n+1)x-b}{a^2(n+1)(n+2)}(ax+b)^{n+1}+C,\quad n\notin\{-1,-2\}.\]
\sssc{Irrational function}
\[\int\sqrt{a^2+x^2}\,\mathrm{d}x=\frac{x}{2}\sqrt{a^2+x^2}+\frac{a^2}{2}\ln\qty(x+\sqrt{a^2+x^2})+C.\]
\[\int\sqrt{x^2-a^2}\,\mathrm{d}x=\frac{x}{2}\sqrt{x^2-a^2}-\frac{a^2}{2}\ln\qty(x+\sqrt{x^2-a^2})+C,\quad x^2>a^2.\]
\[\int\sqrt{a^2-x^2}\,\mathrm{d}x=\frac{x}{2}\sqrt{a^2-x^2}+\frac{a^2}{2}\arcsin\frac{x}{|a|}+C,\quad|a|\geq|x|.\]
\ssc{Lists of Laplace Transform}{{{
\ssc{Lists Fourier Transform}{{{



\sct{Numerical Analysis (數值分析)}
\ssc{Numerical differentiation (數值微分)}
\sssc{Newton's Method (牛頓法) or Newton-Raphson Method (牛頓-拉普森法)}
Newton's method, also known as Newton-Raphson method, is an iterative technique used to approximate the roots of a real-valued function. Given a function $f(x)$ and an initial guess \( x_0 \) close to a root, Newton's method refines this guess by repeatedly applying the formula:
\[
x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)},n\in\mathbb{N}
\]
where:
\begin{itemize}
\item \( x_n \) is the current approximation,
\item \( f(x_n) \) is the value of the function at \( x_n \),
\item \( f'(x_n) \) is the derivative of \( f(x) \) evaluated at \( x_n \).
\end{itemize}
\ssc{Numerical integration (數值積分)}
\sssc{The trapezoidal rule (梯形法)}
Let $f$ be a continuous real-valued function on $[a,b]$, the trapezoidal rule gives the approximation
\[\int_a^bf(x)\,\mathrm{d}x\approx\frac{b-a}{2n}\left(2\left(\sum_{i=0}^nf(a+\frac{i}{n}(b-a))\right)-f(a)-f(b)\right).\]
The error is defined as
\[E_n=\int_a^bf(x)\,\mathrm{d}x-\frac{b-a}{2n}\left(2\left(\sum_{i=0}^nf(a+\frac{i}{n}(b-a))\right)-f(a)-f(b)\right).\]
When $\frac{\mathrm{d}^2f(x)}{\mathrm{d}x^2}$ is continuous on $[a,b]$, the error satisfies that
\[\abs{E_n}\leq\frac{(b-a)^3}{12n^2}\max_{a\leq x\leq b}\left(\abs{\frac{\mathrm{d}^2f(x)}{\mathrm{d}x^2}}\right).\]
\sssc{The Simpson's rule (辛普森法) or the Simpson's 1 or 3 rule}
Let $f$ be a continuous real-valued function on $[a,b]$, the Simpson's rule gives the approximation
\[\int_a^bf(x)\,\mathrm{d}x\approx\frac{b-a}{3n}\left(2\left(\sum_{i=0}^nf(a+\frac{i}{n}(b-a))\right)+2\left(\sum_{i=1}^{\frac{n}{2}}f(a+\frac{2i-1}{n}(b-a))\right)-f(a)-f(b)\right),\]
where $\frac{n}{2}\in\mathbb{N}$.

The error is defined as
\[E_n=\int_a^bf(x)\,\mathrm{d}x-\frac{b-a}{3n}\left(2\left(\sum_{i=0}^nf(a+\frac{i}{n}(b-a))\right)+2\left(\sum_{i=1}^{\frac{n}{2}}f(a+\frac{2i-1}{n}(b-a))\right)-f(a)-f(b)\right).\]
When $\frac{\mathrm{d}^4f(x)}{\mathrm{d}x^4}$ is continuous on $[a,b]$, the error satisfies that
\[\abs{E_n}\leq\frac{(b-a)^5}{180n^4}\max_{a\leq x\leq b}\left(\abs{\frac{\mathrm{d}^4f(x)}{\mathrm{d}x^4}}\right).\]



\sct{Ordinary differential equations (ODE) (常微分方程)}
\ssc{Introduction}
\sssc{Differential form of first-order ODEs}
For a first-order ODE of a dependent variable $y$ with respect to an independent variable $x$,
\[M(x,y)=-N(x,y)\dv{y}{x},\]
where $M$ and $N$ are functions of two variables, $x$ and $y$, the differential form of it is
\[M(x,y)\dd{x}+N(x,y)\dd{y}=0.\]
\sssc{Normal form of ODEs}
The normal form of an $n$th-order ODE of a dependent variable $y$ in codomain $Y$ with respect to an independent variable $x$ in domain $X$ is
\[\dv[n]{y}{x}=F(x,y,y',y'',\dots y^{(n-1)}),\]
in which $F$ is a function of $(n+1)$ variables, $x,y,y',y'',\dots y^{(n-1)}$, with domain being a subset of $X\times Y^n$ and codomain being $Y$.
\sssc{Linear ODE}
An $n$th order ODE of a dependent variable $y$ with respect to an independent variable $x$ is linear if and only if it can be written in the form
\[\sum_{i=0}^na_n(x)y^{(i)}=g(x),\]
where $a_0(x),\dots a_n(x)$, called the coefficients, and $g(x)$, called the forcing term, are given functions of one variable, $x$, and $a_n(x)\neq 0$ on the domain of interest.

An ODE is nonlinear if it is not linear.

A linear ODE is called a homgeneous linear ODE if $g(x)=0$; otherwise, it is called a nonhomogeneous linear ODE.

Let $L[y]=\sum_{i=0}^na_n(x)y^{(i)}$ denotes the left-hand side, then $L[\alpha y_1+\beta y_2]=\alpha L[y_1]+\beta L[y_2]$. That's why it's called to be linear.
\sssc{Solution or flow of an ODE}
Any function $f$ that is defined on an interval $I$, called interval of definition, the interval of existence, the interval of validity, or the domain of the solution, and of class $C^n$ on $I$, and when substituted into an $n$th-order ordinary differential equation reduces the equation to an identity, is said to be a solution (aka flow) of the equation on $I$.

An ODE does not necessarily have to possess a solution.
\sssc{Solution curve or trajectory}
The graph of a solution $f$ on its interval of definition of an ODE is called a solution curve or a trajectory.
\sssc{Explicit solution}
An explicit solution of an ODE of a dependent variable $y$ with respect to an independent variable $x$ is in the form $y=f(x)$, where $f(x)$ is a function of $x$.
\sssc{Implicit solution}
A relation $G(x, y) = 0$ is said to be an implicit solution of an ODE on an interval $I$ if there exists at least one function $f$ that satisfes the relation $G(x, y) = 0$ as well as the ODE on $I$.
\sssc{Type of solutions}
An $n$-parameter family of solutions of an $(\geq n)$th-order ODE of a dependent variable $y$ with respect to an independent variable $x$ is in the form $y=f(x,c_1,c_2,\dots c_n)$ (explicit) or $G(x,y,c_1,c_2,\dots c_n)=0$ (implicit), in which $c_1,c_2,\dots c_n$ are parameters that are arbitrary given that the solution obtained is a solution of the ODE.

If every solution of an $(\geq n)$th-order ODE on an interval $I$ can be obtained from an $n$-parameter family of solutions by appropriate choices of the parameters, we then say that that family of solutions is the general solution (通解) of the ODE.

A solution of an ODE that is free of parameters is called a particular solution (特解).

Sometimes a differential equation possesses a solution that is not a member of a family of solutions of the equation, that is, a solution that cannot be obtained by specializing any of the parameters in the family of solutions. Such an extra solution is called a singular solution (奇異解).
\sssc{System of ODEs (常微分方程組)}
A system of ODEs is two or more equations involving the derivatives of two or more unknown functions or dependent variables of a single independent variable.

A solution of a system of ODEs involving the derivatives of $n$ unknown functions or dependent variables, $y_1,y_2,\dots y_n$ of a single independent variable $x$ is a $n$-tuple of sufficiently smooth functions of $x$ defined on a common interval of definition that satisfy all equations in the system.

A system of ODEs does not necessarily have to possess a solution.
\sssc{Initial-value problem (IVP) (初值問題)}
An $n$th-order initial-value problem is an $n$th-order ODE with $n$ conditions for $y$ and $(<n)$th derivative functions of $y$ at the same point, that is, $\{y^{(k)}(x_0)=y_k\}_{k\in[0,n-1]\cap\mathbb{Z}}$, called initial conditions (IC) (初始條件).

A solution of an IVP is a solution of the ODE that complies with all the ICs.

The interval of existence of an IVP is the largest open interval containing $x_0$ where a solution of the IVP exists; the interval of existence of an IVP is the largest open interval containing $x_0$ where a unique solution of the IVP exists.
\sssc{Rectangle}
A rectangle in $\mathbb{R}\times\mathbb{R}^n$ is a subset $D$ of it in the form:
\[D=\{(t,y)\mid|t-T|\leq a\land\forall\tx{\ integer\ }1\leq i\leq n\colon |y_i-Y_i|\leq b_i\}\]
where $t,T\in\mathbb{R}$, $y=(y_1, y_2,\dots  y_n)\in\mathbb{R}^n$, $Y=(Y_1, Y_2,\dots  Y_n)\in\mathbb{R}^n$, and constant $a,b_i\in\mathbb{R}_{>0}$.
\sssc{Peano existence theorem (皮亞諾存在性定理), Peano theorem (皮亞諾定理), or Cauchy–Peano theorem (柯西-皮亞諾定理)}
Let $D$ be an open subset of $\mathbb{R}\times\mathbb{R}^n$ and $f\colon D\to \mathbb {R}$ be a continuous function, then every initial value problem given by explicit first-order ODE $y'(t)=f\left(t,y(t)\right)$ defined on $D$ and initial condition $y\left(t_{0}\right)=y_{0}$ with $(t_{0},y_{0})\in D$ has a local solution $z\colon I\to \mathbb {R}^n$ where $I$ is a neighbourhood of $t_0$ in $\mathbb {R} $, such that $z'(t)=f\left(t,z(t)\right)$ for all $t\in I$.
\sssc{Carathéodory's existence theorem}
Let
\[D=\{(t,y)\mid|t-T|\leq a\land\forall\tx{\ integer\ }1\leq i\leq n\colon |y_i-Y_i|\leq b_i\}\]
be a rectangle in $\mathbb{R}\times\mathbb{R}^n$ where $t,T\in\mathbb{R}$, $y=(y_1, y_2,\dots  y_n)\in\mathbb{R}^n$, $Y=(Y_1, Y_2,\dots  Y_n)\in\mathbb{R}^n$, and constant $a,b_i\in\mathbb{R}_{>0}$, and $f\colon D\to \mathbb {R}$ be a function that is:
\bit
\item continuous in $y$ for each fixed $t$, 
\item Lebesgue-measurable in $t$ for each fixed $y$, and
\item such that there is a Lebesgue-integrable function $m\colon [T-a,T+a]\to [0,\infty )$ such that $|f(t,y)|\leq m(t)$ for all $(t,y)\in D$,
\end{itemize}
then every initial value problem given by explicit first-order ODE $y'(t)=f\left(t,y(t)\right)$ defined on $D$ and initial condition $y\left(t_{0}\right)=y_{0}$ with $(t_{0},y_{0})\in D$ has a local solution $z\colon I\to \mathbb {R}^n$ where $I$ is a neighbourhood of $t_0$ in $\mathbb {R} $, such that $z'(t)=f\left(t,z(t)\right)$ for all $t\in I$.
\sssc{Picard–Lindelöf theorem (皮卡-林德勒夫定理) or Cauchy–Lipschitz theorem (柯西-利普希茨定理)}
Let
\[D=\{(t,y)\mid|t-T|\leq a\land\forall\tx{\ integer\ }1\leq i\leq n\colon |y_i-Y_i|\leq b_i\}\]
be a rectangle in $\mathbb{R}\times\mathbb{R}^n$ where $t,T\in\mathbb{R}$, $y=(y_1, y_2,\dots  y_n)\in\mathbb{R}^n$, $Y=(Y_1, Y_2,\dots  Y_n)\in\mathbb{R}^n$, and constant $a,b_i\in\mathbb{R}_{>0}$, and $f\colon D\to \mathbb {R}$ be a function that is continuous in $t$ and Lipschitz continuous in all $y_i$, then every initial value problem given by explicit first-order ODE $y'(t)=f\left(t,y(t)\right)$ defined on $D$ and initial condition $y\left(t_{0}\right)=y_{0}$ with $(t_{0},y_{0})\in D$ has a unique local solution $z\colon I\to \mathbb {R}^n$ where $I$ is a neighbourhood of $t_0$ in $\mathbb {R} $, such that $z'(t)=f\left(t,z(t)\right)$ for all $t\in I$.
\sssc{Boundary-value problem (BVP) (邊值問題)}
An $n$th-order boundary-value problem is an $n$th-order ODE with some conditions called boundary conditions (BC) (邊界條件).

A solution of an BVP is a solution of the ODE that complies with all the BCs.
\sssc{Slope function or rate function}
In a first-order ODE in the form $\dv{y}{x}=f(x,y)$, $f$ is called the slope function or rate function.
\sssc{Direction field or slope field (斜率場)}
In a first-order ODE in the form $\dv{y}{x}=f(x,y)$, if we evaluate $f$ over a rectangle grid of points and draw a lineal element at each point $(x,y)$ of the grid with slope $f(x,y)$, then the collection of all these lineal elements is called a direction field or a slope field of the ODE.
\sssc{Isocline}
In a first-order ODE in the form $\dv{y}{x}=f(x,y)$, the isocline for slope $m$ is defined as the family of points $\{(x,y)\mid f(x,y)=m\}$. In the method of isocline, we draw a lineal element at each point in the isocline for slope $m$ of $f$ with slope $m$.
\sssc{Autonomous system (自治系統) (of ODEs)}
A system of first-order ODE is called autonomous if it can be written in the form 
\[\dv{x}{t}=f(x),\quad x\in D\subseteq\mathbb{R}^n\land f\colon D\to\mathbb{R}^n.\]
\sssc{Critical point (臨界點), equilibrium, equilibrium point (平衡點), or stationary point (駐點) of autonomous systems of ODEs}
For an autonomous systems of ODEs $\dv{y}{x}=f(y)$, we say that a point $c$ in the domain of $f$ is a critical point, equilibrium, equilibrium point, or stationary point if $f(c)=0$.

If $c$ is a critical point, then $y(x)=c$ is a constant solution of the system of autonomous first-order ODEs, also called an equilibrium solution (平衡解).

If $c$ is a critical point and $f$ is locally Lipschitz at $c$, then $y(x)=c$ is the unique solution of the system of autonomous first-order ODEs through $c$.
\sssc{Translation property or shift property of solutions of autonomous systems of ODEs}
Let function $\Phi(t,y)$ denotes the solution of the autonomous system of ODEs
\[\dv{x}{t}=f(x),\quad x\in D\subseteq\mathbb{R}^n\land f\colon D\to\mathbb{R}^n,\]
with IC $x(0)=y$.

Then the translation property or shift property states that
\[\forall s\in\mathbb{R}\colon\Phi(t+s,y)=\Phi(t,\Phi(s,y)).\]
\ssc{Solving a separable ODE}


\end{document}
