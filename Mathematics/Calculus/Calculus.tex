\documentclass[a4paper,12pt]{report}
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{3}
\input{/usr/share/LaTeX-ToolKit/template.tex}
\begin{document}
\title{Calculus}
\author{沈威宇}
\date{\temtoday}
\titletocdoc
\chapter{Calculus (微積分)}
\section{Limit (極限)}
\subsection{Limits of Real Sequences}
Below, we are discussing limits of sequences with domain $\mathbb{N}$ and codomain $\mathbb{R}$. For sequences $\langle a_n\rangle_{i=l}^\infty$ in $\mathbb{R}$, its limit is the same as the limit of another sequence $\langle b_n=a_{n+l-1}\rangle_{i=1}^\infty$.
\subsubsection{Definition}
For a real sequence \(\langle a_n\rangle\), the limit of \(\langle a_n\rangle\) (as $n$ approaches infinity), denoted as $\lim_{n \to \infty} a_n$ or $\lim_n a_n$, is defined as follows:
\[\lim_{n \to \infty} a_n = L \equiv \forall \epsilon > 0:\, \exists M \in\mathbb{N}\text{\ s.t.\ } n\in\mathbb{N}\land n \geq M\implies |a_n - L| < \epsilon.\]
In other words, as \(n\) becomes arbitrarily large, \(a_n\) gets arbitrarily close to \(L\).

If such $M$ exists, we say the limit exists or the sequence converges (收斂) to $L$; otherwise, we say the limit doesn't exist or the sequence diverge (發散).
\subsubsection{Infinite Limits}
\[\lim_{n\to \infty}a_n=\infty \equiv \forall M > 0, \exists M \in\mathbb{N} \text{\ s.t.\ } n\in\mathbb{N}\land n \geq M \implies a_n > M.\]
\[\lim_{n\to \infty}a_n=-\infty \equiv \forall M < 0, \exists M \in\mathbb{N} \text{\ s.t.\ } n\in\mathbb{N}\land n \geq M \implies a_n < M.\]
Note that if a limit equals to $\infty$ or $-\infty$, the limit doesn't exist.
\sssc{Preservation of equal to}
Given real sequences $\langle a_n\rangle$ and $\langle b_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$, $a_k=b_k$. If $\lim_{n\to\infty}a_n=L\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{n\to\infty}b_n=L.\]
\sssc{Preservation of less than or equal to}
Given real sequences $\langle a_n\rangle$ and $\langle b_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$, $a_k\leq b_k$. If both $\lim_{n\to\infty}a_n$ and $\lim_{n\to\infty}b_n$ are in $\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{n\to\infty}a_n\leq\lim_{n\to\infty}b_n.\]
If $\lim_{n\to\infty}a_n=\infty$, then $\lim_{n\to\infty}b_n=\infty$; if $\lim_{n\to\infty}b_n=-\infty$, then $\lim_{n\to\infty}a_n=-\infty$.
\sssc{Squeeze (夾擠) theorem or Sandwich (三明治) theorem}
Given real sequences $\langle a_n\rangle$, $\langle b_n\rangle$, and $\langle c_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$:
\[a_k\leq c_k\leq b_k.\]
If
\[\lim_{n\to\infty}a_n=\lim_{n\to\infty}b_n=L\in\mathbb{R}\cup\{-\infty,\infty\},\]
then
\[\lim_{n\to\infty}c_n=L.\]
\subsubsection{Monotone Convergence Theorem (單調收斂定理) or Completeness (Axiom) of the Real Numbers (實數的完備性)}
\textit{Statement.}
\begin{enumerate}[label=(\Alph*)]
\item For a non-decreasing and bounded-above sequence of real numbers $\langle a_n\rangle_{n\in\mathbb {N}}$:
\[\lim_{n\to\infty}a_n=\sup_n a_n.\]
\item For a non-increasing and bounded-below sequence of real numbers $\langle a_n\rangle_{n\in\mathbb {N}}$:
\[\lim_{n\to\infty}a_n=\inf_n a_n.\]
\end{enumerate}
\begin{proof}\mbox{}\\
Let $\{a_{n}\}$ be the set of values of $\langle a_n\rangle_{n\in\mathbb {N}}$. By assumption, $\{a_n\}$ is non-empty and bounded-above by $\sup_n a_n$. Let $c=\sup_n a_n$.
\[\forall\epsilon>0:\,\exists M\in\mathbb {N}\text{\ s.t.\ }c\geq a_M>c-\epsilon,\]
since otherwise $c-\epsilon$ is a strictly smaller upper bound of $\langle a_n\rangle$, contradicting the definition of the supremum. 

Then since $\langle a_n\rangle$ is non-decreasing, and $c$ is an upper bound:
\[\forall\epsilon>0:\,\exists M\in\mathbb {N}\text{\ s.t.\ }\forall n\geq M:\,|c-a_n|=c-a_n\leq c-a_M=|c-a_M|<\epsilon.\]
The proof of the (B) part is analogous or follows from (A) by considering $\langle -a_{n}\rangle_{n\in \mathbb{N}}$.
\end{proof}
\textit{Statement.}

If $\langle a_n\rangle_{n\in\mathbb {N}}$ is a monotone sequence of real numbers, i.e., if 
$a_n\leq a_{n+1}$ for every $n\geq 1$ or $a_n\geq a_{n+1}$ for every $n\geq 1$, then this sequence has a finite limit if and only if the sequence is bounded.
\begin{proof}\mbox{}\\
"If"-direction: The proof follows directly from the proposition.

"Only If"-direction: By $(\epsilon,\delta)$-definition of limit, every sequence $\langle a_n\rangle_{n\in\mathbb {N}}$ with a finite limit $L$ is necessarily bounded.
\end{proof}
\sssc{Bolzano–Weierstrass Theorem (波爾查諾-魏爾斯特拉斯定理)}
Every bounded sequence in an Euclidean space $\bbR^n$ has a convergent subsequence.

\begin{proof}\mbox{}\\
    For $\bbR$, take any bounded sequence $(x_n)$ in $\bbR$. Then there exist real numbers $m,M$ such that
    \[m\leq x_n\leq M,\quad\forall n.\]
    So the sequence lies in the closed interval $[m,M]$.

    For $\varepsilon=1$. Divide $[m,M]$ into disjoint subintervals with length $\frac{M-m}{2^\varepsilon}$:
    \[\qty[m,\frac{m+M}{2}],\qty[\frac{m+M}{2},M].\]
    Since $(x_n)$ is infinite, by the pigeonhole principle, one of the subintervals must contain infinitely many terms of $(x_n)$. Denote it by $I_1$ and pick the subsequence $\qty(x_n^{(1)})$ of $(x_n)$ that is entirely in $I_1$.

    Repeat it for $\varepsilon=2,3,\ldots$ by dividing $I_{\varepsilon-1}$ into two halves, we can construct a nested sequence of subsequences
    \[\qty(x_n^{(1)})\supseteq \qty(x_n^{(2)})\supseteq\ldots\]
    where $\qty(x_n^{(k)})$ lies in a closed interval of length $\frac{M-m}{2^k}$, $I_k$.

    Pick the diagonal sequence $y_k=x_k^{(k)}$. Then
    \[y_k\in\qty(x_n^{(k)})\subseteq I_k,\]
    and the sequence $(y_k)$ is a convergent subsequence of $(x_n)$ because
    \[\forall N\in\bbN\colon m,n\geq N\implies |y_m-y_n|\leq\frac{M-m}{2^N}.\]

    To generalized to $\bbR^n$, consider each coordinate sequence in $\bbR$, it has a convergent subsequence. Diagonalization gives a subsequence converging in all coordinates.
\end{proof}
\subsection{Limits of Real Series}
\subsubsection{Definition}
Let:
\[S_n = \sum_{i=1}^n a_i,\]
where \(a_i\) are terms of a real sequence. The limit of \(S_n\), denoted as \(\lim_{n\to\infty}S_n\) or \(\sum_{i=1}^{\infty}a_i\), is defined as the following:
\[\sum_{i=1}^{\infty}a_i = L \equiv \forall \epsilon > 0:\, \exists M \in\mathbb{N}\text{\ s.t.\ } n \geq M\implies |S_n - L| < \epsilon.\]

If such $M$ exists, we say the limit exists or the series converges to $L$; otherwise, we say the limit doesn't exist or the series diverge.
\subsubsection{Absolute convergence and conditional convergence}
A series $S_n=\sum_{i=1}^{\infty}a_i$ converges absolutely to $L$ if $\exists\lim_{n\to\infty}\sum_{i=1}^{\infty}\abs{a_1}\land\lim_{n\to\infty}\sum_{i=1}^{\infty}\abs{a_1}=L$. If $S_n$ is convergent but not convergent absolutely, we say $S_n$ converges conditionally.
\sssc{Preservation of equal to}
Given real sequences $\langle a_n\rangle$ and $\langle b_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$:
\[\sum_{i=1}^ka_i=\sum_{i=1}^kb_i.\]
If $\sum_{i=1}^{\infty}a_i=L\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\sum_{i=1}^{\infty}b_i=L.\]
\sssc{Preservation of less than or equal to}
Given real sequences $\langle a_n\rangle$ and $\langle b_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$:
\[\sum_{i=1}^ka_i\leq\sum_{i=1}^kb_i.\]
If both $\sum_{i=1}^{\infty}a_i$ and $\sum_{i=1}^{\infty}b_i$ are in $\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\sum_{i=1}^{\infty}a_i\leq\sum_{i=1}^{\infty}b_i.\]
\sssc{Squeeze theorem or Sandwich theorem}
Given real sequences $\langle a_n\rangle$, $\langle b_n\rangle$, and $\langle c_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$:
\[\sum_{i=1}^ka_i\leq\sum_{i=1}^kc_i\leq\sum_{i=1}^kb_i.\]
If
\[\sum_{i=1}^{\infty}a_i=\sum_{i=1}^{\infty}b_i=L\in\mathbb{R}\cup\{-\infty,\infty\},\]
then: 
\[\sum_{i=1}^{\infty}c_i=L.\]
\subsection{Limits of Real Nets}
Below, we are discussing limits of nets in the set of real number.
\subsubsection{Definition}
For a real net $\langle x_a\rangle_{a\in A}$ in which $A$ is a directed set, the limit of $\langle x_a\rangle_{a\in A}$, denoted as $\lim_{a\in A} x_a$ or $\lim_a x_a$, is defined as follows:
\[\lim_ax_a = L \equiv \forall \epsilon > 0:\, \exists a_0 \in A\text{\ s.t.\ } a\in A\land a\ge a_0\implies |x_a - L| < \epsilon.\]

If such $a_0$ exists, we say the limit exists or the net converges to $L$; otherwise, we say the limit doesn't exist.
\subsubsection{Infinite Limits}
\[\lim_{a}x_a=\infty \equiv \forall M > 0, \exists a_0 \in A \text{\ s.t.\ } a\in A\land a\geq a_0 \implies x_a > M.\]
\[\lim_{a}x_a=-\infty \equiv \forall M < 0, \exists a_0 \in A \text{\ s.t.\ } a\in A\land a\geq a_0 \implies x_a < M.\]
Note that if a limit equals to $\infty$ or $-\infty$, the limit doesn't exist.
\sssc{Preservation of equal to}
Let $A$ be a directed set. Given real nets $\langle x_a\rangle_{a\in A}$ and $\langle y_a\rangle_{a\in A}$ which for all $k\in A$ such that there exists $j\in A$ with $j\leq k$, $x_k=y_k$. If $\lim_{a}x_a$ exists, then:
\[\lim_{a}x_a=\lim_{a}y_a.\]
\sssc{Preservation of less than or equal to}
Let $A$ be a directed set. Given real nets $\langle x_a\rangle_{a\in A}$ and $\langle y_a\rangle_{a\in A}$ which for all $k\in A$ such that there exists $j\in A$ with $j\leq k$, $x_k\leq y_k$. If both $\lim_{a}x_a$ and $\lim_{a}y_a$ exist, then:
\[\lim_{a}x_a\leq\lim_{a}y_a.\]
\sssc{Squeeze theorem or Sandwich theorem}
Let $A$ be a directed set. Given real nets $\langle x_a\rangle_{a\in A}$, $\langle y_a\rangle_{a\in A}$, and $\langle z_a\rangle_{a\in A}$ which for all $k\in A$ such that there exists $j\in A$ with $j\leq k$:
\[x_k\leq z_k\leq y_k.\]
If
\[\lim_{a}x_a=\lim_{a}y_a=L,\]
then: 
\[\lim_{a}z_a=L.\]
\begin{proof}
Start from the limits of $x_a$ and $y_a$, by definition of limit:

For every $\varepsilon\in\mathbb{R}_{>0}$, there exists some $a_1\in A$ such that for every $b\in A$ with $b\geq a_1$, the point $L-\varepsilon\leq x_b\leq L+\varepsilon$.

For every $\varepsilon\in\mathbb{R}_{>0}$, there exists some $a_2\in A$ such that for every $b\in A$ with $b\geq a_2$, the point $L-\varepsilon\leq y_b\leq L+\varepsilon$.

Choose $a\in A$ such that $a_1\leq a$ and $a_2\leq a$.

so,
\[L-\varepsilon\leq x_{a}\leq z_{a}\leq y_{a}\leq L+\varepsilon.\]

Since $\varepsilon > 0$ was arbitrary, by definition of limit:
\[\lim_{a}z_a=L.\]
\end{proof}
\subsection{Limits of Functions with Real Domains}
\subsubsection{Definition at Finity}
Let \(I\) be an interval containing the point \(a\). Let \( f(x) \) be a function defined on \(I\), except possibly at \(a\) itself. The limit of \( f(x) \) as \( x \) approaches \( a \) is defined as follows:
\[\lim_{x \to a} f(x) = L \equiv \forall \epsilon > 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < |x - a| < \delta \implies |f(x) - L| < \epsilon.\]
In other words, as \(x\) becomes arbitrarily close to \(a\), \(f(x)\) gets arbitrarily close to \(L\).

If such $\detla$s exist, we say the limit exists; otherwise, we say the limit doesn't exist.
\subsubsection{Definition at Infinity}
Let \(I\) be a left-bounded, right-unbounded interval with the point \(a\) being its endpoint on the left. Let \( f(x) \) be a function defined on \(I\). The limit of \( f(x) \) as \( x \) approaches \( \infty \) is defined as follows:
\[\lim_{x \to \infty} f(x) = L \equiv \forall \epsilon > 0: \, \exists M > a \text{\ s.t.\ } x > M \implies |f(x) - L| < \epsilon.\]
In other words, as \(x\) becomes arbitrarily large, \(f(x)\) gets arbitrarily close to \(L\). We say $f(x)$ converge to $L$ as $x\to\infty$ if $\lim_{x \to \infty} f(x) = L$.

Let \(I\) be a right-bounded, left-unbounded interval with the point \(a\) being its endpoint on the right. Let \( f(x) \) be a function defined on \(I\). The limit of \( f(x) \) as \( x \) approaches \( -\infty \) is defined as follows:
\[\lim_{x \to -\infty} f(x) = L \equiv \forall \epsilon > 0: \, \exists M < a \text{\ s.t.\ } x < M \implies |f(x) - L| < \epsilon.\]
In other words, as \(x\) becomes arbitrarily small, \(f(x)\) gets arbitrarily close to \(L\). We say $f(x)$ converge to $L$ as $x\to-\infty$ if $\lim_{x \to -\infty} f(x) = L$.
\subsubsection{Horizontal asymptote (水平漸近線)}
\[ \qty(\lim_{x \to \infty} f(x)=L \lor\lim_{x \to -\infty} f(x)=L) \iff \qty(y=L\tx{ is a horizontal asymptote of $y=f(x)$}).\]
\subsubsection{Slant asymptote (斜漸近線)}
\[ \qty(\lim_{x \to \infty} f(x)-(mx+b)=0 \lor\lim_{x \to -\infty} f(x)-(mx+b)=0) \iff \qty(y=mx+b\tx{\ is a slant asymptote of $y=f(x)$}).\]
\subsubsection{One-side Limits}
\tb{Right-hand Limit (右極限)}: Let \(I\) be a left-open interval with the point \(a\) being its endpoint on the left. Let \( f(x) \) be a function defined on \(I\). The right-hand limit of \( f(x) \) as \( x \) approaches \( a \) is defined as follows:
\[\lim_{x \to a^+} f(x) = L \equiv \forall \epsilon > 0 :\,\exists \delta > 0 \text{\ s.t.\ } 0 < x - a < \delta \implies |f(x) - L| < \epsilon.\]
In other words, as \(x\) becomes arbitrarily close to \(a\) and is greater than \(a\), \(f(x)\) gets arbitrarily close to \(L\). For a function $f(x)$, $\lim_{x\to a^+}f(x)$ can also be denoted as $f(a^+)$.

\tb{Left-hand Limit (左極限)}: Let \(I\) be a right-open interval with the point \(a\) being its endpoint on the right. Let \( f(x) \) be a function defined on \(I\). The left-hand limit of \( f(x) \) as \( x \) approaches \( a \) is defined as follows:
\[\lim_{x \to a^-} f(x) = L \equiv \forall \epsilon > 0 :\,\exists \delta > 0 \text{\ s.t.\ } 0 < a - x < \delta \implies |f(x) - L| < \epsilon.\]
In other words, as \(x\) becomes arbitrarily close to \(a\) and is less than \(a\), \(f(x)\) gets arbitrarily close to \(L\). For a function $f(x)$, $\lim_{x\to a^-}f(x)$ can also be denoted as $f(a^-)$.
\subsubsection{Infinite Limits}
\[\lim_{x\to a}f(x)=\infty \equiv \forall N > 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < |x - a| < \delta \implies f(x) > N.\]
\[\lim_{x\to a^+}f(x)=\infty \equiv \forall N > 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < x - a < \delta \implies f(x) > N.\]
\[\lim_{x\to a^-}f(x)=\infty \equiv \forall N > 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < a - x < \delta \implies f(x) > N.\]
\[\lim_{x\to a}f(x)=-\infty \equiv \forall N < 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < |x - a| < \delta \implies f(x) < N.\]
\[\lim_{x\to a^+}f(x)=-\infty \equiv \forall N < 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < x - a < \delta \implies f(x) < N.\]
\[\lim_{x\to a^-}f(x)=-\infty \equiv \forall N < 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < a - x < \delta \implies f(x) < N.\]
\[\lim_{x\to\infty}f(x)=\infty \equiv \forall N > 0:\, \exists M > 0 \text{\ s.t.\ } x > M \implies f(x) > N.\]
\[\lim_{x\to\infty}f(x)=-\infty \equiv \forall N > 0:\, \exists M > 0 \text{\ s.t.\ } x > M \implies f(x) < N.\]
\[\lim_{x\to-\infty}f(x)=\infty \equiv \forall N > 0:\, \exists M < 0 \text{\ s.t.\ } x < M \implies f(x) > N.\]
\[\lim_{x\to-\infty}f(x)=-\infty \equiv \forall N > 0:\, \exists M < 0 \text{\ s.t.\ } x < M \implies f(x) < N.\]
Note that if a limit equals to $\infty$ or $-\infty$, the limit doesn't exist.
\sssc{Vertical asymptote (鉛直漸近線)}
\[\qty(\exists a\in\mathbb{R}\colon\abs{\lim_{x \to a^+} f(x)}=\infty\lor\abs{\lim_{x \to a^-} f(x)}=\infty)\iff \qty(x=a\tx{\ is a vertical asymptote of $y=f(x)$}).\]
\sssc{Preservation of equal to}
Let $I$ be an open interval and $a\in I$, and $f(x)$ and $g(x)$ be functions defined on $I\setminus\{a\}$ which for all $x\in I\land x\neq a$, $f(x)=g(x)$. If $\lim_{x\to a}f(x)=L\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to a}g(x)=L.\]

Let $f(x)$ and $g(x)$ be functions defined on $(a,b)$ with $a<b$ which for all $x\in I$, $f(x)=g(x)$. If $\lim_{x\to a^+}f(x)=L\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to a^+}g(x)=L.\]

Let $f(x)$ and $g(x)$ be functions defined on $(b,a)$ with $a>b$ which for all $x\in I$, $f(x)=g(x)$. If $\lim_{x\to a^-}f(x)=L\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to a^-}g(x)=L.\]

Let $f(x)$ and $g(x)$ be functions defined on $(a,\infty)$ which for all $x\in I$, $f(x)=g(x)$. If $\lim_{x\to\infty}f(x)=L\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to\infty}g(x)=L.\]

Let $f(x)$ and $g(x)$ be functions defined on $(-\infty,a)$ which for all $x\in I$, $f(x)=g(x)$. If $\lim_{x\to-\infty}f(x)=L\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to-\infty}g(x)=L.\]
\sssc{Preservation of less than or equal to}
Let $I$ be an open interval and $a\in I$, and $f(x)$ and $g(x)$ be functions defined on $I\setminus\{a\}$ which for all $x\in I\land x\neq a$, $f(x)\leq g(x)$. If both $\lim_{x\to a}f(x)$ and $\lim_{x\to a}g(x)$ are in $\mathbb{R}\setminus\{-\infty,\infty\}$, then
\[\lim_{x\to a}f(x)\leq\lim_{x\to a}g(x).\]
If $\lim_{x\to a}f(x)=\infty$, then $\lim_{x\to a}g(x)=\infty$; if $\lim_{x\to a}g(x)=-\infty$, then $\lim_{x\to a}f(x)=-\infty$.

Let $f(x)$ and $g(x)$ be functions defined on $(a,b)$ with $a<b$ which for all $x\in I$, $f(x)\leq g(x)$. If both $\lim_{x\to a^+}f(x)$ and $\lim_{x\to a^+}g(x)$ are in $\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to a^+}f(x)\leq\lim_{x\to a^+}g(x).\]
If $\lim_{x\to a^+}f(x)=\infty$, then $\lim_{x\to a^+}g(x)=\infty$; if $\lim_{x\to a^+}g(x)=-\infty$, then $\lim_{x\to a^+}f(x)=-\infty$.

Let $f(x)$ and $g(x)$ be functions defined on $(b,a)$ with $a>b$ which for all $x\in I$, $f(x)\leq g(x)$. If both $\lim_{x\to a^-}f(x)$ and $\lim_{x\to a^-}g(x)$ are in $\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to a^-}f(x)\leq\lim_{x\to a^-}g(x).\]
If $\lim_{x\to a^-}f(x)=\infty$, then $\lim_{x\to a^-}g(x)=\infty$; if $\lim_{x\to a^-}g(x)=-\infty$, then $\lim_{x\to a^-}f(x)=-\infty$.

Let $f(x)$ and $g(x)$ be functions defined on $(a,\infty)$ which for all $x\in I$, $f(x)\leq g(x)$. If both $\lim_{x\to\infty}f(x)$ and $\lim_{x\to\infty}g(x)$ are in $\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to\infty}f(x)\leq\lim_{x\to\infty}g(x).\]
If $\lim_{x\to\infty}f(x)=\infty$, then $\lim_{x\to\infty}g(x)=\infty$; if $\lim_{x\to\infty}g(x)=-\infty$, then $\lim_{x\to\infty}f(x)=-\infty$.

Let $f(x)$ and $g(x)$ be functions defined on $(-\infty,a)$ which for all $x\in I$, $f(x)\leq g(x)$. If both $\lim_{x\to-\infty}f(x)$ and $\lim_{x\to-\infty}g(x)$ are in $\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to-\infty}f(x)\leq\lim_{x\to-\infty}g(x).\]
If $\lim_{x\to-\infty}f(x)=\infty$, then $\lim_{x\to-\infty}g(x)=\infty$; if $\lim_{x\to-\infty}g(x)=-\infty$, then $\lim_{x\to-\infty}f(x)=-\infty$.
\subsubsection{Squeeze theorem or Sandwich theorem}
Let $I$ be an open interval and $a\in I$, and $f(x)$, $g(x)$, and $h(x)$ be functions defined on $I\setminus\{a\}$ which for all $x\in I\land x\neq a$, $f(x)\leq h(x)\leq g(x)$. If
\[\lim_{x\to a}f(x)=\lim_{x\to a}g(x)=L\in\mathbb{R}\setminus\{-\infty,\infty\},\]
then
\[\lim_{x\to a}h(x)=L.\]

Let $f(x)$, $g(x)$, and $h(x)$ be functions defined on $(a,b)$ with $a<b$ which for all $x\in I$, $f(x)\leq h(x)\leq g(x)$. If
\[\lim_{x\to a^+}f(x)=\lim_{x\to a^+}g(x)=L\in\mathbb{R}\setminus\{-\infty,\infty\},\]
then
\[\lim_{x\to a^+}h(x)=L.\]

Let $f(x)$, $g(x)$, and $h(x)$ be functions defined on $(b,a)$ with $a>b$ which for all $x\in I$, $f(x)\leq h(x)\leq g(x)$. If
\[\lim_{x\to a^-}f(x)=\lim_{x\to a^-}g(x)=L\in\mathbb{R}\setminus\{-\infty,\infty\},\]
then
\[\lim_{x\to a^-}h(x)=L.\]

Let $f(x)$, $g(x)$, and $h(x)$ be functions defined on $(a,\infty)$ which for all $x\in I$, $f(x)\leq h(x)\leq g(x)$. If
\[\lim_{x\to\infty}f(x)=\lim_{x\to\infty}g(x)=L\in\mathbb{R}\setminus\{-\infty,\infty\},\]
then
\[\lim_{x\to\infty}h(x)=L.\]

Let $f(x)$, $g(x)$, and $h(x)$ be functions defined on $(-\infty,a)$ which for all $x\in I$, $f(x)\leq h(x)\leq g(x)$. If
\[\lim_{x\to-\infty}f(x)=\lim_{x\to-\infty}g(x)=L\in\mathbb{R}\setminus\{-\infty,\infty\},\]
then
\[\lim_{x\to-\infty}h(x)=L.\]
\begin{proof}
Take the first statement for example. The other statements can be proved similarly.

Start from the limits of $f$ and $g$, by definition of limit:
\[\forall\varepsilon>0, \exists\delta_1>0\text{\ s.t.\ }0<|x-a|<\delta_1\implies|f(x)-L|<\varepsilon,\]
and
\[\forall\varepsilon>0, \exists\delta_2>0\text{\ s.t.\ }0<|x-a|<\delta_2\implies|g(x)-L|<\varepsilon,\]

Choose:
\[\delta\coloneq\min(\delta_1,\delta_2),\]

so,
\[L-\varepsilon<f(x)\leq h(x)\leq g(x)<L+\varepsilon.\]

Since $\varepsilon > 0$ was arbitrary, by definition of limit:
\[\lim_{x\to a}h(x)=L.\]
\end{proof}
\sssc{Limits involving quotient functions}
Let \( a \) and \( b \) be real numbers, set
\[A=\left\{f\colon U\subseteq\mathbb{R}\to\mathbb{R} \middle | f(x) = x \lor \ln(f(x)) \in A \lor e^{f\left(x\right)}  \in A \right\},\]
and function $f\in A$. Then:
\[\lim_{x \to \infty} \frac{\left(f\left(x\right)\right)^a}{\left(f\left(x\right)\right)^b} = \infty, \quad a > b \]
\[ \lim_{x \to \infty} \frac{af\left(x\right)}{bf\left(x\right)} = \frac{a}{b}, \quad b \neq 0 \]
\[ \lim_{x \to \infty}\frac{n^{af\left(x\right)}}{bf\left(x\right)} = \infty, \quad a,b > 0 \land  n > 1 \]
\[ \lim_{x \to \infty}\frac{n^{af\left(x\right)}}{bf\left(x\right)} = 0, \quad a,b > 0 \land  0\leq n<1 \]
\[ \lim_{x \to \infty}\frac{af\left(x\right)}{b\log_n f\left(x\right)} = \infty, \quad a,b > 0 \land  n > 1 \]
\ssc{Limit of nets of fuctions}
\sssc{Pointwise convergence (逐點收斂)}
Let $V$ be a set and $Y$ be a topological space. A net of functions $\lange f_n\rangle_{n\in A}$ all having the same domain $X\subseteq V$ and codomain $Y$ is said to converge pointwise to a given function $f\colon X\to Y$, denoted as 
\[\lim_nf_n=f\text{\ pointwise},\]
if and only if
\[\forall x\in X\colon\lim_nf_n(x)=f(x).\]
The function $f$ is said to be the pointwise limit function of $\lange f_n\rangle$.
\sssc{Uniform convergence (一致收斂)}
Let $V$ be a set and $(Y,d)$ be a metric topological space. A net of functions $\lange f_n\rangle_{n\in A}$ all having the same domain $X\subseteq V$ and codomain $Y$ is said to converge uniformly to a given function $f\colon X\to Y$, denoted as 
\[\lim_nf_n=f\text{\ uniformly},\]
if and only if
\[\forall\varepsilon\in\mathbb{R}_{>0}\colon\exists N\in A\text{\ s.t.\ }\left(n\in A\land N\leq n\implies\sup_{x\in X}d(f_n(x),f(x))<\varepsilon\right).\]
The function $f$ is said to be the uniform limit function of $\lange f_n\rangle$.
\ssc{Limit Laws}
Limits (including one-sided ones for functions with real domains) of sequences, series, nets, or functions with real domains (hereinafter referred to as functions) that are in $\mathbb{R}\cup\{-\infty,\infty\}$ follow the following law.
\sssc{Linearity or sum law, difference law, and constant multiple law}
The limit of a sum of constant multiples of functions is the sum of the constant multiples of the limits of the functions.
\sssc{Product law}
The limit of a product of functions is the product of the limits of the functions.
\sssc{Quotient law}
The limit of a quotient of functions is the quotient of the limits of the functions, provided that the limit of the denominator is not 0.
\sssc{Power law}
The limit of the $n$th power of a function, in which $n$ is a positive integer, is the $n$th power of the limit of the function.
\sssc{Root law}
The limit of the $n$th root of a function, in which $n$ is a positive integer, is the $n$th root of the limit of the function.
\sssc{The Uniqueness of Limits}
If a limit exists, it is unique.



\section{Continuity (連續性)}
\ssc{Continuity}
\sssc{Definition of continuity of real functions}
\begin{itemize}
\item For a point $a$ in the domain of a function $f$, if and only if $\exists\lim_{x\to a}f(x)$ and $\lim_{x\to a}f(x)=f(a)$, we say $f(x)$ is continuous (連續的) at $a$.
\item For a point $a$ in the domain of a function $f$, if and only if $\exists\lim_{x\to a^+}f(x)$ and $\lim_{x\to a^+}f(x)=f(a)$, we say $f(x)$ is continuous from the right at $a$; if and only if $\exists \lim_{x\to a^-} f(x)$ and $\lim_{x\to a^-} f(x)=f(a)$, we say $f(x)$ is continuous from the left at $a$.
\item For an open interval $I$ that is a subset of the domain of a function $f$, if and only if $f(x)$ is continuous at all points in $I$, we say $f(x)$ is continuous on $I$.
\item For an right-open interval $[a,b)$ that is a subset of the domain of a function $f$, if and only if $f(x)$ is continuous on $(a,b)$ and continuous from the right at $a$, we say $f(x)$ is continuous on $[a,b)$.
\item For an left-open interval $(a,b]$ that is a subset of the domain of a function $f$, if and only if $f(x)$ is continuous on $(a,b)$ and continuous from the left at $b$, we say $f(x)$ is continuous on $(a,b]$.
\item For an closed interval $[a,b]$ that is a subset of the domain of a function $f$, if and only if $f(x)$ is continuous on both $[a,b)$ and $(a,b]$, we say $f(x)$ is continuous on $[a,b]$.
\item if and only if $f(x)$ is continuous at all points in its domain, we say $f(x)$ is continuous.
\eit
\sssc{Definition of continuity of functions between topological spaces}
\begin{itemize}
\item A function $f\colon I\subeteq X\to Y$ where $X$ and $Y$ are topological spaces is continuous at a point $x\in I$ if and only if for any neighborhood $V$ of $f(x)$ in $Y$, there is a neighborhood $U$ of $x$ such that $f(U)\subseteq V$.
\item A function $f\colon I\subeteq X\to Y$ where $X$ and $Y$ are topological spaces is continuous if and only if for any open subset $V$ of $Y$, the preimage of $f$ on $V$ is an open subset of $X$.
\item A function $f\colon I\subeteq X\to Y$ where $X$ and $Y$ are topological spaces is continuous on a subset $J$ of $I$ if and only if for any open subset $V$ of $Y$, the joint set of the preimage of $f$ on $V$ and $J$ is open in the subspace topology of $X$ in $J$.
\eit
\sssc{Discontinuity (不連續（點）)}
A point is a discontinuity of a function $f$ if it is in the domain of $f$ but $f$ is not continuous on it.
\sssc{Type of discontinuity of real functions}
For a function $f$ with domain $U\subseteq\mathbb{R}$ and a point $a\in U$ that $f$ is discontinuous at, the discontinuity $a$ of $f$ can be classified as below:
\bit
\item \tb{Removable (可去) discontinuity}: If $\exists\lim_{x\to a}f(x)\land\lim_{x\to a}f(x)\neq f(a)$, we call $f(a)$ a removable discontinuity. A discontinuity that is not a removable discontinuity is called a non-removable discontinuity.
\item \tb{Jump (跳躍) discontinuity}: If $\exists\lim_{x\to a^-}f(x)\land\exists\lim_{x\to a^+}f(x)\land\lim_{x\to a^-}f(x)\neq\lim_{x\to a^+}f(x)$, we call $f(a)$ a jump discontinuity.
\item\tb{Infinite (無窮) discontinuity}: If at least one of $\lim_{x\to a^-}f(x)$ and $\lim_{x\to a^+}f(x)$ does not exist, and that those in $\lim_{x\to a^-}f(x)$ and $\lim_{x\to a^+}f(x)$ that do not exist are either $\infty$ or $-\infty$, we call $f(a)$ an infinite discontinuity.
\item\tb{Type I discontinuity}: A discontinuity of $f$ that is either a removable discontinuity or a jump discontinuity is called a type I discontinuity of $f$.
\item\tb{Essential (本質) discontinuity or type II discontinuity}: A discontinuity of $f$ that is not a type I discontinuity is called an essential discontinuity or a type II discontinuity of $f$.
\eit
\sssc{Singularity or singular point (奇點)}
A point is a singularity or a singular point of a function $f$ if it is in the closure of its domain but not in its domain, or it is a discontinuity of $f$.
\sssc{Arithmetic Laws}
If $f$ and $g$ are continuous at $a$ and $c$ is a constant, then the following functions are also continuous at $a$:
\[f+g;\quad f-g;\quad cf;\quad fg;\]
\[\frac{f}{g}\text{\ if\ }g(a)\neq 0.\]
\sssc{Composte Laws}
If $g$ is continuous at $a$ and $f$ is continuous at $g(a)$, then the composite function $f\circ g$ is continuous at $a$.
\sssc{Examples of continuous real functions}
The following types of functions are continuous at every number in their domains: algebraic functions, trigonometric functions, inverse trigonometric functions, exponential functions, logarithmic functions.
\ssc{Intermediate Value Theorem (IVT) (中間值定理)}
\sssc{Intermediate value theorem of real functions}
Let $f\colon I\subseteq\mathbb{R}\to\mathbb{R}$ be a function, then for any interval $[a,b]\subseteq I$ such that $f$ is continuous on $[a,b]$ and $f(a)\neq f(b)$, $N$ is strictly between $f(a)$ and $f(b)$ implies there exists $c\in (a,b)$ such that $f(c)=N$.
\begin{proof}
Without loss of generality, assume $f(a)<N<f(b)$.

Consider the set
\[S=\{x\in [a,b]\mid f(x)\leq N\}.\]
Since $f(a)<N$, $a\in S$; since $f(b)>N$, $b\notin S$. So $S$ is nonempty and bounded-above by $b$.

Let $c=\sup S$. We claim that $f(c)=N$. Argue by contradiction.

Assume $f(c)<N$. By continuity, there exists $\delta>0$ such that for all $x\in (c,c+\delta)\cap [a,b]$, $|f(x)-f(c)|<N-f(c)$. So $f(x)<N$ for some $x>c$. Contradicting that $c$ is the least upper bound.

Assume $f(c)>N$. By continuity, there exists $\delta>0$ such that for all $x\in (c-\delta,c)\cap [a,b]$, $|f(x)-f(c)|<f(c)-N$. So $f(x)>N$ for some $x<c$. Contradicting that $c$ is the least upper bound.

Therefore, $f(c)=N$.
\end{proof}
\sssc{Intermediate value theorem of functions between topological spaces}
Let $X$ and $Y$ be topological spaces and function $f\colon I\subseteq X\to Y$ be continuous on a subset $J$ of $I$, then for any connected subset $K$ of $J$, $f(K)$ is a connected subset of $Y$.

Let $X$ and $Y$ be topological spaces and function $f\colon I\subseteq X\to Y$ be continuous on a subset $J$ of $I$, then for any path-connected subset $K$ of $J$, $f(K)$ is a path-connected subset of $Y$.
\ssc{Piecewise continuity}
\sssc{Piecewise continuity of real functions}
Let $f\colon D\subseteq\mathbb{R}\to\mathbb{R}$ be a function. If there exists a family $\{[a_i,b_i]\mid i\in I\}$ of closed intervals such that:
\begin{itemize}
\item for every closed interval $V$, the set $\{i\in I\mid V\cap [a_i,b_i]\neq\varnothing\}$ is finite (some sources require instead that $n(I)$ is finite, which is stronger),
\item $D=\bigcup_{i\in I}[a_i,b_i]$,
\item function $f\big\vert_{a_i}^{b_i}\colon(a_i,b_i)\to Y$ is continuous for every $i\in I$, and
\item there exist finite $\lim_{x\to a_i^{\phantom{i}+}}f(x)$ and $\lim_{x\to b_i^{\phantom{i}-}}f(x)$ for every $i\in I$.
\end{itemize},
we say $f$ is piecewise continuous (on $\bigcup_{i\in I}[a_i,b_i]$).
\sssc{Piecewise continuity of functions between topological spaces}
Let $X$ and $Y$ be topological spaces, and $f\colon D\subseteq X\to Y$ be a function. If there exists a locally finite (some sources require instead finite, which is stronger) family $\{U_i\mid i\in I\}$ of closed subsets of $X$ such that:
\begin{itemize}
\item $D=\bigcup_{i\in I}U_i$, and
\item there exists a function $g_i\colon U_i\to Y$ that is continuous on $U_i$ such that $\forall x\in\operatorname{int}\left(U_i\right)f(x)=g_i(x)$ for every $i\in I$.
\end{itemize},
we say $f$ is piecewise continuous (on $\bigcup_{i\in I}U_i$).
\ssc{Uniform continuity (一致連續)}
\sssc{Uniform continuity of functions between metric spaces}
Let $(X,d_1)$ and $(Y,d_2)$ be metric spaces, and $f\colon D\subseteq X\to Y$ be a function. $f$ is called to be uniformly continuous if for every real number $\varepsilon >0$ there exists a real number $\delta >0$ such that $x,y\in D$ with $d_{1}(x,y)<\delta$ implies $d_{2}(f(x),f(y))<\varepsilon$.

Let $(X,d_1)$ and $(Y,d_2)$ be metric spaces, and $f\colon O\subseteq X\to Y$ be a function. $f$ is called to be uniformly continuous on $D\subseteq O$ if for every real number $\varepsilon >0$ there exists a real number $\delta >0$ such that $x,y\in D$ with $d_{1}(x,y)<\delta$ implies $d_{2}(f(x),f(y))<\varepsilon$.

Uniform continuity implies continuity.
\sssc{Uniform continuity of functions between topological vector spaces}
Let $X$ and $Y$ be topological vector spaces, and $f\colon D\subseteq X\to Y$ be a function. $f$ is called to be uniformly continuous if for every neighborhood $V$ of the zero vector in $Y$, there exists a neighborhood $U$ of the zero vector in $X$ such that $x,y\in D$ with $x-y\in U$ implies $f(x)-f(y)\in V$.

Let $X$ and $Y$ be topological vector spaces, and $f\colon O\subseteq X\to Y$ be a function. $f$ is called to be uniformly continuous on $D\subseteq O$ if for every neighborhood $V$ of the zero vector in $Y$, there exists a neighborhood $U$ of the zero vector in $X$ such that $x,y\in D$ with $x-y\in U$ implies $f(x)-f(y)\in V$.

Uniform continuity implies continuity.
\ssc{Absolute continuity (絕對連續) of functions from an interval to a metric space}
Let $(X, d)$ be a metric space and $I\subseteq\mathbb{R}$ be an interval. A function $f\colon I \to X$ is absolutely continuous on $I$ if for every positive number $\varepsilon$, there exists a positive number $\delta$ such that for any finite sequence of disjoint subintervals $[x_k, y_k]$ of $I$,
\[\sum _{k}\left|y_{k}-x_{k}\right|<\delta\]
implies
\[\sum _{k}d\left(f(y_{k}),f(x_{k})\right)<\varepsilon.\]
The collection of all absolutely continuous functions from $I$ into $X$ is denoted $AC(I; X)$.

Let $(X, d)$ be a metric space and $I\subseteq\mathbb{R}$ be an interval. A function $f\colon I \to X$ is absolutely continuous on $J\subseteq I$ if for every positive number $\varepsilon$, there exists a positive number $\delta$ such that for any finite sequence of disjoint subintervals $[x_k, y_k]$ of $J$,
\[\sum _{k}\left|y_{k}-x_{k}\right|<\delta\]
implies
\[\sum _{k}d\left(f(y_{k}),f(x_{k})\right)<\varepsilon.\]

Absolute continuity implies uniform continuity.



\section{Derivative (導數)}
\ssc{Notation}
\sssc{Leibniz's notation (萊布尼茲符號) for derivative}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable $x$, that is,
\[y=f(x).\]
Then, the derivative of the function $f$ can be written as
\[\frac{\mathrm{d}y}{\mathrm{d}x},\quad\frac{\mathrm{d}}{\mathrm{d}x}y,\quad\frac{\mathrm{d}\qty(f(x))}{\mathrm{d}x},\quad\text{or\ }\frac{\mathrm{d}}{\mathrm{d}x}\qty(f(x)),\]
in which $\frac{\mathrm{d}}{\mathrm{d}x}$ is called a differential operator (微分運算子) or a derivative operator (導數運算子);

the $n$th derivative of the function $f$ can be written as
\[\frac{\mathrm{d}^ny}{\mathrm{d}x^n},\quad\frac{\mathrm{d}^n}{\mathrm{d}x^n}y,\quad\frac{\mathrm{d}^n\qty(f(x))}{\mathrm{d}x^n},\quad\tx{or\ }\frac{\mathrm{d}^n}{\mathrm{d}x^n}\qty(f(x)),\]
in which $\frac{\mathrm{d}^n}{\mathrm{d}x^n}$ is called a differential operator or a derivative operator.
\sssc{Leibniz's notation for partial derivative}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable vector $\mb{x}=(x_1,x_2,\dots x_n)$, that is,
\[y=f(\mb{x}).\]
Then, the partial derivative of the function $f$ with respect to $x_i$ can be written as
\[\frac{\partial y}{\partial x_i},\quad\frac{\partial }{\partial x_i}y,\quad\frac{\partial \qty(f(x))}{\partial x_i},\quad\text{or\ }\frac{\partial }{\partial x_i}\qty(f(x)),\]
in which $\frac{\partial}{\partial x_i}$ is called a partial differential operator (偏微分運算子) or a partial derivative operator (偏導數運算子);

the $n$th partial derivative of the function $f$ with respect to $x_i$ can be written as
\[\frac{\partial^ny}{\partial x_i^{\phantom{i}n}},\quad\frac{\partial^n}{\partial x_i^{\phantom{i}n}}y,\quad\frac{\partial^n\qty(f(x))}{\partial x_i^{\phantom{i}n}}\text{or\ }\frac{\partial^n}{\partial x_i^{\phantom{i}n}}\qty(f(x)),\]
in which $\frac{\partial^n}{\partial x_i^{\phantom{i}n}}$ is called a partial differential operator or a partial derivative operator;

the $n$th mixed partial derivative of the function $f$ $m_{i_1}$ times with respect to $x_{i_1}$, $m_{i_1}$ times with respect to $x_{i_2}$, $\dots $, $m_{i_k}$ times with respect to $x_{i_k}$, in which $\sum_{j=1}^km_{i_j}=n$, can be written as
\[\frac{\partial^ny}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}},\]
\[\frac{\partial^n}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}}y,\]
\[\frac{\partial^nf\qty(\mb{x})}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}},\quad \tx{or}\]
\[\frac{\partial^n}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}}f(\mb{x}),\]
in which $\frac{\partial^n}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}}$ is called a partial differential operator or a partial derivative operator.
\sssc{Lagrange's notation (拉格朗日符號) or Prime notation for derivative}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable $x$, that is,
\[y=f(x).\]
Then, the derivative of the function $f$ can be written as
\[y',\quad\tx{or\ }f'(x);\]
the $n$th derivative of the function $f$ can also be written as
\[y^{(n)},\quad\tx{or\ }f^{(n)}(x),\]
in which $^{(n)}$ can be replaced with $n$ primes ($'$) for usually $n<4$ (For example, $y''$ is equivalent to $y^{(2)}$, and $f''$ is equivalent to $f^{(2)}$.).
\sssc{Newton's notation (牛頓符號), dot notation, flyspeck notation, or fluxions for derivative}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable $t$, that is,
\[y=f(t),\]
where $t$ usually represents time.

Then, the derivative of the function $f$ can be written as
\[\dot{y},\]
the second derivative of the function $f$ can be written as
\[\ddot{y},\]
and so on.
\sssc{Subscript notation for partial derivative}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable vector $\mb{x}=(x_1,x_2,\dots x_n)$, that is,
\[y=f(\mb{x}).\]
Then, the partial derivative of the function $f$ with respect to $x_i$ can be written as
\[y_{x_i},\quad y'_{x_i},\quad f_{x_i},\quad \tx{or\ }f'_{x_i};\]
the $n$th partial derivative of the function $f$ with respect to $x_i$ can be written as below, in which subscript are $n$ $x_i$s
\[y_{x_ix_i\dots  x_i},\quad y^{(n)}_{\pht{(n)}x_ix_i\dots  x_i},\quad f_{x_ix_i\dots  x_i},\tx{or\ }\quad f^{(n)}_{\pht{(n)}x_ix_i\dots  x_i},\]
in which $^{(n)}$ can be replaced with $n$ primes ($'$) for usually $n<4$ (For example, $y''$ is equivalent to $y^{(2)}$, and $f''$ is equivalent to $f^{(2)}$.);

the $n$th mixed partial derivative of the function $f$ $m_{i_1}$ times with respect to $x_{i_1}$, $m_{i_1}$ times with respect to $x_{i_2}$, $\dots $, $m_{i_k}$ times with respect to $x_{i_k}$, in which $\sum_{j=1}^km_{i_j}=n$, can be written as below, in which subscript are $m_{i_j}$ $x_{i_j}$s for all $x_{i_j}$
\[y_{x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}},\quad y^{(n)}_{\pht{(n)}x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}},\]
\[f_{x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}},\quad \tx{or\ }f^{(n)}_{\pht{(n)}x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}.\]
\sssc{Euler's notation (歐拉符號) for derivative}
Given a function $f$ of an independent variable $x$, that is,
\[f(x).\]
Then, the derivative of the function $f$ can be written as
\[Df(x),\quad(Df)(x),\quad D_xf(x),\quad \tx{or\ }(D_xf)(x)\]
in which $Df$ and $D_xf$ are called differential operators or derivative operators;

the $n$th derivative of the function $f$ can be written as
\[D^nf(x),\quad(D^nf)(x),\quad D^n_{\pht{(n)}xx\dots x}f(x),\quad \tx{or\ }\qty(D^n_{\pht{(n)}xx\dots x}f)(x)\]
in which subscript are $n$ $x$s, and $D^nf$ and $D^n_{\pht{(n)}xx\dots x}f$ are called differential operators or derivative operators.
\sssc{Euler's notation for partial derivative}
Given a function $f$ of an independent variable vector $\mb{x}=(x_1,x_2,\dots x_n)$, that is,
\[f(\mb{x}).\]
Then, the partial derivative of the function $f$ with respect to $x_i$ can be written as
\[\partial_{x_i}f,\quad \tx{or\ }D_{x_i}f,\]
in which $\partial_{x_i}$ and $D_{x_i}$ are called partial differential operators or partial derivative operators;

the $n$th partial derivative of the function $f$ with respect to $x_i$ can be written as
\[\partial_{x_ix_i\dots  x_i}f,\quad\partial^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}f,\quad D_{x_ix_i\dots  x_i}f,\quad\tx{or\ }D^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}f,\]
in which subscript are $n$ $x_i$s, $^{(n)}$ can be replaced with $n$ primes ($'$) for usually $n<4$ (For example, $\partial''$ is equivalent to $\partial^{(2)}$, and $D''$ is equivalent to $D^{(2)}$.), and $\partial_{x_ix_i\dots  x_i}$, $\partial^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}$, $D_{x_ix_i\dots  x_i}$, and $D^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}$ are called partial differential operators or partial derivative operators;

the $n$th mixed partial derivative of the function $f$ $m_{i_1}$ times with respect to $x_{i_1}$, $m_{i_1}$ times with respect to $x_{i_2}$, $\dots $, $m_{i_k}$ times with respect to $x_{i_k}$, in which $\sum_{j=1}^km_{i_j}=n$, can be written as
\[\partial_{x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}f,\quad\partial^{(n)}_{\pht{(n)}x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}f,\]
\[ D_{x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}f,\quad \tx{or\ }D^{(n)}_{\pht{(n)}x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}f,\]
in which subscript are $m_{i_j}$ $x_{i_j}$s for all $x_{i_j}$, $^{(n)}$ can be replaced with $n$ primes ($'$) for usually $n<4$ (For example, $\partial''$ is equivalent to $\partial^{(2)}$, and $D''$ is equivalent to $D^{(2)}$.), and $\partial_{x_ix_i\dots  x_i}$, $\partial^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}$, $D_{x_ix_i\dots  x_i}$, and $D^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}$ are called partial differential operators or partial derivative operators.
\sssc{Physical interpretation}
We sometimes interpret a function physically and call is the position function. Then the derivative function of it is called the velocity function, the second derivative function of it is called the acceleration function, and the third derivative function of it is called the jerk function.
\ssc{Ordinary Derivatives of Functions with Real Domain}
Let $W$ be a topological vector space. The ordinary derivative (常導數) or derivative (導數) $f'(x)$ of a function $f\colon U\subeteq\mathbb{R}\to W$ (with respect to $x$) at $x\in U$ is defined as
\[f'(x)=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}\]
if the limit exists. If such limit exists, we say $f$ is differentiable (可微的) at $x$.

We define the (first(-order)) ordinary derivative (function) (常導（函）數) or derivative (function) (導（函）數) of $f$ (with respect to (w.r.t.) to $x$) as a function $f'$ with codomain $W$ such that for any $x\in U$ at which $f$ is differentiable, $f'$ maps $x$ to the derivative of $f$ at $x$.

The derivative of the $k$th(-order) ($k\in\mathbb{N}$) derivative function of $f$ at $x\in U$ is called the $(k+1)$th(-order) derivative of $f$ (with respect to $x$) at $x\in U$. The derivative function of the $k$th(-order) ($k\in\mathbb{N}$) derivative function of $f$ is called the $k+1$th(-order) derivative function of $f$ (with respect to $x$).

If for any $n\in\mathbb{N}$, the $n$th(-order) derivative of a function $f$ at a point $x$ in its domain exists, we say $f$ is infinitely differentiable at $x$.

If $f$ is differentiable at all point in $I\subeteq U$, we say $f$ is differentiable on $I$; if $f$ is differentiable on $U$, we say $f$ is differentiable. If $f^{(n-1)}$ exists and is differentiable at all point in $I\subeteq U$, we say $f$ is $n$-times differentiable on $I$; if $f^{(n-1)}$ exists and is differentiable on $U$, we say $f$ is $n$-times differentiable.

The operation of finding the derivative or derivative function is called ordinary differentiation (常微分) or differentiation (微分).

Specifically, the $0$th(-order) derivative of $f$ is $f$ itself.

The derivative of a $f$ at $x$ represents the slope (斜率) at $x$ or the lineal element at $x$ (a miniature tangent line at $x$).
\ssc{One-sided Derivative of Functions with Real Domain}
Let $W$ be a topological vector space and $f\colon U\subeteq\mathbb{R}\to W$ be a function.

The left-hand derivative of $f$ at $x\in U$, denoted as $f'_-(x)$, is defined as
\[f'_-(x)=\lim_{h\to 0^-}\frac{f(x+h)-f(x)}{h}\]
if the limit exists.

The right-hand derivative of $f$ at $x\in U$, denoted as $f'_+(x)$, is defined as
\[f'_+(x)=\lim_{h\to 0^+}\frac{f(x+h)-f(x)}{h}\]
if the limit exists.
\ssc{Partial derivatives of Functions with Real Vector Domain}
Let $W$ be a topological vector space and $f\colon U\subeteq\mathbb{R}^n\to W$ be a function, $\mb{x}$ be the independent variable vector of $f$, and $X$ be the set of all independent variables of $f$.

The (first(-order)) partial derivative (偏導數) $\pdv{f}{x_i}$ of $f$ with respect to $x_i\in X$ at $u\in U$ is defined as
\bma
\pdv{f}{x_i}&=\lim_{h\to 0}\frac{f(u+h\mb{e}_i)-f(u)}{h}\]
&=\frac{\mathrm{d}}{\mathrm{d}h}f(u+h\mb{e}_i)\big\vert_{h=0}
\end{aligned},\]
in which $\mb{e}_i\in\mathbb{R}^n$ is the unit vector in the direction of $x_i$.

The partial derivative of the $k$th(-order) ($k\in\mathbb{N}$) partial derivative (function) (偏導（函）數) of $f$ with respect to $ x \in X$ with respect to $ x \in X$ at $u\in U$ is called the $k+1$th(-order) partial derivative of $f$ with respect to $ x$ at $u\in U$. The partial derivative function of the $k$th(-order) ($k\in\mathbb{N}$) partial derivative function of $f$ with respect to $ x \in X$ with respect to $ x \in X$ is called the $k+1$th(-order) partial derivative function of $f$ with respect to $ x$.

The partial derivative of the $k$th(-order) partial derivative function of $f$ with respect to $ x_1\in X$ with respect to $ x_2\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative of $f$ with respect to $ x_1, x_1,\dots  x_1$ ($k$ times) and $ x_2$ at $u\in U$. The partial derivative function of the $k$th(-order) partial derivative function of $f$ with respect to $ x_1\in X$ with respect to $ x_2\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_1,\dots  x_1$ ($k$ times) and $ x_2$.

The partial derivative of the $k$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k\in X$ with respect to $ x_{k+1}\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative of $f$ with respect to $ x_1, x_2,\dots  x_k, x_{k+1}$ at $u\in U$. The partial derivative function of the $k$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k\in X$ with respect to $ x_{k+1}\in X$ is called the $(k+1)$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k, x_{k+1}$.

The operation of finding the partial derivative or partial derivative function is called partial differentiation (偏微分).

Specifically, the $0$th(-order) partial derivative of $f$ is $f$ itself.
\ssc{Fréchet derivative (弗蘭歇導數)}
\sssc{Fréchet derivative}
Let $V$ and $W$ be normed vector spaces and $U$ be an open subset of $V$. A function $f\colon U\to W$ is Fréchet differentiable (弗蘭歇可微的) or differentiable at $x\in U$ if there exists a bounded linear operator $A\colon V\to W$ such that
\[\lim_{\|h\|_V\to 0}\frac{\|f(x+h)-f(x)-A(h)\|_W}{\|h\|_V}=0.\]
If there exists such an operator $A$, it is unique, so we define the (first(-order)) Fréchet derivative, ordinary derivative, or derivative of $f$ (with respect to $x$) at $x$, denoted as $Df(x)$, as $A$.

We define the (first(-order)) Fréchet derivative (function) (弗蘭歇導（函）數), ordinary derivative (function), or derivative (function) of $f$ (with respect to $x$) as a function $Df$ with codomain $B(V,W)$, in which $B(V,W)$ is the space of all bounded linear operators from $V$ to $W$, such that for any $x\in U$ at which $f$ is Fréchet differentiable, $Df$ maps $x$ to the Fréchet derivative of $f$ at $x$.

The Fréchet derivative of the $k$th(-order) ($k\in\mathbb{N}$) Fréchet derivative function of $f$ at $x\in U$ is called the $k+1$th(-order) Fréchet derivative of $f$ (with respect to $x$) at $x\in U$, denoted as $(D^{k+1}f)(x)$. The Fréchet derivative function of the $k$th(-order) ($k\in\mathbb{N}$) Fréchet derivative function of $f$ is called the $k+1$th(-order) Fréchet derivative function of $f$ (with respect to $x$), denoted as $D^{k+1}f$.

If $f$ is Fréchet differentiable at all point in $I\subeteq U$, we say $f$ is Fréchet differentiable on $I$; if $f$ is Fréchet differentiable on $U$, we say $f$ is Fréchet differentiable. If $D^{(n-1)}f$ exists and is Fréchet differentiable at all point in $I\subeteq U$, we say $f$ is $n$-times Fréchet differentiable on $I$; if $D^{(n-1)}f$ exists and is Fréchet differentiable on $U$, we say $f$ is $n$-times Fréchet differentiable.

The operation of finding the Fréchet derivative or Fréchet derivative function is called Fréchet differentiation (弗蘭歇微分), ordinary differentiation, or differentiation.

Specifically, the $0$th(-order) Fréchet derivative of $f$ is $f$ itself.
\ssc{Smoothness (光滑性 or 平滑性)}
\sssc{Smoothness}
A function with real domain $f$ that has a $k$th derivative that is continuous on its domain is said to be of class $C^k$, denoted as $f\in C^k$, or be a $C^k$-function.

A function $f$ that has a $k$th derivative that is continuous on a subset $I$ of its domain is said to be of class $C^k$ on $I$ or of class $C^k(I)$, denoted as $f\in C^k(I)$.

Generally, the term smooth function refers to a $C^{\infty}$-function. However, it may also mean "sufficiently differentiable" for the problem under consideration.
\sssc{Piecewise smoothness of real functions}
Let $f\colon D\subseteq\mathbb{R}\to\mathbb{R}$ be a function. If there exists a family $\{[a_i,b_i]\mid i\in I\}$ of closed intervals such that:
\begin{itemize}
\item for every closed interval $V$, the set $\{i\in I\mid V\cap [a_i,b_i]\neq\varnothing\}$ is finite (some sources require instead that $n(I)$ is finite, which is stronger),
\item $D\subseteq\bigcup_{i\in I}[a_i,b_i]$,
\item function $f\big\vert_{a_i}^{b_i}\colon(a_i,b_i)\to Y$ is of class $C^k((a_i,b_i))$ for every $i\in I$, and
\item there exist finite $\lim_{x\to a_i^{\phantom{i}+}}f(x)$ and $\lim_{x\to b_i^{\phantom{i}-}}f(x)$ for every $i\in I$.
\end{itemize},
we say $f$ is of class piecewise $C^k$ (or of class piecewise $C^k\qty(\bigcup_{i\in I}[a_i,b_i])$); when $k=\infty$ or sufficiently large, we say $f$ is piecewise smooth (on $\bigcup_{i\in I}U_i$).
\sssc{Piecewise smoothness of functions between topological spaces}
Let $X$ and $Y$ be topological spaces, and $f\colon D\subseteq X\to Y$ be a function. If there exists a locally finite (some sources require instead finite, which is stronger) family $\{U_i\mid i\in I\}$ of closed subsets of $X$ such that:
\begin{itemize}
\item $D\subseteq\bigcup_{i\in I}U_i$, and
\item there exists a function $g_i\colon U_i\to Y$ that is of class $C^k\qty(U_i)$ such that $\forall x\in\operatorname{int}\left(U_i\right)f(x)=g_i(x)$ for every $i\in I$.
\end{itemize},
we say $f$ is of class piecewise $C^k$ (or of class piecewise $C^k\qty(\bigcup_{i\in I}U_i)$); when $k=\infty$ or sufficiently large, we say $f$ is piecewise smooth (on $\bigcup_{i\in I}U_i$).
\ssc{Gateaux Differentiation (加托微分)}
\sssc{Gateaux derivative (加托導數) and partial derivatives}
Let $V$ be a locally convex topological vector spaces (LCTVS), $W$ be a topological vector space, $U$ be an open subset of $V$, and $f\colon U\to W$ be a function.

The (first(-order)) Gateaux derivative $df(u;\,\psi)$ of $f$ at $u\in U$ in the direction $\psi \in V$ is defined to be
\[\begin{aligned}
df(u;\,\psi) &= \lim_{\tau\to 0}\frac{f(u+\tau \psi)-f(u)}{\tau}\\
&= \frac{\mathrm{d}}{\mathrm{d}\tau}f(u+\tau \psi)\big\vert_{\tau =0}
\end{aligned}\]
if the limit exists. If for any $\psi \in V$, the Gateaux derivative exists, then it is said that $f$ is Gateaux differentiable (加托可微的) at $u$.

We define the (first(-order)) Gateaux derivative (function) (加托導（函）數) of $f$ in the direction $\psi \in V$, denoted as $df$, as a function $df\colon U\to W$, such that for any $u\in U$ at which $f$ is Gateaux differentiable, $df$ maps $u$ to the Gateaux derivative of $f$ at $u$ in the direction $\psi \in V$.

The Gateaux derivative of the $k$th(-order) ($k\in\mathbb{N}$) Gateaux derivative function of $f$ in the direction $\psi \in V$ in the direction $\psi \in V$ at $u\in U$ is called the $k+1$th(-order) Gateaux derivative of $f$ in the direction $\psi$ at $u\in U$. The Gateaux derivative function of the $k$th(-order) ($k\in\mathbb{N}$) Gateaux derivative function of $f$ in the direction $\psi \in V$ in the direction $\psi \in V$ is called the $k+1$th(-order) Gateaux derivative function of $f$ in the direction $\psi$.

The Gateaux derivative of the $k$th(-order) Gateaux derivative function of $f$ in the direction $\psi_1\in V$ in the direction $\psi_2\in V$ at $u\in U$ is called the $(k+1)$th(-order) mixed Gateaux derivative of $f$ in the direction $\psi_1,\psi_1,\dots \psi_1$ ($k$ times) and $\psi_2$ at $u\in U$. The Gateaux derivative function of the $k$th(-order) Gateaux derivative function of $f$ in the direction $\psi_1\in V$ in the direction $\psi_2\in V$ is called the $(k+1)$th(-order) mixed Gateaux derivative function of $f$ in the direction $\psi_1,\psi_1,\dots \psi_1$ ($k$ times) and $\psi_2$.

The Gateaux derivative of the $k$th(-order) mixed Gateaux derivative function of $f$ in the direction $\psi_1,\psi_2,\dots \psi_k\in V$ in the direction $\psi_{k+1}\in V$ at $u\in U$ is called the $(k+1)$th(-order) mixed Gateaux derivative of $f$ in the direction $\psi_1,\psi_2,\dots \psi_k,\psi_{k+1}$ at $u\in U$. The Gateaux derivative function of the $k$th(-order) mixed Gateaux derivative function of $f$ in the direction $\psi_1,\psi_2,\dots \psi_k\in V$ in the direction $\psi_{k+1}\in V$ is called the $(k+1)$th(-order) mixed Gateaux derivative function of $f$ in the direction $\psi_1,\psi_2,\dots \psi_k,\psi_{k+1}$.

The operation of finding the Gateaux derivative or Gateaux derivative function is called Gateaux differentiation (加托微分).

Specifically, the $0$th(-order) Gateaux derivative of $f$ is $f$ itself.
\sssc{Partial derivative}
Let $V$ be a locally convex topological vector spaces (LCTVS), $W$ be a topological vector space, $U$ be an open subset of $V$, and $f\colon U\to W$ be a function, $\mb{x}$ be the independent variable vector of $f$, and $X$ be the set of all independent variables of $f$.

The (first(-order)) partial derivative of $f$ with respect to $x_i\in X$ at $u\in U$ is defined as the Gateaux derivative of $f$ in the direction of $x_i$ at $u$ if it exists.

The partial derivative of the $k$th(-order) ($k\in\mathbb{N}$) partial derivative (function) of $f$ with respect to $ x \in X$ with respect to $ x \in X$ at $u\in U$ is called the $k+1$th(-order) partial derivative of $f$ with respect to $ x$ at $u\in U$. The partial derivative function of the $k$th(-order) ($k\in\mathbb{N}$) partial derivative function of $f$ with respect to $ x \in X$ with respect to $ x \in X$ is called the $k+1$th(-order) partial derivative function of $f$ with respect to $ x$.

The partial derivative of the $k$th(-order) partial derivative function of $f$ with respect to $ x_1\in X$ with respect to $ x_2\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative of $f$ with respect to $ x_1, x_1,\dots  x_1$ ($k$ times) and $ x_2$ at $u\in U$. The partial derivative function of the $k$th(-order) partial derivative function of $f$ with respect to $ x_1\in X$ with respect to $ x_2\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_1,\dots  x_1$ ($k$ times) and $ x_2$.

The partial derivative of the $k$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k\in X$ with respect to $ x_{k+1}\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative of $f$ with respect to $ x_1, x_2,\dots  x_k, x_{k+1}$ at $u\in U$. The partial derivative function of the $k$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k\in X$ with respect to $ x_{k+1}\in X$ is called the $(k+1)$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k, x_{k+1}$.

The operation of finding the partial derivative or partial derivative function is called partial differentiation.

Specifically, the $0$th(-order) partial derivative of $f$ is $f$ itself.
\ssc{Differentiability implies continuity}
For a point $a$ in the domain of $f$, $f$ is differentiable at $a$ implies it is continuous at $a$; for an open subset $I$ of the domain of $f$, $f$ is differentiable on $I$ implies it is continuous on $I$.
\ssc{Antiderivative (反導函數), inverse derivative, primitive function, primitive integral, or indefinite integral (不定積分)}
An antiderivative of a function $f(x)$ is a differentiable function $F(x)$ whose derivative is equal to the original function $f(x)$, that is,
\[F'(x)=f(x),\]
denoted as
\[F(x)=\int f(x)\,\mathrm{d}x.\]
If one of $F(x)$ is $G(x)$, we also write
\[F(x)=G(x)+C,\]
where $C$ is an arbitrary constant that does not depend on $x$, called constant of integration.

The process of solving for antiderivatives is called antidifferentiation (反微分) or indefinite integration (不定積分).
\subsection{Taylor series (泰勒級數) or Taylor expansion (泰勒展開)}
Assume that $F:\,\mathbb{R}\to\mathbb{R}$ is an infinitely differentiable function, and its derivatives of every order exist on $\mathbb{R}$, then the Taylor series of $F$ at $a$ is
\[F(x) = \sum_{n\in\mathbb{N}_0} \frac{F^{(n)}(a)}{n!}(x-a)^n,\]
that is,
\[F(x) = \sum^k_{n=0} \frac{F^{(n)}(a)}{n!}(x-a)^n+\int_0^1\frac{(1-t)^k}{k!}F^{(k+1)}(a+t(x-a))(x-a)^{k+1}\,\mathrm{d}t.\]
Also, the $k$th-order approximation of $f$ near $a$ is
\[F(x) \approx \sum^k_{n=0} \frac{F^{(n)}(a)}{n!}(x-a)^n,\]
and the first-order (aka linear) approximation near $a$ is
\[F(x) \approx F(0)+F'(a)(x-a).\]
The Taylor series of $F$ at $0$ is called Maclaurin series (馬克勞林級數) or Maclaurin expansion (馬克勞林展開).
\ssc{Real analyticity (實解析性) of real-codomain functions}
A real-codomain function $f$ is real analytic at a point $x_0$ in its domain, if it is infinitely differentiable at $x_0$ and that the Taylor expansion of $f$ at $x_0$ converges to $f(x)$ pointwise for any $x$ in a neighborhood of $x_0$.

A real-codomain function is called to be real analytic on an interval $I$ that is a subset of its domain if it is real analytic at any point in $I$.

A real-codomain function is called to be real analytic if it is real analytic at any point in its domain.
\ssc{Points in graph}
\sssc{Critical point (臨界點), equilibrium, equilibrium point (平衡點), or stationary point (駐點)}
Let $f$ be a function where the codomain of it has a zero element $0$ and \( c \) be a point in the domain of $f$ , if \( f'(c) = 0 \) or \( f' \) does not exist at \( c \), then \( c \) is a critical point, equilibrium, equilibrium point, or stationary point of \( f \).

If the domain of $f$ is a subset of $\bbR$, a critical point, equilibrium, equilibrium point, or stationary point of \( f \) is also called a critical number, equilibrium, equilibrium number, or stationary number of \( f \).
\sssc{Relative extremum (相對極值), local extremum (局部極值), or extremum (極值)}
Let $f\colon D\subseteq X\to Y$ be a function with $X$ being a topological space and $Y$ being a preordered set. It is said that a relative maximum (相對極大值) or maximum (極大值) \( f(c) \) of \(f\) occurs at $c\in D$ if there exists an open subset $I\ni c$ of $X$ such that \( \forall x\in I\cap D\colon f(c) \geq f(x) \).

Let $f\colon D\subseteq X\to Y$ be a function with $X$ being a topological space and $Y$ being a preordered set. It is said that a relative minimum (相對極小值) or minimum (極小值) \( f(c) \) of \(f\) occurs at $c\in D$ if there exists an open subset $I\ni c$ of $X$ such that \( \forall x\in I\cap D\colon f(c) \leq f(x) \).

The relative maximum and relative minimum are collectively called the relative extreme.
\subsection{Absolute extremum (絕對極值 or 最值) or global extremum (全域極值)}
Let $f\colon D\to Y$ be a function with $Y$ be a preordered set. It is said that a absolute maximum (絕對極大值 or 最大值) \( f(c) \) of \(f\) occurs at $c\in D$ if \( \forall x\in D\colon f(c) \geq f(x) \).

Let $f\colon D\to Y$ be a function with $Y$ be a preordered set. It is said that a absolute minimum (絕對極小值 or 最小值) \( f(c) \) of \(f\) occurs at $c\in D$ if \( \forall x\in D\colon f(c) \leq f(x) \).

The absolute maximum and absolute minimum are collectively called the absolute extreme.
\sssc{Saddle point (鞍點)}
Let $f$ be a function where the codomain of it is a preordered set with a zero element and \( c \) be a point in the domain of $f$ , if \( f'(c) = 0 \) and $c$ is not a local extremum of $f$, then $c$ is a saddle point of $f$.
\sssc{Concavity (凹性)}
Let $f\colon J\subseteq X\to Y$ with $X,Y$ being posets be differentiable on the open interval $I\subseteq J$. If $f'$ is strictly increasing on $I$, the graph of $f$ is said to concave upward on $I$; if $f'$ is strictly decreasing on $I$, the graph of $f$ is said to concave downward on $I$; if $f'$ is a constant on $I$, the graph of $f$ is said to be neither upward nor downward (or both upward and downward or undefined in some contexts) on $I$.
\sssc{Point of inflection or inflection point (反曲點 or 拐點)}
Let $f\colon J\subseteq X\to Y$ with $X,Y$ being posets be a continuous function and be differentiable on an open interval $I\subseteq J$, and let $a<b<c\land a,b,c\in I$. If the graph of $f$ is concave upward on interval $(a,b)$ and concave downward on interval $(b,c)$, or concave downward on interval $(a,b)$ and concave upward on interval $(b,c)$, then $(b,f(b))$ is called an inflection point of the graph of $f$.
\sssc{Kink}
A kink is a point $x$ on the graph of a real function $f$ such that $f$ is continuous but not differentiable at $x$.
\sssc{Corner or sharp corner}
A corner or sharp corner is a point $x$ on the graph of a real function $f$ such that $f$ is continuous but not differentiable at $x$ and that the left-hand derivative and the right-hand derivative of $f$ at $x$ both exist and are finite.
\sssc{Vertical tangent}
A vertical tangent is a point $x$ on the graph of a real function $f$ such that $f$ is continuous at $x$ and that the left-hand derivative and the right-hand derivative of $f$ at $x$ are both $\infty$ or are both $-\infty$.
\sssc{Cusp}
A cusp is a point $x$ on the graph of a real function $f$ such that:
\bit
\item $f$ is continuous at $x$,
\item at least one of the left-hand derivative and the right-hand derivative of $f$ at $x$ are $\infty$ or $-\infty$,
\item $x$ is not a vertical tangent of $f$, and
\item the left-hand derivative and the right-hand derivative of $f$ at $x$ are both either finite, $\infty$, or $-\infty$.
\eit



\section{Definte Integration (定積分)}
\ssc{Notation}
The integral of a function $f(x)$ with domain being a subset of $\bbR$, called integrand (被積函數), with respect to $x$, called integration variable (積分變數), from $a$ to $b$, which the open interval between $a$ and $b$ is called the domain of integration (積分域) or interval of integration (積分區間) and $a,b$ are called limits of integration (積分極限 or 積分上下限), is denoted as
\[\int_a^bf(x)\dd{x},\]
in which when $a>b$, the integral is defined as
\[\int_a^bf(x)\dd{x}\coloneq-\int_b^af(x)\dd{x}.\]

The integral of a function $f(\omega)$ with respect to $\omega$ over $\Omega$, called the domain of integration and which the limit points of $\Omega$ are called are called limits of integration (積分極限), is denoted as
\[\int_{\Omega}f(\omega)\dd{\omega}.\]
\subsection{(Proper) Riemann integral (黎曼積分) and Darboux integral (達布積分)}
\sssc{Premise}
(Proper) Riemann integral and Darboux integral are two equivalant definitions of definite integral of functions over compact intervals of $\mathbb{R}$ to $\mathbb{R}$.
\subsubsection{Partition of an interval}
A partition $P(x, n)$ of a compact interval $[a,b]$ is a finite sequence of numbers of the form
\[P(x, n):=\{x_i\colon x_0=a\land x_n=b\land\forall 1\leq i<j\leq n\colon x_i<x_j\}_{i=0}^n.\]

Each $[x_i, x_{i+1}]$ is called a subinterval of the partition. The length of a closed interval $[c,d]$ is defined as $d-c$. The mesh or norm of a partition is defined as
\[\max_i\left(x_{i+1}-x_{i}\right)\]
for every integer $i\in [0,n-1]$.

A tagged partition $P(x,n,\xi)$ of a interval $(a,b)$ is a partition together with a choice of a sample point within each of all $n$ subintervals, that is, numbers $\{\xi_i\}_{i=0}^{n-1}$ with $\xi_i\in [x_i,x_{i+1}]$ for each integer $i\in [0,n-1]$. The mesh of a tagged partition is the same as that of an ordinary partition.

Suppose that two tagged partitions $P(x,n,\xi)$ and $Q(y,m,\zeta)$ are both partitions of the interval $[a,b]$. We say that $Q(y,m,\zeta)$ is a refinement of $P(x,n,\xi)$ if for each integer $i\in [0,n-1]$, there exists an integer $r(i)\in [0,m-1]$ such that $x_i = y_{r(i)}$ and that $\forall i\in [0,n-1]\colon\exists j\in [r(i),r(i + 1)] \text{\ s.t.\ }\xi_i = \zeta_j$. That is, a tagged partition breaks up some of the subintervals and adds sample points where necessary, "refining" the accuracy of the partition.

We can turn the set of all tagged partitions into a directed set by saying that one tagged partition is greater than or equal to another if the former is a refinement of the latter.
\subsubsection{Riemann sum}
Let $f$ be a real-valued function defined on a interval $[a,b]$. The Riemann sum of $f$ with respect to a tagged partition $P(x,n,\xi)$ of $[a,b]$ is defined to be
\[R(f,P):=\sum_{i=0}^{n-1}f(\xi_i)\left(x_{i+1}-x_i\right).\]
Each term in the sum is the product of the value of the function at a given point and the length of an interval. Consequently, each term represents the signed area of a rectangle with height $f(\xi_i)$ and width $x_{i + 1} − x_i$. Thus the Riemann sum is the signed area of all the rectangles.
\subsubsection{Darboux sum}
Let $f$ be a real-valued function defined on a interval $[a,b]$. Lower and upper Darboux sums of $f$ with respect to a partition $P(x,n)$ of $[a,b]$ are two specific Riemann sums of which the tags are chosen to be the infimum and supremum (respectively) of $f$ on each subinterval:
\[\begin{aligned}
L(f,P)&:=\sum_{i=0}^{n-1}\inf_{\xi\in [x_i,x_{i+1}]}f(\xi)(x_{i+1}-x_i),\\
U(f,P)&:=\sum_{i=0}^{n-1}\sup_{\xi\in [x_i,x_{i+1}]}f(\xi)(x_{i+1}-x_i).
\end{aligned}\] 
\subsubsection{Riemann integral}
Let $f$ be a real-valued function defined on a interval $[a,b]$. The Riemann integral of $f$ on $[a,b]$ exists and equals $s$ if for all $\varepsilon > 0$, there exists $\delta > 0$ such that for any tagged partition $P(x,n,\xi)$ whose mesh is less than $\delta$,
\[\abs{R(f,P)-s}<\varepsilon .\]
\subsubsection{Darboux integral}
Let $f$ be a real-valued function defined on a interval $[a,b]$. The Darboux integral of $f$ on $[a,b]$ exists and equals $s$ if for all $\varepsilon > 0$, there exists $\delta > 0$ such that for any partition $P$ whose mesh is less than $\delta$,
\[\abs{U(f,P)-s}<\varepsilon \land \abs{L(f,P)-s}<\varepsilon.\]
\sssc{Lebesgue-Vitali theorem (of characterization of the Riemann integrable functions)}
A function on bounded a compact interval $I$ is Riemann integrable (i.e. Darboux integrable) over $I$ if and only if it is continuous almost everywhere in $I$.
\ssc{Extensions of Riemann integral}
\sssc{Improper (Riemann) integral (瑕（黎曼）積分)}
An integral $\int _{a}^{b}f(x)\dd{x}$ is an improper integral if one or more of the below conditions occur:
\ben
\item $a=-\infty$,
\item $b=\infty$,
\item $f(x)$ is unbounded or undefined somewhere in $[a,b]$.
\een

The improper integrals are defined by limits as:
\bit
\item for $a=-\infty$:
\[\int _{-\infty }^bf(x)\dd{x}=\lim _{a\to -\infty }\int _{a}^{b}f(x)\dd{x},\]
\item for $b=\infty$:
\[\int _{a}^{\infty }f(x)\dd{x}=\lim _{b\to \infty }\int _{a}^{b}f(x)\dd{x},\]
\item for $f(x)$ that is unbounded or undefined at $a$:
\[\int_a^bf(x)\dd{x}=\lim_{c\to a^+}\int_c^bf(x)\dd{x},\]
\item for $f(x)$ that is unbounded or undefined at $b$:
\[\int_a^bf(x)\dd{x}=\lim_{c\to b^-}\int_a^cf(x)\dd{x},\]
\item for $f(x)$ that is unbounded or undefined at $c\in(a,b)$:
\[\int _{a}^{b}f(x)\dd{x}=\lim_{t\to c^-}\int _{a}^{t}f(x)\dd{x}+\lim_{t\to c^+}\int _{t}^{b}f(x)\dd{x},\]
\eit
in which if any of the terms diverge or is undefined, the improper integral diverges and is undefined; otherwise, the improper integral exists finitely and converges to a finite value.

$\lim _{a\to -\infty }\int _{a}^{b}f(x)\dd{x}$ converges absolutely to $L$ if $\exists\lim _{a\to -\infty }\int _{a}^{b}\abs{f(x)}\dd{x}\land\lim _{a\to -\infty }\int _{a}^{b}\abs{f(x)}\dd{x}=L$.

$\lim _{b\to \infty }\int _{a}^{b}f(x)\dd{x}$ converges absolutely to $L$ if $\exists\lim _{b\to \infty }\int _{a}^{b}f(x)\dd{x}\land\lim _{b\to \infty }\int _{a}^{b}f(x)\dd{x}=L$.

If an improper integral is convergent but not convergent absolutely, we say it converges conditionally.
\sssc{Cauchy principal value (柯西主值) or PV integral}
The Cauchy principal value or PV integral, denoted as p.v., is a weaker notion of convergence, defined by taking symmetric limits. 

The p.v. of $\int _{-\infty}^{\infty}f(x)\dd{x}$, denoted as $\text{p.v.\ }\int_{-\infty}^{\infty} f(x)\dd{x}$, is defined with:
\[\text{p.v.\ }\int_{-\infty}^{\infty} f(x)\dd{x}\coloneq\lim_{R\to\infty} \int_{-R}^{R} f(x)\dd{x},\]
if the limit exists.

The p.v. of $\int _{a}^{b}f(x)\dd{x}$, in which $f(x)$ is unbounded or undefined at $c\in (a,b)$, denoted as $\text{p.v.\ }\int_{a}^{b} f(x)\dd{x}$, is defined with:
\[\text{p.v.\ }\int_{a}^{b} f(x)\dd{x}\coloneq\lim_{\epsilon\to 0}\qty(\int_a^{c-\epsilon}f(x)\dd{x}+\int_{c+\epsilon}^bf(x)\dd{x}),\]
if the limit exists.

If an improper integral converges, the p.v. of it converges.
\subsection{Lebesgue integral (勒貝格積分)}
A definition of definite integral.
\sssc{Premise}
Let $(E,\Sigma,\mu)$ be a measure space. Below, we will define the Lebesgue integral of measurable functions on $E$ to $\mathbb{R}\cup\{-\infty,\infty\}$.
\subsubsection{Of an indicator functions}
The integral of an indicator function $1_S$ of a measurable subset $S$ of $E$ is defined to be
\[\int 1_{S}\,\mathrm{d}{\mu} =\mu (S).\]
\sssc{Of a nonnegative simple function}
A simple function $s$ is a finite real linear combinations of indicator functions of disjoint measurable subsets of $E$, that is,
\[s\colon\sum_ka_k1_{S_k},\]
where the coefficients $a_k$ are real numbers and $S_k$ are disjoint measurable sets. When the coefficients $a_k$ are positive real numbers, $s$ is called nonnegative.

The integral of a nonnegative simple function $s=\sum_ka_k1_{S_k}$ over $E$ is defined to be
\[\int_Es\,\mathrm{d}\mu=\sum_ka_k\int 1_{S_k}\,\mathrm{d}\mu=\sum_ka_k\mu(S_k),\]
where this sum can be finite or $\infty$.

The integral of a nonnegative simple function $s=\sum_ka_k1_{S_k}$ over a subset $B$ of $E$ is defined to be:
\[\int_Bs\,\mathrm{d}\mu=\sum_ka_k\mu \qty(S_k\cap B).\]
\subsubsection{Of a nonnegative measurable function}
Let $f$ be a nonnegative function on some measurable subset $B$ of $E$ into $\mathbb{R}\cup\{-\infty,\infty\}$, called a nonnegative measurable function. We define
\[\int_Bf\,\mathrm{d}\mu=\sup\left\{\int_Bs\,\mathrm{d}\mu\mid\forall x\in B\colon 0\leq s(x)\leq f(x)\land s\text{\ is a nonnegative simple function}\right\}.\]
\subsubsection{Of a measurable function}
Let $f$ be a function on some measurable subset $B$ of $E$ into $\mathbb{R}\cup\{-\infty,\infty\}$, called a measurable function. We first define
\[\begin{aligned}
f^{+}(x)&=
\begin{cases}
f(x),\quad&\text{if\ }f(x)>0\\
0,\quad &\text{otherwise}
\end{cases},\quad\tx{and}\\
f^{-}(x)&=
\begin{cases}
-f(x),\quad&\text{if\ }f(x)<0\\
0,\quad&\text{otherwise}
\end{cases}.
\end{aligned}\]
Note that both $f^+$ and $f^-$ are nonnegative and that
\[f=f^+-f^-,\quad |f|=f^++f^-.\]
Then we define the Lebesgue integral of $f$ to exist if
\[ \min \left(\int f^{+}\,\mathrm{d}\mu ,\int f^{-}\,\mathrm{d}\mu \right)<\infty.\]
In this case we define
\[ \int f\,\mathrm{d}\mu =\int f^{+}\,\mathrm{d}\mu -\int f^{-}\,\mathrm{d}\mu.\]
\sssc{Integrability}
Let $f$ be a function on some measurable subset $B$ of $E$ into $\mathbb{R}\cup\{-\infty,\infty\}$.

If
\[\int |f|\,\mathrm {d} \mu <\infty ,\]
we say that $f$ is Lebesgue integrable.
\sssc{$L^p$ spaces ($L^p$ 空間)}{{{

\ssc{Bochner integral (博赫納積分)}
\sssc{Premise}
Let $(E,\Sigma ,\mu )$ be a measure space and $X$ be a Banach space with norm $\|\cdot\|_X$. Below, we will define the Bochner integral of measurable functions on $E$ to $X$.
\subsubsection{Of an indicator functions}
The integral of an indicator function $1_S$ of a measurable subset $S$ of $E$ is defined to be
\[\int 1_{S}\,\mathrm{d}{\mu} =\mu (S).\]
\sssc{Of a simple function}{{{
\sssc{Of a measurable function}{{{

\sssc{Bochner spaces (博赫納空間)}
Let $(E,\Sigma,\mu)$ be a measure space and $X$ be a topological space. 

The Bochner space $L^p(E;X)$ with $p\in\mathbb{N}\cup\{\infty\}$ is defined to be the Kolmogorov quotient space {{{ of the space of all Bochner measurable functions $f(t)\colon E\to X$ such that the norm $\|f(t)\|_{L^p(E;X)}$ of it, defined with
\[\|f(t)\|_{L^p(E;X)}\coloneq\left(\int_E\|f(t)\|_X^{\phantom{X}p}\,\mathrm{d}\mu\right)^{1/p},\quad p\in\mathbb{N},\]
and
\[\|f(t)\|_{L^{\infty }(E;X)}\coloneq\operatorname{ess\,sup}_{t\in E}\|f(t)\|_{X},\]
is finite under the equivalence relation of equality almost everywhere.
\ssc{Fundamental theorem of calculus (FTC) (微積分基本定理) of real functions}
Below is the FTC for functions from a subset of $\mathbb{R}$ to $\mathbb{R}$.
\sssc{The First Theorem}
Let $F(x)$ be a function differentiable on $[a,b]$. Then:
\[\int_a^bF'(x)\dd{x}=F(b)-F(a).\]
\begin{proof}\mbox{}\\
{{{ Change to Lebesgue integral
By the definition of the Riemann integral:
\[
\int_a^b F'(x)\, \dd{x} = \lim_{n \to \infty} \sum_{i=1}^n F'(x_i^*) \Delta x_i,
\]
where \( \{x_i^*\} \) are sample points in the subintervals of a partition \( P = \{x_0, x_1, \dots, x_n\} \) of \([a, b]\), and \( \Delta x_i = x_i - x_{i-1} \).
By the Mean Value Theorem for derivatives, since \( F(x) \) is differentiable, there exists an adequately refined partition \( P = \{x_0, x_1, \dots, x_n\} \) such that on each subinterval \([x_{i-1}, x_i]\) there exists a point \( x_i^* \in [x_{i-1}, x_i] \) such that:
\[
F'(x_i^*) \cdot \Delta x_i = F(x_i) - F(x_{i-1}).
\]
Thus, the Riemann sum becomes:
\[
\sum_{i=1}^n F'(x_i^*) \Delta x_i = \sum_{i=1}^n \left(F(x_i) - F(x_{i-1})\right) = F(b) - F(a).
\]
\end{proof}
\sssc{The Second Theorem}
Let $f(x)$ be a function continuous on $[a,b]$. Then:
\[\dv{x}\int_a^xf(t)\dd{t}=f(x).\]
\begin{proof}
\[\dv{x}\qty(\int_a^xf(t)\,\dd{t})=\lim_{h\to 0}\frac{\int_a^{x+h}f(t)\,\dd{t}-\int_a^xf(t)\,\dd{t}}{h}\]
Using the additivity property of integrals:
\[\int_a^{x+h}f(t)\,\dd{t}-\int_a^xf(t)\,\dd{t}=\int_x^{x+h}f(t)\,\dd{t}\]
By the Mean Value Theorem for integrals, since \(f(t)\) is continuous on \([x,x+h]\), there exists a point \(c\in [x,x+h]\) such that:
\[\int_x^{x+h} f(t)\, \dd{t} = f(c) \cdot h.\]
Substituting into the difference quotient:
\[\frac{\int_x^{x+h}f(t)\,\dd{t}}{h} = f(c).\]
\[\lim_{h\to 0}\frac{\int_x^{x+h}f(t)\,\dd{t}}{h} = f(x).\]
\end{proof}
\ssc{Fundamental theorem of calculus of Banach-space valued functions}{{{



\section{Multivariable (多變數 or 多變量 or 多元) Calculus}
\subsection{Operators}
\begin{itemize}
\item Dot product (點積) operator: $\cdot$
\item Cross product (叉積) operator: $\times$
\item Gradient (梯度) operator: $\nabla$
\item Divergence (散度) operator: $\nabla \cdot$
\item Curl (旋度) operator: $\nabla \times$
\item Directional derivative (方向導數) operator: $\cdot\nabla$
\item Laplace (拉普拉斯) operator: $\nabla^2$或$\Delta$
\item Line or Path integral operator: $\int$
\item Surface integral operator: $\iint$
\item Volume integration operator: $\iiint$
\item Closed line integral operator: $\oint$
\item Closed surface Integral Operator: $\oiint$
\item $\int\mathbf{F}\cdot\mathrm{d}\mathbf{S}$ is used as a shorthand for $\int(\mathbf{F}\cdot\mathbf{\hat{n}})\,\mathrm{d}S$, where $\hat{n}$ is the outward pointing unit normal at almost each point on $S$.
\end{itemize}
\subsection{Convention}
If not otherwise specified:
\begin{itemize}
\item The domain of the funcitons or maps below are subsets of a Euclidean vector space. If not otherwise specified, the coordinates are the Cartesian coordinates, the norms are the Euclidean norms, and the measures are the Lebesgue measures.
\item $\mathbf{0}$ or $0$ refers to the zero tensor (零張量) in the interested Euclidean tensor space $V$, that is, it satisfies 
\[\forall\mathbf{v}\in V:\,\mathbf{v}+\mathbf{0}=\mathbf{v}.\]
\item Unit vector (單位向量): $\mathbf{e}_i$ is the unit vector in the $i$th direction, i.e., a vector with zero norm.
\item Independent variable vector: $\mathbf{x}=(x_1,x_2,\dots,x_n)$
\item Vector fields: $\mathbf{F}(\mathbf{x}) = \sum_{i=1}^n F_i(\mathbf{x}) \mathbf{e}_i$、$\mathbf{G}$
\item Scalar fields: $A(\mathbf{x})$、$B(\mathbf{x})$
\item Tensor fields: $f(\mathbf{x})$、$g(\mathbf{x})$
\item Three-dimensional tensor space field: $\mathbf{T}(\mathbf{x})$
\item The $i$th component of the map $f$: $f_i$
\end{itemize}
\subsection{Gradient}
\[
\nabla f = \begin{pmatrix}\qty(\pdv{f}{x_1})^T & \qty(\pdv{f}{x_2})^T & \dots  & \qty(\pdv{f}{x_n})^T\end{pmatrix}
\]
The gradient of a scalar field is a vector field, the gradient of a vector field is a second-order tensor (matrix) field, and the gradient of a $k$-order tensor field is a $k+1$-order tensor field. 

In particular, the gradient of a scalar field $A$ is
\[
\nabla A = \sum_{i=1}^n \pdv{A}{x_i}e_i.
\]
And the gradient of a vector field $\mathbf{F}$ is also called the Jacobian matrix (雅可比矩陣) of it and also denoted as $\mathbf{J}(\mathbf{F})$, $J(\mathbf{F})$, or $J_{\mathbf{F}}$, of which the $( i,j )$th entry is
\[\mathbf{J}_{ij}=\frac{\partial F_i}{\partial x_j}.\]
The determinant $\det\left(J_{\mathbf{F}}\right)$ of a Jacobian matrix is called a Jacobian determinant, or Jacobian for short.
\subsection{Divergence}
\[
\nabla \cdot f = \sum_{i=1}^n\frac{\partial f_i}{\partial x_i}
\]
The divergence of a vector field is a scalar field, the gradient of a second-order tensor (i.e. matrix) field is a vector field, and the divergence of a $k+1$-order tensor field is a $k$-order tensor field.
\subsection{Curl}
The curl is only defined on three-dimensional vector field.
\[
\nabla \times \mathbf{T} = 
\begin{pmatrix}
\mathbf{e}_1 & \mathbf{e}_2 & \mathbf{e}_3 \\
\frac{\partial}{\partial x_1} & \frac{\partial}{\partial x_2} & \frac{\partial}{\partial x_3} \\
T_1 & T_2 & T_3 \\
\end{pmatrix}
\]
The curl of a three-dimensional vector field is a three-dimensional vector field.
\subsection{Directional derivative}
\[(\mathbf{f}\cdot\nabla)\mathbf{g}=\sum_{i=1}^n f_i\pdv{g}{x_i}\]
\subsection{Laplace operator}
\[
\nabla^2 f = \nabla \cdot (\nabla f) = \sum_{i=1}^n\frac{\partial^2 f}{\partial x_i^{\phantom{i}2}}
\]
The Laplace operator applied to a tensor field is a tensor field of the same order and same dimension (but not necessarily the same field).
\subsection{Poisson's equation (卜瓦松 or 帕松 or 泊松方程)}
\[
\nabla^2 A = B(\mathbf{x})
\]
\subsection{Laplace's equation (拉普拉斯方程)}
\[
\nabla^2 A = 0
\]
A real function $A$ with real independent variables that is second-order differentiable for all independent variables is called a harmonic function if $A$ satisfies Laplace's equation.
\subsection{Multi-index notation (多重指標記號)}
Suppose there are \( n \) variables \( x_1, x_2, \dots, x_n \), then a multi-index $\alpha$ is a vector of \( n \) nonnegative integers: 
\[
\alpha = (\alpha_1, \alpha_2, \ldots, \alpha_n), \quad \text{where\ } \alpha_i \in \mathbb{N}_0.
\]
Define: 
\begin{itemize}
\item Norm \( \|\alpha\| \): 
\[
\|\alpha\| = \alpha_1 + \alpha_2 + \ldots\alpha_n.
\]
\item Factorial \( \alpha! \): 
\[
\alpha! = \alpha_1! \cdot \alpha_2! \cdot \ldots \alpha_n!.
\]
\item Power \( \mathbf{x}^\alpha \): 
If \( \mathbf{x} = (x_1, x_2, \ldots x_n) \), then
\[
\mathbf{x}^\alpha = x_1^{\alpha_1} \cdot x_2^{\alpha_2} \ldots  x_n^{\alpha_n}.
\]
\item Higher-order mixed partial derivatives $D^\alpha f$: 
\[
D^\alpha f = \frac{\partial^{\|\alpha\|} f}{\partial x_1^{\alpha_1} \partial x_2^{\alpha_2} \ldots  \partial x_n^{\alpha_n}}.
\]
\end{itemize}
\subsection{Higher-order derivative}
The $k$th order derivative of $\mathbf{F}:\,\mathbb{R}^n\to\mathbb{R}^m$, denoted as $\mathbf{F}^{(k)}(\mathbf{x})$ or $D^{k}\mathbf{F}(\mathbf{x})$, is a $(\mathbb{R}^n)^k\to\mathbb{R}$ function, where $(\mathbb{R}^n)^k$ is a Cartesian product of $k$ copies of $\mathbb{R}^n$ vector, that is,
\[D^{k}\mathbf{F}(\mathbf{x})=\sum_{\|\alpha\|=k} \left(D^\alpha \mathbf{F}(\mathbf{a})\right).\]
In particular, the first-order derivative of $\mathbf{F}$ is the gradient of it.
\subsection{Taylor expansion}
Assume that $\mathbf{F}:\,\mathbb{R}^n\to\mathbb{R}^m$ is an infinitely differentiable function, and its partial derivatives of every order exist on $\mathbb{R}^n$, then the Taylor expansion of $\mathbf{F}$ at $\mathbf{a}$ is
\[\mathbf{F}(\mathbf{x}) = \sum_{\|\alpha\|\in\mathbb{N}_0} \frac{D^\alpha \mathbf{F}(\mathbf{a})}{\alpha!} (\mathbf{x} - \mathbf{a})^\alpha,\]
that is,
\[\mathbf{F}(\mathbf{x}) = \sum_{\|\alpha\|\leq k} \frac{D^\alpha \mathbf{F}(\mathbf{a})}{\alpha!} (\mathbf{x} - \mathbf{a})^\alpha+\int_0^1\frac{(1-t)^k}{k!} D^{k+1}\mathbf{F}(\mathbf{a} + t(\mathbf{x} - \mathbf{a})) (\mathbf{x} - \mathbf{a})^{k+1} \, \mathrm{d}t.\]
Also, the $k$th-order approximation of $\mathbf{F}$ near $\mathbf{a}$ is
\[\mathbf{F}(\mathbf{x}) \approx \sum_{\|\alpha\|\leq k} \frac{D^\alpha \mathbf{F}(\mathbf{a})}{\alpha!} (\mathbf{x} - \mathbf{a})^\alpha,\]
and the first-order (aka linear) approximation near $\mathbf{a}$ is
\[\mathbf{F}(\mathbf{x}) \approx \mathbf{F}(\mathbf{a}) + \nabla \mathbf{F}(\mathbf{a}) \cdot (\mathbf{x} - \mathbf{a}).\]
\ssc{Line integral (線積分) or Path integral (路徑積分)}
\sssc{Scalar field line or path integral}
For a scalar field $A : \,U\subseteq \mathbb {R} ^{n}\to \mathbb {R}$ and the path $C \in U$, the line integral of $A$ is: 
\[\int _{C}A\,\mathrm {d} s=\int _{a}^{b}A(\mathbf{r}(t))\|\dv{t}\mathbf {r} (t)\|\,\mathrm {d} t,\]
where $\mathbf{r}:\, [a, b] \to C$ is a one-to-one parametric function with $\mathbf{r}(a)$ and $\mathbf{r}(b)$ being the two endpoints of the path $C$. 

$A$ is called the integral function, $C$ is called the integral path, and the result of the line integration does not depend on the parametric function $r$.
\sssc{Vector field line or path integral}
willie169-ckhs-ntuee-notesFor a scalar field $\mathbf{F}: \,U\subseteq \mathbb {R} ^{n}\to \mathbb {R}^n$ and the path $C \in U$, the line integral of $\mathbf{F}$ is: 
\[\int _{C}\mathbf {F} (\mathbf {r} )\cdot \,\mathrm {d} \mathbf{r}=\int _{a}^{b}\mathbf {F} (\mathbf {r} (t))\cdot \dv{t}\mathbf {r} (t)\,\mathrm {d} t\]
where $\mathbf{r}:\, [a, b] \to C$ is a one-to-one parametric function with $\mathbf{r}(a)$ and $\mathbf{r}(b)$ being the two endpoints of the path $C$. 

$\mathbf{F}$ is called the integral function, $C$ is called the integral path, and the result of the line integration does not depend on the parametric function $\mathbf{r}$.
\sssc{Conservative field (保守場)}
A field $f$ whose domain is a subset $U$ of a Euclidean tensor space is called a conservative field if for all paths $C$ between point $a$ and $b$, the integral 
\[\int_Cf(\mathbf{x})\cdot\mathrm{d}\mathbf{x}\]
are the same.

This implies 
\begin{itemize}
\item For any closed path $C$, 
\[\int_Cf(\mathbf{x})\cdot\mathrm{d}\mathbf{x}=0.\]
\item If $\operatorname{dim}(U)=3$, then for any subset of $U$ where $f$ is smooth,
\[\nabla\times f=0.\]
\end{itemize}
\ssc{Fundamental theorem of multivariable calculus (多變數微積分基本定理)}
\sssc{Gradient theorem (梯度定理)}
Suppose $r$ is a oriented differentiable curve that starts at a point $\mathbf{p}$ and ends at a point $\mathbf{q}$. If $\mathbf{F}$ is a differentiable tensor field defined on a neighborhood of $\mathbf{F}$, then,
\[\int_r(\nabla\mathbf{F})\cdot\mathrm{d}\mathbf{r}=\mathbf{F}\left(\mathbf{q}\right)-\mathbf{F}\left(\mathbf{p}\right).\]
Gradient theorem is a special case of generalized Stokes theorem.
\sssc{Divergence theorem, Gauss's theorem, or Ostrogradsky's theorem (高斯散度定理)}
Suppose $V\subseteq\mathbb{R}^n$ is compact and has a piecewise smooth boundary $S$ (also indicated with $\partial V=S$). The closed, measurable set $\partial V$ is oriented by outward-pointing normals. If $F$ is a continuously differentiable vector field defined on a neighborhood of $V$, then,
\[\iiint_V\left(\nabla\cdot\mathbf {F}\right)\,\mathrm{d}V=\oiint_S\mathbf{F}\cdot\mathrm{d}\mathbf{S}\]
Divergence theorem is a special case of generalized Stokes theorem.
\sssc{Stokes' theorem (斯托克斯定理) or Kelvin–Stokes theorem}
Let $S$ be a positively oriented, piecewise smooth surface in $\mathbb{R}^3$ with boundary $\partial S\equiv L$. If a vector field $\mathbf{F}:\,\mathbb{R}^3\rightarrow\mathbb{R}^3$ is defined and has continuous first order partial derivatives in a region containing $S$, then,
\[\iint_S(\nabla\times\mathbf{F})\cdot \mathrm{d}\mathbf{S}=\oint_{L}\mathbf{F}\cdot\mathrm{d}\mathbf{L}\]
Stokes' theorem is a special case of generalized Stokes theorem.
\sssc{Green's theorem (格林定理或綠定理)}
Let $S$ be a positively oriented, piecewise smooth surface in $\mathbb{R}^2$ with boundary $\partial S\equiv L$. If scalar function $P,(x,y)\,Q(x,y)$ are defined and has continuous first order partial derivatives in a region containing $S$, then,
\[\oint_L (P\mathrm{d}x+Q\mathrm{d}y)=\iint_S\left(\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y}\right)\mathrm{d}x\mathrm{d}y\]
where the path of integration along C is counterclockwise.

Green's theorem is a special case of Stokes' theorem.
\sssc{Generalized Stokes theorem, Stokes–Cartan theorem, or fundamental theorem of multivariable calculus}
The generalized Stokes theorem says that the integral of a differential form $\omega$ over the boundary $\partial\Omega$ of some orientable manifold $\Omega$ is equal to the integral of its exterior derivative $\mathrm{d}\boldsymbol{\omega}$ over the whole of $\Omega$, i.e.,
\[\int _{\partial\Omega}\omega=\int_{\Omega}\mathrm{d}\boldsymbol{\omega}\]



\section{Differential theorems and methods}
\ssc{Linearity, or sum rule, difference rule, and constant multiple rule}
If functions $f$ and $g$ are differentiable on $I$ and $a,b\in\mathbb{R}$, then $af(x)+bg(x)$ is also differentiable on $I$ and its derivative is given by
\[\dv{}{x}\qty(af(x)+bg(x))=af'(x)+bg'(x).\]
\begin{proof}
\[\ba
\dv{}{x}\qty(af(x)+bg(x))&=\lim_{h\to 0}\frac{af(x+h)+bg(x+h)-af(x)-bg(x)}{h}\\
&=af'(x)+bg'(x)
\ea\]
\end{proof}
\ssc{Product rule (乘法定則)}
If functions $f$ and $g$ are differentiable on $I$, then the product $fg$ is also differentiable on $I$ and its derivative is given by
\[\dv{x}\qty(f(x)g(x))=f'(x)g(x)+f(x)g'(x).\]
\begin{proof}
\[\begin{aligned}
\dv{f(x)g(x)}{x}&=\lim_{h\to 0}\frac{f(x+h)g(x+h)-f(x)g(x)}{h}\\
&=\lim_{h\to 0}\frac{f(x+h)(g(x+h)-g(x))+g(x)(f(x+h)-f(x))}{h}\\
&=f(x)g'(x)+f'(x)g(x).
\end{aligned}\]
\end{proof}
\ssc{General Leibniz rule}
If functions $f$ and $g$ are $n$-times differentiable on $I$, then the product $fg$ is also $n$-times differentiable on $I$ and its derivative is given by
\[(fg)^{(n)}=\sum _{k=0}^{n}{n \choose k}f^{(n-k)}g^{(k)}.\] 
\ssc{Quotient rule (除法定則)}
If functions $f$ and $g$ are differentiable on $I$ and $g\neq 0$ on $I$, then the quotient $\frac{f}{g}$ is also differentiable on $I$ and its derivative is given by
\[\dv{x}\qty(\frac{f(x)}{g(x)})=\frac{f'(x)g(x)-f(x)g'(x)}{\qty(g(x))^2}.\]
\begin{proof}
\[\begin{aligned}
\dv{}{x}\frac{f(x)}{g(x)}&=\lim_{h\to 0}\frac{\frac{f(x+h)}{g(x+h)}-\frac{f(x)}{g(x)}}{h}\\
&=\lim_{h\to 0}\frac{f(x+h)g(x)-f(x)g(x+h)}{h\,g(x+h)g(x)}\\
&=\lim_{h\to 0}\frac{(f(x+h)-f(x))g(x)-f(x)(g(x+h)-g(x))}{h\,g(x+h)g(x)}\\
&=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h\,g(x+h)}-f(x)\lim_{h\to 0}\frac{g(x+h)-g(x)}{h\,g(x+h)g(x)}\\
&=\frac{f'(x)g(x)-f(x)g'(x)}{g(x)^2}
\end{aligned}\]
\end{proof}
\ssc{Chain rule (連鎖律)}
If functions $f$ and $g$ are differentiable on $I$, then the composite $f\circ g$ is also differentiable on $I$ and its derivative is given by
\[\dv{}{x}\qty((f\circ g)(x))=f'\qty(g(x))g'(x).\]
\begin{proof}
\[\ba
\dv{}{x}\qty((f\circ g)(x))&=\lim_{h\to 0}\frac{f\qty(g(x+h))-f\qty(g(x))}{h}\\
&=\lim_{h\to 0}\frac{f\qty(g(x+h))-f\qty(g(x))}{g(x+h)-g(x)}\cdot\frac{g(x+h)-g(x)}{h}\\
&=f'\qty(g(x))g'(x)
\ea\]
\end{proof}
\ssc{Power rule combined with chain rule}
If $n\in\bbR$ and $f(x)$ is differentiable on $I$, then $\qty(f(x))^n$ is also differentiable on $I$ and its derivative is given by
\[\dv{}{x}\qty(f(x))^n=n\qty(f(x))^{n-1}\cdot f'(x).\]
\ssc{Faà di Bruno's formula}
\bma
&\frac{\mathrm{d}^n}{\mathrm{d}x}f\left(g(x)\right)\\
=&\sum_{\sum_{i=1}^nim_i=n,\quad m_i\in\mathbb{N}_0}\frac{n!}{\prod_{j=1}^nm_j!}\cdot\\
&f^{\qty(\sum_{j=1}^nm_j)}\left(g(x)\right)\cdot\\
&\prod_{j=1}^n\left(\frac {g^{(j)}(x)}{j!}\right)^{m_j}.
\eam
\ssc{Implicit differentiation (隱函數微分)}{{{

\subsection{Extreme Value Theorem (EVT) (極值定理)}
Let function $f\colon I\subseteq\mathbb{R}\to\mathbb{R}$ be continuous on an interval $[a,b]\subseteq I$, then
\[\exists c,d \in [a, b] \text{\ s.t.\ }\forall x \in [a, b]\colon f(c)\geq f(x)\geq f(d).\]
\begin{proof}\mbox{}\\
We first claim that $f$ is bounded on $[a,b]$. Argue by contradiction. Suppose $f$ is not bounded-above.

For any $n\in\mathbb{N}$, there exists $x_n\in [a,b]$ such that $f\qty(x_n)>n$. This defines a sequence $\langle x_n\rangle$.

By the Bolzano-Weierstrass Theorem and that $[a,b]$ is bounded, it has a convergent subsequence $x_{n_k}$ that converges to some limit $L$. Since $[a,b]$ is closed, $L\in [a,b]$.

Since $f$ is continuous on $[a,b]$, the sequence $f\qty(x_{n_k})$ converges to $f(L)$, which is finite.

This contradicts $f\qty(x_n)>n$ for every $n\in\mathbb{N}$. So the set
\[S=\{f(x)\mid x\in [a,b]\}.\]
must be bounded-above.

By considering $-f$, we obtain that $S$ is also bounded-below.

By the Completeness of the Real Numbers, every non-empty set bounded-above has a least upper bound; every non-empty set bounded-below has a greatest lower bound.

Let
\[M=\sup S,\quad m=\inf S.\]

Since $M$ is the least upper bound of $S$, for any $n\in\mathbb{N}$, $M-\frac{1}{n}$ is not an upper bound of $S$. This means that for each $n\in\mathbb{N}$, there exists a point $y_n\in [a,b]$ such that:
\[M-\frac{1}{n}<f(y_n)\leq M.\]
This defines another sequence $\langle y_n\rangle$ within $[a, b]$.

By the Bolzano-Weierstrass Theorem and that $[a,b]$ is bounded, it has a convergent subsequence $y_{n_k}$ that converges to some limit $c$. Since $[a,b]$ is closed, $c\in [a,b]$.
\[\lim_{n_k\to \infty}\qty(M - \frac{1}{n_k}) = M.\]
By the Squeeze Theorem:
\[\lim_{n_k \to \infty} f\qty(y_{n_k}) = M.\]
Since $f$ is continuous on $[a,b]$, the sequence $f\qty(y_{n_k})$ converges to $f(c)$.

Similarly, we can prove that there exists $d\in [a,b]$ such that $f(d)=m$.
\end{proof}
\ssc{Fermat's Theorem (費馬引理) or Interior Extremum Theorem (內部極值定理)}
Let function $f\colon D\subseteq\mathbb{R}\to\mathbb{R}$ be differentiable on an open interval $I\subseteq D$ and $c\in I$ be a local extreme of $f$, then
\[f'(c)=0.\]
\begin{proof}
Without loss of generality, suppose $c$ is a local extreme. Then there exists $\delta>0$ such that for all $x\in (c-\delta,c+\delta)\colon f(x)\leq f(c)$.

Thus,
\[\lim_{h\to 0^+}\frac{f(x+h)-f(x)}{h}\leq 0\]
and
\[\lim_{h\to 0^-}\frac{f(x+h)-f(x)}{h}\geq 0.\]

Since $f$ is differentiable at $c$,
\[\lim_{h\to 0^+}\frac{f(x+h)-f(x)}{h}=\lim_{h\to 0^-}\frac{f(x+h)-f(x)}{h}=0=f'(c).\]
\end{proof}
\ssc{Rolle's Theorem (羅爾定理)}
Let function $f\colon I\subseteq\mathbb{R}\to\mathbb{R}$ be continuous on an interval $[a, b]\subseteq I$ and differentiable on $(a,b)$, then
\[\exists c\in (a, b)\text{\ s.t.\ }f'(c)=0.\]
\begin{proof}
By the Extreme Value Theorem, $f$ must have maximum and minimum on $[a,b]$.

Let
\[M=\max_{x\in [a,b]}f(x),\quad m=\min_{x\in [a,b]}f(x).\]
If $M=m$, then $f$ is constant on $[a,b]$, then $f'(x)=0$ for any $c\in (a,b)$.

Otherwise, $M>m$. Because $f(a)=f(b)$. 

We claim that there must be $c\in (a,b)$ such that $M=f(c)$ or $m=f(c)$. Argue by contradiction. If the claim is false, then $M=m=f(a)=f(b)$, contradicting $M>m$.

By Fermat's Theorem,
\[f'(c)=0.\]
\end{proof}
\subsection{Mean Value Theorem (MVT) (均值定理)}
Let function $f\colon I\subseteq\mathbb{R}\to\mathbb{R}$ be continuous on an interval $[a, b]\subseteq I$ and differentiable on $(a,b)$, then
\[\exists c\in (a, b)\text{\ s.t.\ }f'(c)=\frac{f(b)-f(a)}{b-a}.\]
\begin{proof}
Let
\[\phi(x) = f(x) - \frac{f(b)-f(a)}{b-a} (x-a).\]
\[\phi(a)=\phi(b)=f(a).\]
By Rolle's Theorem, there exists $c\in (a,b)$ such that $\phi'(c)=0$.
\[\phi'(c)=f'(c)-\frac{f(b)-f(a)}{b-a}.\]
\end{proof}
\sssc{Cauchy's Mean Value Theorem (CMVT) (柯西均值定理)}
Let functions $f\colon I\subseteq\mathbb{R}\to\mathbb{R}$ and $g\colon J\subseteq\mathbb{R}\to\mathbb{R}$ be continuous on an interval $[a, b]\subseteq I\cap J$ and differentiable on $(a,b)$, and $g'(x)\neq 0$ for all $x\in (a,b)$, then
\[\exists c\in (a,b)\text{\ s.t.\ }\frac{f(b)-f(a)}{g(b)-g(a)}=\frac{f'(c)}{g'(c)}.\]
\begin{proof}\mbox{}\\
    Define a function
    \[\phi(x)=f(x)-\frac{f(b)-f(a)}{g(b)-g(a)}g(x).\]
    \[\phi(b)-\phi(a)=\qty(f(b)-f(a))-\frac{f(b)-f(a)}{g(b)-g(a)}\qty(g(b)-g(a))=0.\]
    By Rolle's Theorem, there exists $c\in (a,b)$ such that $\phi'(c)=0$.
    \[\phi'(x)=f'(x)-\frac{f(b)-f(a)}{g(b)-g(a)}g'(x).\]
    \[\frac{f(b)-f(a)}{g(b)-g(a)}=\frac{f'(c)}{g'(c)}.\]
\end{proof}
\subsection{General form of L'Hôpital's rule (羅必達法則) or Bernoulli's rule}
Let $I$ be an open interval and $a\in I$, and $f(x)$ and $g(x)$ be functions differentiable on $I\setminus\{a\}$. If $\lim_{x\to a}f(x)=\lim_{x\to a}g(x)\in\{0,\infty,-\infty\}$ and $\lim_{x\to a}\frac{f'(x)}{g'(x)}\in\mathbb{R}\cup\{-\infty,\infty\}$, then:
\[\lim_{x\to a}\frac{f(x)}{g(x)}=\lim_{x\to a}\frac{f'(x)}{g'(x)}.\]

Let $f(x)$ and $g(x)$ be functions differentiable on $(a,b)$ with $a<b$. If $\lim_{x\to a^+}f(x)=\lim_{x\to a^+}g(x)\in\{0,\infty,-\infty\}$ and $\lim_{x\to a^+}\frac{f'(x)}{g'(x)}\in\mathbb{R}\cup\{-\infty,\infty\}$, then:
\[\lim_{x\to a^+}\frac{f(x)}{g(x)}=\lim_{x\to a^+}\frac{f'(x)}{g'(x)}.\]

Let $f(x)$ and $g(x)$ be functions differentiable on $(b,a)$ with $a>b$. If $\lim_{x\to a^-}f(x)=\lim_{x\to a^-}g(x)\in\{0,\infty,-\infty\}$ and $\lim_{x\to a^-}\frac{f'(x)}{g'(x)}\in\mathbb{R}\cup\{-\infty,\infty\}$, then:
\[\lim_{x\to a^-}\frac{f(x)}{g(x)}=\lim_{x\to a^-}\frac{f'(x)}{g'(x)}.\]

Let $f(x)$ and $g(x)$ be functions differentiable on $(a,\infty)$. If $\lim_{x\to\infty}f(x)=\lim_{x\to\infty}g(x)\in\{0,\infty,-\infty\}$ and $\lim_{x\to\infty}\frac{f'(x)}{g'(x)}\in\mathbb{R}\cup\{-\infty,\infty\}$, then:
\[\lim_{x\to\infty}\frac{f(x)}{g(x)}=\lim_{x\to\infty}\frac{f'(x)}{g'(x)}.\]

Let $f(x)$ and $g(x)$ be functions differentiable on $(-\infty,a)$. If $\lim_{x\to-\infty}f(x)=\lim_{x\to-\infty}g(x)\in\{0,\infty,-\infty\}$ and $\lim_{x\to-\infty}\frac{f'(x)}{g'(x)}\in\mathbb{R}\cup\{-\infty,\infty\}$, then:
\[\lim_{x\to-\infty}\frac{f(x)}{g(x)}=\lim_{x\to-\infty}\frac{f'(x)}{g'(x)}.\]
\begin{proof}\mbox{}\\
Let $f(x)$ and $g(x)$ be functions differentiable on $(a,b)$ with $a<b$. We want to show that if $\lim_{x\to a^+}f(x)=\lim_{x\to a^+}g(x)=0$ and $\lim_{x\to a^+}\frac{f'(x)}{g'(x)}\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to a^+}\frac{f(x)}{g(x)}=\lim_{x\to a^+}\frac{f'(x)}{g'(x)}.\]
Let
\[F(x)=\begin{cases}f(x),\quad & x\in (a,b)\\
\lim_{x\to a^+}f(x),\quad & x=a\end{cases}\]
and
\[G(x)=\begin{cases}g(x),\quad & x\in (a,b)\\
\lim_{x\to a^+}g(x),\quad & x=a\end{cases}\]
By CMVT, for any $x\in (a,b)$, there exists $c\in (a,x)$ such that
\[\frac{F(x)-F(a)}{G(x)-G(a)}=\frac{F'(c)}{G'(c)}.\]
Since $F(a)=G(a)=0$,
\[\frac{F(x)}{G(x)}=\frac{F'(c)}{G'(c)}.\]
Thus,
\[\lim_{x\to a^+}\frac{f(x)}{g(x)}=\lim_{x\to a^+}\frac{f'(x)}{g'(x)}.\]

Other statements can be proved similarly.
\end{proof}
{{{ mb better statement and search name and prove start
\subsection{Concavity theorem}
Let $f:\,J\subseteq\mathbb{R}\to\mathbb{R}$ be differentiable on the open interval $I\subseteq J$. If $\forall x\in I:\,f''>0$, then the graph of $f$ is concave upward on $I$; if $\forall x\in I:\,f''<0$, then the graph of $f$ is concave downward on $I$.
\subsection{Inflection point theorem}
If $(c,f(c))$ is an inflection point of $f$, then $f''(c)=0$ or $f''$ does not exist at $c$.
{{{ end
\subsection{Lagrange multiplier (method) (拉格朗日乘數 or 乘子（法）)}
The Lagrange multiplier method is a method for finding the points where extremes occur of a differentiable function under constraints.
\sssc{Univariate form}
Let $f:\,\mathbb{R} \rightarrow \mathbb{R}$ and $g:\,\mathbb{R} \rightarrow \mathbb{R}$ . We want to find the points where extremes of \( f(x) \) under the constraint \( g(x) = \mathbf{0} \) occur. 

First, construct the Lagrangian function \( \mathcal{L}(x,\lambda) \):
\[\mathcal{L}(x,\lambda) = f(x) - \lambda \cdot g(x),\]
where \( \lambda\in\mathbb{R} \) is the Lagrange multiplier (拉格朗日乘數 or 乘子).

Find the derivative of $\mathcal{L}$ and set it to zero:
\[
\dv{\mathcal{L}}{x} = 0
\]
Solve the equation to find \( x \) and \( \lambda \) . 

\text{Statement:} Let $A$ be the set of all solutions for \( x \) such that $\dv{\mathcal{L}}{x} = 0$, and $B$ be the set of all points where extremes of \( f(x) \) under the constraint \( g(x) = \mathbf{0} \) occur. We claim that $B\subseteq A$.
\sssc{Multivariate form}
Let \( \mathbf{x} = (x_1, x_2, \dots, x_n) \) be the independent variable vector and $\mathbf{0}$ be the zero vector. Now we have $f:\,\mathbb{R}^n \rightarrow \mathbb{R}$ and $g:\,\mathbb{R}^n \rightarrow \mathbb{R}^c$. We want to find the points where extremes of \( f(\mathbf{x}) \) under the constraint \( g(\mathbf{x}) = \mathbf{0}\) occur. 

First, construct the Lagrangian function \( \mathcal{L}(\mathbf{x},\lambda) \):
\[
\mathcal{L}(\mathbf{x},\lambda) = f(\mathbf{x}) - \lambda \cdot g(\mathbf{x}),
\]
where \( \lambda\in\mathbb{R}^c \) is the Lagrange multiplier vector.

Find the gradient of $\mathcal{L}$ and set it to zero:
\[
\nabla \mathcal{L} = \mathbf{0}
\]
Solve the equation to find \( \mathbf{x} \) and \( \lambda \) . 

\text{Statement:} Let $A$ be the set of all solutions for \( \mathbf{x} \) such that $\nabla \mathcal{L} = \mathbf{0}$, and $B$ be the set of all points where extremes of \( f(\mathbf{x}) \) under the constraint \( g(\mathbf{x}) = \mathbf{0}\) occur. We claim that $B\subseteq A$.
\begin{proof}\mbox{}\\
Consider $\mathbf{x}^*\in B$. It must satisfy the constraint:
\[g(\mathbf{x}^*) = \mathbf{0}.\]
Any feasible point $\mathbf{x}$ near $\mathbf{x}^*$ must satisfy the constraint. We can represent $\mathbf{x}$ as:
\[\mathbf{x} = \mathbf{x}^* + \delta\mathbf{x},\]
where $\delta\mathbf{x}$ is a differential change tangent to the manifold defined by $g(\mathbf{x})$, that is, it lies in the kernel of $\nabla g(\mathbf{x}^*)$, that is,
\[g(\mathbf{x}^* + \delta\mathbf{x}) = \mathbf{0}.\]
Find the first-order approximation of $f$ at $\mathbf{x}^*$:
\[f(\mathbf{x}^*+ \delta\mathbf{x}) \approx f(\mathbf{x}^*) + \nabla f(\mathbf{x}^*) \cdot \delta\mathbf{x} + O(\|\delta\mathbf{x}\|^2)\]
Find the first-order approximation of $g$ at $\mathbf{x}^*$:
\[g(\mathbf{x}^*+ \delta\mathbf{x}) \approx g(\mathbf{x}^*) + \nabla g(\mathbf{x}^*) \cdot \delta\mathbf{x} + O(\|\delta\mathbf{x}\|^2)\]
Since $\mathbf{x}^*\in B$, for any feasible $\delta\mathbf{x}$ we must have:
\[\nabla f(\mathbf{x}^*) \cdot \delta\mathbf{x} = 0.\]
Since $g(\mathbf{x}^*) = \mathbf{0}$, we have
\[\nabla g(\mathbf{x}^*) \cdot \delta\mathbf{x} = O(\|\delta\mathbf{x}\|^2).\]
Because \( \delta\mathbf{x} \in \ker(\nabla g(\mathbf{x}^)) \), \( \nabla f(\mathbf{x}^) \) can be expressed as a linear combination of \( \nabla g(\mathbf{x}^) \) . This means that there exists a vector to $\lambda$ such that:
\[\nabla\mathcal{L} = \nabla \qty(f(\mathbf{x}) - \lambda \cdot g(\mathbf{x})) = \mathbf{0} \]
\end{proof}
\ssc{Generalized Schwarz's Theorem, Young's Theorem, or Clairaut's Theorem on equality or symmetry of mixed partial derivatives}
For a function $f\colon\Omega\subseteq\mathbb{R}^n\to\mathbb{R}^o$ and any $m$th derivative function $g$ of it given by
\[g=\frac{\partial^mf}{\prod_{k=1}^r\partial x_{i_k}^{\phantom{i_k}m_k}}\]
with $\sum_{k=1}^rm_k=m$ and $i_k\in\mathbb{N}\land i_k\leq n$ for all $k$. Define constants $t_q$ for all $q\in\mathbb{N}\land q\leq n$ as $t_q=\sum_{i_k=q}m_k$. 

If any such $g$ exists in a neighborhood of $\mathbf{p}\in\Omega$ and is continuous at $\mathbf{p}$, then all such $g$ with the same $t_q$ for all $q\in\mathbb{N}\land q\leq n$ are equal at $\mathbf{p}$.



\section{Integral theorems and methods}
\ssc{Linearity, or sum rule, difference rule, and constant multiple rule}
If functions $f$ and $g$ are integrable over an interval $I$ and $a,b\in\mathbb{R}$, then $af(x)+bg(x)$ is also integrable over $I$ and its integral is given by
\[\int_Iaf(x)+bg(x)\dd{x}=a\int_If(x)\dd{x}+b\int_Ig(x)\dd{x}.\]
\subsection{Integration by substitution (代換積分法), integration by change of variables (換元積分法), u-substitution (u-代換), reverse chain rule, substitution theroem (代換定理), change of variables theorem (換元定理), or transformation theorem (變換定理)}
\subsubsection{Univariate form}
Let $g:\,I\subseteq\mathbb{R}\to\mathbb{R}$ be injective and differentiable on $[a,b]\subseteq I$, with $g'$ being integrable on $[a,b]$, and $f:\,K\supseteq g([a,b])\to\mathbb{R}$ be integrable on $g([a,b])$. Then:
\[\int_a^bf\circ g(x)\cdot g'(x)\,\mathrm{d}x=\int_{g(a)}^{g(b)}f(u)\,\mathrm{d}u,\]
and for $K=g([a,b])$:
\[\int f\circ g(x)\cdot g'(x)\,\mathrm{d}x=\int f(u)\,\mathrm{d}u.\]
\begin{proof}\mbox{}\\
Consider the interval \([a, b]\) partitioned as
\[P = \{a = x_0 < x_1 < \dots  < x_n = b\}.\]
For each subinterval \([x_{i-1}, x_i]\), let \(\xi_i \in [x_{i-1}, x_i]\) be a sample point. The Riemann sum for the left-hand side of the integral is:
\[S_P = \sum_{i=1}^n f(g(\xi_i)) g'(\xi_i) (x_i - x_{i-1}).\]
Since \(g\) is injective and differentiable, it is either strictly increasing or strictly decreasing on \([a, b]\). Assume \(g\) is strictly increasing (the proof for \(g\) strictly decreasing follows similarly).

Under this assumption, \(g\) maps \([a, b]\) to \([g(a), g(b)]\) (with \(g(a) < g(b)\)). Let \([g(a), g(b)]\) be partitioned as
\[Q = \{g(a) = u_0 < u_1 < \dots  < u_m = g(b)\},\]
where \(u_i = g(x_i)\). For \(g\) increasing, \((u_i - u_{i-1}) = g(x_i) - g(x_{i-1})\).

The Riemann sum for the right-hand side of the integral is:
\[T_Q = \sum_{i=1}^n f(u_i) (u_i - u_{i-1}).\]
Since \(u_i = g(x_i)\) and \(g'(\xi_i) \approx \frac{g(x_i) - g(x_{i-1})}{x_i - x_{i-1}}\), we rewrite:
\[ g'(\xi_i) (x_i - x_{i-1}) \approx g(x_i) - g(x_{i-1}) = u_i - u_{i-1}. \]
Thus, the left-hand Riemann sum \(S_P\) becomes:
\[ S_P = \sum_{i=1}^n f(g(\xi_i)) (u_i - u_{i-1}),\]
which matches the structure of the right-hand Riemann sum \(T_Q\) if we let \(\xi_i = g^{-1}(u_i)\).

As the partition \(P\) of \([a, b]\) gets finer, the Riemann sum \(S_P\) converges to \(\int_a^b f(g(x)) g'(x) \, \mathrm{d}x\). Similarly, as the partition \(Q\) of \([g(a), g(b)]\) gets finer, the Riemann sum \(T_Q\) converges to \(\int_{g(a)}^{g(b)} f(u) \, \mathrm{d}u\).
\end{proof}
\subsubsection{Multivariate form}
Let $\mathbf{T}:\,I\subseteq\mathbb{R}^n\to\mathbb{R}^n$ be injective and differentiable on $D\subseteq I$, with all elements of its gradient (i.e. Jacobian matrix) $\nabla\mathbf{T}$ being continuous on $D$, and $f:\,K\supseteq\mathbf{T}(D)\to\mathbb{R}$ be integrable on $\mathbf{T}(D)$. Then:
\[\int_{\mathbf{T}(D)}f(x_1\,x_2\,\dots\,x_n)\cdot\,\mathrm{d}x_1\,\mathrm{d}x_2\,\dots\,\mathrm{d}x_n=\int_D f(u_1\,u_2\,\dots\,u_n)\abs{\det\left(\nabla\mathbf{T}\right)}\,\mathrm{d}u_1\,\mathrm{d}u_2\,\dots\,\mathrm{d}u_n,\]
and for $K=\mathbf{T}(D)$:
\[\int f(x_1\,x_2\,\dots\,x_n)\cdot\,\mathrm{d}x_1\,\mathrm{d}x_2\,\dots\,\mathrm{d}x_n=\int f(u_1\,u_2\,\dots\,u_n)\abs{\det\left(\nabla\mathbf{T}\right)}\,\mathrm{d}u_1\,\mathrm{d}u_2\,\dots\,\mathrm{d}u_n.\]
\subsubsection{Measure theory form}
Let $X$ be a locally compact Hausdorff space equipped with a finite Radon measure $μ$, and let $Y$ be a \text{\textsigma}-compact Hausdorff space with a \text{\textsigma}-finite Radon measure $\rho$. Let $\phi:\,X\to Y$ be an absolutely continuous function, (which implies that $\mu(E)=0\implies\rho(\phi(E))=0$). Then there exists a real-valued Borel measurable function $w$ on $X$ such that for every Lebesgue integrable function $f:\,Y\to\mathbb{R}$, the function $(f\circ\phi)\cdot w$ is Lebesgue integrable on $X$, and for every open subset $U$ of $X$
\[\int_{\phi(U)}f(y)\,\mathrm{d}\rho(y)=\int_U(f\circ\phi)(x)\cdot w(x)\,\mathrm{d}\mu(x).\]
Furthermore, there exists some Borel measurable function $g$ such that 
\[w(x)=(g\circ\phi)(x).\]
\subsection{Integration by parts (IBP) (分部積分法) or partial integration (部分積分法)}
\subsubsection{Theorem}
\[\frac{\mathrm{d}}{\mathrm{d}x}\prod_{i=1}^nf_i(x)=\sum_{j=1}^n\left(\frac{\mathrm{d}f_j(x)}{\mathrm{d}x}\frac{\prod_{\substack{i=1\\i\neq j}}^n f_i(x)}{f_j(x)}\right)\]
For example,
\[\int_{\Omega} u\dd{v} = \qty(u v)\big\vert_{\Omega} - \int_{\Omega} v\dd{u}.\]
\subsubsection{Application}
Integration by parts is a heuristic rather than a purely mechanical process for solving integrals; given a single function to integrate, the typical strategy is to carefully separate this single function into a product of two functions such that the residual integral from the integration by parts formula is easier to evaluate than the single function.

The DETAIL rule or the LIATE rule is a rule of thumb for integration by parts. It involves choosing as u the function that comes first in the following list:
\begin{itemize}
\item L: Logarithmic function
\item I: Inverse trigonometric function
\item A: Algebraic function
\item T: Trigonometric function
\item E: Exponential function
\end{itemize}
\ssc{Leibniz integral rule (for differentiation under the integral sign) (（積分符號內取微分的）萊布尼茲積分法則)}
\sssc{Basic form for constant limits}
Let $a,b\in\mathbb{R}$, $f(x,t)$ be a function with domain $\mathbb{R}^2$, and the following integral exists. Then:
\[\begin{aligned}
&\dv{}{x}\qty(\int_a^bf(x,t)\dd{t})\\
=&\int_a^b\pdv{}{x}f(x,t)\dd{t}
\end{aligned}\]
\sssc{Basic form for variable limits}
Let $a(x),b(x)\in\mathbb{R}$, $f(x,t)$ be a function with domain $\mathbb{R}^2$, and the following integral exists. Then:
\[\begin{aligned}
&\dv{}{x}\qty(\int_{a(x)}^{b(x)}f(x,t)\dd{t})\\
=&f\qty(x,b(x))\cdot\dv{b(x)}{x}-f\qty(x,a(x))\cdot\dv{a(x)}{x}+\int_{a(x)}^{b(x)}\pdv{}{x}f(x,t)\dd{t}
\end{aligned}\]
\sssc{Measure theory form for const limits}
Let $X$ be an open subset of $\mathbb{R}$, and $\Omega$ be a measure space. Suppose $f\colon X\times\Omega\to\mathbb{R}$ satisfies the following conditions:
\ben
\item $f(x,\omega)$ is a Lebesgue-integrable function of $\omega$ for each $x\in X$.
\item For almost all $\omega\in\Omega$, the partial derivative $\pdv{f}{x}$ exists for all $x\in X$.
\item There is an integrable function $\theta\colon\Omega\to\mathbb{R}$ such that $\abs{\pdv{f}{x}\qty(x,\omega)}\leq\theta(\omega)$ for all $x\in X$ and almost all $\omegq\in\Omega$.
\een
Then, for all $x\in X$,
\[\dv{}{x}\int_{\Omega}f(x,\omega)\dd{\omega}=\int_{\Omega}\pdv{f}{x}\qty(x,\omega)\dd{\omega}.\]
\ssc{Fubini's theorem (富比尼定理)}
If a function is Lebesgue integrable on $X\times Y$, then:
\[\iint_{X\times Y}f(x,y)\dd{(x,y)}=\int_X\qty(\int_Yf(x,y)\dd{y))\dd{x}=\int_Y\qty(\int_Xf(x,y)\dd{x})\dd{y}.\]
\ssc{(Lebesgue's) Dominated convergence theorem (DCT) (（勒貝格）控制/受制收斂定理)}
Let $\langle f_n\rangle_{n\in I}$ be a net of real or complex-valued measurable functions on a measure space $(S,\Sigma,\mu)$. If $f_n$ is almost everywhere pointwise convergent to a function $f$, and there is a Lebesgue-integrable function $g$ such that
\[\abs{f_n}\leq g\]
almost everywhere for all $n\in I$.

Then $f_n$ for all $n\in I$ and $f$ are in $L^1(\mu)$ and
\[\lim_n\int_Sf_n\dd{\mu}=\int_S\lim_nf_n\dd{\mu}=\int_Sf\dd{\mu},\]
and
\[\lim_n\int_S\abs{f_n-f}\dd{\mu}=0.\]
\ssc{Laplace transform (拉普拉斯變換)}
\sssc{(Unilateral or One-sided) Laplace transform (（單邊）拉普拉斯變換)}
The (unilateral or one-sided) Laplace transform is an integral transform that converts a function of a real variable (usually $t$, in the time domain) to a function of a complex variable (usually $s$, in the complex-valued frequency domain, also known as $s$-domain, or $s$-plane). The functions are often denoted in lowercase for the time-domain representation and uppercase for the frequency-domain.

The Laplace transform of a real function $f(t)$, denoted as $\mathcal{L}\{f(t)\}(s)$ or $F(s)$ is defined by the improper integral
\[\mathcal{L}\{f(t)\}(s) = F(s) = \int_0^{\infty} e^{-st} f(t)\dd{t}.\]

In the context of Laplace transform, convergence refers to absolute convergence, that is, we say $F(s)$ converges or $f(t)$ is Laplace-transformable if the improper integral
\[\int_0^{\infty} \abs{e^{-st} f(t)}\dd{t}\]
converges absolutely for some real $s$.

The set of values for which $F(s)$ converges, called region of convergence (ROC), is either of the form $\Re(s) > a$ or $\Re(s) \geq a$, where $a$ is an extended real constant, i.e. $-\infty\leq a\leq\infty$.
\sssc{Laplace transformability}
A function $f\colon\mathbb{R}\to\mathbb{R}$ is Laplace-transformable if it is piecewise continuous on $[0,\infty)$ and of exponential order.
\begin{proof}\mbox{}\\
Assume that a $f\colon D\subseteq [0,\infty)\to\mathbb{R}$ is piecewise continuous on $[0,\infty)$ and there exists $M>0$ and $T>0$ such that:
\[|f(t)|\leq Me^{\alpha t}\quad \forall t>T.\]

For $s>\alpha$, since $f(t)$ is piecewise continuous, there exist $t_0=0,t_1,\dots t_k\in\mathbb{R}$ such that:
\begin{itemize}
\item the integral
\[\int_{t_i}^{t_{i+1}} |f(t)| e^{-st}\dd{t}$\]
exists and is finite for every $i\in\mathbb{Z}\land 0\leq i\leq k-1$, and that
\item the family $\{[t_0,t_1],[t_1,t_2],\dots [t_{k-1},t_k]$ is locally finite, and that
\item $f(t)$ is continuous on $[t_k,\infty)$.
\end{itemize}

Rewrite $F(s)$ as:
\[\int_0^\infty |f(t)| e^{-st}\dd{t} = \sum_{i=0}^{k-1} \int_{t_i}^{t_{i+1}} |f(t)| e^{-st}\dd{t} + \int_{t_k}^\infty |f(t)| e^{-st}\dd{t}\]

$\sum_{i=0}^{k-1} \int_{t_i}^{t_{i+1}} |f(t)| e^{-st}\dd{t}$ is finite.

For the second integral, since $|f(t)| \le M e^{\alpha t}$, we have
\[\int_{t_k}^\infty |f(t)| e^{-st}\dd{t}\le \int_{t_k}^\infty M e^{\alpha t} e^{-st}\dd{t} = M \int_{t_k}^\infty e^{-(s-\alpha)t}\dd{t}.\]
Since $s>\alpha$, the integral converges, so the second integral is finite.
\end{proof}
\sssc{Linearity}
\[\mathcal{L}\{af(t)+bg(t)\}=a\mathcal{L}\{f(t)\}+b\mathcal{L}\{g(t)\}.\]
\sssc{First shifting theorem or Time shift}
\[\mathcal{L}\{f(t-a)u(t-a)\}=e^{-as}F(s), \quad a > 0,\]
where $u(t)$ is the unit step function.
\sssc{Second shifting theorem or Frequency shift}
\[\mathcal{L}\{e^{at} f(t)\}(s) = F(s-a).\]
\sssc{Differentiation in Time Domain}
\[\mathcal{L}\{f'(t)\}(s) = sF(s) - f\qty(0^+).\]
\[\mathcal{L}\{f^{(n)}(t)\}(s) = s^n F(s) - \sum_{i=0}^{n-1}s^{n-1-i}f^{(i)}\qty(0^+).\]
\begin{proof}
\[\mathcal{L}\{f'(t)\}(s) = \int_0^\infty e^{-st} f'(t)\dd{t}.\]
\[u = e^{-st} \quad \Rightarrow \quad \dd{u} = -s e^{-st} \dd{t}.\]
\[dv = f'(t)\dd{t} \quad \Rightarrow \quad v = f(t).\]
Integral by parts.
\[\int_0^\infty u\dd{v} = (u v)\big\vert_0^\infty - \int_0^\infty v\dd{u}.\]
\bma
\int_0^\infty e^{-st} f'(t)\dd{t}&=\qty(e^{-st}f(t))\big\vert_0^\infty+\int_0^\infty f(t)se^{-st}\dd{t}\\
&=-f\qty(0^+)+\int_0^\infty f(t)se^{-st}\dd{t}\\
&=s\mathcal{L}\{f(t)\}(s)-f\qty(0^+)
\end{proof}
\sssc{Integration in Time Domain}
\[\mathcal{L}\left\{\int_0^t f(\tau)\dd{\tau}\right\}(s) = \frac{1}{s} F(s).\]
\begin{proof}
\bma
\mathcal{L}\{\int_0^t f(\tau)\dd{\tau}\}(s) &= \int_0^{\infty} e^{-st} \int_0^t f(\tau)\dd{\tau}\dd{t}\\
&=\qty(-\frac{1}{s}e^{-st}\int_0^t f(\tau)\dd{\tau})\big\vert_0^\infty+\int_0^{\infty} \frac{1}{s}e^{-st}f(t)\dd{t}\\
&=\frac{1}{s}\int_0^{\infty} e^{-st}f(t)\dd{t}.
\eam
\end{proof}
\sssc{Differentiation in Frequency Domain}
\[\mathcal{L}\{t f(t)\}(s) = -\dv{}{s} F(s).\]
\[\mathcal{L}\{t^n f(t)\}(s) = (-1)^n \dv[n]{}{s} F(s).\]
\begin{proof}\mbox{}\\
By Leibniz integral rule,
\bma
-\dv{}{s} F(s)&=-\dv{}{s}\int_0^{\infty} e^{-st} f(t)\,\mathrm{d}t\\
&=-\int_0^{\infty} \pdv{}{s}\qty(e^{-st} f(t))\,\mathrm{d}t\\
&=-\int_0^{\infty} -te^{-st} f(t)\,\mathrm{d}t\\
&=\int_0^{\infty} te^{-st} f(t)\,\mathrm{d}t\\
&=\mathcal{L}\{t f(t)\}(s)
\eam
\end{proof}
\sssc{Scaling in Time Domain}
\[\mathcal{L}\{f(at)\}(s) = \frac{1}{a} F\left(\frac{s}{a}\right), \quad a>0.\]
\sssc{Convolution Theorem}
If $h(t) = (f * g)(t) = \int_0^t f(\tau)g(t-\tau)\dd{\tau}$, then
\[\mathcal{L}\{h(t)\}(s) = F(s)G(s).\]
\begin{proof}
\[\mathcal{L}\{h(t)\}(s)=\int_0^{\infty} e^{-st} \qty(\int_0^t f(\tau)g(t-\tau)\dd{\tau})\dd{t}\]
By Fubini's theorem,
\[\mathcal{L}\{h(t)\}(s)=\int_0^\infty\int_\tau^\infty e^{-st} f(\tau)g(t-\tau)\dd{t}\dd{\tau}\]
Let $u=t-\tau$. $\dd{t}=\dd{u}$.
\[\begin(aligned}
\mathcal{L}\{h(t)\}(s)&=\int_0^\infty f(\tau)\int_0^\infty e^{-s(u+\tau)} g(u)\dd{u}\dd{\tau}\\
&=\int_0^\infty f(\tau)e^{-s\tau}\int_0^\infty e^{-su} g(u)\dd{u}\dd{\tau}\\
&=F(s)G(s)
\end{algined}\]
\sssc{Initial Value Theorem}
If $f(t)$ and $f'(t)$ are Laplace-transformable:
\[\lim_{t \to 0^+} f(t) = \lim_{s \to \infty} s F(s).\]
\begin{proof}
\[s F(s) = \int_0^\infty s f(t) e^{-st} \dd{t}.\]
Let $u = st$, $\dd{t} = \frac{\dd{u}}{s}$.
\[s F(s) = \int_0^\infty f\qty(\frac{u}{s}) e^{-u} \dd{u}.\]
\[\lim_{s \to \infty}s F(s)=\int_0^\infty f\qty(\frac{u}{s}) e^{-u} \dd{u}.\]

We define a net of functions $\langle f_s\rangle_{s\in\mathbb{R}_{>s_0}}$, where $s_0$ is such that $F(s)$ converges for all $\Re(s)>s_0$.

For fixed $u \in\mathbb{R}_{>0}$, $\lim_{s\to\infty}\frac{u}{s} \to 0^+$, so $f_n\qty(\frac{u}{s})$ pointwise converges to $f(0^+)$.

For dominated convergence theorem, we require an integrable function $g(u)$ such that
\[\abs{f\qty(\frac{u}{s}) e^{-u}} \le g(u), \quad \forall s > 0.\]

Since $f(t)$ is Laplace-transformable, it is of exponential order, that is, there exists $\alpha>0$, $M>0$, and $T>0$ such that:
\[|f(t)|\leq Me^{\alpha t}\quad \forall t>T.\]
\[M e^{\alpha \frac{u}{s}} e^{-u} = M e^{-u\qty(1 - \frac{\alpha}{s})}\le M e^{-\frac{u}{2}}, \quad \forall s > 2\alpha.\]

By dominated convergence theorem, we obtain:
\[\lim_{s \to \infty}s F(s)=\lim_{n\to\infty
\int_0^\infty f(0^+) e^{-u} \dd{u}.\]

Evaluate the integral:
\[\int_0^\infty f(0^+) e^{-u} \dd{u} = f(0^+) \int_0^\infty e^{-u}\dd{u} = f(0^+).\]
\end{proof}
\sssc{Mellin's inverse formula, Bromwich integral, or Fourier–Mellin integral of Inverse Laplace transform (反拉普拉斯變換)}
The inverse Laplace transform of a complex function $F(s)$, denoted as $\mathcal{L}^{-1}\{F(s)\}(t)$ or $f(t)$, is defined as a real function such that
\[\mathcal{L}\{f(t)\}(s) = F(s),\]
where $\mathcal {L}$ denotes the Laplace transform.

Mellin's inverse formula, Bromwich integral, or Fourier–Mellin integral states that, the inverse Laplace transform of a complex function $F(s)$ is given by the line integral:
\[\mathcal{L}^{-1}\{F(s)\}(t)=f(t)=\frac{1}{2\pi i}\lim_{T\to\infty}\int_{\gamma-iT}^{\gamma+iT}e^{st}F(s)\dd{s},\]
where $\gamma$ is a real number such that it is greater than the real part of all singularities of $F$ and that $F$ is bounded on the line $s=\gamma$.
\sssc{(Bilateral or Two-sided) Laplace Transform (（雙邊）拉普拉斯變換)}
The (bilateral or two-sided) Laplace transform is an integral transform that converts a function of a real variable (usually $t$, in the time domain) to a function of a complex variable (usually $s$, in the complex-valued angular frequency domain, also known as $s$-domain or $s$-plane). The functions are often denoted in lowercase for the time-domain representation and uppercase for the frequency-domain.

The Laplace transform of a real function $f(t)$, denoted as $\mathcal{B}\{f(t)\}(s)$, is defined by the improper integral
\[\mathcal{B}\{f(t)\}(s) = \int_{-\infty}^{\infty} e^{-st} f(t)\,\mathrm{d}t.\]
\ssc{Fourier Transform (FT) (傅立葉變換)}
\sssc{Fourier Transform (FT)}
Fourier transform is an integral transform that converts a function of a real variable (usually $t$, in the time domain) to a function of another real variable (usually $\omega$, in the real-valued angular frequency domain). The functions are often denoted in lowercase for the time-domain representation and uppercase for the frequency-domain.

The Fourier transform, denoted as $\mathcal{F}\{f(t)\}(\omega)$ or $F(\omega)$, is defined by the improper integral
\[\mathcal{F}\{f(t)\}(\omega) = F(\omega) = \int_{-\infty}^{\infty} e^{-i\omega t} f(t)\,\mathrm{d}t.\]
\sssc{Inverse Fourier Transform (反傅立葉變換)}
The inverse Fourier transform of a complex function $F(s)$, denoted as $\mathcal{F}^{-1}\{F(s)\}(t)$ or $f(t)$, is defined as a real function such that
\[\mathcal{F}\{f(t)\}(s) = F(s),\]
where $\mathcal {F}$ denotes the Fourier transform.

The inverse Laplace transform of a complex function $F(s)$ is given by the line integral:
\[f(t) = \frac{1}{2\pi}\int_{-\infty}^{\infty} F(\omega) e^{i\omega t}\dd{\omega} .\]



\sct{Lists}
\ssc{List of Derivatives and Functions as definite integrals}
\sssc{Power function}
\[\dv{x^n}{x}=nx^{n-1}.\]
\[x^n=n\int_0^xt^{n-1}\dd{t}.\]
\begin{proof}
\[\dv{x^n}{x}=\lim_{h\to 0}\frac{(x+h)^n-x^n}{h}=\lim_{h\to 0}\frac{\sum_{k=1}^{\infty}\binom{n}{k}x^{n-k}h^k}{h}=nx^{n-1}.\]
\end{proof}
\sssc{Logarithmic function}
\[\dv{\ln(x)}{x}=\frac{1}{x}.\]
\[\ln(x)=\int_1^x\frac{1}{t}\dd{t},\quad x>0.\]
\sssc{Exponential function}
\[\dv{a^x}{x}=\ln aa^x.\]
\[a^x=1+\int_0^x\ln aa^t\dd{t}.\]
\begin{proof}
\[\ba
\dv{a^x}{x}&=\lim_{h\to 0}\frac{a^{x+h)-a^x}{h}\\
&=a^x\lim_{h\to 0}\frac{a^h-1}{h}\\
&=a^x\lim_{h\to 0}\frac{e^{\ln ah}-1}{h}\\
&=a^x\lim_{h\to 0}\frac{\lim_{n\to\infty}\sum_{k=0}^n\frac{(\ln ah)^k}{k!}-1}{h}\\
&=a^x\lim_{h\to 0}\frac{\lim_{n\to\infty}\sum_{k=1}^n\frac{(\ln ah)^k}{k!}}{h}\\
&=\ln aa^x
\ea\]
\end{proof}
\sssc{Sine function divided by independent variable}
\[\lim_{h\to 0}\frac{\sin h}{h}=1.\]
\begin{proof}\mbox{}\\
From geometry of the arc length, the chord length, and the tangent length of an arc on a unit circle:
\[\sin h<h<\tan h,\quad h>0.\]
\[1<\frac{h}{\sin h}<\frac{1}{\cos h}.\]
\[\cos h<\frac{\sin h}{h}<1.\]
\[\lim_{h\to 0}\cos h=1.\]

By the squeeze theorem:
\[\lim_{h\to 0}\frac{\sin h}{h}=1.\]
\end{proof}
\sssc{Sine function}
\[\dv{\sin(x)}{x}=\cos(x).\]
\[\sin(x)=\int_0^x\cos(t)\dd{t}.\]
\begin{proof}
\[\begin{aligned}
\dv{\sin\theta}{\theta}&=\lim_{h\to 0}\frac{\sin(\theta+h)-\sin(\theta)}{h}\\
&=\lim_{h\to 0}\frac{\sin(\theta)(\cos h-1)+\cos\theta\sin h}{h}
\end{aligned}\]

Lemma:
\[\lim_{h\to 0}\frac{\sin h}{h}=1.\]

\[\cos h-1=-2\sin^2\qty(\frac{h}{2}),\]
\[\frac{\sin^2\qty(\frac{h}{2})}{h}=\frac{\sin\qty(\frac{h}{2})}{\frac{h}{2}}\cdot\frac{\sin\qty(\frac{h}{2})}{2}.\]

By lemma, we have:
\[\lim_{h\to 0}\frac{\cos h-1}{h}=0.\]

\[\begin{aligned}
&=\lim_{h\to 0}\sin\theta\cdot 0+\cos\theta\cdot 1\\
&=\cos\theta.
\end{aligned}\]
\end{proof}
\sssc{Cosine function}
\[\dv{\cos(x)}{x}=-\sin(x).\]
\[\cos(x)=1-\int_0^x\sin(t)\dd{t}.\]
\sssc{Tangent function}
\[\dv{\tan(x)}{x}=\sec^2(x).\]
\[\tan(x)=\int_{\operatorname{round}\qty(\frac{x}{\pi})\pi}^x\sec^2(t)\dd{t},\quad x\in\bbR\setminus\{\frac{\pi}{2}+k\pi\mid k\in\bbZ\},\]
in which $\operatorname{round}(x)=\left\lfloor x+\frac{1}{2}\right\rfloor$.
\begin{proof}
\[\begin{aligned}
\dv{\tan(x)}{x}&=\dv{}{x}\frac{\sin(x)}{\cos(x)}\\
&=\frac{\cos^2(x)+\sin^2(x)}{\cos^2(x)}\\
&=\sec^2(x).
\end{aligned}\]
\end{proof}
\sssc{Cotangent function}
\[\dv{\cot(x)}{x}=-\csc^2(x).\]
\[\cot(x)=-\int_{\frac{\pi}{2}+\operatorname{round}\qty(\frac{x}{\pi}-\frac{1}{2})\pi}^x\csc^2(t)\dd{t},\quad x\in\bbR\setminus\{k\pi\mid k\in\bbZ\},\]
in which $\operatorname{round}(x)=\left\lfloor x+\frac{1}{2}\right\rfloor$.
\begin{proof}
\[\cot(x)=\frac{\cos(x)}{\sin(x)}.\]
\[\begin{aligned}
\dv{\cot(x)}{x}&=\dv{}{x}\frac{\cos(x)}{\sin(x)}\\
&=\frac{-\sin^2(x)-\cos^2(x)}{\sin^2(x)}\\
&=-\csc^2(x).
\end{aligned}\]
\end{proof}
\sssc{Secant function}
\[\dv{\sec(x)}{x}=\sec(x)\tan(x).\]
\[\sec(x)=\int_{\operatorname{round}\qty(\frac{x}{\pi})\pi}^x\sec(t)\tan(t)\dd{t},\quad x\in\bbR\setminus\{\frac{\pi}{2}+k\pi\mid k\in\bbZ\},\]
in which $\operatorname{round}(x)=\left\lfloor x+\frac{1}{2}\right\rfloor$.
\begin{proof}
\[\ba
\dv{\sec(x)}{x}&=\dv{}{x}\frac{1}{\cos(x)}\\
&=\frac{\sin(x)}{\cos^2(x)}\\
&=\sec(x)\tan(x).
\ea\]
\end{proof}
\sssc{Cosecant function}
\[\dv{\csc(x)}{x}=-\csc(x)\cot(x),\quad x\in\bbR\setminus\{k\pi\mid k\in\bbZ\}.\]
\[\csc(x)=-\int_{\frac{\pi}{2}+\operatorname{round}\qty(\frac{x}{\pi}-\frac{1}{2})\pi}^x\csc(t)\cot(t)\dd{t},\]
in which $\operatorname{round}(x)=\left\lfloor x+\frac{1}{2}\right\rfloor$.
\begin{proof}
\[\ba
\dv{\csc(x)}{x}&=\dv{}{x}\frac{1}{\sin(x)}\\
&=\frac{-\cos(x)}{\sin^2(x)}\\
&=-\csc(x)\cot(x).
\ea\]
\end{proof}
\sssc{Inverse sine function}
\[\dv{\arcsin(x)}{x}=\frac{1}{\sqrt{1-x^2}}.\]
\[\arcsin(x)=\int_0^x\frac{1}{\sqrt{1-t^2}}\dd{t},\quad\abs{x}\leq 1.\]
\begin{proof}
Let $y=\arcsin(x)$. $\sin(y)=x$.
\[\dv{}{x}\sin(y)=\dv{}{x}(x).\]
Using the chain rule on the left:
\[\cos(y)\dv{y}{x}=1.\]
\[\dv{y}{x}=\frac{1}{\cos(y)}=\frac{1}{\sqrt{1-x^2}}.\]
\end{proof}
\sssc{Inverse cosine function}
\[\dv{\arccos(x)}{x}=-\frac{1}{\sqrt{1-x^2}}.\]
\[\arccos(x)=\int_x^1\frac{1}{\sqrt{1-t^2}}\dd{t},\quad\abs{x}\leq 1.\]
\begin{proof}
Let $y=\arccos(x)$. $\cos(y)=x$.
\[\dv{}{x}\cos(y)=\dv{}{x}(x).\]
Using the chain rule on the left:
\[-\sin(y)\dv{y}{x}=1.\]
\[\dv{y}{x}=-\frac{1}{\cos(y)}=-\frac{1}{\sqrt{1-x^2}}.\]
\end{proof}
\sssc{Inverse tangent function}
\[\dv{\arctan(x)}{x}=\frac{1}{x^2+1}.\]
\[\arctan(x)=\int_0^x\frac{1}{t^2+1}\dd{t}.\]
\begin{proof}
Let $y=\arctan(x)$. $\tan(y)=x$.
\[\dv{}{x}\tan(y)=\dv{}{x}(x).\]
Using the chain rule on the left:
\[\sec^2(y)\dv{y}{x}=1.\]
\[\dv{y}{x}=\cos^2(y)=\frac{1}{x^2+1}.\]
\end{proof}
\sssc{Inverse cotangent function}
\[\dv{\arccot(x)}{x}=-\frac{1}{x^2+1}.\]
\[\arccot(x)=\int_x^{\infty}\frac{1}{t^2+1}\dd{t}.\]
\begin{proof}
Let $y=\arccot(x)$. $\cot(y)=x$.
\[\dv{}{x}\cot(y)=\dv{}{x}(x).\]
Using the chain rule on the left:
\[-\csc^2(y)\dv{y}{x}=1.\]
\[\dv{y}{x}=-\sin^2(y)=-\frac{1}{x^2+1}.\]
\end{proof}
\sssc{Inverse secant function}
\[\dv{\arcsec(x)}{x}=\frac{1}{|x|\sqrt{x^2+1}}.\]
\[\arcsec(x)=\sgn(x)\int_1^\abs{x}\frac{1}{t\sqrt{t^2-1}}\dd{t}+(1-\sgn(x))\frac{\pi}{2},\quad\abs{x}\geq 1.\]
\begin{proof}
\[\ba
\dv{\arcsec(x)}{x}&=\dv{\arccos(\frac{1}{x})}{x}\\
&=-\frac{1}{\sqrt{1-x^{-2}}}\qty(-x^{-2})\\
&=\frac{1}{|x|\sqrt{x^2+1}}
\ea\]
\end{proof}
\sssc{Inverse cosecant function}
\[\dv{\arccsc(x)}{x}=-\frac{1}{|x|\sqrt{x^2+1}}.\]
\[\arccsc(x)=\sgn(x)\int_\abs{x}^{\infty}\frac{1}{t\sqrt{t^2-1}}\dd{t},\quad\abs{x}\geq 1.\]
\begin{proof}
\[\ba
\dv{\arccsc(x)}{x}&=\dv{\arcsin(\frac{1}{x})}{x}\\
&=\frac{1}{\sqrt{1-x^{-2}}}\qty(-x^{-2})\\
&=-\frac{1}{|x|\sqrt{x^2+1}}
\ea\]
\end{proof}
\ssc{List of Taylor Expansions}
\sssc{Power function}
For any $n\in\mathbb{R}$ and $x\in\mathbb{R}$ in the maximum possible domain:
\[x^n=\sum_{k=0}^{\infty}\binom{n}{k}a^{n-k}(x-a)^k,|x-a|<|a|.\]
\sssc{Logarithmic function}
For any $x\in\mathbb{R}_{>0}$:
\[\ln(x)=\ln(a)+\sum_{n=1}^{\infty}(-1)^{n-1}\frac{(x-a)^n}{na^n},\quad 0<x\leq a.\]
\begin{proof}
\[\dv{\ln(x)}{x}=\frac{1}{x}.\]
Thus for $k\in\mnathbb{N}$:
\[\ba
\dv[k]{\ln(x)}{x}&=\qty(\prod_{j=0}^{k}(-1-j))x^{-k}\\
&=(-1)^k\frac{1}{(k+1)!x^k}
\ea\]
$\sum_{n=1}^{\infty}(-1)^{n-1}\frac{(x-a)^n}{na^n}$ converge if and only if $-1<\frac{(x-a)^n}{a^n}\leq 1$ (alternating harmonic series converges) if and only if $0<x\leq a$.
\end{proof}
\sssc{Exponential function}
For any $x\in\mathbb{R}$ and $a\in\mathbb{R}_{>0}$:
\[a^x=\sum_{n=0}^{\infty}\frac{a^b(\ln a)^n}{n!}(x-b)^n.\]
\sssc{Sine function}
\[\sin(x)=\sum_{n=0}^{\infty}\frac{\sin\qty(a+\frac{n\pi}{2})}{n!}(x-a)^n.\]
\sssc{Cosine function}
\[\cos(x)=\sum_{n=0}^{\infty}\frac{\cos\qty(a+\frac{n\pi}{2})}{n!}(x-a)^n.\]
\sssc{Tangent function}
Define the derivative polynomials $P_n$ such that $P_n\qty(\tan(x))=\tan^{(n)}(x)$ with recursion as:
\[\begin{cases}
&P_0(y)=y,\\
&P_n(y)=(1+y^2)P_{n-1}'(y),\quad n\in\mathbb{N}.
\end{cases}\]

The Taylor expansion of the tangent function at $a$ is:
\[\tan(x)=\sum_{n=0}^{\infty}\frac{P_n\qty(\tan(x))(a)}{n!}(x-a)^n.\]
\begin{proof}
Let $y=\tan(x)$.
\[y'=1+y^2.\]
Prove by mathematical induction. When $n=0$,
\[P_0(y)=y.\]
Assume:
\[P_{n-1}(y)=y^{(n-1)}.\]
Differentiate both side:
\[y'P_{n-1}'(y)=y^{(n)}=(1+y^2)P_{n-1}'(y)=P_n(y).\]
\end{proof}
\sssc{Cotangent function}
Define the derivative polynomials $P_n$ such that $P_n\qty(\cot(x))=\cot^{(n)}(x)$ with recursion as:
\[\begin{cases}
&P_0(y)=y,\\
&P_n(y)=-(1+y^2)P_{n-1}'(y),\quad n\in\mathbb{N}.
\end{cases}\]

The Taylor expansion of the cotangent function at $a$ is:
\[\cot(x)=\sum_{n=0}^{\infty}\frac{P_n\qty(\cot(x))(a)}{n!}(x-a)^n.\]
\begin{proof}
Let $y=\cot(x)$.
\[y'=-(1+y^2).\]
Prove by mathematical induction. When $n=0$,
\[P_0(y)=y.\]
Assume:
\[P_{n-1}(y)=y^{(n-1)}.\]
Differentiate both side:
\[y'P_{n-1}'(y)=y^{(n)}=-(1+y^2)P_{n-1}'(y)=P_n(y).\]
\end{proof}
\ssc{List of Counterexamples}
\sssc{Dirichlet function (狄利克雷函數)}
The Dirichlet function is a function $f\colon\manthbb{R}\to\mathbb{R};$
\[f(x)=\begin{cases}1,\quad & x\in\mathbb{Q}\\
0,\quad & x\in\mathbb{R}\setminus\mathbb{Q}
\end{cases},\]
which is discontinuous at everywhere.
\sssc{Weierstrass function (魏爾施特拉斯函數)}
The Weierstrass function is a function $f\colon\mathbb{R}\to\mathbb{R};$
\[f(x)=\sum_{n=0}^{\infty}a^n\cos\left(b^n\pi x\right),\]
in which $0<a<1$, $b$ is a positive odd integer, and $ab>1+\frac{3}{2}\pi$, which is continuous but differentiable nowhere.
\sssc{Differentiable but derivative not continuous}
The function $f\colon\mathbb{R}\to\mathbb{R};$
\[f(x)=\begin{cases}x^2\sin\qty(\frac{1}{x}),\quad&x\neq 0\\0,\quad&x=0\end{cases},\]
is differentiable but its derivative is not continuous at $0$. (Note that because $\{0\}$ has Lebesgue measure $0$, $f'\colon\mathbb{R}\to\mathbb{R}$ is continuous almost everywhere, that is, $f'$ is Riemann integrable on any closed interval.)
\begin{proof}
\[f'(x)=2x\sin\qty(\frac{1}{x})-x^2\cos\qty(\frac{1}{x}),\quad x\neq 0\]
\bma
f'(0)&=\lim_{h\to 0}\frac{f(h)}{h}\\
&=\lim_{h\to 0}h\sin\qty(\frac{1}{h})
\eam
For any $|h|>0$, we have $-|h|\leq h\sin\qty(\frac{1}{h})\leq |h|$. By the squeeze theorem, $\lim_{h\to 0}-|h|=\lim_{h\to 0}|h|=0$ implies $\lim_{h\to 0}h\sin\qty(\frac{1}{h})=0$.
\bma
\lim_{x\to 0}f'(x)&=2\lim_{x\to 0}x\sin\qty(\frac{1}{x})-\lim_{x\to 0}\cos\qty(\frac{1}{x})\\
&=-\lim_{x\to 0}\cos\qty(\frac{1}{x})\\
\eam
$\lim_{x\to 0}\cos\qty(\frac{1}{x})$ doesn't exist, so $\lim_{x\to 0}f'(x)$ doesn't exist.
\end{proof}
\sssc{Differentiable at one point and discontinuous everywhere else}
The function $f\colon\manthbb{R}\to\mathbb{R};$
\[f(x)=\begin{cases}1,\quad & x^2\in\mathbb{Q}\\
0,\quad & x\in\mathbb{R}\setminus\mathbb{Q}
\end{cases}\]
which is differentiable at $0$ with $f'(0)=0$ and discontinuous everywhere else.
\ssc{List of Integrals}
{{{start
\sssc{Power function}
\sssc{Logarithmic function}
\sssc{Exponential function}
\sssc{Trigonometric functions}
\sssc{Inverse trigonometric functions}
{{{end
\sssc{Rational functions}
\[\int\frac{f'(x)}{f(x)}\,\mathrm{d}x=\ln|f(x)|+C.\]
\[\int\frac{1}{x^2+a^2}\,\mathrm{d}x=\frac{1}{a}\arctan\frac{x}{a}+C.\]
\[\int\frac{1}{x^2-a^2}\,\mathrm{d}x=\frac{1}{2a}\ln\frac{x-a}{x+a}+C.\]
\[\int\frac{1}{a^2-x^2}\,\mathrm{d}x=\frac{1}{2a}\ln\frac{a+x}{a+x}+C.\]
\[\int\frac{1}{ax+b}\,\mathrm{d}x=\frac{1}{a}\ln|ax+b|+C.\]
\[\int(ax+b)^n\,\mathrm{d}x=\frac{(ax+b)^{n-1}}{a(n+1)}+C,\quad n\neq -1.\]
\[\int\frac{x}{ax+b}\,\mathrm{d}x=\frac{x}{a}-\frac{b}{a^2}\ln|ax+b|+C.\]
\[\int\frac{x}{(ax+b)^2}\,\mathrm{d}x=\frac{b}{a^2(ax+b)}+\frac{1}{a^2}\ln|ax+b|+C.\]
\[\int x(ax+b)^n\,\mathrm{d}x=\frac{a(n+1)x-b}{a^2(n+1)(n+2)}(ax+b)^{n+1}+C,\quad n\notin\{-1,-2\}.\]
\sssc{Irrational functions}
\[\int\sqrt{a^2+x^2}\,\mathrm{d}x=\frac{x}{2}\sqrt{a^2+x^2}+\frac{a^2}{2}\ln\qty(x+\sqrt{a^2+x^2})+C.\]
\[\int\sqrt{x^2-a^2}\,\mathrm{d}x=\frac{x}{2}\sqrt{x^2-a^2}-\frac{a^2}{2}\ln\qty(x+\sqrt{x^2-a^2})+C,\quad x^2>a^2.\]
\[\int\sqrt{a^2-x^2}\,\mathrm{d}x=\frac{x}{2}\sqrt{a^2-x^2}+\frac{a^2}{2}\arcsin\frac{x}{|a|}+C,\quad|a|\geq|x|.\]
\sssc{Gaussian integral (高斯積分) or Euler–Poisson integral}
\[\int_{-\infty}^{\infty}e^{-t^2}\dd{t}=\sqrt{\pi}.\]
\[\int_0^{\infty}e^{-t^2}\dd{t}=\frac{\sqrt{\pi}}{2}.\]
\ssc{Lists of Laplace Transform}{{{
\ssc{Lists Fourier Transform}{{{



\sct{Numerical Analysis (數值分析)}
\ssc{Numerical differentiation (數值微分)}
\sssc{Newton's Method (牛頓法) or Newton-Raphson Method (牛頓-拉普森法)}
Newton's method, also known as Newton-Raphson method, is an iterative technique used to approximate the roots of a real-valued function. Given a function $f(x)$ and an initial guess \( x_0 \) close to a root, Newton's method refines this guess by repeatedly applying the formula:
\[
x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)},n\in\mathbb{N}
\]
where:
\begin{itemize}
\item \( x_n \) is the current approximation,
\item \( f(x_n) \) is the value of the function at \( x_n \),
\item \( f'(x_n) \) is the derivative of \( f(x) \) evaluated at \( x_n \).
\end{itemize}
\ssc{Numerical integration (數值積分)}
\sssc{The trapezoidal rule (梯形法)}
Let $f$ be a continuous real-valued function on $[a,b]$, the trapezoidal rule gives the approximation
\[\int_a^bf(x)\,\mathrm{d}x\approx\frac{b-a}{2n}\left(2\left(\sum_{i=0}^nf(a+\frac{i}{n}(b-a))\right)-f(a)-f(b)\right).\]
The error is defined as
\[E_n=\int_a^bf(x)\,\mathrm{d}x-\frac{b-a}{2n}\left(2\left(\sum_{i=0}^nf(a+\frac{i}{n}(b-a))\right)-f(a)-f(b)\right).\]
When $\frac{\mathrm{d}^2f(x)}{\mathrm{d}x^2}$ is continuous on $[a,b]$, the error satisfies that
\[\abs{E_n}\leq\frac{(b-a)^3}{12n^2}\max_{a\leq x\leq b}\left(\abs{\frac{\mathrm{d}^2f(x)}{\mathrm{d}x^2}}\right).\]
\sssc{The Simpson's rule (辛普森法) or the Simpson's 1 or 3 rule}
Let $f$ be a continuous real-valued function on $[a,b]$, the Simpson's rule gives the approximation
\[\int_a^bf(x)\,\mathrm{d}x\approx\frac{b-a}{3n}\left(2\left(\sum_{i=0}^nf(a+\frac{i}{n}(b-a))\right)+2\left(\sum_{i=1}^{\frac{n}{2}}f(a+\frac{2i-1}{n}(b-a))\right)-f(a)-f(b)\right),\]
where $\frac{n}{2}\in\mathbb{N}$.

The error is defined as
\[E_n=\int_a^bf(x)\,\mathrm{d}x-\frac{b-a}{3n}\left(2\left(\sum_{i=0}^nf(a+\frac{i}{n}(b-a))\right)+2\left(\sum_{i=1}^{\frac{n}{2}}f(a+\frac{2i-1}{n}(b-a))\right)-f(a)-f(b)\right).\]
When $\frac{\mathrm{d}^4f(x)}{\mathrm{d}x^4}$ is continuous on $[a,b]$, the error satisfies that
\[\abs{E_n}\leq\frac{(b-a)^5}{180n^4}\max_{a\leq x\leq b}\left(\abs{\frac{\mathrm{d}^4f(x)}{\mathrm{d}x^4}}\right).\]
\end{document}
