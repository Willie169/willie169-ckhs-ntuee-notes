\documentclass[a4paper,12pt]{report}
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{3}
\input{/usr/share/LaTeX-ToolKit/template.tex}
\begin{document}
\title{Calculus}
\author{沈威宇}
\date{\temtoday}
\titletocdoc
\chapter{Calculus (微積分)}
\section{Real Functions}
\ssc{Evaluation}
Let $f$ be a function. We denote $f(b)-f(a)$ as $\evlv{f(x)}_a^b$, $\evlv[f(x)]_a^b$, $\evlv(f(x))_a^b$, $\evlp{f(x)}_a^b$, $\evlp[f(x)]_a^b$, $\evlp(f(x))_a^b$, $\evlb{f(x)}_a^b$, $\evlb[f(x)]_a^b$, or $\evlb(f(x))_a^b$.
\ssc{Tests of real functions}
\sssc{Vertical line test (垂線測試)}
For a graph on $xy$ plane, if any vertical line intersects it, $y$ is not a function of $x$.
\sssc{Horizontal line test (水平線測試)}
Given a graph of a real function $y=f(x)$ on $xy$ plane, if any horizontal line intersects it more than once, $f(x)$ is not bijective.
\ssc{Fixed point, fixpoint, or invariant point (不動點 or 定點)}
A fixed point, fixpoint, or invariant point of a function $f\colon X\subseteq Y\to Y$, is a point $x\in X$ such that $f(x)=x$.
\sssc{Increasing (遞增) Decreasing (遞減), and Monotone (單調)}
Let $f\colon X\subseteq\bbR\to\bbR$ be a function.
\bit
\item $f$ is called strictly increasing on an interval $I\subseteq X$ if
\[\forall a,b\in I\colon a<b\implies f(a)<f(b).\]
\item $f$ is called strictly increasing if
\[\forall a,b\in X\colon a<b\implies f(a)<f(b).\]
\item $f$ is called strictly decreasing on an interval $I\subseteq X$ if
\[\forall a,b\in I\colon a<b\implies f(a)>f(b).\]
\item $f$ is called strictly decreasing if
\[\forall a,b\in X\colon a<b\implies f(a)>f(b).\]
\item $f$ is called non-decreasing or monotone increasing on an interval $I\subseteq X$ if
\[\forall a,b\in I\colon a<b\implies f(a)\leq f(b).\]
\item $f$ is called non-decreasing or monotone increasing if
\[\forall a,b\in X\colon a<b\implies f(a)\leq f(b).\]
\item $f$ is called non-increasing or monotone decreasing on an interval $I\subseteq X$ if
\[\forall a,b\in I\colon a<b\implies f(a)\geq f(b).\]
\item $f$ is called non-increasing or monotone decreasing if
\[\forall a,b\in X\colon a<b\implies f(a)\geq f(b).\]
\item $f$ is called monotone or monotonic on an interval $I\subseteq X$ if it is either monotone increasing or monotone decreasing on $I$.
\item $f$ is called monotone or monotonic if it is either monotone increasing or monotone decreasing.
\eit
The terms increasing and decreasing are define to be either monotone or strictly definition in different sources. Here, we use the monotone definition.
\ssc{Homogeneous function}
\sssc{General homogeneity}
A function $F$ with domain $\Omega\subseteq\bbR^n$ is called a homogeneous function of degree $\alpha\in\bbR$ if and only if for any nonzero real number $t$ and $\mathbf{x},t\mathbf{x}\in\Omega$, $F(t\mathbf{x})=t^{\alpha}F(\mb{x})$.
\sssc{Positive homogeneity}
A function $F$ with domain $\Omega\subseteq\bbR^n$ is called a positively homogeneous function of degree $\alpha\in\bbR$ if and only if for any positive real number $t$ and $\mathbf{x},t\mathbf{x}\in\Omega$, $F(t\mathbf{x})=t^{\alpha}F(\mb{x})$.
\ssc{Periodic function (週期函數)}
Let $f$ be a function with domain $\bbR$ or $\bbR_{\geq 0}$. If there exists $T>0$ such that
\[f(t+T)=f(t)\]
for any $t$ in the domain of $f$, we say that $f$ is periodic and that the smallest $T$ is the period (週期) of $f$.
\ssc{Of Exponential Order}
A real or complex-valued net $f$ on a subset of $\mathbb{R}$ is considered of exponential order $\alpha\in\mathbb{R}_{>0}$ if there exists $M>0$ and $T>0$ such that:
\[|f(t)|\leq Me^{\alpha t}\quad \forall t>T.\]
\ssc{Symmetry}
Given a function $f\colon X\to Y$ such that $\forall x\in X\colon -x\in X$.
\sssc{Even Function (偶函數)}
$f$ is an even function if for all $x\in X$, $f(x)=f(-x)$.
\sssc{Odd Function (奇函數)}
$f$ is an odd function if for all $x\in X$, $-f(x)=f(-x)$.
\ssc{Transformation (變換)}
\sssc{Translation (平移)}
For any function $f\colon\mathbb{R}\to\mathbb{R}$, shifting $y=f(x)$ right by $h$ units and up by $k$ units on the $xy$ coordinate plane yields $y=f(x-h)+k$.
\sssc{Scaling (伸縮 or 縮放 or 拉伸)}
For any function $f\colon\mathbb{R}\to\mathbb{R}$, on the $xy$ coordinate plane, expand $y=f(x)$ vertically by $a$ times the original value with the $x$ axis as the reference line, and expand $y=af\qty(\frac{x}{b})$ horizontally by $b$ times the original value with the $y$ axis as the reference line, to obtain $y=af\qty(\frac{x}{b})$.
\ssc{Function composition (函數合成)}
For two functions $f\colon X\to Y$ and $g\colon V\to W$ such that $g(V)\subseteq X$, the composition of them, denoted as $(f\circ g)$, is defined as:
\[(f \circ g)\colon V\to Y;\,x\mapsto = f(g(x))\]
\ssc{Inverse function (反函數)}
For a bijective function $f\colon X\to Y$, the inverse of it, denoted as $f^{-1}$, is defined as:
\[f^{-1}\colon Y\to X;\,f(x)\mapsto x.\]
\ssc{Preimage (像原) or Inverse image}
Given an open subset $B$ of the codomain of a function $f$ the preimage or inverse image of $f$ on $B$, denoted as $f^{-1}(B)$ is defined as
\[f^{-1}(B)=\{x\in X|f(x)\in B\}.\]
\ssc{Piecewise function (分段函數)}
A piecewise function is a function defined in the form:
\[f(x) =
\begin{cases}
f_1(x), & \quad x\in A_1, \\
f_2(x), & \quad x\in A_2, \\
\dots  \\
f_n(x), & \quad x \in A_n
\end{cases},\]
where
\[\bigcup_{i=1}^nA_i=D_f\land\forall i\neq j\land i,j\in\mathbb{N}\land i,j\leq n\colon A_i\cap A_j=\varnothing.\]
\ssc{Elementary functions}
A constants, a power function, a logarithmic function, an exponential function, a trigonometric function, an inverse trigonometric function, or any function that can be built up with finite defined operations of addition, subtraction, multiplication, division, and composition of functions on any finite set of elementary functions is called an elementary function.

An integral of which the integrand is an elementary function is called an elementary integral.
\ssc{Some Types of Real Functions}
\sssc{Power Function (冪函數)}
A power function if a function $f(x)=kx^a$ where $k\in\mathbb{C}$, called coefficient, and $a\in\mathbb{R}$, called exponent, are constants (some requires $k\in\mathbb{R}$ or $k=1$).
\sssc{Root Function (根式函數)}
A root function is a power function of which the exponent is $\frac{1}{n}$ where $n\in\mathbb{N}$.
\sssc{Reciprocal Function}
The reciprocal function is the function $f(x)=\frac{1}{x}$.
\sssc{Polynomial (多項式)}
A polynomial is a function $P(x)=\sum_{k=0}^na_kx^k$ where $a_k\in\mathbb{R}$ or $\mathbb{C}$ are constants called coefficients and $n$ is a nonnegative integer called the degree of $P$.
\sssc{Rational Function (有理函數)}
A function $f$ is called a rational function if there exists two polynomials $P(x)$ and $Q(x)$ such that $f(x)=\frac{P(x)}{Q(x)}$ for all $x$ in the domain.

If $\deg(P)\geq\deg(Q)$, $f(x)$ is improper; otherwise $f(x)$ is proper.
\sssc{Algebraic Function (代數函數)}
A function $f$ is called an algebraic function if there exists a polynomial $P(y,x)$ in two variables such that $P(f(x),x)=0$ for all $x$ in the domain.
\sssc{Transcendental Function (超越函數)
A real function is called a transcendental function if it is not an algebraic function.
\ssc{Piecewise Functions}
\sssc{Absolute value (絕對值) or modulus (模)}
The absolute value or modulus function $|\cdot|\colon\bbR\to\bbR$ is defined as:
\[|x|=\bcs x,\quad&x\geq 0\\-x,\quad&x<0\ecs.\]
\sssc{Sign function or signum function (符號函數)}
The sign function $\sgn\colon\bbR\to\bbR$ is defined as:
\[\sgn(x)=\bcs\frac{x}{|x|},\quad & x\neq 0\\0,\quad & x=0\end{cases}.\]
\sssc{Floor function (下取整函數), integral part, integer part (整數部份), greatest integer, entier, rounding down (無條件捨去), or rounding toward negative infinity}
The floor function $\lfloor\cdot\rfloor\colon\bbR\to\bbR$ or $[\cdot]\colon\bbR\to\bbR$ is defined as:
\[\lfloor x\rfloor=[x]=\max\{m\in\bbZ\mid m\leq x\},\]
in which $[\cdot]$ is called the Gauss sign (高斯符號).
\sssc{Ceiling function (上取整函數), rounding up (無條件進位), or rounding toward positive infinity}
The ceiling function $\lceil\cdot\rceil\colon\bbR\to\bbR$ is defined as:
\[\lceil x\rceil=\min\{m\in\bbZ\mid m\geq x\}.\]
\sssc{Truncation, rounding toward zero, or rounding away from infinity}
The truncation $\operatorname{truncate}\colon\bb{R}\to\bb{R}$ is defined as:
\[\operatorname{truncate}(x)=
\bcs
\lfloor x\rfloor,\quad & x\geq 0\\
\lceil x\rceil,\quad & x<0
\ecs\]
\sssc{Rounding half up (四捨五入) or rounding half toward positive infinity}
The rounding half up $\operatorname{roundhalfup}\colon\bbR\to\bbR$ is defined as:
\[\operatorname{roundhalfup}(x)=\left\lfloor x+\frac{1}{2}\right\rfloor.\]
\sssc{Rounding half down (五捨六入) or rounding half toward negative infinity}
The rounding half down $\operatorname{roundhalfdown}\colon\bbR\to\bbR$ is defined as:
\[\operatorname{roundhalfdown}(x)=\left\lceil x-\frac{1}{2}\right\rceil.\]
\sssc{Rounding half toward zero or rounding half away from infinity}
The rounding half toward zero $\operatorname{roundhalftowardzero}\colon\bbR\to\bbR$ is defined as:
\[\operatorname{roundhalftowardzero}(x)=\sgn(x)\left\lceil |x|-\frac{1}{2}\right\rceil.\]
\sssc{Rounding half away from zero or rounding half toward infinity}
The rounding half away from zero $\operatorname{roundhalfawayfromzero}\colon\bbR\to\bbR$ is defined as:
\[\operatorname{roundhalfawayfromzero}(x)=\sgn(x)\left\lfloor |x|+\frac{1}{2}\right\rfloor.\]
\sssc{Rounding half to even (四捨六入五成雙)}
The rounding half to even $\operatorname{roundhalftoeven}\colon\bbR\to\bbR$ is defined as:
\[\operatorname{roundhalftoeven}(x)=\bcs
\left\lfloor x+\frac{1}{2}\right\rfloor,\quad & \frac{1}{2}\left\lfloor x+\frac{1}{2}\right\rfloor\in\mathbb{Z}\\
\left\lceil x-\frac{1}{2}\right\rceil,\quad & \frac{1}{2}\left\lfloor x+\frac{1}{2}\right\rfloor\notin\mathbb{Z}
\ecs.\]
\sssc{Rounding half to odd (四捨六入五成單)}
The rounding half to odd $\operatorname{roundhalftoodd}\colon\bbR\to\bbR$ is defined as:
\[\operatorname{roundhalftoodd}(x)=\bcs
\left\lfloor x+\frac{1}{2}\right\rfloor,\quad & \frac{1}{2}\left\lfloor x+\frac{1}{2}\right\rfloor\notin\mathbb{Z}\\
\left\lceil x-\frac{1}{2}\right\rceil,\quad & \frac{1}{2}\left\lfloor x+\frac{1}{2}\right\rfloor\in\mathbb{Z}
\ecs.\]
\sssc{Pulse wave, pulse train, or rectangular wave}
A pulse wave with period $T$, duty cycle $D$, crest $A_1$, and trough $A_0$ is
\[f(t)=A_0+\qty(A_1-A_0)\qty(\left\lfloor\frac{t}{T}+D\rfloor\right-\left\lfloor\frac{t}{T}\rfloor\right).\]
The ratio of the high period to the total period of a pulse wave is called the duty cycle.

When the duty cycle is $50\%$, the pulse wave is called square wave.
\sssc{Triangular wave or triangle wave}
A triangular wave with period $T$, crest $A_1$, and trough $A_0$ is
\[f(t)=A_0+2\qty(A_1-A_0)\abs{\frac{t}{T}-\left\lfloor\frac{t}{T}+\frac{1}{2}\right\rfloor}.\]
\sssc{Sawtooth wave or saw wave}
A sawtooth wave with period $T$, crest $A_1$, and trough $A_0$ is
\[f(t)=\frac{A_0+A_1}{2}+\qty(A_1-A_0)\qty(\frac{t}{T}-\left\lfloor\frac{t}{T}+\frac{1}{2}\right\rfloor).\]
\sssc{Heaviside step function (黑維塞階躍函數) or Unit step function (單位階躍函數)}
The Heaviside step function or unit step function $u(x)\colon\bbR\to\bbR$ (also denoted as $H(x)$) is defined as either
\[u(x)=
\begin{cases}0,\quad &x<0\\
1,\quad &x\geq 0
\end{cases}.\]



\section{Limit (極限)}
\ssc{Extended real number system}
When using the extended real number system as the codomain of limits:
\[\forall a\in\bbR\land a>0\colon a/0=\infty,\]
\[\forall a\in\bbR\land a<0\colon a/0=-\infty,\]
when the numerator $0$ is a limit and the result is to be put in a limit or assigned as a result of a limit by limit definition.

When using the extended real number system as the codomain of limits, any function $f$ with limit at $a\in\{-\infty,\infty\}$ being $\pm\infty$ is extended by $f(a)=\pm\infty$ when the input $a$ is a limit and the result is to be put in a limit or assigned as a result of a limit by limit definition.
\subsection{Of Real Sequence}
\subsubsection{Limit}
For a real sequence \(\langle a_n\rangle_{n=l}^{\infty}\), the limit of it (as $n$ approaches infinity) is denoted as $\lim_{n \to \infty} a_n$ or $\lim_n a_n$. For $L\in\bbR$:
\[\lim_{n \to \infty} a_n = L \equiv \forall \varepsilon > 0:\, \exists M \in\mathbb{N}\text{\ s.t.\ } n\in\mathbb{N}\land n \geq M\implies |a_n - L| < \varepsilon.\]
In other words, as \(n\) becomes arbitrarily large, \(a_n\) gets arbitrarily close to \(L\).

If such $M$ exists for some $L\in\bbR$, we say the limit exists and the sequence converges (收斂) to $L$; otherwise, we say the limit doesn't exist and the sequence diverges (發散).
\[\lim_{n\to \infty}a_n=\infty \equiv \forall M > 0, \exists M \in\mathbb{N} \text{\ s.t.\ } n\in\mathbb{N}\land n \geq M \implies a_n > M.\]
\[\lim_{n\to \infty}a_n=-\infty \equiv \forall M < 0, \exists M \in\mathbb{N} \text{\ s.t.\ } n\in\mathbb{N}\land n \geq M \implies a_n < M.\]
\sssc{Limit inferior, infimum limit, limit infimum, liminf, inferior limit, lower limit, or inner limit, and limit superior, supremum limit, limit supremum, limsup, superior limit, upper limit, or outer limit}
For a real sequence \(\langle a_n\rangle_{n=l}^{\infty}\), the limit inferior is defined as
\[\liminf_{a\to\infty}a_n\coloneq\sup_{n\geq l}\inf_{m\geq n}a_m,\]
and the limit superior is defined as
\[\limsup_{a\to\infty}a_n\coloneq\inf_{n\geq l}\sup_{m\geq n}a_m.\]
\subsection{Of Real Series}
\subsubsection{Limit}
For a real series
\[S_n = \sum_{i=l}^n a_i,\]
where \(a_i\) are terms of a real sequence \(\langle a_n\rangle_{n=l}^{\infty}\). The limit of \(S_n\) is denoted as \(\lim_{n\to\infty}S_n\) or \(\sum_{i=1}^{\infty}a_i\) and defined as the limit of the sequence \(\left\langle S_n\right\rangle_{n=l}^{\infty}\). If the limit exists and equal to $L$, we say the series converges to $L$; otherwise, we say the series diverges.
\subsubsection{Absolute convergence and conditional convergence}
We say a real series $S_n=\sum_{i=1}^{\infty}a_i$ converges absolutely to $L$ iff the series $\sum_{i=1}^{\infty}\abs{a_i}$ converges to $L$. If a real series is convergent but not convergent absolutely, we say it is convergent conditionally.
\subsection{Of Real Net}
Below, we will discuss limits of nets in the set of real number.
\subsubsection{Limit}
For a real net $\langle x_a\rangle_{a\in A}$ in which $A$ is a directed set, the limit of $\langle x_a\rangle_{a\in A}$ is denoted as $\lim_a x_a$. For $L\in\bbR$:
\[\lim_ax_a = L \equiv \forall \varepsilon > 0:\, \exists a_0 \in A\text{\ s.t.\ } a\in A\land a\ge a_0\implies |x_a - L| < \varepsilon.\]

If such $a_0$ exists for some $L\in\bbR$, we say the limit exists or the net converges to $L$; otherwise, we say the limit doesn't exist.
\[\lim_{a}x_a=\infty \equiv \forall M > 0, \exists a_0 \in A \text{\ s.t.\ } a\in A\land a\geq a_0 \implies x_a > M.\]
\[\lim_{a}x_a=-\infty \equiv \forall M < 0, \exists a_0 \in A \text{\ s.t.\ } a\in A\land a\geq a_0 \implies x_a < M.\]
\sssc{Limit inferior, infimum limit, limit infimum, liminf, inferior limit, lower limit, or inner limit, and limit superior, supremum limit, limit supremum, limsup, superior limit, upper limit, or outer limit}
For a real net $\langle x_a\rangle_{a\in A}$, the limit inferior is defined as
\[\liminf_{x}x_n\coloneq\sup_{n\geq l}\inf_{m\geq n}x_m,\]
and the limit superior is defined as
\[\limsup_{x}x_n\coloneq\inf_{n\geq l}\sup_{m\geq n}x_m.\]
\subsection{Real-Domain Function}
\subsubsection{Limit at Finity}
Let \(I\) be an interval containing the point \(a\). Let \( f(x) \) be a function defined on \(I\), except possibly at \(a\) itself. The limit of \( f(x) \) as \( x \) approaches \( a \) is denoted as $\lim_{x \to a} f(x)$. For $L\in\bbR$:
\[\lim_{x \to a} f(x) = L \equiv \forall \varepsilon > 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < |x - a| < \delta \implies |f(x) - L| < \varepsilon.\]
In other words, as \(x\) becomes arbitrarily close to \(a\), \(f(x)\) gets arbitrarily close to \(L\).

If such $\delta$ exist for some $L\in\bbR$, we say the limit exists; otherwise, we say the limit doesn't exist.
\[\lim_{x\to a}f(x)=\infty \equiv \forall N > 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < |x - a| < \delta \implies f(x) > N.\]
\[\lim_{x\to a}f(x)=-\infty \equiv \forall N < 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < |x - a| < \delta \implies f(x) < N.\]
\subsubsection{Limit at Infinity}
Let \(I\) be a left-bounded, right-unbounded interval with the point \(a\) being its endpoint on the left. Let \( f(x) \) be a function defined on \(I\). The limit of \( f(x) \) as \( x \) approaches \( \infty \) is denoted as $\lim_{x \to \infty} f(x)$. For $L\in\bbR$:
\[\lim_{x \to \infty} f(x) = L \equiv \forall \varepsilon > 0: \, \exists M > a \text{\ s.t.\ } x > M \implies |f(x) - L| < \varepsilon.\]
In other words, as \(x\) becomes arbitrarily large, \(f(x)\) gets arbitrarily close to \(L\).

If such $M$ exists for some $L\in\bbR$, we say the limit exists and the function converges to $L$ as \(x\) becomes arbitrarily large; otherwise, we say the limit doesn't exist and the function diverges as \(x\) becomes arbitrarily large.

Let \(I\) be a right-bounded, left-unbounded interval with the point \(a\) being its endpoint on the right. Let \( f(x) \) be a function defined on \(I\). The limit of \( f(x) \) as \( x \) approaches \( -\infty \) is defined as follows:
\[\lim_{x \to -\infty} f(x) = L \equiv \forall \varepsilon > 0: \, \exists M < a \text{\ s.t.\ } x < M \implies |f(x) - L| < \varepsilon.\]
In other words, as \(x\) becomes arbitrarily small, \(f(x)\) gets arbitrarily close to \(L\).

If such $M$ exists for some $L\in\bbR$, we say the limit exists and the function converges to $L$ as \(x\) becomes arbitrarily small; otherwise, we say the limit doesn't exist and the function diverges as \(x\) becomes arbitrarily small.
\[\lim_{x\to\infty}f(x)=\infty \equiv \forall N > 0:\, \exists M > 0 \text{\ s.t.\ } x > M \implies f(x) > N.\]
\[\lim_{x\to\infty}f(x)=-\infty \equiv \forall N > 0:\, \exists M > 0 \text{\ s.t.\ } x > M \implies f(x) < N.\]
\[\lim_{x\to-\infty}f(x)=\infty \equiv \forall N > 0:\, \exists M < 0 \text{\ s.t.\ } x < M \implies f(x) > N.\]
\[\lim_{x\to-\infty}f(x)=-\infty \equiv \forall N > 0:\, \exists M < 0 \text{\ s.t.\ } x < M \implies f(x) < N.\]

$\lim_{x\to\infty}f(x)$ is sometimes denoted as $f(\infty)$; $\lim_{x\to-\infty}f(x)$ is sometimes denoted as $f(-\infty)$.
\subsubsection{One-sided Limits}
\tb{Right-hand Limit (右極限)}: Let \(I\) be a left-open interval with the point \(a\) being its endpoint on the left. Let \( f(x) \) be a function defined on \(I\). The right-hand limit of \( f(x) \) as \( x \) approaches \( a \) is denoted as $\lim_{x \to a^+} f(x)$. For $L\in\bbR$:
\[\lim_{x \to a^+} f(x) = L \equiv \forall \varepsilon > 0 :\,\exists \delta > 0 \text{\ s.t.\ } 0 < x - a < \delta \implies |f(x) - L| < \varepsilon.\]
In other words, as \(x\) becomes arbitrarily close to \(a\) and is greater than \(a\), \(f(x)\) gets arbitrarily close to \(L\).
\[\lim_{x\to a^+}f(x)=\infty \equiv \forall N > 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < x - a < \delta \implies f(x) > N.\]
\[\lim_{x\to a^+}f(x)=-\infty \equiv \forall N < 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < x - a < \delta \implies f(x) < N.\]
For a function $f(x)$, $\lim_{x\to a^+}f(x)$ can also be denoted as $f(a^+)$.

$\lim_{x\to-\infty^+}$ is the same as $\lim_{x\to-\infty}$.

\tb{Left-hand Limit (左極限)}: Let \(I\) be a right-open interval with the point \(a\) being its endpoint on the right. Let \( f(x) \) be a function defined on \(I\). The left-hand limit of \( f(x) \) as \( x \) approaches \( a \) is denoted as $\lim_{x \to a^-} f(x)$. For $L\in\bbR$:
\[\lim_{x \to a^-} f(x) = L \equiv \forall \varepsilon > 0 :\,\exists \delta > 0 \text{\ s.t.\ } 0 < a - x < \delta \implies |f(x) - L| < \varepsilon.\]
In other words, as \(x\) becomes arbitrarily close to \(a\) and is less than \(a\), \(f(x)\) gets arbitrarily close to \(L\).
\[\lim_{x\to a^-}f(x)=\infty \equiv \forall N > 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < a - x < \delta \implies f(x) > N.\]
\[\lim_{x\to a^-}f(x)=-\infty \equiv \forall N < 0:\, \exists \delta > 0 \text{\ s.t.\ } 0 < a - x < \delta \implies f(x) < N.\]
For a function $f(x)$, $\lim_{x\to a^-}f(x)$ can also be denoted as $f(a^-)$.

$\lim_{x\to\infty^-}$ is the same as $\lim_{x\to\infty}$.
\subsubsection{Horizontal asymptote (水平漸近線)}
We say $y=L$ is a horizontal asymptote of $y=f(x)$ iff $\lim_{x \to \infty} f(x)=L$ or $\lim_{x \to -\infty} f(x)=L$.
\subsubsection{Slant asymptote (斜漸近線)}
We say $y=mx+b$ with $m\neq 0$ is a slant asymptote of $y=f(x)$ iff $\lim_{x \to \infty} \qty(f(x)-(mx+b))=0$ or $\lim_{x \to -\infty} \qty(f(x)-(mx+b))=0$.
\sssc{Vertical asymptote (鉛直漸近線)}
We say $x=a$ is a vertical asymptote of $y=f(x)$ iff $\abs{\lim_{x \to a^+} f(x)}=\infty$ or $\abs{\lim_{x \to a^-} f(x)}=\infty$.
\ssc{Of Real-valued Functions from Topological Space}
\sssc{Limit}
Let $(X,\tau)$ be a topological space, $a\in E\subseteq X$, and $f$ be a function definited on $E$ except possibly at $a$ with codomain $\bbR$. The limit of $f$ as $x$ approaches $a\in E$ is denoted as $\lim_{x\to a}f(x)$. For $L\in\bbR$:
\[\lim_{x \to a} f(x) = L \equiv \forall \varepsilon > 0:\, \exists U\in\tau\land a\in U \text{\ s.t.\ } x\in E\cap U\setminus\{a\} \implies |f(x) - L| < \varepsilon.\]
If such $U$ exist for some $L\in\bbR$, we say the limit exists; otherwise, we say the limit doesn't exist.
\[\lim_{x\to a}f(x)=\infty \equiv \forall N > 0:\, \exists U\in\tau\land a\in U \text{\ s.t.\ }x\in E\cap U\setminus\{a\}\implies f(x) > N.\]
\[\lim_{x\to a}f(x)=\infty \equiv \forall N < 0:\, \exists U\in\tau\land a\in U \text{\ s.t.\ }x\in E\cap U\setminus\{a\}\implies f(x) < N.\]
\sssc{Limit inferior, infimum limit, limit infimum, liminf, inferior limit, lower limit, or inner limit, and limit superior, supremum limit, limit supremum, limsup, superior limit, upper limit, or outer limit}
Let $(X,\tau)$ be a topological space, $a\in E\subseteq X$, and $f$ be a function definited on $E$ except possibly at $a$ with codomain $\bbR$. The limit inferior of $f$ as $x$ approaches $a\in E$ is defined as
\[\liminf_{x\to a}f(x)\coloneq\sup\{\inf\{f(x)\mid x\in E\cap U\setminus\{a\}\}\mid a\in U\in\tau\},\]
and the limit superior of $f$ as $x$ approaches $a\in E$ is defined as
\[\limsup_{x\to a}f(x)\coloneq\inf\{\sup\{f(x)\mid x\in E\cap U\setminus\{a\}\}\mid a\in U\in\tau\}.\]
\ssc{Of Nets of Fuctions}
\sssc{(Pointwise) limit}
Let $X$ be a set and $Y$ be a topological space. A net of functions $\langle f_a\rangle_{a\in A}$ all having the same domain $X$ and codomain $Y$ is said to converge pointwise (逐點收斂) to a function $f\colon X\to Y$ or have a pointwise limit function $f\colon X\to Y$, denoted as 
\[\lim_af_a=f\text{\ pointwise}\]
or
\[\lim_af_a=f,\]
iff
\[\forall x\in X\colon\lim_af_a(x)=f(x).\]
\sssc{Uniform limit}
Let $X$ be a set and $(Y,d)$ be a metric space. A net of functions $\langle f_a\rangle_{a\in A}$ all having the same domain $X$ and codomain $Y$ is said to converge uniformly (一致收斂) to a function $f\colon X\to Y$ or have a uniform limit function $f\colon X\to Y$, denoted as 
\[\lim_af_a=f\text{\ uniformly},\]
iff
\[\forall\varepsilon\in\mathbb{R}_{>0}\colon\exists N\in A\text{\ s.t.\ }a\in A\land N\leq a\implies\sup_{x\in X}d(f_a(x),f(x))<\varepsilon.\]



\section{Continuity (連續性)}
\ssc{Continuity}
\sssc{Definition of continuity of real functions}
\begin{itemize}
\item For a point $a$ in the domain of a function $f$, if and only if $\exists\lim_{x\to a}f(x)$ and $\lim_{x\to a}f(x)=f(a)$, we say $f(x)$ is continuous (連續的) at $a$.
\item For a point $a$ in the domain of a function $f$, if and only if $\exists\lim_{x\to a^+}f(x)$ and $\lim_{x\to a^+}f(x)=f(a)$, we say $f(x)$ is continuous from the right at $a$; if and only if $\exists \lim_{x\to a^-} f(x)$ and $\lim_{x\to a^-} f(x)=f(a)$, we say $f(x)$ is continuous from the left at $a$.
\item For an open interval $I$ that is a subset of the domain of a function $f$, if and only if $f(x)$ is continuous at all points in $I$, we say $f(x)$ is continuous on $I$.
\item For an right-open interval $[a,b)$ that is a subset of the domain of a function $f$, if and only if $f(x)$ is continuous on $(a,b)$ and continuous from the right at $a$, we say $f(x)$ is continuous on $[a,b)$.
\item For an left-open interval $(a,b]$ that is a subset of the domain of a function $f$, if and only if $f(x)$ is continuous on $(a,b)$ and continuous from the left at $b$, we say $f(x)$ is continuous on $(a,b]$.
\item For an closed interval $[a,b]$ that is a subset of the domain of a function $f$, if and only if $f(x)$ is continuous on both $[a,b)$ and $(a,b]$, we say $f(x)$ is continuous on $[a,b]$.
\item if and only if $f(x)$ is continuous at all points in its domain, we say $f(x)$ is continuous.
\item $f$ is called continuous at $\infty$ if $\lim_{x\to\infty}f(x)\in\bbR\cup\{-\infty,\infty\}$.
\item $f$ is called continuous at $-\infty$ if $\lim_{x\to-\infty}f(x)\in\bbR\cup\{-\infty,\infty\}$.
\eit
\sssc{Definition of continuity of functions between topological spaces}
\begin{itemize}
\item A function $f\colon I\subseteq X\to Y$ where $X$ and $Y$ are topological spaces is continuous at a point $x\in I$ if and only if for any neighborhood $V$ of $f(x)$ in $Y$, there is a neighborhood $U$ of $x$ such that $f(U)\subseteq V$.
\item A function $f\colon I\subseteq X\to Y$ where $X$ and $Y$ are topological spaces is continuous if and only if for any open subset $V$ of $Y$, the preimage of $f$ on $V$ is an open subset of $X$.
\item A function $f\colon I\subseteq X\to Y$ where $X$ and $Y$ are topological spaces is continuous on a subset $J$ of $I$ if and only if for any open subset $V$ of $Y$, the joint set of the preimage of $f$ on $V$ and $J$ is open in the subspace topology of $X$ in $J$.
\eit
\sssc{Discontinuity (不連續（點）)}
A point is a discontinuity of a function $f$ if it is in the domain of $f$ but $f$ is not continuous on it.
\sssc{Type of discontinuity of real functions}
For a function $f$ with domain $U\subseteq\mathbb{R}$ and a point $a\in U$ that $f$ is discontinuous at, the discontinuity $a$ of $f$ can be classified as below:
\bit
\item \tb{Removable (可去) discontinuity}: If $\exists\lim_{x\to a}f(x)\land\lim_{x\to a}f(x)\neq f(a)$, we call $f(a)$ a removable discontinuity. A discontinuity that is not a removable discontinuity is called a non-removable discontinuity.
\item \tb{Jump (跳躍) discontinuity}: If $\exists\lim_{x\to a^-}f(x)\land\exists\lim_{x\to a^+}f(x)\land\lim_{x\to a^-}f(x)\neq\lim_{x\to a^+}f(x)$, we call $f(a)$ a jump discontinuity.
\item\tb{Infinite (無窮) discontinuity}: If at least one of $\lim_{x\to a^-}f(x)$ and $\lim_{x\to a^+}f(x)$ does not exist, and that those in $\lim_{x\to a^-}f(x)$ and $\lim_{x\to a^+}f(x)$ that do not exist are either $\infty$ or $-\infty$, we call $f(a)$ an infinite discontinuity.
\item\tb{Type I discontinuity}: A discontinuity of $f$ that is either a removable discontinuity or a jump discontinuity is called a type I discontinuity of $f$.
\item\tb{Essential (本質) discontinuity or type II discontinuity}: A discontinuity of $f$ that is not a type I discontinuity is called an essential discontinuity or a type II discontinuity of $f$.
\eit
\sssc{Removable discontinuity of functions between topological spaces}
Let $f\colon I\subseteq X\to Y$ be a function where $X$ and $Y$ are topological spaces. We say that $f(a)$ is a removable discontinuity of $f$ iff $f$ is discontinuous at $a$ and there exists $L\in Y$ such that the function
\[g(x)=\begin{cases}L,\quad&x=a\\f(x),\quad&x\in I\setminus\{a\}\end{cases}\]
is continuous at $a$. A discontinuity that is not a removable discontinuity is called a non-removable discontinuity.
\sssc{Singularity or singular point (奇點)}
A point is a singularity or a singular point of a function $f$ if it is in the closure of its domain but not in its domain, or it is a discontinuity of $f$.
\sssc{Arithmetic Laws}
If $f$ and $g$ are continuous at $a$ and $c$ is a constant, then the following functions are also continuous at $a$:
\[f+g;\quad f-g;\quad cf;\quad fg;\]
\[\frac{f}{g}\text{\ if\ }g(a)\neq 0.\]
\sssc{Composte Laws}
If $g$ is continuous at $a$ and $f$ is continuous at $g(a)$, then the composite function $f\circ g$ is continuous at $a$.
\sssc{Examples of continuous real functions}
The following types of functions are continuous at every number in their domains: algebraic functions, trigonometric functions, inverse trigonometric functions, exponential functions, logarithmic functions.
\ssc{Intermediate Value Theorem (IVT) (中間值定理)}
\sssc{Intermediate value theorem of real functions}
Let $f\colon I\subseteq\mathbb{R}\to\mathbb{R}$ be a function, then for any interval $[a,b]\subseteq I$ such that $f$ is continuous on $[a,b]$ and $f(a)\neq f(b)$, $N$ is strictly between $f(a)$ and $f(b)$ implies there exists $c\in (a,b)$ such that $f(c)=N$.
\begin{proof}
Without loss of generality, assume $f(a)<N<f(b)$.

Consider the set
\[S=\{x\in [a,b]\mid f(x)\leq N\}.\]
Since $f(a)<N$, $a\in S$; since $f(b)>N$, $b\notin S$. So $S$ is nonempty and bounded-above by $b$.

Let $c=\sup S$. We claim that $f(c)=N$. Argue by contradiction.

Assume $f(c)<N$. By continuity, there exists $\delta>0$ such that for all $x\in (c,c+\delta)\cap [a,b]$, $|f(x)-f(c)|<N-f(c)$. So $f(x)<N$ for some $x>c$. Contradicting that $c$ is the least upper bound.

Assume $f(c)>N$. By continuity, there exists $\delta>0$ such that for all $x\in (c-\delta,c)\cap [a,b]$, $|f(x)-f(c)|<f(c)-N$. So $f(x)>N$ for some $x<c$. Contradicting that $c$ is the least upper bound.

Therefore, $f(c)=N$.
\end{proof}
\sssc{Intermediate value theorem of functions between topological spaces}
Let $X$ and $Y$ be topological spaces and function $f\colon I\subseteq X\to Y$ be continuous on a subset $J$ of $I$, then for any connected subset $K$ of $J$, $f(K)$ is a connected subset of $Y$.

Let $X$ and $Y$ be topological spaces and function $f\colon I\subseteq X\to Y$ be continuous on a subset $J$ of $I$, then for any path-connected subset $K$ of $J$, $f(K)$ is a path-connected subset of $Y$.
\ssc{Piecewise continuity}
\sssc{Piecewise continuity of real functions}
Let $f\colon B\subseteq\bbR\to\bbR$ be a function and $D$ be subset of $B$. If there exists an indexed family $\{[a_i,b_i]\mid i\in I\}$ of closed intervals such that:
\begin{itemize}
\item for every closed interval $V$, the set $\{i\in I\mid V\cap [a_i,b_i]\neq\varnothing\}$ is finite (some sources require instead that $n(I)$ is finite, which is stronger and not used here),
\item $D\subseteq\bigcup_{i\in I}[a_i,b_i]\subseteq B$,
\item function $f\big\vert_{a_i}^{b_i}\colon(a_i,b_i)\to Y$ is continuous for every $i\in I$, and
\item there exist finite $\lim_{x\to a_i^{\phantom{i}+}}f(x)$ and $\lim_{x\to b_i^{\phantom{i}-}}f(x)$ for every $i\in I$.
\end{itemize},
we say $f$ is piecewise continuous on $D$.

We say $f$ is piecewise continuous iff it is piecewise continuous on $B$.
\sssc{Piecewise continuity of functions between topological spaces}
Let $X$ and $Y$ be topological spaces, $f\colon B\subseteq X\to Y$ be a function, and $D$ be a subset of $B$. If there exists a locally finite (some sources require instead finite, which is stronger and not used here) indexed family $\{U_i\mid i\in I\}$ of closed subsets of $X$ such that:
\begin{itemize}
\item $D\subseteq\bigcup_{i\in I}U_i\subseteq B$, and
\item there exists a function $g_i\colon U_i\to Y$ that is continuous on $U_i$ such that $\forall x\in\operatorname{int}\left(U_i\right)\colon f(x)=g_i(x)$ for every $i\in I$.
\end{itemize},
we say $f$ is piecewise continuous on $B$.

We say $f$ is piecewise continuous iff it is piecewise continuous on $B$.
\ssc{Uniform continuity (一致連續)}
\sssc{Uniform continuity of functions between metric spaces}
Let $(X,d_1)$ and $(Y,d_2)$ be metric spaces, and $f\colon D\subseteq X\to Y$ be a function. $f$ is called to be uniformly continuous if for every real number $\varepsilon >0$ there exists a real number $\delta >0$ such that $x,y\in D$ with $d_{1}(x,y)<\delta$ implies $d_{2}(f(x),f(y))<\varepsilon$.

Let $(X,d_1)$ and $(Y,d_2)$ be metric spaces, and $f\colon O\subseteq X\to Y$ be a function. $f$ is called to be uniformly continuous on $D\subseteq O$ if for every real number $\varepsilon >0$ there exists a real number $\delta >0$ such that $x,y\in D$ with $d_{1}(x,y)<\delta$ implies $d_{2}(f(x),f(y))<\varepsilon$.

Uniform continuity implies continuity.
\sssc{Uniform continuity of functions between topological vector spaces}
Let $X$ and $Y$ be topological vector spaces, and $f\colon D\subseteq X\to Y$ be a function. $f$ is called to be uniformly continuous if for every neighborhood $V$ of the zero vector in $Y$, there exists a neighborhood $U$ of the zero vector in $X$ such that $x,y\in D$ with $x-y\in U$ implies $f(x)-f(y)\in V$.

Let $X$ and $Y$ be topological vector spaces, and $f\colon O\subseteq X\to Y$ be a function. $f$ is called to be uniformly continuous on $D\subseteq O$ if for every neighborhood $V$ of the zero vector in $Y$, there exists a neighborhood $U$ of the zero vector in $X$ such that $x,y\in D$ with $x-y\in U$ implies $f(x)-f(y)\in V$.

Uniform continuity implies continuity.
\ssc{Absolute continuity (絕對連續) of functions from an interval to a metric space}
Let $(X, d)$ be a metric space and $I\subseteq\mathbb{R}$ be an interval. A function $f\colon I \to X$ is absolutely continuous on $I$ if for every positive number $\varepsilon$, there exists a positive number $\delta$ such that for any finite sequence of disjoint subintervals $[x_k, y_k]$ of $I$,
\[\sum _{k}\left|y_{k}-x_{k}\right|<\delta\]
implies
\[\sum _{k}d\left(f(y_{k}),f(x_{k})\right)<\varepsilon.\]
The collection of all absolutely continuous functions from $I$ into $X$ is denoted $AC(I; X)$.

Let $(X, d)$ be a metric space and $I\subseteq\mathbb{R}$ be an interval. A function $f\colon I \to X$ is absolutely continuous on $J\subseteq I$ if for every positive number $\varepsilon$, there exists a positive number $\delta$ such that for any finite sequence of disjoint subintervals $[x_k, y_k]$ of $J$,
\[\sum _{k}\left|y_{k}-x_{k}\right|<\delta\]
implies
\[\sum _{k}d\left(f(y_{k}),f(x_{k})\right)<\varepsilon.\]

Absolute continuity implies uniform continuity.
\sssc{(Golbal/regular) Lipschitz continuity (利普希茨連續) of functions between metric spaces}
Let $(X,d_1)$ and $(Y,d_2)$ be metric spaces, and $f\colon D\subseteq X\to Y$ be a function. $f$ is called to be Lipschitz continuous if there exists a real constant $K$ such that $\forall x,y\in D$, $d_{2}(f(x),f(y))\leq Kd_{1}(x,y)$.

Let $(X,d_1)$ and $(Y,d_2)$ be metric spaces, and $f\colon O\subseteq X\to Y$ be a function. $f$ is called to be Lipschitz continuous on $D\subseteq O$ if there exists a real constant $K$ such that $\forall x,y\in D$, $d_{2}(f(x),f(y))\leq Kd_{1}(x,y)$.

Lipschitz continuity implies absolute continuity.

If a function $f\colon D\subseteq X\to Y$ between metric spaces $(X,d_1)$ and $(Y,d_2)$ is such that there exists a real constant $K$ such that $\forall x,y\in D$, $d_{2}(f(x),f(y))\leq Kd_{1}(x,y)$, then, any such $K$ is called a Lipschitz constant (利普希茨常數) of the function $f$, and $f$ is called to be $K$-Lipschitz or Lipschitz continuous with constant $K$. The smallest such $K$ is called (best) Lipschitz constant or dilation of $f$.
\sssc{Short map}
A short map is a function between metric spaces that is $1$-Lipschitz.
\sssc{Contraction mapping, contraction map, contraction, contractive mapping, contractive map, or contractor (壓縮映射)}
A contraction mapping is a function $f$ from a metric space to itself such that there exists a real number $0\leq K<1$ such that $f$ is $K$-Lipschitz, in which $K$ is sometimes called a contraction constant and the smallest such $K$ is sometimes called the best contraction constant or the contraction constant.
\sssc{Banach fixed-point theorem (巴拿赫不動點定理), contraction mapping theorem (壓縮映射定理), contraction principle, or Banach–Caccioppoli theorem}
For any contraction mapping $T$ over a non-empty complete metric space $X$ with best contraction constant $K$, there must exist a unique fixed-point $x^*$ of $T$ in $X$, and for any $x\in X$, for any sequence $\langle x_n\rangle_{n\in \mathbb {N}_0}$ defined as
\[\begin{cases}
&x_0=x\\
&x_n=T\qty(x_{n-1}),n\in\mathbb{N}
\end{cases},\]
\[\lim_{n\to \infty }x_{n}=x^{*}\]
and
\[d(x_n,x^*)\leq\frac{K^n}{1-K}d(x_1,x_0).\]
\sssc{Locally Lipschitz of functions between metric spaces}
Let $(X,d_1)$ and $(Y,d_2)$ be metric spaces, and $f\colon D\subseteq X\to Y$ be a function. $f$ is called to be locally Lipschitz if $\forall x\in D$, there exists a real constant $K$ and an open set $V\subseteq D$ with $x\in V$ such that $d_{2}(f(y),f(z))\leq Kd_{1}(y,z)$ for all $y,z\in V$.

Let $(X,d_1)$ and $(Y,d_2)$ be metric spaces, and $f\colon O\subseteq X\to Y$ be a function. $f$ is called to be locally Lipschitz on $D\subseteq O$ if $\forall x\in D$, there exists a real constant $K$ and an open set $V\subseteq D$ with $x\in V$ such that $d_{2}(f(y),f(z))\leq Kd_{1}(y,z)$ for all $y,z\in V$.



\section{Derivative (導數)}
\ssc{Notation}
\sssc{Leibniz's notation (萊布尼茲符號) for derivatives}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable $x$, that is,
\[y=f(x).\]
Then, the derivative function of $y$ or $f$ (with respect to (w.r.t.) $x$) can be written as
\[\frac{\mathrm{d}y}{\mathrm{d}x},\quad\frac{\mathrm{d}}{\mathrm{d}x}y,\quad\frac{\mathrm{d}\qty(f(x))}{\mathrm{d}x},\quad\text{or\ }\frac{\mathrm{d}}{\mathrm{d}x}\qty(f(x)),\]
in which $\frac{\mathrm{d}}{\mathrm{d}x}$ is called a differential operator (微分運算子) or a derivative operator (導數運算子);

the $n$th derivative function of $y$ or $f$ (with respect to $x$) can be written as
\[\frac{\mathrm{d}^ny}{\mathrm{d}x^n},\quad\frac{\mathrm{d}^n}{\mathrm{d}x^n}y,\quad\frac{\mathrm{d}^n\qty(f(x))}{\mathrm{d}x^n},\quad\tx{or\ }\frac{\mathrm{d}^n}{\mathrm{d}x^n}\qty(f(x)),\]
in which $\frac{\mathrm{d}^n}{\mathrm{d}x^n}$ is called a differential operator or a derivative operator.
\sssc{Leibniz's notation for partial derivatives}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable vector $\mb{x}=(x_1,x_2,\dots x_n)$, that is,
\[y=f(\mb{x}).\]
Then, the partial derivative function of $y$ or $f$ with respect to $x_i$ can be written as
\[\frac{\partial y}{\partial x_i},\quad\frac{\partial }{\partial x_i}y,\quad\frac{\partial \qty(f(x))}{\partial x_i},\quad\text{or\ }\frac{\partial }{\partial x_i}\qty(f(x)),\]
in which $\frac{\partial}{\partial x_i}$ is called a partial differential operator (偏微分運算子) or a partial derivative operator (偏導數運算子);

the $n$th partial derivative function of $y$ or $f$ with respect to $x_i$ can be written as
\[\frac{\partial^ny}{\partial x_i^{\phantom{i}n}},\quad\frac{\partial^n}{\partial x_i^{\phantom{i}n}}y,\quad\frac{\partial^n\qty(f(x))}{\partial x_i^{\phantom{i}n}}\text{or\ }\frac{\partial^n}{\partial x_i^{\phantom{i}n}}\qty(f(x)),\]
in which $\frac{\partial^n}{\partial x_i^{\phantom{i}n}}$ is called a partial differential operator or a partial derivative operator;

the $n$th mixed partial derivative function of $y$ or $f$ $m_{i_1}$ times with respect to $x_{i_1}$, $m_{i_1}$ times with respect to $x_{i_2}$, $\dots $, $m_{i_k}$ times with respect to $x_{i_k}$, in which $\sum_{j=1}^km_{i_j}=n$, can be written as
\[\frac{\partial^ny}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}},\]
\[\frac{\partial^n}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}}y,\]
\[\frac{\partial^nf\qty(\mb{x})}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}},\quad \tx{or}\]
\[\frac{\partial^n}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}}f(\mb{x}),\]
in which $\frac{\partial^n}{\partial^{m_{i_1}}x_{i_1}^{\phantom{i_1}m_{i_1}}\partial^{m_{i_2}}x_{i_2}^{\phantom{i_2}m_{i_2}}\dots \partial^{m_{i_k}}x_{i_k}^{\phantom{i_k}m_{i_k}}}$ is called a partial differential operator or a partial derivative operator.
\sssc{Lagrange's notation (拉格朗日符號) or Prime notation for derivatives}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable $x$, that is,
\[y=f(x).\]
Then, the derivative function of $y$ or $f$ (with respect to $x$) can be written as
\[y',\quad\tx{or\ }f'(x);\]
the $n$th derivative function of $y$ or $f$ (with respect to $x$) can be written as
\[y^{(n)},\quad\tx{or\ }f^{(n)}(x),\]
in which $^{(n)}$ can be replaced with $n$ primes ($'$) for usually $n<4$ (For example, $y''$ is equivalent to $y^{(2)}$, and $f''$ is equivalent to $f^{(2)}$.).
\sssc{Newton's notation (牛頓符號), dot notation, flyspeck notation, or fluxions for derivatives}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable $t$, that is,
\[y=f(t),\]
where $t$ usually represents time.

Then, the derivative function of $y$ or $f$ (with respect to $t$) of the function $f$ can be written as
\[\dot{y},\]
the second derivative function of $y$ or $f$ (with respect to $t$) of the function $f$ can be written as
\[\ddot{y},\]
and so on.
\sssc{Subscript notation for partial derivatives}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable vector $\mb{x}=(x_1,x_2,\dots x_n)$, that is,
\[y=f(\mb{x}).\]
Then, the partial derivative function of $y$ or $f$ with respect to $x_i$ can be written as
\[y_{x_i},\quad y'_{x_i},\quad f_{x_i},\quad \tx{or\ }f'_{x_i};\]
the $n$th partial derivative of the function $f$ with respect to $x_i$ can be written as
\[y_{x_ix_i\dots  x_i},\quad y^{(n)}_{\pht{(n)}x_ix_i\dots  x_i},\quad f_{x_ix_i\dots  x_i},\tx{or\ }\quad f^{(n)}_{\pht{(n)}x_ix_i\dots  x_i},\]
in which the subscript are $n$ $x_i$s and $^{(n)}$ can be replaced with $n$ primes ($'$) for usually $n<4$ (For example, $y''$ is equivalent to $y^{(2)}$, and $f''$ is equivalent to $f^{(2)}$.);

the $n$th mixed partial derivative of the function $f$ $m_{i_1}$ times with respect to $x_{i_1}$, $m_{i_1}$ times with respect to $x_{i_2}$, $\dots $, $m_{i_k}$ times with respect to $x_{i_k}$, in which $\sum_{j=1}^km_{i_j}=n$, can be written as
\[y_{x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}},\quad y^{(n)}_{\pht{(n)}x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}},\]
\[f_{x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}},\quad \tx{or\ }f^{(n)}_{\pht{(n)}x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}},\]
in which the subscript are $m_{i_j}$ $x_{i_j}$s for all $x_{i_j}$.
\sssc{Euler's notation (歐拉符號) for derivatives}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable $x$, that is,
\[y=f(x).\]
Then, the derivative function of $y$ or $f$ (with respect to $x$) can be written as
\[Df(x),\quad(Df)(x),\quad D_xf(x),\quad (D_xf)(x),\quad \mathrm{d}f(x),\quad(\mathrm{d}f)(x),\quad \mathrm{d}_xf(x),\quad \tx{or\ }(\mathrm{d}_xf)(x),\]
in which $D$, $D_x$, $\mathrm{d}$, or $\mathrm{d}_x$ is called a (unary) differential operators or a derivative operator, and  $Df$, $D_xf$, $\mathrm{d}f$, or $\mathrm{d}_xf$ are called the differential (微分子) of $y$ or $f$ (with respect to $x$);

the $n$th derivative function of $y$ or $f$ (with respect to $x$) can be written as
\[D^nf(x),\quad(D^nf)(x),\quad D^n_{\pht{(n)}xx\dots x}f(x),\quad\qty(D^n_{\pht{(n)}xx\dots x}f)(x),\quad \mathrm{d}^nf(x),\quad(\mathrm{d}^nf)(x),\quad \mathrm{d}^n_{\pht{(n)}xx\dots x}f(x),\quad \tx{or\ }\qty(\mathrm{d}^n_{\pht{(n)}xx\dots x}f)(x),\]
in which subscript are $n$ $x$s, $D^n$, $D^n_{\pht{(n)}xx\dots x}$, $\mathrm{d}^n$, or $\mathrm{d}^n_{\pht{(n)}xx\dots x}$ is called a (unary) differential operators or a derivative operators, and $D^nf$, $D^n_{\pht{(n)}xx\dots x}f$, $\mathrm{d}^nf$, or $\mathrm{d}^n_{\pht{(n)}xx\dots x}f$ is called the differential of the $(n-1)$th derivative function of $y$ or $f$.
\sssc{Euler's notation for partial derivatives}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable vector $\mb{x}=(x_1,x_2,\dots x_n)$, that is,
\[y=f(\mb{x}).\]
Then, the partial derivative function of $y$ or $f$ with respect to $x_i$ can be written as
\[\partial_{x_i}f(\mb{x}),\quad \qty(\partial_{x_i}f)(\mb{x}),\quad \mathrm{d}_{x_i}f(\mb{x})\tx{or\ }\qty(\mathrm{d}_{x_i}f)(\mb{x}),\quad D_{x_i}f(\mb{x})\tx{or\ }\qty(D_{x_i}f)(\mb{x}),\]
in which $\partial_{x_i}$, $\mathrm{d}_{x_i}$, or $D_{x_i}$ is called a partial differential operator or a partial derivative operator;

the $n$th partial derivative function of $y$ or $f$ with respect to $x_i$ can be written as
\[\partial_{x_ix_i\dots  x_i}f(\mb{x}),\quad\partial^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}f(\mb{x}),\quad D_{x_ix_i\dots  x_i}f(\mb{x}),\quad D^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}f(\mb{x}),\quad \mathrm{d}_{x_ix_i\dots  x_i}f(\mb{x}),\quad\tx{or\ }\mathrm{d}^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}f(\mb{x}),\]
in which subscript are $n$ $x_i$s, $^{(n)}$ can be replaced with $n$ primes ($'$) for usually $n<4$ (For example, $\partial''$ is equivalent to $\partial^{(2)}$, and $D''$ is equivalent to $D^{(2)}$.), and $\partial_{x_ix_i\dots  x_i}$, $\partial^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}$, $D_{x_ix_i\dots  x_i}$, $D^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}$, $\mathrm{d}D_{x_ix_i\dots  x_i}$, or $\mathrm{d}^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}$ is called a partial differential operator or a partial derivative operator;

the $n$th mixed partial derivative function of $y$ or $f$ $m_{i_1}$ times with respect to $x_{i_1}$, $m_{i_1}$ times with respect to $x_{i_2}$, $\dots $, $m_{i_k}$ times with respect to $x_{i_k}$, in which $\sum_{j=1}^km_{i_j}=n$, can be written as
C\[\partial_{x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}f(\mb{x}),\quad\partial^{(n)}_{\pht{(n)}x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}f(\mb{x}),\]
\[ D_{x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}f(\mb{x}),\quad D^{(n)}_{\pht{(n)}x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}f(\mb{x}),\]
\[ \mathrm{d}_{x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}f(\mb{x}),\quad\tx{or\ }\mathrm{d}^{(n)}_{\pht{(n)}x_{i_1}x_{i_1}\dots  x_{i_2}x_{i_2}x_{i_2}\dots  x_{i_2}\dots  x_{i_k}x_{i_k}\dots  x_{i_k}}f(\mb{x}),\]
in which subscript are $m_{i_j}$ $x_{i_j}$s for all $x_{i_j}$, $^{(n)}$ can be replaced with $n$ primes ($'$) for usually $n<4$ (For example, $\partial''$ is equivalent to $\partial^{(2)}$, and $D''$ is equivalent to $D^{(2)}$.), and $\partial_{x_ix_i\dots  x_i}$, $\partial^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}$, $D_{x_ix_i\dots  x_i}$, $D^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}$, $\mathrm{d}_{x_ix_i\dots  x_i}$, and $\mathrm{d}^{(n)}_{\pht{(n)}x_ix_i\dots  x_i}$ is called a partial differential operator or a partial derivative operator.
\ssc{Ordinary Derivatives of Functions with Real Domain}
Let $W$ be a topological vector space. The ordinary derivative (常導數) or derivative (導數) $f'(x)$ of a function $f\colon U\subseteq\mathbb{R}\to W$ (with respect to $x$) at $x\in U$ is defined as
\[f'(x)=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}\]
if the limit exists. If such limit exists, we say $f$ is differentiable (可微的) at $x$.

We define the (first(-order)) ordinary derivative (function) (常導（函）數) or derivative (function) (導（函）數) of $f$ (with respect to $x$) as a function $f'$ with codomain $W$ such that for any $x\in U$ at which $f$ is differentiable, $f'$ maps $x$ to the derivative of $f$ at $x$.

The derivative of the $k$th(-order) ($k\in\mathbb{N}$) derivative function of $f$ at $x\in U$ is called the $(k+1)$th(-order) derivative of $f$ (with respect to $x$) at $x\in U$. The derivative function of the $k$th(-order) ($k\in\mathbb{N}$) derivative function of $f$ is called the $k+1$th(-order) derivative function of $f$ (with respect to $x$).

If for any $n\in\mathbb{N}$, the $n$th(-order) derivative of a function $f$ at a point $x$ in its domain exists, we say $f$ is infinitely differentiable at $x$.

If $f$ is differentiable at all point in $I\subseteq U$, we say $f$ is differentiable on $I$; if $f$ is differentiable on $U$, we say $f$ is differentiable. If $f^{(n-1)}$ exists and is differentiable at all point in $I\subseteq U$, we say $f$ is $n$-times differentiable on $I$; if $f^{(n-1)}$ exists and is differentiable on $U$, we say $f$ is $n$-times differentiable.

The operation of finding the derivative or derivative function is called ordinary differentiation (常微分) or differentiation (微分).

Specifically, the $0$th(-order) derivative of $f$ is $f$ itself.

The derivative of a $f$ at $x$ represents the slope (斜率) at $x$ or the lineal element at $x$ (a miniature tangent line at $x$).
\ssc{One-sided Derivative of Functions with Real Domain}
Let $W$ be a topological vector space and $f\colon U\subseteq\mathbb{R}\to W$ be a function.

The left-hand derivative of $f$ at $x\in U$, denoted as $f'_-(x)$, is defined as
\[f'_-(x)=\lim_{h\to 0^-}\frac{f(x+h)-f(x)}{h}\]
if the limit exists.

The right-hand derivative of $f$ at $x\in U$, denoted as $f'_+(x)$, is defined as
\[f'_+(x)=\lim_{h\to 0^+}\frac{f(x+h)-f(x)}{h}\]
if the limit exists.
\ssc{Ordinary derivatives of Functions with Real Vector Domain}
Let $W$ be a normed vector space. A function $f\colon U\subseteq\mathbb{R}^n\to W$ with $n\in\bbN$ is differentiable at $x\in U$ if there exists a bounded linear operator $A\colon\bbR^n\to W$ such that
\[\lim_{\|h\|\to 0}\frac{\|f(x+h)-f(x)-A(h)\|_W}{\|h\|}=0.\]
If there exists such an operator $A$, it is unique, so we define the (first(-order)) ordinary derivative or derivative of $f$ (with respect to $x$) at $x$, denoted as $Df(x)$, as $A$.

We define the (first(-order)) ordinary derivative (function) or derivative (function) of $f$ (with respect to $x$) as a function $Df$ with codomain $B(\bbR^n,W)$, in which $B(\bbR^n,W)$ is the space of all bounded linear operators from $\bbR^n$ to $W$, such that for any $x\in U$ at which $f$ is differentiable, $Df$ maps $x$ to the derivative of $f$ at $x$.

The derivative of the $k$th(-order) ($k\in\mathbb{N}$) derivative function of $f$ at $x\in U$ is called the $k+1$th(-order) derivative of $f$ (with respect to $x$) at $x\in U$, denoted as $(D^{k+1}f)(x)$. The derivative function of the $k$th(-order) ($k\in\mathbb{N}$) derivative function of $f$ is called the $k+1$th(-order) derivative function of $f$ (with respect to $x$), denoted as $D^{k+1}f$.

If $f$ is differentiable at all point in $I\subseteq U$, we say $f$ is differentiable on $I$; if $f$ is differentiable on $U$, we say $f$ is differentiable. If $D^{(n-1)}f$ exists and is differentiable at all point in $I\subseteq U$, we say $f$ is $n$-times differentiable on $I$; if $D^{(n-1)}f$ exists and is differentiable on $U$, we say $f$ is $n$-times differentiable.

The operation of finding the derivative or derivative function is called ordinary differentiation or differentiation.

Specifically, the $0$th(-order) Fréchet derivative of $f$ is $f$ itself.
\ssc{Partial derivatives of Functions with Real Vector Domain}
Let $W$ be a topological vector space and $f\colon U\subseteq\mathbb{R}^n\to W$ be a function, $\mb{x}$ be the independent variable vector of $f$, and $X$ be the set of all independent variables of $f$.

The (first(-order)) partial derivative (偏導數) $\pdv{f}{x_i}$ of $f$ with respect to $x_i\in X$ at $u\in U$ is defined as
\bma
\pdv{f}{x_i}&=\lim_{h\to 0}\frac{f(u+h\mb{e}_i)-f(u)}{h}\\
&=\frac{\mathrm{d}}{\mathrm{d}h}f(u+h\mb{e}_i)\big\vert_{h=0}
\end{aligned},\]
in which $\mb{e}_i\in\mathbb{R}^n$ is the unit vector in the direction of $x_i$.

The partial derivative of the $k$th(-order) ($k\in\mathbb{N}$) partial derivative (function) (偏導（函）數) of $f$ with respect to $ x \in X$ with respect to $ x \in X$ at $u\in U$ is called the $k+1$th(-order) partial derivative of $f$ with respect to $ x$ at $u\in U$. The partial derivative function of the $k$th(-order) ($k\in\mathbb{N}$) partial derivative function of $f$ with respect to $ x \in X$ with respect to $ x \in X$ is called the $k+1$th(-order) partial derivative function of $f$ with respect to $ x$.

The partial derivative of the $k$th(-order) partial derivative function of $f$ with respect to $ x_1\in X$ with respect to $ x_2\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative of $f$ with respect to $ x_1, x_1,\dots  x_1$ ($k$ times) and $ x_2$ at $u\in U$. The partial derivative function of the $k$th(-order) partial derivative function of $f$ with respect to $ x_1\in X$ with respect to $ x_2\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_1,\dots  x_1$ ($k$ times) and $ x_2$.

The partial derivative of the $k$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k\in X$ with respect to $ x_{k+1}\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative of $f$ with respect to $ x_1, x_2,\dots  x_k, x_{k+1}$ at $u\in U$. The partial derivative function of the $k$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k\in X$ with respect to $ x_{k+1}\in X$ is called the $(k+1)$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k, x_{k+1}$.

The operation of finding the partial derivative or partial derivative function is called partial differentiation (偏微分).

Specifically, the $0$th(-order) partial derivative of $f$ is $f$ itself.
\ssc{Fréchet derivative (弗蘭歇導數)}
\sssc{Fréchet derivative}
Let $V$ and $W$ be normed vector spaces and $U$ be an open subset of $V$. A function $f\colon U\to W$ is Fréchet differentiable (弗蘭歇可微的) or differentiable at $x\in U$ if there exists a bounded linear operator $A\colon V\to W$ such that
\[\lim_{\|h\|_V\to 0}\frac{\|f(x+h)-f(x)-A(h)\|_W}{\|h\|_V}=0.\]
If there exists such an operator $A$, it is unique, so we define the (first(-order)) Fréchet derivative, ordinary derivative, or derivative of $f$ (with respect to $x$) at $x$, denoted as $Df(x)$, as $A$.

We define the (first(-order)) Fréchet derivative (function) (弗蘭歇導（函）數), ordinary derivative (function), or derivative (function) of $f$ (with respect to $x$) as a function $Df$ with codomain $B(V,W)$, in which $B(V,W)$ is the space of all bounded linear operators from $V$ to $W$, such that for any $x\in U$ at which $f$ is Fréchet differentiable, $Df$ maps $x$ to the Fréchet derivative of $f$ at $x$.

The Fréchet derivative of the $k$th(-order) ($k\in\mathbb{N}$) Fréchet derivative function of $f$ at $x\in U$ is called the $k+1$th(-order) Fréchet derivative of $f$ (with respect to $x$) at $x\in U$, denoted as $(D^{k+1}f)(x)$. The Fréchet derivative function of the $k$th(-order) ($k\in\mathbb{N}$) Fréchet derivative function of $f$ is called the $k+1$th(-order) Fréchet derivative function of $f$ (with respect to $x$), denoted as $D^{k+1}f$.

If $f$ is Fréchet differentiable at all point in $I\subseteq U$, we say $f$ is Fréchet differentiable on $I$; if $f$ is Fréchet differentiable on $U$, we say $f$ is Fréchet differentiable. If $D^{(n-1)}f$ exists and is Fréchet differentiable at all point in $I\subseteq U$, we say $f$ is $n$-times Fréchet differentiable on $I$; if $D^{(n-1)}f$ exists and is Fréchet differentiable on $U$, we say $f$ is $n$-times Fréchet differentiable.

The operation of finding the Fréchet derivative or Fréchet derivative function is called Fréchet differentiation (弗蘭歇微分), ordinary differentiation, or differentiation.

Specifically, the $0$th(-order) Fréchet derivative of $f$ is $f$ itself.
\ssc{Smoothness (光滑性 or 平滑性)}
\sssc{Continuously differentiable functions}
A function is called ($n$-times) continuously differentiable iff it is ($n$-times) differentiable and its ($n$th) derivative is continuous.
\sssc{Smoothness}
A function $f$ with real domain that has a derivative that is continuous on its domain is said to be of class $C^1$ or continuously differentiable, denoted as $f\in C^1$, or be a $C^1$-function.

A function $f$ that has a derivative that is continuous on a subset $I$ of its domain is said to be of class $C^1$ on $I$, of class $C^1(I)$, or continuously differentiable on $I$, denoted as $f\in C^1(I)$.

A function $f$ with real domain that has a $k$th derivative that is continuous on its domain is said to be of class $C^k$ or $k$-times continuously differentiable, denoted as $f\in C^k$, or be a $C^k$-function.

A function $f$ that has a $k$th derivative that is continuous on a subset $I$ of its domain is said to be of class $C^k$ on $I$ or of class $C^k(I)$, denoted as $f\in C^k(I)$.

Generally, the term smooth function refers to a $C^{\infty}$-function, that is a function that is of class $C^k$ for any $k\in\bbR$. However, it may also mean "sufficiently differentiable" for the problem under consideration.
\sssc{Piecewise smoothness of real functions}
Let $f\colon D\subseteq\mathbb{R}\to\mathbb{R}$ be a function. If there exists a family $\{[a_i,b_i]\mid i\in I\}$ of closed intervals such that:
\begin{itemize}
\item for every closed interval $V$, the set $\{i\in I\mid V\cap [a_i,b_i]\neq\varnothing\}$ is finite (some sources require instead that $n(I)$ is finite, which is stronger),
\item $D\subseteq\bigcup_{i\in I}[a_i,b_i]$,
\item function $f\big\vert_{a_i}^{b_i}\colon(a_i,b_i)\to Y$ is of class $C^k((a_i,b_i))$ for every $i\in I$, and
\item there exist finite $\lim_{x\to a_i^{\phantom{i}+}}f(x)$ and $\lim_{x\to b_i^{\phantom{i}-}}f(x)$ for every $i\in I$.
\end{itemize},
we say $f$ is of class piecewise $C^k$ (or of class piecewise $C^k\qty(\bigcup_{i\in I}[a_i,b_i])$); when $k=\infty$ or sufficiently large, we say $f$ is piecewise smooth (on $\bigcup_{i\in I}U_i$).
\sssc{Piecewise smoothness of functions between topological spaces}
Let $X$ and $Y$ be topological spaces, and $f\colon D\subseteq X\to Y$ be a function. If there exists a locally finite (some sources require instead finite, which is stronger) family $\{U_i\mid i\in I\}$ of closed subsets of $X$ such that:
\begin{itemize}
\item $D\subseteq\bigcup_{i\in I}U_i$, and
\item there exists a function $g_i\colon U_i\to Y$ that is of class $C^k\qty(U_i)$ such that $\forall x\in\operatorname{int}\left(U_i\right)f(x)=g_i(x)$ for every $i\in I$.
\end{itemize},
we say $f$ is of class piecewise $C^k$ (or of class piecewise $C^k\qty(\bigcup_{i\in I}U_i)$); when $k=\infty$ or sufficiently large, we say $f$ is piecewise smooth (on $\bigcup_{i\in I}U_i$).
\ssc{Gateaux Differentiation (加托微分)}
\sssc{Gateaux derivative (加托導數) and partial derivatives}
Let $V$ be a locally convex topological vector spaces (LCTVS), $W$ be a topological vector space, $U$ be an open subset of $V$, and $f\colon U\to W$ be a function.

The (first(-order)) Gateaux derivative $df(u;\,\psi)$ of $f$ at $u\in U$ in the direction $\psi \in V$ is defined to be
\[\begin{aligned}
df(u;\,\psi) &= \lim_{\tau\to 0}\frac{f(u+\tau \psi)-f(u)}{\tau}\\
&= \frac{\mathrm{d}}{\mathrm{d}\tau}f(u+\tau \psi)\big\vert_{\tau =0}
\end{aligned}\]
if the limit exists. If for any $\psi \in V$, the Gateaux derivative exists, then it is said that $f$ is Gateaux differentiable (加托可微的) at $u$.

We define the (first(-order)) Gateaux derivative (function) (加托導（函）數) of $f$ in the direction $\psi \in V$, denoted as $df$, as a function $df\colon U\to W$, such that for any $u\in U$ at which $f$ is Gateaux differentiable, $df$ maps $u$ to the Gateaux derivative of $f$ at $u$ in the direction $\psi \in V$.

The Gateaux derivative of the $k$th(-order) ($k\in\mathbb{N}$) Gateaux derivative function of $f$ in the direction $\psi \in V$ in the direction $\psi \in V$ at $u\in U$ is called the $k+1$th(-order) Gateaux derivative of $f$ in the direction $\psi$ at $u\in U$. The Gateaux derivative function of the $k$th(-order) ($k\in\mathbb{N}$) Gateaux derivative function of $f$ in the direction $\psi \in V$ in the direction $\psi \in V$ is called the $k+1$th(-order) Gateaux derivative function of $f$ in the direction $\psi$.

The Gateaux derivative of the $k$th(-order) Gateaux derivative function of $f$ in the direction $\psi_1\in V$ in the direction $\psi_2\in V$ at $u\in U$ is called the $(k+1)$th(-order) mixed Gateaux derivative of $f$ in the direction $\psi_1,\psi_1,\dots \psi_1$ ($k$ times) and $\psi_2$ at $u\in U$. The Gateaux derivative function of the $k$th(-order) Gateaux derivative function of $f$ in the direction $\psi_1\in V$ in the direction $\psi_2\in V$ is called the $(k+1)$th(-order) mixed Gateaux derivative function of $f$ in the direction $\psi_1,\psi_1,\dots \psi_1$ ($k$ times) and $\psi_2$.

The Gateaux derivative of the $k$th(-order) mixed Gateaux derivative function of $f$ in the direction $\psi_1,\psi_2,\dots \psi_k\in V$ in the direction $\psi_{k+1}\in V$ at $u\in U$ is called the $(k+1)$th(-order) mixed Gateaux derivative of $f$ in the direction $\psi_1,\psi_2,\dots \psi_k,\psi_{k+1}$ at $u\in U$. The Gateaux derivative function of the $k$th(-order) mixed Gateaux derivative function of $f$ in the direction $\psi_1,\psi_2,\dots \psi_k\in V$ in the direction $\psi_{k+1}\in V$ is called the $(k+1)$th(-order) mixed Gateaux derivative function of $f$ in the direction $\psi_1,\psi_2,\dots \psi_k,\psi_{k+1}$.

The operation of finding the Gateaux derivative or Gateaux derivative function is called Gateaux differentiation (加托微分).

Specifically, the $0$th(-order) Gateaux derivative of $f$ is $f$ itself.
\sssc{Partial derivative}
Let $V$ be a locally convex topological vector spaces (LCTVS), $W$ be a topological vector space, $U$ be an open subset of $V$, and $f\colon U\to W$ be a function, $\mb{x}$ be the independent variable vector of $f$, and $X$ be the set of all independent variables of $f$.

The (first(-order)) partial derivative of $f$ with respect to $x_i\in X$ at $u\in U$ is defined as the Gateaux derivative of $f$ in the direction of $x_i$ at $u$ if it exists.

The partial derivative of the $k$th(-order) ($k\in\mathbb{N}$) partial derivative (function) of $f$ with respect to $ x \in X$ with respect to $ x \in X$ at $u\in U$ is called the $k+1$th(-order) partial derivative of $f$ with respect to $ x$ at $u\in U$. The partial derivative function of the $k$th(-order) ($k\in\mathbb{N}$) partial derivative function of $f$ with respect to $ x \in X$ with respect to $ x \in X$ is called the $k+1$th(-order) partial derivative function of $f$ with respect to $ x$.

The partial derivative of the $k$th(-order) partial derivative function of $f$ with respect to $ x_1\in X$ with respect to $ x_2\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative of $f$ with respect to $ x_1, x_1,\dots  x_1$ ($k$ times) and $ x_2$ at $u\in U$. The partial derivative function of the $k$th(-order) partial derivative function of $f$ with respect to $ x_1\in X$ with respect to $ x_2\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_1,\dots  x_1$ ($k$ times) and $ x_2$.

The partial derivative of the $k$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k\in X$ with respect to $ x_{k+1}\in X$ at $u\in U$ is called the $(k+1)$th(-order) mixed partial derivative of $f$ with respect to $ x_1, x_2,\dots  x_k, x_{k+1}$ at $u\in U$. The partial derivative function of the $k$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k\in X$ with respect to $ x_{k+1}\in X$ is called the $(k+1)$th(-order) mixed partial derivative function of $f$ with respect to $ x_1, x_2,\dots  x_k, x_{k+1}$.

The operation of finding the partial derivative or partial derivative function is called partial differentiation.

Specifically, the $0$th(-order) partial derivative of $f$ is $f$ itself.
\ssc{Applicational interpretation}
\sssc{Rate of change}
If $y=f(x)$, then $f'(a)$ where defined is called the instantaneous rate of change of $y$ with repsect to $x$ at $a$.
A function $f\colon U\to W$ is Fréchet differentiable (弗蘭歇可微的) or differentiable at $x\in U$ if there exists a bounded linear operator $A\colon V\to W$ such that
\[\lim_{\|h\|_V\to 0}\frac{\|f(x+h)-f(x)-A(h)\|_W}{\|h\|_V}=0.\]
If there exists such an operator $A$, it is unique, so we define the (first(-order)) Fréchet derivative, ordinary derivative, or derivative of $f$ (with respect to $x$) at $x$, denoted as $Df(x)$, as $A$.

We define the (first(-order)) Fréchet derivative (function) (弗蘭歇導（函）數), ordinary derivative (function), or derivative (function) of $f$ (with respect to $x$) as a function $Df$ with codomain $B(V,W)$, in which $B(V,W)$ is the space of all bounded linear operators from $V$ to $W$, such that for any $x\in U$ at which $f$ is Fréchet differentiable, $Df$ maps $x$ to the Fréchet derivative of $f$ at $x$.

The Fréchet derivative of the $k$th(-order) ($k\in\mathbb{N}$) Fréchet derivative function of $f$ at $x\in U$ is called the $k+1$th(-order) Fréchet derivative of $f$ (with respect to $x$) at $x\in U$, denoted as $(D^{k+1}f)(x)$. The Fréchet derivative function of the $k$th(-order) ($k\in\mathbb{N}$) Fréchet derivative function of $f$ is called the $k+1$th(-order) Fréchet derivative function of $f$ (with respect to $x$), denoted as $D^{k+1}f$.

If $f$ is Fréchet differentiable at all point in $I\subseteq U$, we say $f$ is Fréchet differentiable on $I$; if $f$ is Fréchet differentiable on $U$, we say $f$ is Fréchet differentiable. If $D^{(n-1)}f$ exists and is Fréchet differentiable at all point in $I\subseteq U$, we say $f$ is $n$-times Fréchet differentiable on $I$; if $D^{(n-1)}f$ exists and is Fréchet differentiable on $U$, we say $f$ is $n$-times Fréchet differentiable.

The operation of finding the Fréchet derivative or Fréchet derivative function is called Fréchet differentiation (弗蘭歇微分), ordinary differentiation, or differentiation.

Specifically, the $0$th(-order) Fréchet derivative of $f$ is $f$ itself.

If $y=f(x)$ is defined on some interval $[a,b]$ with $b>a$, then $\frac{f(b)-f(a)}{b-a}$ is called the average rate of change of $y$ with repsect to $x$ over $[a,b]$.
\sssc{Physical interpretation}
Let $f$ be a function with domain being $\bbR$ or $\bbR_{\geq 0}$. If we interprets $f(t)$ as the position of $y$ at time $t$, then:
\bit
\item $f$ is called the position function of $y$,
\item if $f(x)$ is defined on some interval $[a,b]$ with $b>a$, then $f(b)-f(a)$ is called the displacement of $y$ over $[a,b]$,
\item $f'$ is called the velocity function of $y$,
\item $f'(a)$ where defined is called the instantaneous velocity of $y$ at $a$,
\item if $f(x)$ is defined on some interval $[a,b]$ with $b>a$, then $\frac{f(b)-f(a)}{b-a}$ is called the average velocity of $y$ over $[a,b]$,
\item $f''$ is called the acceleration function of $y$,
\item $f''(a)$ where defined is called the instantaneous acceleration of $y$ at $a$,
\item if $f'(x)$ is defined on some interval $[a,b]$ with $b>a$, then $\frac{f'(b)-f'(a)}{b-a}$ is called the average acceleration of $y$ over $[a,b]$,
\item $f'''$ is called the jerk function of $y$,
\item $f'''(a)$ where defined is called the instantaneous jerk of $y$ at $a$, and
\item if $f''(x)$ is defined on some interval $[a,b]$ with $b>a$, then $\frac{f''(b)-f''(a)}{b-a}$ is called the average jerk of $y$ over $[a,b]$.
\eit
\sssc{Biological interpretation}
Let $f$ be a function with domain being $\bbR$ or $\bbR_{\geq 0}$. If we interprets $f(t)$ as the number of some population $y$ at time $t$, then:
\bit
\item $f$ is called the growth (function) of $y$,
\item $f'(a)$ where defined is called the instantaneous rate of growth of $y$ at $a$, and
\item if $f(x)$ is defined on some interval $[a,b]$ with $b>a$, then $\frac{f(b)-f(a)}{b-a}$ is called the average rate of growth of $y$ over $[a,b]$.
\eit
\sssc{Economical interpretation}
Let $f$ be a function with domain being $\bbR$ or $\bbR_{\geq 0}$. If we interprets $f(t)$ as the benefit (aka revenue) or cost of consuming or producing $y$ of quantity $t$, then:
\bit
\item $f$ is called benefit (aka revenue) or cost (function) of $y$, and
\item $f'(a)$ where defined is called the margin benefit (aka revenue) or cost of $y$ at $a$.
\eit
\ssc{Differentials (微分子)}
Suppose a dependent variable $y$ represents a function $f$ of an independent variable $x$, that is,
\[y=f(x),\]
with the domain $V$ of $f$ being a subset of some vector space.

If $y$ or $f$ is defined and differentiable on some set $U\subseteq V$ with the derivative function denoted as $y'$ or $f'(x)$, then we define the differential of them, denoted as $\dd{y}$ and $\dd{f}$ respectively, in terms of the differential of $x$, denoted as $\dd{x}$, by the equations
\[\dd{y}=y'\dd{x},\quad \tx{and\ }\dd{f}=f'\dd{x}\]
respectively, in which the differentials of $x$, $y$, or $f$ are often called to be an infinitesimal changes in $x$, $y$, or $f$.
\ssc{Antiderivative (反導函數), inverse derivative, primitive function, primitive integral, or indefinite integral (不定積分)}
\sssc{Definition}
An antiderivative (aka inverse derivative, primitive function, primitive integral, or indefinite integral) of a function $f(x)$ on subset $I$ of the domain of $f$ is a differentiable function $F(x)$ such that
\[F'(x)=f(x)\]
for all $x\in I$.

The process of solving for antiderivatives is called antidifferentiation (反微分) or indefinite integration (不定積分).
\sssc{Theorem}
If a function $F(x)$ with codomain $Y$ is an antiderivative of a function $f(x)$ on subset $I$ of the domain of $f$, then the family of all antiderivatives of $f(x)$ on $I$ is
\[\{F(x)+C\mid C\in Y\}.\]
\sssc{Notation}
If a function $F(x)$ with codomain $Y$ is an antiderivative of a function $f(x)$ on subset $I$ of the domain of $f$, we write
\[\int f(x)\dd{x}=F(x)+C,\]
where $C$ denotes an arbitrary constant in $Y$ that does not depend on $x$, called constant of integration. The symbol $\int$ is called integral sign, introduced by Leibniz.

An indefinite integral in the form
\[\int f(x)\dd{x}=
\begin{cases}
F(x)+C_1,\quad & x\in A_1\\
F(x)+C_2,\quad & x\in A_2\\
\vdots
F(x)+C_n,\quad & x\in A_n\\
(\ldots)
\end{cases}\]
with an interval $A$ such that $\bigcup_{i=1}^nA_i\subseteq A$ and that $A\setminus\bigcup_{i=1}^nA_i$ is a set $B$ of measure zero and that $F(x)$ is not defined on $C$ and defined on $\bigcup_{i=1}^nA_i$, is usually abbreviated as
\[\int f(x)\dd{x}=
\begin{cases}
F(x)+C,\quad & x\in A\\
\ldots
\end{cases}\]
where $C$ is to be understood as notation for a locally constant function of $x$.

When computing indefinite integral, we usually absorb constants into $C$ without changing its symbol, that is,
\[\int f(x)\dd{x}=\ldots=F(x)+a+C=F(x)+C.\]
\subsection{Taylor series (泰勒級數) or Taylor expansion (泰勒展開)}
Assume that $F:\,\mathbb{R}\to\mathbb{R}$ is an infinitely differentiable function, and its derivatives of every order exist on $\mathbb{R}$, then the Taylor series of $F$ at $a$ is
\[F(x) = \sum_{n\in\mathbb{N}_0} \frac{F^{(n)}(a)}{n!}(x-a)^n,\]
that is,
\[F(x) = \sum^k_{n=0} \frac{F^{(n)}(a)}{n!}(x-a)^n+\int_0^1\frac{(1-t)^k}{k!}F^{(k+1)}(a+t(x-a))(x-a)^{k+1}\,\mathrm{d}t.\]
Also, the $k$th-order approximation of $f$ near $a$ is
\[F(x) \approx \sum^k_{n=0} \frac{F^{(n)}(a)}{n!}(x-a)^n,\]
and the first-order (aka linear or tangent line) approximation of $f$ near $a$ is
\[F(x) \approx F(a)+F'(a)(x-a).\]
THe linearization of $f$ near $a$ is
\[L(x)=F(a)+F'(a)(x-a).\]
The Taylor series of $F$ at $0$ is called Maclaurin series (馬克勞林級數) or Maclaurin expansion (馬克勞林展開).
\ssc{Differential equation (微分方程)}
\sssc{Differential Equation}
An equation containing the derivatives of one or more unknown functions or dependent variables, with respect to one or more independent variables, is said to be a differential equation (DE).
\sssc{Ordinary differential equation (ODE) (常微分方程)}
If a differential equation contains only ordinary derivatives of one or more unknown functions with respect to a single independent variable, it is said to be an ordinary differential equation (ODE).
\sssc{Partial differential equation (PDE) (偏微分方程)}
If a DE contains partial derivatives of one or more unknown functions of two or more independent variables is called a partial differential equation (PDE).
\sssc{Order of a DE}
The order of a differential equation is the order of the highest derivative in the equation.
\ssc{Real analyticity (實解析性) of real-codomain functions}
A real-codomain function $f$ is real analytic at a point $x_0$ in its domain, if it is infinitely differentiable at $x_0$ and that the Taylor expansion of $f$ at $x_0$ converges to $f(x)$ pointwise for any $x$ in a neighborhood of $x_0$.

A real-codomain function is called to be real analytic on an interval $I$ that is a subset of its domain if it is real analytic at any point in $I$.

A real-codomain function is called to be real analytic if it is real analytic at any point in its domain.



\section{Definte Integration (定積分)}
\ssc{Notation}
The integral of a function $f(x)$ with domain being a subset of $\bbR$, called integrand (被積函數), with respect to $x$, called integration variable (積分變數), from $a$ to $b$, which the open interval between $a$ and $b$ is called the domain of integration (積分域) or interval of integration (積分區間) and $a,b$ are called limits of integration (積分極限 or 積分上下限), is denoted as
\[\int_a^bf(x)\dd{x},\]
in which when $a>b$, the integral is defined as
\[\int_a^bf(x)\dd{x}\coloneq-\int_b^af(x)\dd{x}.\]

The integral of a function $f(\omega)$ with respect to $\omega$ over $\Omega$, called the domain of integration and which the limit points of $\Omega$ are called are called limits of integration (積分極限), is denoted as
\[\int_{\Omega}f(\omega)\dd{\omega}.\]
\subsection{(Proper) Riemann integral (黎曼積分) and Darboux integral (達布積分)}
\sssc{Premise}
(Proper) Riemann integral and Darboux integral are two equivalant definitions of definite integral of functions over compact intervals of $\mathbb{R}$ to $\mathbb{R}$.
\subsubsection{Partition of an interval}
A partition $P(x, n)$ of a compact interval $[a,b]$ is a finite sequence of numbers of the form
\[P(x, n):=\{x_i\colon x_0=a\land x_n=b\land\forall 1\leq i<j\leq n\colon x_i<x_j\}_{i=0}^n.\]

Each $[x_i, x_{i+1}]$ is called a subinterval of the partition. The length of a closed interval $[c,d]$ is defined as $d-c$. The mesh or norm of a partition is defined as
\[\max_i\left(x_{i+1}-x_{i}\right)\]
for every integer $i\in [0,n-1]$.

A tagged partition $P(x,n,\xi)$ of a interval $(a,b)$ is a partition together with a choice of a sample point or tag within each of all $n$ subintervals, that is, numbers $\{\xi_i\}_{i=0}^{n-1}$ with $\xi_i\in [x_i,x_{i+1}]$ for each integer $i\in [0,n-1]$. The mesh of a tagged partition is the same as that of an ordinary partition.

Suppose that two tagged partitions $P(x,n,\xi)$ and $Q(y,m,\zeta)$ are both partitions of the interval $[a,b]$. We say that $Q(y,m,\zeta)$ is a refinement of $P(x,n,\xi)$ if for each integer $i\in [0,n-1]$, there exists an integer $r(i)\in [0,m-1]$ such that $x_i = y_{r(i)}$ and that $\forall i\in [0,n-1]\colon\exists j\in [r(i),r(i + 1)] \text{\ s.t.\ }\xi_i = \zeta_j$. That is, a tagged partition breaks up some of the subintervals and adds sample points where necessary, "refining" the accuracy of the partition.

We can turn the set of all tagged partitions into a directed set by saying that one tagged partition is greater than or equal to another if the former is a refinement of the latter.
\subsubsection{Riemann sum}
Let $f$ be a real-valued function defined on a interval $[a,b]$. The Riemann sum of $f$ over a tagged partition $P(x,n,\xi)$ of $[a,b]$ is defined to be
\[R(f,P):=\sum_{i=0}^{n-1}f(\xi_i)\left(x_{i+1}-x_i\right).\]
Each term in the sum is the product of the value of the function at a given point and the length of an interval. Consequently, each term represents the signed area of a rectangle with height $f(\xi_i)$ and width $x_{i + 1} − x_i$. Thus the Riemann sum is the signed area of all the rectangles.
\subsubsection{Darboux sum}
Let $f$ be a real-valued function defined on a interval $[a,b]$. The lower and upper Darboux sums, $L(f,P)$ and $U(f,P)$, of $f$ over a partition $P(x,n)$ of $[a,b]$, are two specific Riemann sums of which the tags are chosen to be the infimum and supremum (respectively) of $f$ on each subinterval:
\[\begin{aligned}
L(f,P)&:=\sum_{i=0}^{n-1}\inf_{\xi\in [x_i,x_{i+1}]}f(\xi)(x_{i+1}-x_i),\\
U(f,P)&:=\sum_{i=0}^{n-1}\sup_{\xi\in [x_i,x_{i+1}]}f(\xi)(x_{i+1}-x_i).
\end{aligned}\]
\subsubsection{Riemann left, right, and midpoint sums}
Let $f$ be a real-valued function defined on a interval $[a,b]$. The Riemann left (aka left-sided), right (aka right-sided), and midpoint sums, $R_L(f,P)$, $R_R(f,P)$, and $R_M(f,P)$, of $f$ over a partition $P(x,n)$ of $[a,b]$, are three specific Riemann sums of which the tags are chosen to be the left endpoint, right endpoint, and midpoint (respectively) on each subinterval:
\[\begin{aligned}
R_L(f,P)&:=\sum_{i=0}^{n-1}f\qty(x_i)(x_{i+1}-x_i),\\
R_L(f,P)&:=\sum_{i=0}^{n-1}f\qty(x_{i+1})(x_{i+1}-x_i),\\
R_M(f,P)&:=\sum_{i=0}^{n-1}f\qty(\frac{x_i+x_{i+1}}{2})(x_{i+1}-x_i).
\end{aligned}\]
\subsubsection{Riemann sums over partition that divides interval equally}
A Riemann sum of $f$ over a tagged partition $P(x,n,\xi)$ that divides an interval into subintervals of equal length is denoted as $R_n(f)$.

A lower Darboux sum, an upper Darboux sum, a Riemann left sum, a Riemann right sum, and a Riemann midpoint sum of $f$ over a partition $P(x,n)$ that divides an interval into subintervals of equal length are sometimes denoted as $L_n(f),U_n(f),{R_L}_n(f),{R_R}_n(f)$, and ${R_M}_n(f)$ respectively.
\subsubsection{Riemann integral}
Let $f$ be a real-valued function defined on a interval $[a,b]$. The Riemann integral of $f$ on $[a,b]$ exists and equals $s$ if for all $\varepsilon > 0$, there exists $\delta > 0$ such that for any tagged partition $P(x,n,\xi)$ whose mesh is less than $\delta$,
\[\abs{R(f,P)-s}<\varepsilon .\]
\subsubsection{Darboux integral}
Let $f$ be a real-valued function defined on a interval $[a,b]$. The Darboux integral of $f$ on $[a,b]$ exists and equals $s$ if for all $\varepsilon > 0$, there exists $\delta > 0$ such that for any partition $P$ whose mesh is less than $\delta$,
\[\abs{U(f,P)-s}<\varepsilon \land \abs{L(f,P)-s}<\varepsilon.\]
\ssc{Extensions of Riemann integral}
\sssc{Improper (Riemann) integral (瑕（黎曼）積分)}
An integral $\int _{a}^{b}f(x)\dd{x}$ is an improper integral if it satisfies one or more of the below conditions:
\ben
\item $a=-\infty$,
\item $b=\infty$,
\item $f(x)$ is unbounded or undefined somewhere in $[a,b]$.
\een

The improper integrals are defined by limits recursively as:
\bit
\item For $a=-\infty$:
\[\int _{-\infty }^bf(x)\dd{x}=\lim _{a\to -\infty }\int _{a}^{b}f(x)\dd{x},\]
called improper integrals of type 1.
\item For $b=\infty$:
\[\int _{a}^{\infty }f(x)\dd{x}=\lim _{b\to \infty }\int _{a}^{b}f(x)\dd{x},\]
called improper integrals of type 1.
\item For $f(x)$ that is unbounded or undefined at $a$:
\[\int_a^bf(x)\dd{x}=\lim_{c\to a^+}\int_c^bf(x)\dd{x},\]
called improper integrals of type 2.
\item For $f(x)$ that is unbounded or undefined at $b$:
\[\int_a^bf(x)\dd{x}=\lim_{c\to b^-}\int_a^cf(x)\dd{x},\]
called improper integrals of type 2.
\item For $f(x)$ that is unbounded or undefined at $c\in(a,b)$:
\[\int _{a}^{b}f(x)\dd{x}=\lim_{t\to c^-}\int _{a}^{t}f(x)\dd{x}+\lim_{t\to c^+}\int _{t}^{b}f(x)\dd{x},\]
called improper integrals of type 2.
\eit
In which if any of the terms diverge or is undefined, the improper integral diverges and is undefined; otherwise, the improper integral exists finitely and converges to a finite value.

We say an improper integral of $f(x)$ over interval $I$ converges absolutely to $L$ iff the improper integral of $\abs{f(x)}$ over $I$ converges to $L$. If an improper integral is convergent but not convergent absolutely, we say it is convergent conditionally.
\sssc{Cauchy principal value (柯西主值) or PV integral}
The Cauchy principal value or PV integral, denoted as p.v., is a weaker notion of convergence, defined by taking symmetric limits. 

The p.v. of $\int _{-\infty}^{\infty}f(x)\dd{x}$, denoted as $\PV{\int_{-\infty}^{\infty} f(x)\dd{x}}$ or $\pv{\int_{-\infty}^{\infty} f(x)\dd{x}}$, is defined with:
\[\PV{\int_{-\infty}^{\infty} f(x)\dd{x}}\coloneq\lim_{R\to\infty} \int_{-R}^{R} f(x)\dd{x},\]
if the limit exists.

The p.v. of $\int _{a}^{b}f(x)\dd{x}$, in which $f(x)$ is unbounded or undefined at $c\in (a,b)$, denoted as $\PV{\int_{a}^{b} f(x)\dd{x}}$ or $\pv{\int_{a}^{b} f(x)\dd{x}}$, is defined with:
\[\PV{\int_{a}^{b} f(x)\dd{x}}\coloneq\lim_{\varepsilon\to 0}\qty(\int_a^{c-\varepsilon}f(x)\dd{x}+\int_{c+\varepsilon}^bf(x)\dd{x}),\]
if the limit exists.

If an improper integral converges, the p.v. of it converges.
\ssc{Riemann–Stieltjes integral}
\sssc{Definition}
Below, we will define the Riemann–Stieltjes integral of a function $f\colon X\subseteq\bbR\to\bbR$ over another function $g\colon Y\subseteq\bbR\to\bbR$ over an interval $[a,b]\subseteq (X\cap Y)$, denoted as
\[\int_{x=a}^bf(x)\dd{g(x)},\]
or
\[\int_a^bf(x)\dd{g(x)}.\]

The Riemann–Stieltjes sum of $f$ with respect to $g$ over a tagged partition $P(x,n,\xi)$ is defined as
\[S(f,g,P):=\sum_{i=0}^{n-1}f(\xi_i)\left(g\qty(x_{i+1})-g(x_i)\right).\]

The Riemann–Stieltjes integral
\[\int_{x=a}^bf(x)\dd{g(x)}\]
exists and equals $s$ if for all $\varepsilon > 0$, there exists $\delta > 0$ such that for any tagged partition $P(x,n,\xi)$ whose mesh is less than $\delta$,
\[\abs{S(f,g,P)-s}<\varepsilon.\]
\sssc{Extension}
An integral $\int_{x=a}^bf(x)\dd{g(x)}$ is an improper integral if it satisfies one or more of the below conditions:
\ben
\item $a=-\infty$,
\item $b=\infty$,
\item $f(x)$ is unbounded or undefined somewhere in $[a,b]$.
\een
The definition of improper integral and Cauchy principal value as extensions of the Riemann–Stieltjes integral are the same as those for the Riemann integral.
\subsection{Lebesgue integral (勒貝格積分)}
A definition of definite integral.
\sssc{Premise}
Let $(E,\Sigma,\mu)$ be a measure space. Below, we will define the Lebesgue integral of measurable functions on $E$ to $\mathbb{R}\cup\{-\infty,\infty\}$.
\subsubsection{Of an indicator functions}
The integral of an indicator function $1_S$ of a measurable subset $S$ of $E$ is defined to be
\[\int 1_{S}\,\mathrm{d}{\mu} =\mu (S).\]
\sssc{Of a nonnegative simple function}
A simple function $s$ is a finite real linear combinations of indicator functions of disjoint measurable subsets of $E$, that is,
\[s\colon\sum_ka_k1_{S_k},\]
where the coefficients $a_k$ are real numbers and $S_k$ are disjoint measurable sets. When the coefficients $a_k$ are positive real numbers, $s$ is called nonnegative.

The integral of a nonnegative simple function $s=\sum_ka_k1_{S_k}$ over $E$ is defined to be
\[\int_Es\,\mathrm{d}\mu=\sum_ka_k\int 1_{S_k}\,\mathrm{d}\mu=\sum_ka_k\mu(S_k),\]
where this sum can be finite or $\infty$.

The integral of a nonnegative simple function $s=\sum_ka_k1_{S_k}$ over a subset $B$ of $E$ is defined to be:
\[\int_Bs\,\mathrm{d}\mu=\sum_ka_k\mu \qty(S_k\cap B).\]
\subsubsection{Of a nonnegative measurable function}
Let $f$ be a nonnegative measurable function on some measurable subset $B$ of $E$ into $\mathbb{R}\cup\{-\infty,\infty\}$. We define
\[\int_Bf\,\mathrm{d}\mu=\sup\left\{\int_Bs\,\mathrm{d}\mu\mid\forall x\in B\colon 0\leq s(x)\leq f(x)\land s\text{\ is a nonnegative simple function}\right\}.\]
\subsubsection{Of a measurable function}
Let $f$ be a measurable function on some measurable subset $B$ of $E$ into $\mathbb{R}\cup\{-\infty,\infty\}$. We first define
\[\begin{aligned}
f^{+}(x)&=
\begin{cases}
f(x),\quad&\text{if\ }f(x)>0\\
0,\quad &\text{otherwise}
\end{cases},\quad\tx{and}\\
f^{-}(x)&=
\begin{cases}
-f(x),\quad&\text{if\ }f(x)<0\\
0,\quad&\text{otherwise}
\end{cases}.
\end{aligned}\]
Note that both $f^+$ and $f^-$ are nonnegative and that
\[f=f^+-f^-,\quad |f|=f^++f^-.\]
Then we define the Lebesgue integral of $f$ to exist if
\[ \min \left(\int f^{+}\,\mathrm{d}\mu ,\int f^{-}\,\mathrm{d}\mu \right)<\infty.\]
In this case we define
\[ \int f\,\mathrm{d}\mu =\int f^{+}\,\mathrm{d}\mu -\int f^{-}\,\mathrm{d}\mu.\]
\sssc{Integrability}
Let $f$ be a function on some measurable subset $B$ of $E$ into $\mathbb{R}\cup\{-\infty,\infty\}$.

If
\[\int |f|\,\mathrm {d} \mu <\infty ,\]
we say that $f$ is Lebesgue integrable.
\sssc{$L^p$ spaces ($L^p$ 空間)}
PLACEHOLDER
\ssc{Bochner integral (博赫納積分)}
\sssc{Premise}
Let $(E,\Sigma ,\mu )$ be a measure space and $X$ be a Banach space with norm $\|\cdot\|_X$. Below, we will define the Bochner integral of measurable functions on $E$ to $X$.
\subsubsection{Of an indicator functions}
The integral of an indicator function $1_S$ of a measurable subset $S$ of $E$ is defined to be
\[\int 1_{S}\,\mathrm{d}{\mu} =\mu (S).\]
\sssc{Of a simple function}
PLACEHOLDER
\sssc{Of a measurable function}
PLACEHOLDER
\sssc{Bochner spaces (博赫納空間)}
Let $(E,\Sigma,\mu)$ be a measure space and $X$ be a topological space. 

The Bochner space $L^p(E;X)$ with $p\in\mathbb{N}\cup\{\infty\}$ is defined to be the quotient space of the space of all Bochner measurable functions $f(t)\colon E\to X$ such that the norm $\|f(t)\|_{L^p(E;X)}$ of it, defined with
\[\|f(t)\|_{L^p(E;X)}\coloneq\left(\int_E\|f(t)\|_X^{\phantom{X}p}\,\mathrm{d}\mu\right)^{1/p},\quad p\in\mathbb{N},\]
and
\[\|f(t)\|_{L^{\infty }(E;X)}\coloneq\operatorname{ess\,sup}_{t\in E}\|f(t)\|_{X},\]
is finite by the equivalence relation of equality almost everywhere.
\ssc{Total variation, functions of bounded variation (BV functions), and functions of locally bounded variation (locally BV functions)}
\sssc{Of real functions}
Let $f\colon X\subseteq\bbR\to\bbR$ be a function. The total variation of $f$ over interval $[a,b]\subseteq X$ is
\[V_a^b(f)=\sup_{P(x,n_p)\in\mathcal{P}}\sum_{i=0}^{n_p-1}\abs{f\qty(x_{i+1})-f\qty(x)},\]
where $\mathcal{P}$ is the set of all partitions of $f$ over $[a,b]$.

$f$ is called of bounded variation or called a (globally) BV function over $[a,b]$ iff $V_a^b(f)$ is finite.

$f$ is called of locally bounded variation or called a locally BV function over an open interval $(a,b)$ iff $V_c^d(f)$ is finite for all $[c,d]\in (a,b)$.

The space of all (globally) BV functions over $[a,b]$ is denoted as $\operatorname{BV}([a,b])$. The space of all locally BV functions over $(a,b)$ is denoted as
\[\operatorname{BV}_{\tx{loc}}((a,b)).\]

If $f$ is monotone on $[a,b]$, it is BV over $[a,b]$.
\sssc{Of real fields}
PLACEHOLDER
\sssc{In measure theory}
PLACEHOLDER
\sssc{Space of BV functions}
PLACEHOLDER (is a Banach space)
\ssc{Dirac delta function or unit impulse}
\sssc{As an extended real function with informally assigned integral properties}
The Dirac delta function $\delta(x)\colon\bbR^n\to\bar{\bbR}$ with $n\in\bbN$ is a function defined as
\[\delta(x) =
\begin{cases}
\infty, & x = 0, \\
0, & x \neq 0
\end{cases}\]
and for all $0\in\Omega\subseteq D_f\subseteq\bbR^n$ with $n\in\bbN$, for all indexed family $A\colon I\to\mathcal{A}\subseteq D_f;\;i\mapsto A_i$ with $I=J\cap\bbN$ for some interval $J$,
\[\int f(x)\prod_{i\in I}\delta(A_i)\dd{x}\coloneq\sum_{i\in I}u(f(A_i)),\]
\[\int_{\Omega}f(x)\prod_{i\in I}\delta(A_i)\dd{x}\coloneq\sum_{i\in I}f(A_i).\]
Let
\[u_U(x)\coloneq\sum_{i\in I}u(A_i),\]
\[u_U'(x)\coloneq\prod_{i\in I}\delta(A_i).\]
\sssc{As a measure}
For all indexed family $A\colon I\to\mathcal{A}\subseteq\bbR^n;\;i\mapsto A_i$ with $n\in\bbN$ and $I=J\cap\bbN$ for some interval $J$, the definite integrals involving the product of Dirac delta functions $\prod_{i\in I}\delta(A_i)$ can be rigorously defined via a Radon measure called Dirac measure $\delta_A$ that for any $\Omega\in\bbR^n$,
\[\delta_A(\Omega)\coloneq\abs{\Omega\cap A(I)}.\]
Thus for any function $f$ such that $0\in\Omega\subseteq D_f\subseteq\bbR^n$ with $n\in\bbN$, for all such indexed family with $A(I)\subseteq D_f$,
\[\int_{\Omega}f(x)\prod_{i\in I}\delta(A_i)\dd{x}\coloneq\int_{\Omega}f(x)\dd{\delta_A(x)}=\sum_{i\in I}f(A_i).\]
\sssc{As proper or improper Riemann–Stieltjes integral}
For any function $f$ such that $0\in\Omega\subseteq D_f\subseteq\bbR^n$ with $n\in\bbN$, for all indexed family $A\colon I\to\mathcal{A}\subseteq D_f;\;i\mapsto A_i$ with $n\in\bbN$ and $I=J\cap\bbN$ for some interval $J$, with
\[u_A(x)\coloneq\sum_{i\in I}u(A_i),\]
where $u$ is the unit step function, we define
\[\int_{\Omega}f(x)\prod_{i\in I}\delta(A_i)\dd{x}\coloneq\int_{\Omega}f(x)\dd{u_A(x)}=\sum_{i\in I}f(A_i),\]
where $\int_{\Omega}f(x)\dd{u_A(x)}$ is a proper or improper Riemann–Stieltjes integral.



\section{Multivariable (多變數 or 多變量 or 多元) Calculus}
\subsection{Operators}
\begin{itemize}
\item Dot product (點積) operator: $\cdot$
\item Cross product (叉積) operator: $\times$
\item Gradient (梯度) operator: $\nabla$ or $\operatorname{grad}$
\item Jacobian matrix (雅可比矩陣): $\nabla$, or $\mathbf{J}(\mathbf{F})$, $J(\mathbf{F})$, $\mb{J}_{\mb{F}}$, or $J_{\mathbf{F}}$ for operand $\mb{F}$.
\item Divergence (散度) operator: $\nabla \cdot$ or $\operatorname{div}$
\item Curl (旋度) operator: $\nabla \times$ or $\operatorname{curl}$
\item Directional derivative (方向導數) operator: $\cdot\nabla$
\item Hessian (黑塞) (matrix): $\nabla\nabla$, $\nabla^2$, $\nabla\otimes\nabla$, $D^2$, or $\mb{H}(f)$, $H(f)$, $\mb{H}_f$ or $H_f$ for operand $f$, or simply as second derivative.
\item Laplace operator (拉普拉斯算子): $\nabla\cdot\nabla$, $\nabla^2$, or $\Delta$. For clarity, we use $\nabla\cdot\nabla$ here.
\item Line or Path integral operator: $\int$
\item Surface integral operator: $\iint$
\item Volume integration operator: $\iiint$
\item Closed line integral operator: $\oint$
\item Closed surface Integral Operator: $\oiint$
\item $\int\mathbf{F}\cdot\mathrm{d}\mathbf{S}$ is used as a shorthand for $\int(\mathbf{F}\cdot\mathbf{\hat{n}})\,\mathrm{d}S$, where $\hat{n}$ is the outward pointing unit normal at almost each point on $S$.
\end{itemize}
\subsection{Convention}
If not otherwise specified:
\begin{itemize}
\item The domain of the funcitons or maps below are subsets of a Euclidean vector space. If not otherwise specified, the coordinates are the Cartesian coordinates, the norms are the Euclidean norms, and the measures are the Lebesgue measures.
\item $\mathbf{0}$ or $0$ refers to the zero tensor (零張量) in the interested Euclidean tensor space $V$, that is, it satisfies 
\[\forall\mathbf{v}\in V:\,\mathbf{v}+\mathbf{0}=\mathbf{v}.\]
\item Unit vector (單位向量): $\mathbf{e}_i$ is the unit vector in the $i$th direction, i.e., a vector with zero norm.
\item Independent variable vector: $\mathbf{x}=(x_1,x_2,\dots,x_n)$
\item Vector fields: $\mathbf{F}(\mathbf{x}) = \sum_{i=1}^n F_i(\mathbf{x}) \mathbf{e}_i$、$\mathbf{G}$
\item Scalar fields: $A(\mathbf{x})$、$B(\mathbf{x})$
\item Tensor fields: $f(\mathbf{x})$、$g(\mathbf{x})$
\item Three-dimensional tensor space field: $\mathbf{T}(\mathbf{x})$
\item The $i$th component of the map $f$: $f_i$
\end{itemize}
\ssc{First order}
\sssc{Gradient (梯度) or first derivative, and Jacobian matrix}
\[
\nabla f = \begin{pmatrix}\qty(\pdv{f}{x_1})^T & \qty(\pdv{f}{x_2})^T & \dots  & \qty(\pdv{f}{x_n})^T\end{pmatrix}
\]
The gradient of a scalar field is a vector field, the gradient of a vector field is a second-order tensor (matrix) field, and the gradient of a $k$-order tensor field is a $k+1$-order tensor field. 

In particular, the gradient of a scalar field $A$ is
\[
\nabla A = \sum_{i=1}^n \pdv{A}{x_i}e_i.
\]
And the gradient of a vector field $\mathbf{F}$, also called the Jacobian matrix (雅可比矩陣) of $\mb{F}$, is a matrix such that the $( i,j )$th entry is
\[(J(\mb{F}))_{ij}=\frac{\partial F_i}{\partial x_j}.\]
The determinant of Jacobian matrix is called Jacobian determinant, or Jacobian for short.\sssc{Divergence (散度)}
\[
\nabla \cdot f = \sum_{i=1}^n\frac{\partial f_i}{\partial x_i}
\]
The divergence of a vector field is a scalar field, the gradient of a second-order tensor (i.e. matrix) field is a vector field, and the divergence of a $k+1$-order tensor field is a $k$-order tensor field.
\sssc{Curl (旋度)}
The curl is only defined on three-dimensional vector field.
\[
\nabla \times \mathbf{T} = 
\begin{pmatrix}
\mathbf{e}_1 & \mathbf{e}_2 & \mathbf{e}_3 \\
\frac{\partial}{\partial x_1} & \frac{\partial}{\partial x_2} & \frac{\partial}{\partial x_3} \\
T_1 & T_2 & T_3 \\
\end{pmatrix}
\]
The curl of a three-dimensional vector field is a three-dimensional vector field.
\sssc{Directional derivative (方向導數)}
\[(\mathbf{f}\cdot\nabla)\mathbf{g}=\sum_{i=1}^n f_i\pdv{g}{x_i}\]
\ssc{Higher order}
\sssc{Hessian (黑塞) (matrix) or second derivative}
The Hessian or second derivative $H_f$ of field $f$ is defined as a matrix such that
\[(H(f))_{ij}=\frac{\partial f}{\partial x_i\partial x_j},\]
that is,
\[H(f)=\nabla\qty((\nabla f)^\top).\]
\sssc{Laplace operator (拉普拉斯算子)}
\[\nabla\cdot\nabla f = \nabla \cdot (\nabla f) = \tr(H(f))=\sum_{i=1}^n\frac{\partial^2 f}{\partial x_i^{\phantom{i}2}}\]
The Laplace operator applied to a tensor field is a tensor field of the same order and same dimension.
\sssc{Poisson's equation (卜瓦松 or 帕松 or 泊松方程)}
\[
\nabla\cdot\nabla A = B(\mathbf{x})
\]
\sssc{Laplace's equation (拉普拉斯方程)}
\[
\nabla\cdot\nabla A = 0
\]
A real function $A$ with real independent variables that is second-order differentiable for all independent variables is called a harmonic function if $A$ satisfies Laplace's equation.
\sssc{Multi-index notation (多重指標記號)}
Suppose there are \( n \) variables \( x_1, x_2, \dots, x_n \), then a multi-index $\alpha$ is a vector of \( n \) nonnegative integers: 
\[
\alpha = (\alpha_1, \alpha_2,\ldots,, \alpha_n), \quad \text{where\ } \alpha_i \in \mathbb{N}_0.
\]
Define: 
\begin{itemize}
\item Norm \( \|\alpha\| \): 
\[
\|\alpha\| = \alpha_1 + \alpha_2 + \ldots\alpha_n.
\]
\item Factorial \( \alpha! \): 
\[
\alpha! = \alpha_1! \cdot \alpha_2! \cdot \ldots \alpha_n!.
\]
\item Power \( \mathbf{x}^\alpha \): 
If \( \mathbf{x} = (x_1, x_2,\ldots, x_n) \), then
\[
\mathbf{x}^\alpha = x_1^{\alpha_1} \cdot x_2^{\alpha_2} \ldots  x_n^{\alpha_n}.
\]
\item Higher-order mixed partial derivatives $D^\alpha f$: 
\[
D^\alpha f = \frac{\partial^{\|\alpha\|} f}{\partial x_1^{\alpha_1} \partial x_2^{\alpha_2} \ldots  \partial x_n^{\alpha_n}}.
\]
\end{itemize}
\sssc{Higher-order derivative}
The $k$th order derivative of $\mathbf{F}:\,\mathbb{R}^n\to\mathbb{R}^m$, denoted as $\mathbf{F}^{(k)}(\mathbf{x})$ or $D^{k}\mathbf{F}(\mathbf{x})$, is a $(\mathbb{R}^n)^k\to\mathbb{R}$ function, where $(\mathbb{R}^n)^k$ is a Cartesian product of $k$ copies of $\mathbb{R}^n$ vector, that is,
\[D^{k}\mathbf{F}(\mathbf{x})=\sum_{\|\alpha\|=k} \left(D^\alpha \mathbf{F}(\mathbf{a})\right).\]
In particular, the first-order derivative of $\mathbf{F}$ is the gradient of it.
\sssc{Taylor expansion}
Assume that $\mathbf{F}:\,\mathbb{R}^n\to\mathbb{R}^m$ is an infinitely differentiable function, and its partial derivatives of every order exist on $\mathbb{R}^n$, then the Taylor expansion of $\mathbf{F}$ at $\mathbf{a}$ is
\[\mathbf{F}(\mathbf{x}) = \sum_{\|\alpha\|\in\mathbb{N}_0} \frac{D^\alpha \mathbf{F}(\mathbf{a})}{\alpha!} (\mathbf{x} - \mathbf{a})^\alpha,\]
that is,
\[\mathbf{F}(\mathbf{x}) = \sum_{\|\alpha\|\leq k} \frac{D^\alpha \mathbf{F}(\mathbf{a})}{\alpha!} (\mathbf{x} - \mathbf{a})^\alpha+\int_0^1\frac{(1-t)^k}{k!} D^{k+1}\mathbf{F}(\mathbf{a} + t(\mathbf{x} - \mathbf{a})) (\mathbf{x} - \mathbf{a})^{k+1} \, \mathrm{d}t.\]
Also, the $k$th-order approximation of $\mathbf{F}$ near $\mathbf{a}$ is
\[\mathbf{F}(\mathbf{x}) \approx \sum_{\|\alpha\|\leq k} \frac{D^\alpha \mathbf{F}(\mathbf{a})}{\alpha!} (\mathbf{x} - \mathbf{a})^\alpha,\]
the first-order (aka linear or tangent line) approximation of $f$ near $\mathbf{a}$ is
\[\mathbf{F}(\mathbf{x}) \approx \mathbf{F}(\mathbf{a}) + \nabla \mathbf{F}(\mathbf{a}) \cdot (\mathbf{x} - \mathbf{a}),\]
and the second-order approximation of $f$ near $\mathbf{a}$ is
\[\mathbf{F}(\mathbf{x}) \approx \mathbf{F}(\mathbf{a}) + \nabla \mathbf{F}(\mathbf{a}) \cdot (\mathbf{x} - \mathbf{a}) + \frac{1}{2}(\mathbf{x} - \mathbf{a})^\top H(\mb{F})(\mb{a})(\mathbf{x} - \mathbf{a}).\]
The linearization of $f$ near $\mathbf{a}$ is
\[\mathbf{L}(\mathbf{x})= \mathbf{F}(\mathbf{a}) + \nabla \mathbf{F}(\mathbf{a}) \cdot (\mathbf{x} - \mathbf{a}).\]
\sssc{Definiteness (正定性)}
\bit
\item Positive definite: We say the Hessian $H(\mb{F})$ of $\mb{F}$ at $\mb{a}$ is positive definite if the second derivative term in Taylor series is positive for all inifinisimal changes $\delta\mb{x}$ near $\mb{a}$, that is,
\[(\delta\mb{x})^\top H(\mb{F})(\mb{a})\delta\mb{x}>0,\quad\forall \delta\mb{x}.\]
\item Negative definite: We say the Hessian $H(\mb{F})$ of $\mb{F}$ at $\mb{a}$ is positive definite if the second derivative term in Taylor series is negative for all inifinisimal changes $\delta\mb{x}$ near $\mb{a}$, that is,
\[(\delta\mb{x})^\top H(\mb{F})(\mb{a})\delta\mb{x}<0,\quad\forall \delta\mb{x}.\]
\item Neutral semidefinite: We say the Hessian $H(\mb{F})$ of $\mb{F}$ at $\mb{a}$ is zero semidefinite if the second derivative term in Taylor series is zero for all inifinisimal changes $\delta\mb{x}$ near $\mb{a}$, that is,
\[(\delta\mb{x})^\top H(\mb{F})(\mb{a})\delta\mb{x}=0,\quad\forall \delta\mb{x}.\]
\item Nonnegative semidefinite: We say the Hessian $H(\mb{F})$ of $\mb{F}$ at $\mb{a}$ is nonnegative semidefinite if the second derivative term in Taylor series is nonnegative for all inifinisimal changes $\delta\mb{x}$ near $\mb{a}$ but not all positive, that is,
\[(\delta\mb{x})^\top H(\mb{F})(\mb{a})\delta\mb{x}\geq 0,\quad\forall \delta\mb{x},\quad\land\]
\[(\delta\mb{x})^\top H(\mb{F})(\mb{a})\delta\mb{x}=0,\quad\exists \delta\mb{x}.\]
\item Nonpositive semidefinite: We say the Hessian $H(\mb{F})$ of $\mb{F}$ at $\mb{a}$ is nonpositive semidefinite if the second derivative term in Taylor series is nonpositive for all inifinisimal changes $\delta\mb{x}$ near $\mb{a}$ but not all negative, that is,
\[(\delta\mb{x})^\top H(\mb{F})(\mb{a})\delta\mb{x}\leq 0,\quad\forall \delta\mb{x},\quad\land\]
\[(\delta\mb{x})^\top H(\mb{F})(\mb{a})\delta\mb{x}=0,\quad\exists \delta\mb{x}.\]
\item Indefinite: We say the Hessian $H(\mb{F})$ of $\mb{F}$ at $\mb{a}$ is indefinite if it is neither definite nor semidefinite.
\eit
\ssc{Line integral (線積分) or Path integral (路徑積分)}
\sssc{Scalar field line or path integral}
For a scalar field $A : \,U\subseteq \mathbb {R} ^{n}\to \mathbb {R}$ and the path $C \in U$, the line integral of $A$ is: 
\[\int _{C}A\,\mathrm {d} s=\int _{a}^{b}A(\mathbf{r}(t))\|\dv{t}\mathbf {r} (t)\|\,\mathrm {d} t,\]
where $\mathbf{r}:\, [a, b] \to C$ is a one-to-one parametric function with $\mathbf{r}(a)$ and $\mathbf{r}(b)$ being the two endpoints of the path $C$. 

$A$ is called the integral function, $C$ is called the integral path, and the result of the line integration does not depend on the parametric function $r$.
\sssc{Vector field line or path integral}
willie169-ckhs-ntuee-notesFor a scalar field $\mathbf{F}: \,U\subseteq \mathbb {R} ^{n}\to \mathbb {R}^n$ and the path $C \in U$, the line integral of $\mathbf{F}$ is: 
\[\int _{C}\mathbf {F} (\mathbf {r} )\cdot \,\mathrm {d} \mathbf{r}=\int _{a}^{b}\mathbf {F} (\mathbf {r} (t))\cdot \dv{t}\mathbf {r} (t)\,\mathrm {d} t\]
where $\mathbf{r}:\, [a, b] \to C$ is a one-to-one parametric function with $\mathbf{r}(a)$ and $\mathbf{r}(b)$ being the two endpoints of the path $C$. 

$\mathbf{F}$ is called the integral function, $C$ is called the integral path, and the result of the line integration does not depend on the parametric function $\mathbf{r}$.
\sssc{Conservative field (保守場)}
A field $f$ whose domain is a subset $U$ of a Euclidean tensor space is called a conservative field iff for all paths $C$ between point $a$ and $b$, the integral 
\[\int_Cf(\mathbf{x})\cdot\mathrm{d}\mathbf{x}\]
are the same, iff for any closed path $C$, 
\[\oint_Cf(\mathbf{x})\cdot\mathrm{d}\mathbf{x}=0.\]

\bit
\item Field $f$ whose domain is $U\subseteq\bbR$ is conservative iff it is continuous.
\item If field $f=(f_x,f_y)$ whose domain is $U\subseteq\bbR^2$ is conservative, then
\[\pdv{f_y}{x}-\pdv{f_x}{y}=0\]
wherever it is defined.
\item Field $f=(f_x,f_y)$ whose domain is a simply connected set $U\subseteq\bbR^2$ is conservative iff
\[\pdv{f_y}{x}-\pdv{f_x}{y}=0\]
for all $(x,y)\in U$.
\item If field $f$ whose domain is $U\subseteq\bbR^3$ is conservative, then
\[\nabla\times f=0\]
wherever it is defined.
\item Field $f$ whose domain is a simply connected set $U\subseteq\bbR^3$ is conservative iff
\[\nabla\times f(\mb{x})=0\]
for all $\mb{x}\in U$.
\eit



\sct{Limit Theorems and Methods}
\ssc{Uniqueness and Existence}
\sssc{For real sequence}
\bit
\item A limit inferior must exist uniquely in $[-\infty,\infty)$.
\item A limit superior must exist uniquely in $(-\infty,\infty]$.
\item If a limit exists, it is unique, and the limit inferior and limit superior are it.
\eit
\sssc{For real series}
If a limit exists, it is unique.
\sssc{For real net}
\bit
\item A limit inferior must exist uniquely in $[-\infty,\infty)$, and all cluster points are greater than or equal to it.
\item A limit superior must exist uniquely in $(-\infty,\infty]$, and all cluster points are less than or equal to it.
\item If a limit exists, it is unique, and the limit inferior, limit superior, and only cluster point are it.
\eit
\sssc{For real-domain function at finity}
\bit
\item If an one-sided limit exists, it is unique.
\item If a limit exists, it is unique, and the left-hand limit and right-hand limit are it.
\eit
\sssc{For real-valued function from topological space}
\bit
\item A limit inferior must exist uniquely in $[-\infty,\infty)$.
\item A limit superior must exist uniquely in $(-\infty,\infty]$.
\item If a limit exists, it is unique, and the limit inferior and limit superior are it.
\eit
\sssc{For net of functions}
\bit
\item If a pointwise limit function exists, it is unique.
\item If a uniform limit function exists, it is unique, and the pointwise limit function is it.
\eit
\ssc{Limit Laws}
If the limit (including one-sided ones for functions with real domains) of sequences, series, nets, or functions with real domains, hereinafter referred to as a function, in one side exists in $\mathbb{R}\cup\{-\infty,\infty\}$, then the limit in the other side exists in $\mathbb{R}\cup\{-\infty,\infty\}$ and follows the following law.
\sssc{Linearity, or sum law, difference law, and constant multiple law}
The limit of a sum of constant multiples of functions is the sum of the constant multiples of the limits of the functions.
\sssc{Product law}
The limit of a product of functions is the product of the limits of the functions.
\sssc{Quotient law}
The limit of a quotient of functions is the quotient of the limits of the functions, provided that the limit of the denominator is not 0, in which the reciprocals of $\infty$ and $-\infty$ are $0$.

Thus, if $\lim f=\pm\infty$ and $\lim(fg)\in\bbR$, then $\lim g=0$.
\sssc{Power law}
The limit of the $n$th power of a function, in which $n$ is a positive integer, is the $n$th power of the limit of the function.
\sssc{Root law}
The limit of the $n$th root of a function, in which $n$ is a positive integer, is the $n$th root of the limit of the function.
\sssc{Continuity principle}
For any function $f\colon D\subseteq\bbR\to\bbR$ that is continuous at a limit of a function $g$, $f$ of the limit of $g$ is the limit of $f$ of $g$, where $f$ is called continuous at $\infty$ if $\lim_{x\to\infty}f(x)\in\bbR\cup\{-\infty,\infty\}$ and called continuous at $-\infty$ if $\lim_{x\to-\infty}f(x)\in\bbR\cup\{-\infty,\infty\}$.
\ssc{Limit inferior and limit superior laws}
\sssc{Addition law}
The limit inferior of a sum of functions is greater than or equal to the sum of the limit inferiors of the functions.

The limit superior of a sum of functions is less than or equal to the sum of the limit superiors of the functions.
\sssc{Constant multiple law}
The limit inferior of a constant multiple of a function is the constant multiple of the limit inferior of the function.

The limit superior of a constant multiple of a function is the constant multiple of the limit superior of the function.
\sssc{Multiplication law}
The limit inferior of a product of nonnegative real-valued functions is the product of the limit inferiors of the functions.

The limit superior of a product of nonnegative real-valued functions is the product of the limit superiors of the functions.
\ssc{Preservation of equal to}
\sssc{For real sequence}
Given real sequences $\langle a_n\rangle$ and $\langle b_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$, $a_k=b_k$. If $\lim_{n\to\infty}a_n=L\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{n\to\infty}b_n=L.\]
\sssc{For real series}
Given real sequences $\langle a_n\rangle$ and $\langle b_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$:
\[\sum_{i=1}^ka_i=\sum_{i=1}^kb_i.\]
If $\sum_{i=1}^{\infty}a_i=L\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\sum_{i=1}^{\infty}b_i=L.\]
\sssc{For real net}
Let $A$ be a directed set. Given real nets $\langle x_a\rangle_{a\in A}$ and $\langle y_a\rangle_{a\in A}$ which for all $k\in A$ such that there exists $j\in A$ with $j\leq k$, $x_k=y_k$. If $\lim_{a}x_a$ exists, then:
\[\lim_{a}x_a=\lim_{a}y_a.\]
\sssc{For real function}
Let $I$ be an open interval and $a\in I$, and $f(x)$ and $g(x)$ be functions defined on $I\setminus\{a\}$ which for all $x\in I\land x\neq a$, $f(x)=g(x)$. If $\lim_{x\to a}f(x)=L\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to a}g(x)=L.\]

Let $f(x)$ and $g(x)$ be functions defined on $(a,b)$ with $a<b$ which for all $x\in I$, $f(x)=g(x)$. If $\lim_{x\to a^+}f(x)=L\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to a^+}g(x)=L.\]

Let $f(x)$ and $g(x)$ be functions defined on $(b,a)$ with $a>b$ which for all $x\in I$, $f(x)=g(x)$. If $\lim_{x\to a^-}f(x)=L\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to a^-}g(x)=L.\]

Let $f(x)$ and $g(x)$ be functions defined on $(a,\infty)$ which for all $x\in I$, $f(x)=g(x)$. If $\lim_{x\to\infty}f(x)=L\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to\infty}g(x)=L.\]

Let $f(x)$ and $g(x)$ be functions defined on $(-\infty,a)$ which for all $x\in I$, $f(x)=g(x)$. If $\lim_{x\to-\infty}f(x)=L\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to-\infty}g(x)=L.\]
\ssc{Preservation of less than or equal to}
\sssc{For real sequence}
Given real sequences $\langle a_n\rangle$ and $\langle b_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$, $a_k\leq b_k$. If both $\lim_{n\to\infty}a_n$ and $\lim_{n\to\infty}b_n$ are in $\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{n\to\infty}a_n\leq\lim_{n\to\infty}b_n.\]
If $\lim_{n\to\infty}a_n=\infty$, then $\lim_{n\to\infty}b_n=\infty$; if $\lim_{n\to\infty}b_n=-\infty$, then $\lim_{n\to\infty}a_n=-\infty$.
\sssc{For real series}
Given real sequences $\langle a_n\rangle$ and $\langle b_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$:
\[\sum_{i=1}^ka_i\leq\sum_{i=1}^kb_i.\]
If both $\sum_{i=1}^{\infty}a_i$ and $\sum_{i=1}^{\infty}b_i$ are in $\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\sum_{i=1}^{\infty}a_i\leq\sum_{i=1}^{\infty}b_i.\]
If $\sum_{i=1}^{\infty}a_i=\infty$, then $\sum_{i=1}^{\infty}b_i=\infty$; if $\sum_{i=1}^{\infty}b_i=-\infty$, then $\sum_{i=1}^{\infty}a_i=-\infty$.
\sssc{For real net}
Let $A$ be a directed set. Given real nets $\langle x_a\rangle_{a\in A}$ and $\langle y_a\rangle_{a\in A}$ which for all $k\in A$ such that there exists $j\in A$ with $j\leq k$, $x_k\leq y_k$. If both $\lim_{a}x_a$ and $\lim_{a}y_a$ exist, then:
\[\lim_{a}x_a\leq\lim_{a}y_a.\]
\sssc{For real function}
Let $I$ be an open interval and $a\in I$, and $f(x)$ and $g(x)$ be functions defined on $I\setminus\{a\}$ which for all $x\in I\land x\neq a$, $f(x)\leq g(x)$. If both $\lim_{x\to a}f(x)$ and $\lim_{x\to a}g(x)$ are in $\mathbb{R}\setminus\{-\infty,\infty\}$, then
\[\lim_{x\to a}f(x)\leq\lim_{x\to a}g(x).\]
If $\lim_{x\to a}f(x)=\infty$, then $\lim_{x\to a}g(x)=\infty$; if $\lim_{x\to a}g(x)=-\infty$, then $\lim_{x\to a}f(x)=-\infty$.

Let $f(x)$ and $g(x)$ be functions defined on $(a,b)$ with $a<b$ which for all $x\in I$, $f(x)\leq g(x)$. If both $\lim_{x\to a^+}f(x)$ and $\lim_{x\to a^+}g(x)$ are in $\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to a^+}f(x)\leq\lim_{x\to a^+}g(x).\]
If $\lim_{x\to a^+}f(x)=\infty$, then $\lim_{x\to a^+}g(x)=\infty$; if $\lim_{x\to a^+}g(x)=-\infty$, then $\lim_{x\to a^+}f(x)=-\infty$.

Let $f(x)$ and $g(x)$ be functions defined on $(b,a)$ with $a>b$ which for all $x\in I$, $f(x)\leq g(x)$. If both $\lim_{x\to a^-}f(x)$ and $\lim_{x\to a^-}g(x)$ are in $\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to a^-}f(x)\leq\lim_{x\to a^-}g(x).\]
If $\lim_{x\to a^-}f(x)=\infty$, then $\lim_{x\to a^-}g(x)=\infty$; if $\lim_{x\to a^-}g(x)=-\infty$, then $\lim_{x\to a^-}f(x)=-\infty$.

Let $f(x)$ and $g(x)$ be functions defined on $(a,\infty)$ which for all $x\in I$, $f(x)\leq g(x)$. If both $\lim_{x\to\infty}f(x)$ and $\lim_{x\to\infty}g(x)$ are in $\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to\infty}f(x)\leq\lim_{x\to\infty}g(x).\]
If $\lim_{x\to\infty}f(x)=\infty$, then $\lim_{x\to\infty}g(x)=\infty$; if $\lim_{x\to\infty}g(x)=-\infty$, then $\lim_{x\to\infty}f(x)=-\infty$.

Let $f(x)$ and $g(x)$ be functions defined on $(-\infty,a)$ which for all $x\in I$, $f(x)\leq g(x)$. If both $\lim_{x\to-\infty}f(x)$ and $\lim_{x\to-\infty}g(x)$ are in $\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to-\infty}f(x)\leq\lim_{x\to-\infty}g(x).\]
If $\lim_{x\to-\infty}f(x)=\infty$, then $\lim_{x\to-\infty}g(x)=\infty$; if $\lim_{x\to-\infty}g(x)=-\infty$, then $\lim_{x\to-\infty}f(x)=-\infty$.
\ssc{Squeeze (夾擠) theorem or Sandwich (三明治) theorem}
\sssc{For real sequence}
Given real sequences $\langle a_n\rangle$, $\langle b_n\rangle$, and $\langle c_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$:
\[a_k\leq c_k\leq b_k.\]
If
\[\lim_{n\to\infty}a_n=\lim_{n\to\infty}b_n=L\in\mathbb{R}\cup\{-\infty,\infty\},\]
then
\[\lim_{n\to\infty}c_n=L.\]
\sssc{For real series}
Given real sequences $\langle a_n\rangle$, $\langle b_n\rangle$, and $\langle c_n\rangle$ which for all $k$ that is greater than or equal to a specific $j\in \mathbb{N}$:
\[\sum_{i=1}^ka_i\leq\sum_{i=1}^kc_i\leq\sum_{i=1}^kb_i.\]
If
\[\sum_{i=1}^{\infty}a_i=\sum_{i=1}^{\infty}b_i=L\in\mathbb{R}\cup\{-\infty,\infty\},\]
then: 
\[\sum_{i=1}^{\infty}c_i=L.\]
\sssc{For real net}
Let $A$ be a directed set. Given real nets $\langle x_a\rangle_{a\in A}$, $\langle y_a\rangle_{a\in A}$, and $\langle z_a\rangle_{a\in A}$ which for all $k\in A$ such that there exists $j\in A$ with $j\leq k$:
\[x_k\leq z_k\leq y_k.\]
If
\[\lim_{a}x_a=\lim_{a}y_a=L,\]
then: 
\[\lim_{a}z_a=L.\]
\begin{proof}
Start from the limits of $x_a$ and $y_a$, by definition of limit:

For every $\varepsilon\in\mathbb{R}_{>0}$, there exists some $a_1\in A$ such that for every $b\in A$ with $b\geq a_1$, the point $L-\varepsilon\leq x_b\leq L+\varepsilon$.

For every $\varepsilon\in\mathbb{R}_{>0}$, there exists some $a_2\in A$ such that for every $b\in A$ with $b\geq a_2$, the point $L-\varepsilon\leq y_b\leq L+\varepsilon$.

Choose $a\in A$ such that $a_1\leq a$ and $a_2\leq a$.

so,
\[L-\varepsilon\leq x_{a}\leq z_{a}\leq y_{a}\leq L+\varepsilon.\]

Since $\varepsilon > 0$ was arbitrary, by definition of limit:
\[\lim_{a}z_a=L.\]
\end{proof}
\sssc{For real function}
Let $I$ be an open interval and $a\in I$, and $f(x)$, $g(x)$, and $h(x)$ be functions defined on $I\setminus\{a\}$ which for all $x\in I\land x\neq a$, $f(x)\leq h(x)\leq g(x)$. If
\[\lim_{x\to a}f(x)=\lim_{x\to a}g(x)=L\in\mathbb{R}\setminus\{-\infty,\infty\},\]
then
\[\lim_{x\to a}h(x)=L.\]

Let $f(x)$, $g(x)$, and $h(x)$ be functions defined on $(a,b)$ with $a<b$ which for all $x\in I$, $f(x)\leq h(x)\leq g(x)$. If
\[\lim_{x\to a^+}f(x)=\lim_{x\to a^+}g(x)=L\in\mathbb{R}\setminus\{-\infty,\infty\},\]
then
\[\lim_{x\to a^+}h(x)=L.\]

Let $f(x)$, $g(x)$, and $h(x)$ be functions defined on $(b,a)$ with $a>b$ which for all $x\in I$, $f(x)\leq h(x)\leq g(x)$. If
\[\lim_{x\to a^-}f(x)=\lim_{x\to a^-}g(x)=L\in\mathbb{R}\setminus\{-\infty,\infty\},\]
then
\[\lim_{x\to a^-}h(x)=L.\]

Let $f(x)$, $g(x)$, and $h(x)$ be functions defined on $(a,\infty)$ which for all $x\in I$, $f(x)\leq h(x)\leq g(x)$. If
\[\lim_{x\to\infty}f(x)=\lim_{x\to\infty}g(x)=L\in\mathbb{R}\setminus\{-\infty,\infty\},\]
then
\[\lim_{x\to\infty}h(x)=L.\]

Let $f(x)$, $g(x)$, and $h(x)$ be functions defined on $(-\infty,a)$ which for all $x\in I$, $f(x)\leq h(x)\leq g(x)$. If
\[\lim_{x\to-\infty}f(x)=\lim_{x\to-\infty}g(x)=L\in\mathbb{R}\setminus\{-\infty,\infty\},\]
then
\[\lim_{x\to-\infty}h(x)=L.\]
\begin{proof}
Take the first statement for example. The other statements can be proven similarly.

Start from the limits of $f$ and $g$, by definition of limit:
\[\forall\varepsilon>0, \exists\delta_1>0\text{\ s.t.\ }0<|x-a|<\delta_1\implies|f(x)-L|<\varepsilon,\]
and
\[\forall\varepsilon>0, \exists\delta_2>0\text{\ s.t.\ }0<|x-a|<\delta_2\implies|g(x)-L|<\varepsilon,\]

Choose:
\[\delta\coloneq\min(\delta_1,\delta_2),\]

so,
\[L-\varepsilon<f(x)\leq h(x)\leq g(x)<L+\varepsilon.\]

Since $\varepsilon > 0$ was arbitrary, by definition of limit:
\[\lim_{x\to a}h(x)=L.\]
\end{proof}
\ssc{Limit of real sequence theorems}
\subsubsection{Monotone Convergence Theorem (單調收斂定理) or Completeness of the Real Numbers (實數的完備性)}
\textit{Statement.}
\begin{enumerate}[label=(\Alph*)]
\item For a non-decreasing and bounded-above sequence of real numbers $\langle a_n\rangle_{n\in\mathbb {N}}$:
\[\lim_{n\to\infty}a_n=\sup_n a_n.\]
\item For a non-increasing and bounded-below sequence of real numbers $\langle a_n\rangle_{n\in\mathbb {N}}$:
\[\lim_{n\to\infty}a_n=\inf_n a_n.\]
\end{enumerate}
\begin{proof}
Let $\{a_{n}\}$ be the set of values of $\langle a_n\rangle_{n\in\mathbb {N}}$. By assumption, $\{a_n\}$ is non-empty and bounded-above by $\sup_n a_n$. Let $c=\sup_n a_n$.
\[\forall\varepsilon>0:\,\exists M\in\mathbb {N}\text{\ s.t.\ }c\geq a_M>c-\varepsilon,\]
since otherwise $c-\varepsilon$ is a strictly smaller upper bound of $\langle a_n\rangle$, contradicting the definition of the supremum. 

Then since $\langle a_n\rangle$ is non-decreasing, and $c$ is an upper bound:
\[\forall\varepsilon>0:\,\exists M\in\mathbb {N}\text{\ s.t.\ }\forall n\geq M:\,|c-a_n|=c-a_n\leq c-a_M=|c-a_M|<\varepsilon.\]
The proof of the (B) part is analogous or follows from (A) by considering $\langle -a_{n}\rangle_{n\in \mathbb{N}}$.
\end{proof}
\textit{Statement.}

If $\langle a_n\rangle_{n\in\mathbb {N}}$ is a monotone sequence of real numbers, i.e., if 
$a_n\leq a_{n+1}$ for every $n\geq 1$ or $a_n\geq a_{n+1}$ for every $n\geq 1$, then this sequence has a finite limit if and only if the sequence is bounded.
\begin{proof}
"If"-direction: The proof follows directly from the proposition.

"Only If"-direction: By $(\varepsilon,\delta)$-definition of limit, every sequence $\langle a_n\rangle_{n\in\mathbb {N}}$ with a finite limit $L$ is necessarily bounded.
\end{proof}
\sssc{Bolzano–Weierstrass Theorem (波爾查諾-魏爾斯特拉斯定理)}
Every bounded sequence in an Euclidean space $\bbR^n$ has a convergent subsequence.

\begin{proof}
    For $\bbR$, take any bounded sequence $(x_n)$ in $\bbR$. Then there exist real numbers $m,M$ such that
    \[m\leq x_n\leq M,\quad\forall n.\]
    So the sequence lies in the closed interval $[m,M]$.

    For $\varepsilon=1$. Divide $[m,M]$ into disjoint subintervals with length $\frac{M-m}{2^\varepsilon}$:
    \[\qty[m,\frac{m+M}{2}],\qty[\frac{m+M}{2},M].\]
    Since $(x_n)$ is infinite, by the pigeonhole principle, one of the subintervals must contain infinitely many terms of $(x_n)$. Denote it by $I_1$ and pick the subsequence $\qty(x_n^{(1)})$ of $(x_n)$ that is entirely in $I_1$.

    Repeat it for $\varepsilon=2,3,\ldots,$ by dividing $I_{\varepsilon-1}$ into two halves, we can construct a nested sequence of subsequences
    \[\qty(x_n^{(1)})\supseteq \qty(x_n^{(2)})\supseteq\ldots\]
    where $\qty(x_n^{(k)})$ lies in a closed interval of length $\frac{M-m}{2^k}$, $I_k$.

    Pick the diagonal sequence $y_k=x_k^{(k)}$. Then
    \[y_k\in\qty(x_n^{(k)})\subseteq I_k,\]
    and the sequence $(y_k)$ is a convergent subsequence of $(x_n)$ because
    \[\forall N\in\bbN\colon m,n\geq N\implies |y_m-y_n|\leq\frac{M-m}{2^N}.\]

    To generalized to $\bbR^n$, consider each coordinate sequence in $\bbR$, it has a convergent subsequence. Diagonalization gives a subsequence converging in all coordinates.
\end{proof}
\sssc{Abel transformation or summation by parts}
Let $\langle f_k\rangle$ and $\langle g_k\rangle$ be two sequences.
\[\sum_{k=m}^nf_k\qty(g_{k+1}-g_k)=\qty(f_{n+1}g_{n+1}-f_mg_m)-\sum_{k=m}^ng_{k+1}\qty(f_{k+1}-f_k).\]
\[\sum_{k=m}^nf_k\qty(g_k-g_{k-1})=\qty(f_ng_n-f_{m-1}g_{m-1})-\sum_{k=m}^ng_{k-1}\qty(f_k-f_{k-1}).\]
\[\sum_{k=m}^n\qty(f_k\qty(g_{k+1}-g_k)+g_k\qty(f_k-f_{k-1}))=f_ng_{n+1}-f_{m-1}g_m.\]
\ssc{Limit of real function theorems}
\sssc{Limits involving quotient functions}
Let \( a \) and \( b \) be real numbers, set
\[A=\left\{f\colon U\subseteq\mathbb{R}\to\mathbb{R} \middle | f(x) = x \lor \ln(f(x)) \in A \lor e^{f\left(x\right)}  \in A \right\},\]
and function $f\in A$. Then:
\[\lim_{x \to \infty} \frac{\left(f\left(x\right)\right)^a}{\left(f\left(x\right)\right)^b} = \infty, \quad a > b \]
\[ \lim_{x \to \infty} \frac{af\left(x\right)}{bf\left(x\right)} = \frac{a}{b}, \quad b \neq 0 \]
\[ \lim_{x \to \infty}\frac{n^{af\left(x\right)}}{bf\left(x\right)} = \infty, \quad a,b > 0 \land  n > 1 \]
\[ \lim_{x \to \infty}\frac{n^{af\left(x\right)}}{bf\left(x\right)} = 0, \quad a,b > 0 \land  0\leq n<1 \]
\[ \lim_{x \to \infty}\frac{af\left(x\right)}{b\log_n f\left(x\right)} = \infty, \quad a,b > 0 \land  n > 1 \]
\sssc{BV function has limit}
If function $f\colon[a,b)\to\bbR$ with $b\in(a,\infty]$ is of bounded variation on $[a,b)$, then $\lim_{x\to b^-}f(x)$ exists in $\bbR$.
\begin{proof}
PLACEHOLDER
\end{proof}
\ssc{Real series theorems}
\sssc{Cauchy's convergence test}
A series $\sum_{n=0}^{\infty}a_n$ converges iff for every $\varepsilon>0$, there is a natural number $N$ such that
\[\abs{\sum_{i=n+1}^{n+p}a_i}<\varepsilon\]
for all $n\geq N$ and $p\geq 1$.
\sssc{Term test}
If $\sum_{n=0}^{\infty}a_n$ converges, then $\lim_{n\to\infty}a_n=0$.
\sssc{Convergence and Mertens' theorem}
If $\sum_{n=0}^{\infty}a_n$ converges to $A$, $\sum_{n=0}^{\infty}b_n$ converges to $B$, and at least one of them converges absolutely, then their Cauchy product converges to $AB$.
\begin{proof}
PLACEHOLDER
\end{proof}
\ssc{Improper integral theorems}
\sssc{p-test I}
$\int_a^{\infty}x^p\dd{x},\quad a>0$ converges iff $p<-1$. And for $p<-1\land a>0$,
\[\int_a^{\infty}x^p\dd{x}=-\frac{1}{p+1}a^{p+1}.\]
\begin{proof}
\[\int x^p\dd{x}=\begin{cases}
\frac{1}{p+1}x^{p+1},\quad&p\neq -1\\
\ln(x),\quad&p=-1
\end{cases}\]
\[\forall p>-1\nexists\lim_{x\to\infty}\frac{1}{p+1}x^{p+1}\]
\[\nexists\lim_{x\to\infty}\ln(x)\]
\[\forall p<-1\lim_{x\to\infty}\frac{1}{p+1}x^{p+1}=0\]
\end{proof}
\sssc{p-test II}
$\int_0^ax^p\dd{x},\quad a>0$ converges iff $p>-1$. And for $p>-1\land a>0$,
\[\int_0^ax^p\dd{x}=\frac{1}{p+1}a^{p+1}.\]
\begin{proof}
\[\int x^p\dd{x}=\begin{cases}
\frac{1}{p+1}x^{p+1},\quad&p\neq -1\\
\ln(x),\quad&p=-1
\end{cases}\]
\[\forall p<-1\nexists\lim_{x\to 0^+}\frac{1}{p+1}x^{p+1}\]
\[\nexists\lim_{x\to 0^+}\ln(x)\]
\[\forall p>-1\lim_{x\to 0^+}\frac{1}{p+1}x^{p+1}=0\]
\end{proof}
\sssc{$x^p(\ln x)^q$-test I}
$\int_a^{\infty}x^p(\ln x)^q\dd{x},\quad a>0$ converges iff $p<-1\lor (p=-1\land q<-1)$.
\begin{proof}
\[\lim_{x\to\infty}\frac{(\ln x)^q}{x^{\varepsilon}}=\lim_{u\to\infty}\frac{u^q}{e^{\varepsilon u}}=0,\quad\forall\varepsilon>0,\quad\forall q.\]
For all $p<-1$, take $-1-p>\varepsilon>0$, $p+\varepsilon<-1$:
\[\lim_{x\to\infty}\frac{x^p(\ln x)^q}{x^{p+\varepsilon}}=0.\]
Thus, by one-sided LCT, since
\[\int_a^{\infty}x^{p+\varepsilon}\dd{x}\]
is convergent,
\[\int_a^{\infty}x^p(\ln x)^q\dd{x}\]
is convergent.
\[\lim_{x\to\infty}\frac{(\ln x)^q}{x^{\varepsilon}}=\lim_{u\to\infty}\frac{u^q}{e^{\varepsilon u}}=\infty,\quad\forall\varepsilon<0,\quad\forall q.\]
For all $p>-1$, take $-1-p<\varepsilon<0$, $p+\varepsilon>-1$:
\[\lim_{x\to\infty}\frac{x^p(\ln x)^q}{x^{p+\varepsilon}}=\infty.\]
Thus, by one-sided LCT, since
\[\int_a^{\infty}x^{p+\varepsilon}\dd{x}\]
is divergent,
\[\int_a^{\infty}x^p(\ln x)^q\dd{x}\]
is divergent.

For $p=-1$:
\[u=\ln x,\quad\dd{u}=\frac{1}{x}\dd{x}.\]
\[\int_a^{\infty}\frac{(\ln x)^q}{x}\dd{x}=\int_{\ln a}^{\infty}u^q\dd{u},\]
which converges iff $q<-1$.
\end{proof}
\sssc{$x^p(\ln x)^q$-test II}
$\int_0^ax^p(\ln x)^q\dd{x},\quad a>0$ converges iff $p>-1\lor (p=-1\land q>-1)$.
\begin{proof}
\[\lim_{x\to 0^+}\frac{(\ln x)^q}{x^{\varepsilon}}=\lim_{u\to-\infty}\frac{u^q}{e^{\varepsilon u}}=0,\quad\forall\varepsilon<0,\quad\forall q.\]
For all $p>-1$, take $-1-p<\varepsilon<0$, $p+\varepsilon>-1$:
\[\lim_{x\to 0^+}\frac{x^p(\ln x)^q}{x^{p+\varepsilon}}=0.\]
Thus, by one-sided LCT, since
\[\int_0^ax^{p+\varepsilon}\dd{x}\]
is convergent,
\[\int_0^ax^p(\ln x)^q\dd{x}\]
is convergent.
\[\lim_{x\to 0^+}\frac{(\ln x)^q}{x^{\varepsilon}}=\lim_{u\to-\infty}\frac{u^q}{e^{\varepsilon u}}=\infty,\quad\forall\varepsilon>0,\quad\forall q.\]
For all $p<-1$, take $-1-p>\varepsilon>0$, $p+\varepsilon<-1$:
\[\lim_{x\to 0^+}\frac{x^p(\ln x)^q}{x^{p+\varepsilon}}=\infty.\]
Thus, by one-sided LCT, since
\[\int_0^ax^{p+\varepsilon}\dd{x}\]
is divergent,
\[\int_0^ax^p(\ln x)^q\dd{x}\]
is divergent.

For $p=-1$:
\[u=\ln x,\quad\dd{u}=\frac{1}{x}\dd{x}.\]
\[\int_0^a\frac{(\ln x)^q}{x}\dd{x}=\int_0^au^q\dd{u},\]
which converges iff $q>-1$.
\end{proof}
\sssc{Convergent improper integral of BV integrand implies limit of integrand converges to 0}
If function $f\colon[a,\infty)\to\bbR$ is of bounded variation on $[a,\infty)$ and $\int_a^{\infty}f(x)\dd{x}$ converges, then $\lim_{x\to\infty}f(x)=0$.
\begin{proof}
PLACEHOLDER
\end{proof}
\sssc{Convergent improper integral of nonnegative and non-increasing integrand implies limit of product of integrand and independent variable converges to 0}
If function $f\colon[a,\infty)\to\bbR$ is nonnegative and non-increasing on $[a,\infty)$ and $\int_a^{\infty}f(x)\dd{x}$ converges, then $\lim_{x\to\infty}xf(x)=0$.
\begin{proof}
Since $\int_a^{\infty}f(x)\dd{x}$ and $f(x)$ is nonnegative, $\forall\varepsilon>0$, there exists $M>a$ such that $\forall A>M$:
\[0\leq\int_A^{\infty}f(x)\dd{x}<\varepsilon.\]
Thus for $t>2M$,
\[0\leq\int_{t/2}^tf(x)\dd{x}=\int_{t/2}^{\infty}f(x)\dd{x}-\int_t^{\infty}f(x)\dd{x}<2\varepsilon.\]
Since $f(x)$ is non-increasing,
\[f(x)\geq f(t),\quad\forall x\in[t/2,t]\]
\[\int_{t/2}^tf(x)\dd{x}\geq\int_{t/2}^tf(t)\dd{x}=\frac{t}{2}f(t)\]
\[tf(t)<4\varepsilon.\]
Thus, $\forall\varepsilon>0$, there exists $2M>0$ such that $\forall t>2M$,
\[tf(t)<\varepsilon,\]
that is,
\[\lim_{x\to\infty}xf(x)=0.\]
\end{proof}
\ssc{Absolute convergence implies convergence}
\sssc{For real series}
A real series is convergent if it is absolutely convergent.
\sssc{For improper integral}
An improper integral is convergent if it is absolutely convergent.
\ssc{Deleting head}
\sssc{For real series}
For real sequence $\langle a_i\rangle_{i=m}^{\infty}$, $\sum_{i=m}^{\infty}a_i$ converges iff $\sum_{i=m+n}^{\infty}a_i$ converges, for all $n\in\bbN$.
\sssc{For improper integral}
If function $f\colon [a,b)\to\bbR$ is measurable with $b\in(a,\infty]$, $\int_a^bf(x)\dd{x}$ is improper integral, $\int_a^cf(x)\dd{x}$ is proper integral for any $a<c<b$, then $\int_a^bf(x)\dd{x}$ converges iff $\int_c^bf(x)\dd{x} converges, for all $a<c<b$.
\ssc{(Direct) comparison theorem}
\sssc{For real series}
If real sequences $\langle a_n\rangle_{n=1}^{\infty}$ and $\langle b_n\rangle_{n=1}^{\infty}$ are such that $a_n\geq b_n\geq 0$ for all $n\in\bbN$, then
\ben
\item $\sum_{n=1}^{\infty}a_n$ is convergent implies $\sum_{n=1}^{\infty}b_n$ is convergent.
\item $\sum_{n=1}^{\infty}b_n$ is divergent implies $\sum_{n=1}^{\infty}a_n$ is divergent.
\een
\begin{proof}
Let $\left\langle s_n=\sum_{i=1}^na_i\right\rangle_{i=1}^{\infty}$ and $\left\langle t_n=\sum_{i=1}^nb_i\right\rangle_{i=1}^{\infty}$ be the sequences of partial sums of $\langle a_n\rangle_{n=1}^{\infty}$ and $\langle b_n\rangle_{n=1}^{\infty}$.

$s_n$ and $t_n$ are monotone increasing for all $n\in\bbN$ since $a_n,b_n\geq 0$. $s_n\geq t_n$ for all $n\in\bbN$ since $a_n\geq b_n$.

Statement 1:
\[\sum_{n=1}^{\infty}a_n=\lim_{n\to\infty}s_n=L.\]
Since
\[0\leq t_n\leq s_n,\]
then,
\[\sum_{n=1}^{\infty}b_n=\lim_{n\to\infty}t_n\]
exists and $\in[0,L]$.

Statement 2 is the contrapositive of statement 1.
\end{proof}
\sssc{For improper integral}
If functions $f\colon [a,b)\to\bbR$ and $g\colon [a,b)\to\bbR$ are measurable with $b\in(a,\infty]$, $\int_a^bf(x)\dd{x}$ and $\int_a^bg(x)\dd{x}$ are improper integrals, $\int_a^cf(x)\dd{x}$ and $\int_a^cg(x)\dd{x}$ are proper integrals for any $a<c<b$,
and $f(x)\geq g(x)\geq 0$ a.e. for $x\in[a,b)$, then
\ben
\item $\int_a^bf(x)\dd{x}$ is convergent implies $\int_a^bg(x)\dd{x}$ is convergent.
\item $\int_a^bg(x)\dd{x}$ is divergent implies $\int_a^bf(x)\dd{x}$ is divergent.
\een
\begin{proof}
Let
\[F(t)=\int_a^tf(x)\dd{x},\quad t\in[a,b),\]
\[G(t)=\int_a^tg(x)\dd{x},\quad t\in[a,b).\]
$F$ and $G$ are monotone increasing since $f(x),g(x)\geq 0$ a.e. for $x\in[a,b)$.

$F(x)\geq G(x)$ since $f(x)\geq g(x)$ a.e. for $x\in[a,b)$.

Statement 1:
\[\int_a^bf(x)\dd{x}=\lim_{t\to b}F(t)=L.\]
Since
\[0\leq G(x)\leq F(x),\]
then,
\[\int_a^bg(x)\dd{x}=\lim_{t\to b}G(t)\]
exists and $\in [0,L]$.

Statement 2 is the contrapositive of statement 1.
\end{proof}
\ssc{Limit comparison theorem (LCT)}
\sssc{For real series}
If real sequences $\langle a_n\rangle_{n=1}^{\infty}$ and $\langle b_n\rangle_{n=1}^{\infty}$ are such that $a_n\geq 0$ and $b_n>0$ for all $n\geq m$ for some $m\in\bbN$, if
\[L=\lim_{n\to\infty}\frac{a_n}{b_n}\in[0,\infty],\]
then:
\ben
\item If $0<L<\infty$, then $\sum_{n=1}^{\infty}a_n$ is convergent iff $\sum_{n=1}^{\infty}b_n$ is convergent. (classical LCT)
\item if $L=0$, then:
\ben
\item $\sum_{n=1}^{\infty}b_n$ is convergent implies $\sum_{n=1}^{\infty}a_n$ is convergent.
\item $\sum_{n=1}^{\infty}a_n$ is divergent implies $\sum_{n=1}^{\infty}b_n$ is divergent.
\een
(one-sided LCT)
\item If $L=\infty$, then:
\ben
\item $\sum_{n=1}^{\infty}a_n$ is convergent implies $\sum_{n=1}^{\infty}b_n$ is convergent.
\item $\sum_{n=1}^{\infty}b_n$ is divergent implies $\sum_{n=1}^{\infty}a_n$ is divergent.
\een
(one-sided LCT)
\een
\begin{proof}
Statement 1:

For every $\varepsilon>0$, there exists $N\in\bbN$ such that for all $n\geq N$, $\abs{\frac{a_n}{b_n}-L}<\varepsilon$, equivalently,
\[(L-\varepsilon)b_n<a_n<(L+\varepsilon)b_n.\]
As $L>0$, choose $\varepsilon$ such that $L-\varepsilon>0$, so that
\[\frac{a_n}{L+\varepsilon}<b_n<\frac{a_n}{L-\varepsilon}.\]
$\sum_{n=1}^{\infty}\frac{a_n}{L+\varepsilon}$ is convergent iff $\sum_{n=1}^{\infty}a_n$ is convergent iff $\sum_{n=1}^{\infty}\frac{a_n}{L-\varepsilon}$ is convergent.

And by direct comparison test,
\bit
\item $\sum_{n=1}^{\infty}\frac{a_n}{L-\varepsilon}$ is convergent implies $\sum_{n=1}^{\infty}b_n$ is convergent,
\item $\sum_{n=1}^{\infty}b_n$ is convergent implies $\sum_{n=1}^{\infty}\frac{a_n}{L+\varepsilon}$ is convergent.
\eit

Statement 2:

There exists $N\in\bbN$ such that for all $n\geq N$, $0\leq\frac{a_n}{b_n}<1$, equivalently,
\[0\leq a_n<b_n.\]

By direct comparison test of $\sum_{n=N}^{\infty}a_n$ and $\sum_{n=N}^{\infty}b_n$, the statements hold.

Statement 3:

There exists $N\in\bbN$ such that for all $n\geq N$, $\frac{a_n}{b_n}>1$, equivalently,
\[a_n>b_n>0.\]

By direct comparison test of $\sum_{n=N}^{\infty}a_n$ and $\sum_{n=N}^{\infty}b_n$, the statements hold.
\end{proof}
\sssc{For improper integral}
If functions $f\colon [a,b)\to\bbR$ and $g\colon [a,b)\to\bbR$ are measurable with $b\in(a,\infty]$, $\int_a^bf(x)\dd{x}$ and $\int_a^bg(x)\dd{x}$ are improper integrals, $\int_a^cf(x)\dd{x}$ and $\int_a^cg(x)\dd{x}$ are proper integrals for any $a<c<b$, $f(x)\geq 0$ and $g(x)>0$ for $x\in[a,b)$, if
\[L=\lim_{x\to b^-}\frac{f(x)}{g(x)}\in[0,\infty],\]
then:
\ben
\item If $0<L<\infty$, then $\int_a^bf(x)\dd{x}$ is convergent iff $\int_a^bg(x)\dd{x}$ is convergent. (classical LCT)
\item if $L=0$, then:
\ben
\item $\int_a^bg(x)\dd{x}$ is convergent implies $\int_a^bf(x)\dd{x}$ is convergent.
\item $\int_a^bf(x)\dd{x}$ is divergent implies $\int_a^bg(x)\dd{x}$ is divergent.
\een
(one-sided LCT)
\item If $L=\infty$, then:
\ben
\item $\int_a^bg(x)\dd{x}$ is divergent implies $\int_a^bf(x)\dd{x}$ is divergent.
\item $\int_a^bf(x)\dd{x}$ is convergent implies $\int_a^bg(x)\dd{x}$ is convergent.
\een
(one-sided LCT)
\een
\begin{proof}
Statement 1:

For every $\varepsilon>0$, there exists $a\leq M<b$ such that for all $b>x\geq M$, $\abs{\frac{f(x)}{g(x)}-L}<\varepsilon$, equivalently,
\[(L-\varepsilon)g(x)<f(x)<(L+\varepsilon)g(x).\]
As $L>0$, we can choose $\varepsilon$ such that $L-\varepsilon>0$, so that
\[\frac{f(x)}{L+\varepsilon}<g(x)<\frac{f(x)}{L-\varepsilon}.\]
$\int_a^b\frac{f(x)}{L+\varepsilon}\dd{x}$ is convergent iff $\int_a^bf(x)\dd{x}$ is convergent iff $\int_a^b\frac{f(x)}{L-\varepsilon}\dd{x}$ is convergent.

And by direct comparison test,
\bit
\item $\int_a^b\frac{f(x)}{L-\varepsilon}\dd{x}$ is convergent implies $\int_a^bg(x)\dd{x}$ is convergent,
\item $\int_a^bg(x)\dd{x}$ is convergent implies $\int_a^b\frac{f(x)}{L+\varepsilon}\dd{x}$ is convergent.
\eit

Statement 2:

There exists $a\leq M<b$ such that for all $b>x\geq M$, $0\leq\frac{f(x)}{g}<1$, equivalently,
\[0\leq f(x)<g(x).\]

By direct comparison test of $\int_M^bf(x)\dd{x}$ and $\int_M^bg(x)\dd{x}$, the statements hold.

Statement 3:

There exists $a\leq M<b$ such that for all $b>x\geq M$, $\frac{f(x)}{g(x)}>1$, equivalently,
\[f(x)>g(x)>0.\]

By direct comparison test of $\int_M^bf(x)\dd{x}$ and $\int_M^bg(x)\dd{x}$, the statements hold.
\end{proof}
\ssc{Dirichlet test or Abel's test}
\sssc{For real series}
If $\langle a_n\rangle_{n=1}^{\infty}$ is a sequence such that the sequence of partial sums $\langle s_n=\sum_{i=0}^na_i\rangle_{n=0}^{\infty}$ where $s_0=0$ is bounded and $\langle b_n\rangle_{n=1}^{\infty}$ is a monotone sequence such that $\lim_{n\to\infty}b_n=0$, then
\[\sum_{n=1}^{\infty}a_nb_n\]
converges.
\begin{proof}
Choose $M$ such that $\langle\abs{s_n}\rangle_{n=0}^{\infty}$ is bounded above by $M$.

For any $\varepsilon>0$, there is $N\in\bbN$ such that $\abs{b_m}<\frac{\varepsilon}{2M}$ for all $m\geq N$.

For any $N\leq p\leq q$, using Abel transformation,
\[\ba
\abs{\sum_{n=p}^qa_nb_n}&=\abs{\sum_{n=p}^q\qty(s_{n+1}-s_n)b_n}\\
&=\abs{s_{q+1}b_{q+1}-s_pb_p-\sum_{n=p}^qs_{n+1}\qty(b_{n+1}-b_n)}\\
&\leq M\qty(\abs{b_{q+1}}+\abs{b_p}+\sum_{n=p}^q\abs{b_{n+1}-b_n})\\
&=M\qty(\abs{b_{q+1}}+\abs{b_p}+\abs{b_{q+1}-b_p})\\
&=M\qty(\abs{b_{q+1}}+\abs{b_p}+\abs{b_p}-\abs{b_{q+1}})\\
&=2M\abs{b_p}\\
&\leq\varepsilon
\ea\]
\end{proof}
\sssc{For improper integral}
If $f\colon [a,b)\to\bbR$ with $b\in(a,\infty]$ is a function such that the function
\[F(x)=\int_a^xf(t)\dd{t},\quad b>x\geq a\]
is bounded, $g\colon [a,b)\to\bbR$ is a monotone and measurable function such that $\lim_{x\to b^-}g(x)=0$, then
\[\int_a^bf(x)g(x)\dd{x}\]
converges.
\begin{proof}
Rewrite as Riemann–Stieltjes integral
\[\int_a^bf(x)g(x)\dd{x}=\int_{x=a}^bg(x)\dd{F(x)}.\]

Choose $M$ such that $\abs{F(x)}$ is bounded above by $M$.

For any $\varepsilon>0$, there is $a\leq N<b$ such that $\abs{g(N)}<\frac{\varepsilon}{2M}$ for all $m\geq N$.

For any $N\leq p\leq q<b$, using integration by parts of Riemann–Stieltjes integral,
\[\ba
\abs{\int_{x=p}^qg(x)\dd{F(x)}}&=\abs{F(q)g(q)-F(p)g(p)-\int_{x=p}^qf(x)\dd{g(x)}}\\
&\leq M\qty(\abs{g(q)}+\abs{g(p)}+\int_{x=p}^q\dd{g(x)})\\
&=M\qty(\abs{g(q)}+\abs{g(p)}+\abs{g(q)-g(p)})\\
&=M\qty(\abs{g(q)}+\abs{g(p)}+\abs{g(p)}-\abs{g(q)})\\
&=2M\abs{g(p)}\\
&\leq\varepsilon
\ea\]
\end{proof}



\section{Differential theorems and methods}
\ssc{Theorems and methods of differentiation}
\sssc{Linearity, or sum rule, difference rule, and constant multiple rule}
If functions $f$ and $g$ are differentiable on $I$ and $a,b\in\mathbb{R}$, then $af(x)+bg(x)$ is also differentiable on $I$ and its derivative is given by
\[\dv{}{x}\qty(af(x)+bg(x))=af'(x)+bg'(x).\]
\begin{proof}
\[\ba
\dv{}{x}\qty(af(x)+bg(x))&=\lim_{h\to 0}\frac{af(x+h)+bg(x+h)-af(x)-bg(x)}{h}\\
&=af'(x)+bg'(x)
\ea\]
\end{proof}
\sssc{Product rule (乘法定則)}
If functions $f$ and $g$ are differentiable on $I$, then the product $fg$ is also differentiable on $I$ and its derivative is given by
\[\dv{x}\qty(f(x)g(x))=f'(x)g(x)+f(x)g'(x).\]
\begin{proof}
\[\begin{aligned}
\dv{f(x)g(x)}{x}&=\lim_{h\to 0}\frac{f(x+h)g(x+h)-f(x)g(x)}{h}\\
&=\lim_{h\to 0}\frac{f(x+h)(g(x+h)-g(x))+g(x)(f(x+h)-f(x))}{h}\\
&=f(x)g'(x)+f'(x)g(x).
\end{aligned}\]
\end{proof}
\sssc{General Leibniz rule}
If functions $f$ and $g$ are $n$-times differentiable on $I$, then the product $fg$ is also $n$-times differentiable on $I$ and its derivative is given by
\[(fg)^{(n)}=\sum _{k=0}^{n}{n \choose k}f^{(n-k)}g^{(k)}.\]
\sssc{Quotient rule (除法定則)}
If functions $f$ and $g$ are differentiable on $I$ and $g\neq 0$ on $I$, then the quotient $\frac{f}{g}$ is also differentiable on $I$ and its derivative is given by
\[\dv{x}\qty(\frac{f(x)}{g(x)})=\frac{f'(x)g(x)-f(x)g'(x)}{\qty(g(x))^2}.\]
\begin{proof}
\[\begin{aligned}
\dv{}{x}\frac{f(x)}{g(x)}&=\lim_{h\to 0}\frac{\frac{f(x+h)}{g(x+h)}-\frac{f(x)}{g(x)}}{h}\\
&=\lim_{h\to 0}\frac{f(x+h)g(x)-f(x)g(x+h)}{h\,g(x+h)g(x)}\\
&=\lim_{h\to 0}\frac{(f(x+h)-f(x))g(x)-f(x)(g(x+h)-g(x))}{h\,g(x+h)g(x)}\\
&=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h\,g(x+h)}-f(x)\lim_{h\to 0}\frac{g(x+h)-g(x)}{h\,g(x+h)g(x)}\\
&=\frac{f'(x)g(x)-f(x)g'(x)}{g(x)^2}
\end{aligned}\]
\end{proof}
\sssc{Chain rule (連鎖律) of real-domain functions}
Let $f\colon X\subseteq\bbR\to\bbR$ and $g\colon Y\subseteq\bbR\to\bbR$ be functions, $g$ be differentiable on $I\subseteq\bbR$, and $f$ be differentiable on $g(I)$. Then the composite $f\circ g$ is differentiable on $I$ and its derivative on $I$ is given by
\[\dv{}{x}\qty((f\circ g)(x))=f'\qty(g(x))g'(x).\]
\begin{proof}
\[\ba
\dv{}{x}\qty((f\circ g)(x))&=\lim_{h\to 0}\frac{f\qty(g(x+h))-f\qty(g(x))}{h}\\
&=\lim_{h\to 0}\frac{f\qty(g(x+h))-f\qty(g(x))}{g(x+h)-g(x)}\cdot\frac{g(x+h)-g(x)}{h}\\
&=f'\qty(g(x))g'(x)
\ea\]
\end{proof}
\sssc{Faà di Bruno's formula}
\bma
&\frac{\mathrm{d}^n}{\mathrm{d}x}f\left(g(x)\right)\\
=&\sum_{\sum_{i=1}^nim_i=n,\quad m_i\in\mathbb{N}_0}\frac{n!}{\prod_{j=1}^nm_j!}\cdot\\
&f^{\qty(\sum_{j=1}^nm_j)}\left(g(x)\right)\cdot\\
&\prod_{j=1}^n\left(\frac {g^{(j)}(x)}{j!}\right)^{m_j}.
\eam
\sssc{Chain rule of real-vector-space-domain fields}
Let $f\colon X\subseteq\bbR^n\to\bbR^p$ and $g\colon Y\subseteq\bbR^m\to\bbR^n$ be functions, $g$ be differentiable on $\Omega\subseteq\bbR^m$, and $f$ be differentiable on $g(\Omega)$. Then the composite $f\circ g$ is differentiable on $\Omega$ and its derivative on $\Omega$ is given by
\[\nabla\qty(f\circ g)(\mb{x})=(\nabla f)(g(\mb{x}))\cdot(\nabla g)(\mb{x}).\]
\sssc{Exponential Bell polynomials}
Partially or incomplete exponential Bell polynomials $B_{n,k}\qty(x_1,x_2,\ldots, x_{n-k+1})$ is defined as
\[B_{n,k}\qty(x_1,x_2,\ldots, x_{n-k+1})=n!\sum_{\langle j_i\rangle\in C}\prod_{i=1}^{n-k+1}\frac{x_i^{\phantom{i}j_i}}{(i!)^{j_i}j_i!},\]
where
\[C=\left\{\langle j_i\rangle_{i=1}^{n-k+1}\middle|\sum_{i=1}^{n-k+1}=k\land\sum_{i=1}^{n-k+1}ij_i=n\right\}.\]
Complete exponential Bell polynomial $B_n\qty(x_1,x_2,\ldots, x_n)$ is defined as
\[B_n\qty(x_1,x_2,\ldots, x_n)=n!\sum_{k=0}^nB_{n,k}\qty(x_1,x_2,\ldots, x_{n-k+1}).\]
\sssc{Derivative of inverse functions}
\[\qty(f^{-1})'(x)=\frac{1}{f'\qty(f^{-1}(x)).\]
\begin{proof}
\[f\qty(f^{-1}(x))=x.\]
Differentiate both sides:
\[f'\qty(f^{-1}(x))\qty(f^{-1})'(x)=1.\]
\end{proof}
\[\qty(f^{-1})''(x)=\frac{f''\qty(f^{-1}(x))}{\qty(f'\qty(f^{-1}(x)))^3}.\]
\begin{proof}
\[f'\qty(f^{-1}(x))\qty(f^{-1})'(x)=1.\]
Differentiate both sides:
\[f''\qty(f^{-1}(x))\qty(\qty(f^{-1})'(x))^2+f'\qty(f^{-1}(x))\qty(f^{-1})''(x)=0.\]
\[\qty(f^{-1})''(x)=\frac{f''\qty(f^{-1}(x))\qty(\qty(f^{-1})'(x))^2}{f'\qty(f^{-1}(x))}=\frac{f''\qty(f^{-1}(x))}{\qty(f'\qty(f^{-1}(x)))^3}.\]
\end{proof}
\[\dv[n]{f^{-1}(x)}{x}=\frac{(-1)^{n-1}}{\qty(f'\qty(f^{-1}(x)))^{2n-1}}B_{n-1}\sum_{i=2}^{n}f^{(i)}\qty(f^{-1}(x)),\quad n\in\bbN,\]
where $B_n$ is complete exponential Bell polynomial.
\sssc{Implicit differentiation (隱函數微分)}
If $x$ and $y$ are related by an equation $F(x,y)=0$, then we can differentiate both sides with respect to $x$, treating $y$ as a function of $x$.

Whenever we differentiate a term involving $y$, we apply the chain rule, which introduces a factor of $\dv{y}{x}$.

We can compute derivatives of $y$ with respect to $x$ without solving for $y$ by implicit differentiation.
\sssc{Derivative of natural logarithm of absolute value of function}
If functions $f$ is differentiable and nonzero on $I$, then $\ln|f(x)|$ is also differentiable on $I$ and its derivative is given by
\[\dv{\ln|f(x)|}{x}=\frac{f'(x)}{f(x)}.\]
\sssc{Logarithmic differentiation}
Logarithmic differentiation is a method for finding derivatives by taking the natural logarithm of (the absolute values of) both sides of an equation first, and then differentiating.

It’s especially useful when the function involves products or quotients of many factors, or variables in both the base and the exponent.
\sssc{Derivative of variable base, constant exponent funcion}
If $n\in\bbR$ and $f(x)$ is differentiable on $I$, then $\qty(f(x))^n$ is also differentiable on $I$ and its derivative is given by
\[\dv{}{x}\qty(f(x))^n=n\qty(f(x))^{n-1}f'(x).\]
\sssc{Derivative of constant base, variable exponent funcion}
If $n\in\bbR$ and $f(x)$ is differentiable on $I$, then $n^{f(x)}$ is also differentiable on $I$ and its derivative is given by
\[\dv{}{x}n^{f(x)}=n^{f(x)}\qty(\ln n)f'(x).\]
\sssc{Derivative of variable base, variable exponent funcion}
\[\dv{}{x}\qty(f(x))^{g(x)}=\qty(f(x))^{g(x)}\qty(g'(x)\ln(f(x))+g(x)\frac{f'(x)}{f(x)}).\]
\begin{proof}
\[y\coloneq\qty(f(x))^{g(x)}\]
Take natural logarithm of both sides:
\[\ln y=g(x)\ln(f(x)).\]
Take differentiation of both sides:
\[\frac{y'}{y}=g'(x)\ln(f(x))+g(x)\frac{f'(x)}{f(x)}.\]
\[y'=\qty(f(x))^{g(x)}\qty(g'(x)\ln(f(x))+g(x)\frac{f'(x)}{f(x)}).\]
\end{proof}
\ssc{Graph-related}
\sssc{Differentiability implies continuity}
Let $V$ and $W$ be normed vector spaces, $U$ be an open subset of $V$, and $f\colon U\subseteq V\to W$ be a function. For a point $a\in U$, $f$ is differentiable at $a$ implies it is continuous at $a$; for an open subset $I\subseteq U$, $f$ is differentiable on $I$ implies it is continuous on $I$.
\begin{proof}
$f$ is differentiable at $a$ iff there exists bounded linear operator $A\colon V\to W$ such that
\[\lim_{\|h\|_V\to 0}\frac{\|f(a+h)-f(a)-A(h)\|_W}{\|h\|_V}=0,\]
that is,
\[\forall\varepsilon>0\colon\exists\delta>0\text{\ s.t.\ }\|h\|_V<\delta\implies\|f(a+h)-f(a)-A(h)\|_W\leq\varepsion\|h\|_V.\]
By the triangular identity,
\[\|f(a+h)-f(a)\|_W\leq\|A(h)\|_W+\|f(a+h)-f(a)-A(h)\|_W.\]
By the definition of bounded linear operator, there exists $C\in\bbR_{>0}$ such that
\[\|A(h)\|_W\leq C\|h\|_V.\]
\[\|f(a+h)-f(a)\|_W\leq (C+\varepsilon)\|h\|_V.\]
Thus,
\[\forall\varepsilon>0\colon\exists\delta'=\frac{\varepsilon}{C+\varepsilon}\text{\ s.t.\ }\|h\|_V<\delta'\implies\|f(a+h)-f(a)\|_W\leq(C+\varepsilon)\|h\|_V<(C+\varepsilon)\delta'=\varepsilon.\]
\end{proof}
\sssc{Critical point (臨界點)}
Let $f$ be a function with codomain $\bbR$ and \( c \) be a point in the domain of $f$, if \( f'(c) = 0 \) or \( f' \) does not exist at \( c \), then \( c \) is a critical point, of \( f \), and $f(c)$ is called a critical value of $f$.

If the domain of $f$ is a subset of $\bbR$ or $\bbC$, a critical point is also called a critical number.
\sssc{Relative extremum (相對極值), local extremum (局部極值), or extremum (極值)}
Let $f\colon D\subseteq X\to\bbR$ be a function with $X$ being a topological space. It is said that a relative maximum (相對極大值) or maximum (極大值) \( f(c) \) of \(f\) occurs at $c\in D$ if there exists an open subset $I\ni c$ of $X$ such that \( \forall x\in I\cap D\colon f(c) \geq f(x) \).

Let $f\colon D\subseteq X\to\bbR$ be a function with $X$ being a topological space. It is said that a relative minimum (相對極小值) or minimum (極小值) \( f(c) \) of \(f\) occurs at $c\in D$ if there exists an open subset $I\ni c$ of $X$ such that \( \forall x\in I\cap D\colon f(c) \leq f(x) \).

Relative maximum and relative minimum are collectively called relative extreme.

Let $f\colon D\subseteq X\to\bbR$ be a function with $X$ being a topological space. It is said that a strict relative maximum or strict maximum \( f(c) \) of \(f\) occurs at $c\in D$ if there exists an open subset $I\ni c$ of $X$ such that \( \forall x\in I\cap D\colon f(c) > f(x) \).

Let $f\colon D\subseteq X\to\bbR$ be a function with $X$ being a topological space. It is said that a strict relative minimum or strict minimum \( f(c) \) of \(f\) occurs at $c\in D$ if there exists an open subset $I\ni c$ of $X$ such that \( \forall x\in I\cap D\colon f(c) < f(x) \).

Strict relative maximum and strict relative minimum are collectively called strict relative extreme.
\sssc{Absolute extremum (絕對極值 or 最值) or global extremum (全域極值)}
Let $f\colon D\to\bbR$ be a function. It is said that a absolute maximum (絕對極大值 or 最大值) \( f(c) \) of \(f\) occurs at $c\in D$ if \( \forall x\in D\colon f(c) \geq f(x) \).

Let $f\colon D\to\bbR$ be a function. It is said that a absolute minimum (絕對極小值 or 最小值) \( f(c) \) of \(f\) occurs at $c\in D$ if \( \forall x\in D\colon f(c) \leq f(x) \).

Absolute maximum and absolute minimum are collectively called absolute extreme.
\sssc{Saddle point (鞍點)}
Let $f$ be a function with codomain $\bbR$ and \( c \) be a point in the domain of $f$ , if \( f'(c) = 0 \) and $c$ is not a local extremum of $f$, then $c$ is a saddle point of $f$.
\sssc{Extreme Value Theorem (EVT) (極值定理)}
Let function $f\colon I\subseteq\mathbb{R}\to\mathbb{R}$ be continuous on an interval $[a,b]\subseteq I$, then
\[\exists c,d \in [a, b] \text{\ s.t.\ }\forall x \in [a, b]\colon f(c)\geq f(x)\geq f(d).\]
\begin{proof}
We first claim that $f$ is bounded on $[a,b]$. Argue by contradiction. Suppose $f$ is not bounded-above.

For any $n\in\mathbb{N}$, there exists $x_n\in [a,b]$ such that $f\qty(x_n)>n$. This defines a sequence $\langle x_n\rangle$.

By the Bolzano-Weierstrass Theorem and that $[a,b]$ is bounded, it has a convergent subsequence $x_{n_k}$ that converges to some limit $L$. Since $[a,b]$ is closed, $L\in [a,b]$.

Since $f$ is continuous on $[a,b]$, the sequence $f\qty(x_{n_k})$ converges to $f(L)$, which is finite.

This contradicts $f\qty(x_n)>n$ for every $n\in\mathbb{N}$. So the set
\[S=\{f(x)\mid x\in [a,b]\}.\]
must be bounded-above.

By considering $-f$, we obtain that $S$ is also bounded-below.

By the Completeness of the Real Numbers, every non-empty set bounded-above has a least upper bound; every non-empty set bounded-below has a greatest lower bound.

Let
\[M=\sup S,\quad m=\inf S.\]

Since $M$ is the least upper bound of $S$, for any $n\in\mathbb{N}$, $M-\frac{1}{n}$ is not an upper bound of $S$. This means that for each $n\in\mathbb{N}$, there exists a point $y_n\in [a,b]$ such that:
\[M-\frac{1}{n}<f(y_n)\leq M.\]
This defines another sequence $\langle y_n\rangle$ within $[a, b]$.

By the Bolzano-Weierstrass Theorem and that $[a,b]$ is bounded, it has a convergent subsequence $y_{n_k}$ that converges to some limit $c$. Since $[a,b]$ is closed, $c\in [a,b]$.
\[\lim_{n_k\to \infty}\qty(M - \frac{1}{n_k}) = M.\]
By the Squeeze Theorem:
\[\lim_{n_k \to \infty} f\qty(y_{n_k}) = M.\]
Since $f$ is continuous on $[a,b]$, the sequence $f\qty(y_{n_k})$ converges to $f(c)$.

Similarly, we can prove that there exists $d\in [a,b]$ such that $f(d)=m$.
\end{proof}
\sssc{Extreme Value Theorem (EVT) for compact set}
Let $X$ be a topological space, and function $f\colon I\subset X\to\mathbb{R}$ be continuous on a compact set $D\subseteq I$, then
\[\exists a,b \in D \text{\ s.t.\ }\forall x \in D\colon f(a)\geq f(x)\geq f(b).\]
\sssc{Fermat's Theorem (費馬引理) or Interior Extremum Theorem (內部極值定理)}
Let function $f\colon D\subseteq\mathbb{R}\to\mathbb{R}$ be differentiable on an open interval $I\subseteq D$ and $c\in I$ be a local extreme of $f$, then
\[f'(c)=0.\]
\begin{proof}
Without loss of generality, suppose $c$ is a local extreme. Then there exists $\delta>0$ such that for all $x\in (c-\delta,c+\delta)\colon f(x)\leq f(c)$.

Thus,
\[\lim_{h\to 0^+}\frac{f(x+h)-f(x)}{h}\leq 0\]
and
\[\lim_{h\to 0^-}\frac{f(x+h)-f(x)}{h}\geq 0.\]

Since $f$ is differentiable at $c$,
\[\lim_{h\to 0^+}\frac{f(x+h)-f(x)}{h}=\lim_{h\to 0^-}\frac{f(x+h)-f(x)}{h}=0=f'(c).\]
\end{proof}
In terms of critical point, Fermat's Theorem can be rephrased as, if function $f\colon D\subseteq\mathbb{R}\to\mathbb{R}$ has a local extreme $c$ of $f$, then $c$ is a critical point of $f$.
\sssc{Rolle's Theorem (羅爾定理)}
Let function $f\colon I\subseteq\mathbb{R}\to\mathbb{R}$ be continuous on an interval $[a, b]\subseteq I$ and differentiable on $(a,b)$, and $f(a)=f(b)$, then
\[\exists c\in (a, b)\text{\ s.t.\ }f'(c)=0.\]
\begin{proof}
By the Extreme Value Theorem, $f$ must have maximum and minimum on $[a,b]$.

Let
\[M=\max_{x\in [a,b]}f(x),\quad m=\min_{x\in [a,b]}f(x).\]
If $M=m$, then $f$ is constant on $[a,b]$, then $f'(x)=0$ for any $c\in (a,b)$.

Otherwise, $M>m$. Because $f(a)=f(b)$. 

We claim that there must be $c\in (a,b)$ such that $M=f(c)$ or $m=f(c)$. Argue by contradiction. If the claim is false, then $M=m=f(a)=f(b)$, contradicting $M>m$.

By Fermat's Theorem,
\[f'(c)=0.\]
\end{proof}
\sssc{Mean Value Theorem (MVT) (均值定理) (for Derivatives)}
Let function $f\colon I\subseteq\mathbb{R}\to\mathbb{R}$ be continuous on an interval $[a, b]\subseteq I$ and differentiable on $(a,b)$ with $a<b$, then
\[\exists c\in (a, b)\text{\ s.t.\ }f'(c)=\frac{f(b)-f(a)}{b-a}.\]
\begin{proof}
Let
\[\phi(x) = f(x) - \frac{f(b)-f(a)}{b-a} (x-a).\]
\[\phi(a)=\phi(b)=f(a).\]
By Rolle's Theorem, there exists $c\in (a,b)$ such that $\phi'(c)=0$.
\[\phi'(c)=f'(c)-\frac{f(b)-f(a)}{b-a}.\]
\end{proof}
\ssc{Cauchy's Mean Value Theorem (CMVT) (柯西均值定理)}
Let functions $f\colon I\subseteq\mathbb{R}\to\mathbb{R}$ and $g\colon J\subseteq\mathbb{R}\to\mathbb{R}$ be continuous on an interval $[a, b]\subseteq I\cap J$ and differentiable on $(a,b)$ with $a<b$, then
\[\exists c\in (a,b)\text{\ s.t.\ }\qty(f(b)-f(a))g'(c)=\qty(g(b)-g(a))f'(c).\]
\begin{proof}
    If $f(b)-f(a)=g(b)-g(a)=0$, it holds. For the other cases, without loss of generality, assume $g(b)-g(a)\neq 0$.

    Define a function $\phi(x)$
    \[\phi(x)=f(x)-\frac{f(b)-f(a)}{g(b)-g(a)}g(x).\]
    \[\phi(b)-\phi(a)=\qty(f(b)-f(a))-\frac{f(b)-f(a)}{g(b)-g(a)}\qty(g(b)-g(a))=0.\]
    By Rolle's Theorem, there exists $c\in (a,b)$ such that $\phi'(c)=0$.
    \[\phi'(x)=f'(x)-\frac{f(b)-f(a)}{g(b)-g(a)}g'(x).\]
\end{proof}
\sssc{Generalized Racetrack principle}
If $f'(x)>g'(x)$ for all $x\in (a,b)$ with $b\in\bbR_{>a}\cup\{\infty\}$, and $f(a)=g(a)$, then $f(x)>g(x)$ for all $x\in(a,b)$.

If $f'(x)>g'(x)$ for all $x\in (a,b)$ with $b\in\bbR_{>a}\cup\{\infty\}$, $f$ is continuous on $(a,b]$, and $f(a)=g(a)$, then $f(x)>g(x)$ for all $x\in(a,b]$.

If $f'(x)\geq g'(x)$ for all $x\in (a,b)$ with $b\in\bbR_{>a}\cup\{\infty\}$, and $f(a)=g(a)$, then $f(x)\geq g(x)$ for all $x\in(a,b]$.

If $f'(x)\geq g'(x)$ for all $x\in (a,b)$ with $b\in\bbR_{>a}\cup\{\infty\}$, $f$ is continuous on $(a,b]$, and $f(a)=g(a)$, then $f(x)\geq g(x)$ for all $x\in(a,b]$.
\begin{proof}
    For the first and second statements, define a function
    \[h(x)=f(x)-g(x).\]
    \[h'(x)=f'(x)-g'(x)>0,\quad\forall x\in(a,b).\]
    \[h(a)=f(a)-g(a)=0.\]
    By MVT, for all $x\in(a,b)$ for the first statement and $x\in(a,b]$ for the second statement, there exists $c\in(a,x)$ such that
    \[\frac{h(x)-h(a)}{x-a}=h'(c)>0.\]
    \[f(x)-g(x)=h(x)=(x-a)h'(c)>0.\]
    The other statements can be proven similarly.
\end{proof}
\sssc{Increasing/Decreasing Test (I/D Test) Theorem}
Let function $f\colon I\subseteq\bbR\to\bbR$ be differentiable on an open interval $(a,b)\subseteq I$.
\bit
\item if $f'(x)>0$ for any $x\in (a,b)$, then $f$ is strictly increasing on $(a,b)$.
\item If $f'(x)>0$ for any $x\in (a,b)$ and $f$ is continuous on $[a,b)$, then $f$ is strictly increasing on $[a,b)$.
\item If $f'(x)>0$ for any $x\in (a,b)$ and $f$ is continuous on $(a,b]$, then $f$ is strictly increasing on $(a,b]$.
\item if $f'(x)<0$ for any $x\in (a,b)$, then $f$ is strictly decreasing on $(a,b)$.
\item If $f'(x)<0$ for any $x\in (a,b)$ and $f$ is continuous on $[a,b)$, then $f$ is strictly decreasing on $[a,b)$.
\item If $f'(x)<0$ for any $x\in (a,b)$ and $f$ is continuous on $(a,b]$, then $f$ is strictly decreasing on $(a,b]$.
\item $f'(x)\geq 0$ for any $x\in (a,b)$ iff $f$ is non-decreasing on $(a,b)$.
\item If $f'(x)\geq 0$ for any $x\in (a,b)$ and $f$ is continuous on $[a,b)$, then $f$ is non-decreasing on $[a,b)$.
\item If $f'(x)\geq 0$ for any $x\in (a,b)$ and $f$ is continuous on $(a,b]$, then $f$ is non-decreasing on $(a,b]$.
\item $f'(x)\leq 0$ for any $x\in (a,b)$ iff $f$ is non-increasing on $(a,b)$.
\item If $f'(x)\leq 0$ for any $x\in (a,b)$ and $f$ is continuous on $[a,b)$, then $f$ is non-increasing on $[a,b)$.
\item If $f'(x)\leq 0$ for any $x\in (a,b)$ and $f$ is continuous on $(a,b]$, then $f$ is non-increasing on $(a,b]$.
\eit
\begin{proof}
    For the first statement, we want to show that $\forall c,d\in (a,b)\colon c<d\implies f(c)<f(d)$ if $f'(x)>0$ for any $x\in (a,b)$.

    Take any two points $c,d\in (a,b)$ with $c<d$. By MVT, there exists $g\in (c,d)$ such that
    \[f'(g)=\frac{f(d)-f(c)}{d-c}.\]
    Because $f'(g)>0$ and $d-c>0$, we get $f(d)-f(c)>0$.
    
    The second and third statements are obviously true as the first holds.
    
    The "if" directions of the other statements can be proven similarly.
    
    For the "only if" direction of the seventh statement, we want to show that $f'(x)\geq 0$ if $\forall c,d\in (a,b)\colon c<d\implies f(c)\leq f(d)$ and $f$ is differentiable on $(a,b)$.
    
    Fix any $x\in (a,b)$. For any $h>0$ with $(x+h)\in(a,b)$, we have
    \[f(x)\leq f(x+h).\]
    For any $h<0$ with $(x+h)\in(a,b)$, we have
    \[f(x)\geq f(x+h).\]
    Thus for any $h$ with $(x+h)\in(a,b)$, we have
    \[\frac{x+h}-f(x)}{h}\geq 0.\]
    The "only if" direction of the tenth statement can be proven similarly.
\end{proof}
\sssc{First Derivative Test for Local Extrema Theorem}
Let $f\colon I\subseteq\mathbb{R}\to\mathbb{R}$ be a function, $c$ be a critical point of $f$, and $f'$ be continuous at $c$.
\bit
\item If exist $a<c<b$ such that $f'(c)>0$ for any $x\in (a,c)$ and $f'(c)<0$ for any $x\in (c,b)$, then $f$ has a strict local maximum at $c$.
\item If exist $a<c<b$ such that $f'(c)\geq 0$ for any $x\in (a,c)$ and $f'(c)\leq 0$ for any $x\in (c,b)$, then $f$ has a local maximum at $c$.
\item If exist $a<c<b$ such that $f'(c)<0$ for any $x\in (a,c)$ and $f'(c)>0$ for any $x\in (c,b)$, then $f$ has a strict local minimum at $c$.
\item If exist $a<c<b$ such that $f'(c)\leq 0$ for any $x\in (a,c)$ and $f'(c)\geq 0$ for any $x\in (c,b)$, then $f$ has a local minimum at $c$.
\item If exist $a<c<b$ such that $f'(c)>0$ for any $x\in (a,b)$, then $f$ has no local exteme at $c$.
\item If exist $a<c<b$ such that $f'(c)<0$ for any $x\in (a,b)$, then $f$ has no local ext
eme at $c$.
\eit
\begin{proof}
    By Increasing/Decreasing Test Theorem, it is obvious.
\end{proof}
\sssc{Second Derivative Test for Local Extrema Theorem of Real Functions}
Let $f\colon I\subseteq\mathbb{R}\to\mathbb{R}$ be a function, $c$ be a critical point of $f$, and $f$ be twice differentiable at $c$.
\bit
\item If $f''<0$, then $f$ has a strict local maximum at $c$.
\item If $f''>0$, then $f$ has a strict local minimum at $c$.
\eit
\begin{proof}
By First Derivative Test for Local Extrema Theorem, it is obvious.
\end{proof}
\sssc{Eigenvalues Test of Definiteness for Symmetric Hessians of Scalar Fields}
If a Hessian $H$ of a scalar field is symmetric, that is,
\[H=H^\top,\]
then:
\bit
\item $H$ is positive definte if $\lambda>0$ for all eigenvalues $\lambda$ of $H$.
\item $H$ is negative definte if $\lambda<0$ for all eigenvalues $\lambda$ of $H$.
\item $H$ is nonnegative semidefinte if $\lambda\geq 0$ for all eigenvalues $\lambda$ of $H$.
\item $H$ is nonpositive semidefinte if $\lambda\leq 0$ for all eigenvalues $\lambda$ of $H$.
\item $H$ is neutral semidefinte if $\lambda=0$ for all eigenvalues $\lambda$ of $H$.
\item $H$ is indefinte if none of above conditions is true.
\eit
\sssc{Second Derivative Test for Local Extrema Theorem of Scalar Fields}
Let $f\colon I\subseteq\mathbb{R}^n\to\mathbb{R}$ be a function, $c$ be a critical point of $f$, and $f$ be twice differentiable at $c$.
\bit
\item If $f''$ is negative definite, then $f$ has a strict local maximum at $c$.
\item If $f''$ is nonpositive definite, then $f$ has a local maximum at $c$.
\item If $f''$ is positive definite, then $f$ has a strict local minimum at $c$.
\item If $f''$ is nonnegative definite, then $f$ has a local minimum at $c$.
\item If $f''$ is indefinite, then $f$ has no local exteme at $c$.
\eit
\sssc{Concavity (凹性)}
Let $V$ be a vector space and function $f\colon J\subseteq V\to\bbR$ be continuous on a convex set $I\subseteq J$.
\bit
\item If for any $x,y\in I$ and $\alpha\in(0,1)$, $f((1-\alpha)x+\alpha y)<(1-\alpha)f(x)+\alpha f(y)$, often called "$f$ lies strictly below all of its secant lines on $I$", then $f$ is called to be strictly concave up/upward/upwards (CU), strictly convex, strictly convex up/upward/upwards, or strictly cup-shaped.
\item If for any $x,y\in I$ and $\alpha\in(0,1)$, $f((1-\alpha)x+\alpha y)>(1-\alpha)f(x)+\alpha f(y)$, often called "$f$ lies strictly above all its secant lines on $I$", then $f$ is called to be strictly concave, strictly concave down/downward/downwards (CD), strictly convex down/downward/downwards, or strictly cap-shaped.
\item If for any $x,y\in I$ and $\alpha\in(0,1)$, $f((1-\alpha)x+\alpha y)\leq (1-\alpha)f(x)+\alpha f(y)$, often called "$f$ lies weakly below all of its secant lines on $I$", then $f$ is called to be weakly concave up/upward/upwards (CU), weakly convex, weakly convex up/upward/upwards, or weakly cup-shaped.
\item If for any $x,y\in I$ and $\alpha\in(0,1)$, $f((1-\alpha)x+\alpha y)\geq (1-\alpha)f(x)+\alpha f(y)$, often called "$f$ lies weakly above all of its secant lines on $I$", then $f$ is called to be weakly concave, weakly concave down/downward/downwards (CD), weakly convex down/downward/downwards, or weakly cap-shaped.
\eit
The terms without weakly and strictly are define to be either weakly or strictly in different contexts; here we define them to be strictly.
\sssc{Point of inflection or inflection point (反曲點 or 拐點)}
Let $V$ be a vector space, $f\colon J\subseteq V\to\bbR$ be a function, and $I\subseteq J$ be a convex set. If $f$ is concave upward on $(a,b)$ and concave downward on $(b,c)$, or, concave downward on $(a,b)$ and concave upward on $(b,c)$, then $(b,f(b))$ is called an inflection point of $f$.
\sssc{First Derivative Test for Concavity Theorem}
Let $f\colon I\subseteq\bbR\to\bbR$ be a function and $(a,b)\subseteq I$ be an open interval.
\bit
\item If $f'$ is strictly increasing on $(a,b)$, often called "$f$ lies strictly below all its tagent lines on $(a,b)$", then $f$ is strictly concave upward on $(a,b)$.
\item If $f'$ is strictly increasing on $(a,b)$ and $f$ is continuous on $[a,b)$, then $f$ is strictly concave upward on $[a,b)$.
\item If $f'$ is strictly increasing on $(a,b)$ and $f$ is continuous on $(a,b]$, then $f$ is strictly concave upward on $(a,b]$.
\item If $f'$ is strictly decreasing on $I$, often called "$f$ lies strictly above all its tagent lines on $(a,b)$", then $f$ is strictly concave downward on $(a,b)$.
\item If $f'$ is strictly decreasing on $(a,b)$ and $f$ is continuous on $[a,b)$, then $f$ is strictly concave downward on $[a,b)$.
\item If $f'$ is strictly decreasing on $(a,b)$ and $f$ is continuous on $(a,b]$, then $f$ is strictly concave downward on $(a,b]$.
\item $f'$ is non-decreasing on $(a,b)$, often called "$f$ lies weakly below all its tagent lines on $(a,b)$", iff $f$ is weakly concave upward on $(a,b)$.
\item If $f'$ is non-decreasing on $(a,b)$ and $f$ is continuous on $[a,b)$, then $f$ is weakly concave upward on $[a,b)$.
\item If $f'$ is non-decreasing on $(a,b)$ and $f$ is continuous on $(a,b]$, then $f$ is weakly concave upward on $(a,b]$.
\item $f'$ is non-increasing on $(a,b)$, often called "$f$ lies weakly above all its tagent lines on $(a,b)$", iff $f$ is weakly concave downward on $(a,b)$.
\item If $f'$ is non-increasing on $(a,b)$ and $f$ is continuous on $[a,b)$, then $f$ is weakly concave downward on $[a,b)$.
\item If $f'$ is non-increasing on $(a,b)$ and $f$ is continuous on $(a,b]$, then $f$ is weakly concave downward on $(a,b]$.
\eit
\begin{proof}
    For the first statement, we want to show that for any $c,d\in (a,b)$ and $\alpha\in(0,1)$, $f((1-\alpha)c+\alpha d)<(1-\alpha)f(c)+\alpha f(d)$ if for any $a\leq A<B\leq b$, $f'(A)<f'(B)$.

    Fix any $a\leq c<x<d\leq b$. By MVT, there exists $A\in (c,x)$ such that
    \[f'(A)=\frac{f(x)-f(c)}{x-c}.\]
    By MVT, there exists $B\in (b,c)$ such that
    \[f'(B)=\frac{f(d)-f(x)}{d-x}.\]
    Since $A<B$, $f'(A)\leq f'(B)$.
    \[\frac{f(x)-f(c)}{x-c}\leq\frac{f(d)-f(x)}{d-x}.\]
    \[(f(x)-f(c))(d-x)\leq(f(d)-f(x))(x-c).\]
    \[(d-c)f(x)\leq(d-x)f(c)+(x-c)f(d).\]
    \[f(x)\leq\frac{(d-x)}{(d-c)}f(c)+\frac{(x-c)}{(d-c)}f(d).\]
    Set
    \[\alpha=\frac{(x-c)}{(d-c)}\in(0,1).\]
    Then
    \[x=(1-\alpha)c+\alpha d.\]
    Thus the inequality becomes
    \[f\qty((1-\alpha)c+\alpha d)\leq(1-\alpha)f(c)+\alpha f(d).\]
    
    For the second statement, argue by contradiction. Assume that there exists $d\in(a,b)$ and $\alpha\in(0,1)$ such that
    \[f((1-\alpha)a+\alpha d)\geq (1-\alpha)f(a)+\alpha f(d).\]
    Let $x=(1-\alpha)a+\alpha d$.
    \[f(x)-f(a)\geq\alpha(f(d)-f(a)).\]
    By MVT, there exists $B\in (a,x)$ such that
    \[f(x)-f(a)=f'(B)(x-a)=f'(B)\alpha (d-a).\]
    By MVT, there exists $c\in (x,d)$ such that
    \[f(d)-f(x)=f'(C)(d-x)=f'(C)(1-\alpha)(d-a).\]
    \[f(d)-f(a)=(f'(B)\alpha+f'(C)(1-\alpha))(d-a).\]
    \[f(x)-f(a)=f'(B)\alpha (d-a)\geq\alpha(f'(B)\alpha+f'(C)(1-\alpha))(d-a).\]
    \[f'(B)\geq f'(B)\alpha+f'(C)(1-\alpha).\]
    \[f'(B)\geq f'(C).\]
    This contradicts the condition that $B<C\implies f'(B)<f'(C)$ for any $a<B<C<b$.
    
    The third statement can be proven similarly.
    
    The "if" directions of the other statements can be proven similarly.
    
    For the "only if" direction of the seventh statement, we want to show that for any $c,d\in (a,b)$ and $\alpha\in(0,1)$, $f((1-\alpha)c+\alpha d)\leq (1-\alpha)f(c)+\alpha f(d)$ if $\forall c,d\in (a,b)\colon c<d\implies f'(c)\leq f'(d)$.
    
    Fix any $c,d\in(a,b)$ with $c<d$.
    
    By MVT, there exists $g\in(c,((1-\alpha)c+\alpha d))$ such that
    \[f((1-\alpha)c+\alpha d)-f(c)=f'(g)((1-\alpha)c+\alpha d-c)=f'(g)\alpha(d-c).\]
    By MVT, there exists $h\in(((1-\alpha)c+\alpha d)),d)$ such that
    \[f(d)-f((1-\alpha)c+\alpha d)=f'(h)(d-(1-\alpha)c-\alpha d)=f'(h)(1-\alpha)(d-c).\]
    Thus,
    \[f((1-\alpha)c+\alpha d)=f(c)+f'(g)\alpha(d-c)=f(d)-f'(h)(1-\alpha)(d-c).\]
    \[f'(g)\alpha+f'(h)(1-\alpha)=\frac{f(d)-f(c)}{d-c}.\]
    Because $f'(g)\leq f'(h)$, we have
    \[f'(g)(d-c)\leq f(d)-f(c).\]
    Substitute:
    \[f((1-\alpha)c+\alpha d)\leq f(c)+\alpha(f(d)-f(c))=(1-\alpha)f(c)+\alpha f(d).\]
    The "only if" direction of the tenth statement can be proven similarly.
\end{proof}
\sssc{Concavity Test Theorem or Second Derivative Test for Concavity Theorem}
Let function $f\colon I\subseteq\bbR\to\bbR$ be twice differentiable on an open interval $(a,b)\subseteq I$.
\bit
\item If $f''>0$ for any $x\in (a,b)$, then the graph of $f$ is strictly concave upward on $(a,b)$.
\item If $f''>0$ for any $x\in (a,b)$ and $f'$ is continuous on $[a,b)$, then the graph of $f$ is strictly concave upward on $[a,b)$.
\item If $f''>0$ for any $x\in (a,b)$ and $f'$ is continuous on $(a,b]$, then the graph of $f$ is strictly concave upward on $(a,b]$.
\item If $f''<0$ for any $x\in (a,b)$, then the graph of $f$ is strictly concave downward on $(a,b)$.
\item If $f''<0$ for any $x\in (a,b)$ and $f'$ is continuous on $[a,b)$, then the graph of $f$ is strictly concave downward on $[a,b)$.
\item If $f''<0$ for any $x\in (a,b)$ and $f'$ is continuous on $(a,b]$, then the graph of $f$ is strictly concave downward on $(a,b]$.
\item $f''\geq 0$ for any $x\in (a,b)$ iff the graph of $f$ is weakly concave upward on $(a,b)$.
\item If $f''\geq 0$ for any $x\in (a,b)$ and $f'$ is continuous on $[a,b)$, then the graph of $f$ is weakly concave upward on $[a,b)$.
\item If $f''\geq 0$ for any $x\in (a,b)$ and $f'$ is continuous on $(a,b]$, then the graph of $f$ is weakly concave upward on $(a,b]$.
\item $f''\leq 0$ for any $x\in (a,b)$ iff the graph of $f$ is weakly concave downward on $(a,b)$.
\item If $f''\leq 0$ for any $x\in (a,b)$ and $f'$ is continuous on $[a,b)$, then the graph of $f$ is weakly concave downward on $[a,b)$.
\item If $f''\leq 0$ for any $x\in (a,b)$ and $f'$ is continuous on $(a,b]$, then the graph of $f$ is weakly concave downward on $(a,b]$.
\eit
\begin{proof}
By Increasing/Decreasing Test Theorem and First Derivative Test for Concavity Theorem, it is obvious.
\end{proof}
\sssc{Inflection Point Theorem}
Let $f\colon I\subseteq\bbR\to\bbR$ be a function. If $(c,f(c))$ is an inflection point of $f$ and $f$ is differentiable at $c$, then $c$ is a critical point of $f'$.
\begin{proof}
By the First Derivative Test for Concavity Theorem, it is obvious.
\end{proof}
\sssc{Kink}
A kink is a point $x$ on the graph of a real function $f$ such that $f$ is continuous but not differentiable at $x$.
\sssc{Corner or sharp corner}
A corner or sharp corner is a point $x$ on the graph of a real function $f$ such that $f$ is continuous but not differentiable at $x$ and that the left-hand derivative and the right-hand derivative of $f$ at $x$ both exist and are finite.
\sssc{Vertical tangent}
A vertical tangent is a point $x$ on the graph of a real function $f$ such that $f$ is continuous at $x$ and that the left-hand derivative and the right-hand derivative of $f$ at $x$ are both $\infty$ or are both $-\infty$.
\sssc{Cusp}
A cusp is a point $x$ on the graph of a real function $f$ such that:
\bit
\item $f$ is continuous at $x$,
\item at least one of the left-hand derivative and the right-hand derivative of $f$ at $x$ are $\infty$ or $-\infty$,
\item $x$ is not a vertical tangent of $f$, and
\item the left-hand derivative and the right-hand derivative of $f$ at $x$ are both either finite, $\infty$, or $-\infty$.
\eit
\ssc{Indeterminate forms and L'Hôpital's rule (羅必達法則) or Bernoulli's rule}
\sssc{(General form of) L'Hôpital's rule or Bernoulli's rule and indeterminate quotients}
Let $I$ be an open interval and $a\in I$, and $f(x)$ and $g(x)$ be functions differentiable on $I\setminus\{a\}$. If
\bit
\item $\lim_{x\to a}f(x)=\lim_{x\to a}g(x)=0$, where $\lim_{x\to a}\frac{f(x)}{g(x)}$ is called indeterminate form of type $\frac{0}{0}$, or $\abs{\lim_{x\to a}f(x)}=\abs{\lim_{x\to a}g(x)}=\infty$, where $\lim_{x\to a}\frac{f(x)}{g(x)}$ is called indeterminate form of type $\frac{\infty}{\infty}$, and
\item $\lim_{x\to a}\frac{f'(x)}{g'(x)}\in\mathbb{R}\cup\{-\infty,\infty\}$,
\eit
then:
\[\lim_{x\to a}\frac{f(x)}{g(x)}=\lim_{x\to a}\frac{f'(x)}{g'(x)}.\]

Let $f(x)$ and $g(x)$ be functions differentiable on $(a,b)$ with $a<b$. If
\bit
\item $\lim_{x\to a^+}f(x)=\lim_{x\to a^+}g(x)=0$, where $\lim_{x\to a^+}\frac{f(x)}{g(x)}$ is called indeterminate form of type $\frac{0}{0}$, or $\abs{\lim_{x\to a^+}f(x)}=\abs{\lim_{x\to a^+}g(x)}=\infty$, where $\lim_{x\to a^+}\frac{f(x)}{g(x)}$ is called indeterminate form of type $\frac{\infty}{\infty}$, and
\item $\lim_{x\to a^+}\frac{f'(x)}{g'(x)}\in\mathbb{R}\cup\{-\infty,\infty\}$,
\eit
then:
\[\lim_{x\to a^+}\frac{f(x)}{g(x)}=\lim_{x\to a^+}\frac{f'(x)}{g'(x)}.\]

Let $f(x)$ and $g(x)$ be functions differentiable on $(b,a)$ with $a>b$. If
\bit
\item $\lim_{x\to a^-}f(x)=\lim_{x\to a^-}g(x)=0$, where $\lim_{x\to a^-}\frac{f(x)}{g(x)}$ is called indeterminate form of type $\frac{0}{0}$, or $\abs{\lim_{x\to a^-}f(x)}=\abs{\lim_{x\to a^-}g(x)}=\infty$, where $\lim_{x\to a^-}\frac{f(x)}{g(x)}$ is called indeterminate form of type $\frac{\infty}{\infty}$, and
\item $\lim_{x\to a^-}\frac{f'(x)}{g'(x)}\in\mathbb{R}\cup\{-\infty,\infty\}$,
\eit
then:
\[\lim_{x\to a^-}\frac{f(x)}{g(x)}=\lim_{x\to a^-}\frac{f'(x)}{g'(x)}.\]

Let $f(x)$ and $g(x)$ be functions differentiable on $(a,\infty)$. If
\bit
\item $\lim_{x\to\infty}f(x)=\lim_{x\to\infty}g(x)=0$, where $\lim_{x\to\infty}\frac{f(x)}{g(x)}$ is called indeterminate form of type $\frac{0}{0}$, or $\abs{\lim_{x\to\infty}f(x)}=\abs{\lim_{x\to\infty}g(x)}=\infty$, where $\lim_{x\to\infty}\frac{f(x)}{g(x)}$ is called indeterminate form of type $\frac{\infty}{\infty}$, and
\item $\lim_{x\to\infty}\frac{f'(x)}{g'(x)}\in\mathbb{R}\cup\{-\infty,\infty\}$,
\eit
then:
\[\lim_{x\to\infty}\frac{f(x)}{g(x)}=\lim_{x\to\infty}\frac{f'(x)}{g'(x)}.\]

Let $f(x)$ and $g(x)$ be functions differentiable on $(-\infty,a)$. If
\bit
\item $\lim_{x\to -\infty}f(x)=\lim_{x\to -\infty}g(x)=0$, where $\lim_{x\to -\infty}\frac{f(x)}{g(x)}$ is called indeterminate form of type $\frac{0}{0}$, or $\abs{\lim_{x\to -\infty}f(x)}=\abs{\lim_{x\to -\infty}g(x)}=\infty$, where $\lim_{x\to -\infty}\frac{f(x)}{g(x)}$ is called indeterminate form of type $\frac{\infty}{\infty}$, and
\item $\lim_{x\to -\infty}\frac{f'(x)}{g'(x)}\in\mathbb{R}\cup\{-\infty,\infty\}$,
\eit
then:
\[\lim_{x\to -\infty}\frac{f(x)}{g(x)}=\lim_{x\to -\infty}\frac{f'(x)}{g'(x)}.\]
\begin{proof}
Let $f(x)$ and $g(x)$ be functions differentiable on $(a,b)$ with $a<b$. We want to show that if $\lim_{x\to a^+}f(x)=\lim_{x\to a^+}g(x)=0$ and $\lim_{x\to a^+}\frac{f'(x)}{g'(x)}\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to a^+}\frac{f(x)}{g(x)}=\lim_{x\to a^+}\frac{f'(x)}{g'(x)}.\]
Because the existence of the limits, we know that there exists interval $(a,c)$ such that $g(x)$ and $g'(x)$ both $\neq 0$ on $(a,c)$. Let
\[F(x)=\begin{cases}f(x),\quad & x\in (a,c)\\
0,\quad & x=a\end{cases}\]
and
\[G(x)=\begin{cases}g(x),\quad & x\in (a,c)\\
0,\quad & x=a\end{cases}\]
By CMVT, for any $x\in (a,c)$, there exists $c\in (a,x)$ such that
\[\qty(F(x)-F(a))G'(c)=\qty(G(x)-G(a))F'(c).\]
Since $F(a)=G(a)=0$,
\[F(x)G'(c)=G(x)F'(c).\]
Thus,
\[\lim_{x\to a^+}\frac{f(x)}{g(x)}=\lim_{x\to a^+}\frac{F(x)}{G(x)}=\lim_{x\to a^+}\frac{F'(x)}{G'(x)}=\lim_{x\to a^+}\frac{f'(x)}{g'(x)}.\]

Let $f(x)$ and $g(x)$ be functions differentiable on $(a,b)$ with $a<b$. We want to show that if $\lim_{x\to a^+}f(x)=\lim_{x\to a^+}g(x)=\infty$ and $\lim_{x\to a^+}\frac{f'(x)}{g'(x)}\in\mathbb{R}\cup\{-\infty,\infty\}$, then
\[\lim_{x\to a^+}\frac{f(x)}{g(x)}=\lim_{x\to a^+}\frac{f'(x)}{g'(x)}.\]
Because $\lim_{x\to a^+}f(x)=\lim_{x\to a^+}g(x)=\infty$, by quotient law, we know that
\[\lim_{x\to a^+}\frac{1}{f(x)}=\lim_{x\to a^+}\frac{1}{g(x)}=0.\]
Because the existence of the limits, there exists interval $(a,c)$ such that $\frac{1}{f(x)}$ and $\frac{1}{g(x)}$ both $\neq 0$ on $(a,c)$. Let
\[F(x)=\begin{cases}\frac{1}{f(x)},\quad & x\in (a,b)\\
0,\quad & x=a\end{cases}\]
and
\[G(x)=\begin{cases}\frac{1}{g(x)},\quad & x\in (a,b)\\
0,\quad & x=a\end{cases}\]
\[F'(x)=\frac{-f'(x)}{\qty(f(x))^2}.\]
\[G'(x)=\frac{-g'(x)}{\qty(g(x))^2}.\]
By CMVT, for any $x\in (a,c)$, there exists $c\in (a,x)$ such that
\[\qty(F(x)-F(a))G'(c)=\qty(G(x)-G(a))F'(c).\]
Since $F(a)=G(a)=0$,
\[F(x)G'(c)=G(x)F'(c).\]
Thus,
\[\ba
\lim_{x\to a^+}\frac{f(x)}{g(x)}&=\lim_{x\to a^+}\frac{G(x)}{F(x)}=\lim_{x\to a^+}\frac{G'(x)}{F'(x)}\\
&=\lim_{x\to a^+}\frac{g'(x)}{f'(x)}\lim_{x\to a^+}\qty(\frac{f(x)}{g(x)})^2
\ea\]
\[\lim_{x\to a^+}\frac{f(x)}{g(x)}=\lim_{x\to a^+}\frac{f'(x)}{g'(x)}.\]

All other statements can be proven either similarly or by applying other statements.
\end{proof}
\sssc{Indeterminate products}
Let $I$ be an open interval and $a\in I$, and $f(x)$ and $g(x)$ be functions differentiable on $I\setminus\{a\}$. If $\lim_{x\to a}f(x)=0$ and $\abs{\lim_{x\to a}g(x)}=\infty$, where $\lim_{x\to a}f(x)g(x)$ is called indeterminate form of type $0\cdot\infty$, we may find $\lim_{x\to a}f(x)g(x)$ by writing the product $f(x)g(x)$ as a quotient:
\[fg=\frac{f}{1/g},\quad\tx{or\ }fg=\frac{g}{1/f}\]
and use general form of L'Hôpital's rule.

Let $f(x)$ and $g(x)$ be functions differentiable on $(a,b)$ with $a<b$. If $\lim_{x\to a^+}f(x)=0$ and $\abs{\lim_{x\to a^+}g(x)}=\infty$, where $\lim_{x\to a^+}f(x)g(x)$ is called indeterminate form of type $0\cdot\infty$, we may find $\lim_{x\to a^+}f(x)g(x)$ by writing the product $f(x)g(x)$ as a quotient:
\[fg=\frac{f}{1/g},\quad\tx{or\ }fg=\frac{g}{1/f}\]
and use general form of L'Hôpital's rule.

Let $f(x)$ and $g(x)$ be functions differentiable on $(b,a)$ with $a>b$. If $\lim_{x\to a^-}f(x)=0$ and $\abs{\lim_{x\to a^-}g(x)}=\infty$, where $\lim_{x\to a^-}f(x)g(x)$ is called indeterminate form of type $0\cdot\infty$, we may find $\lim_{x\to a^-}f(x)g(x)$ by writing the product $f(x)g(x)$ as a quotient:
\[fg=\frac{f}{1/g},\quad\tx{or\ }fg=\frac{g}{1/f}\]
and use general form of L'Hôpital's rule.

Let $f(x)$ and $g(x)$ be functions differentiable on $(a,\infty)$. If $\lim_{x\to\infty}f(x)=0$ and $\abs{\lim_{x\to\infty}g(x)}=\infty$, where $\lim_{x\to\infty}f(x)g(x)$ is called indeterminate form of type $0\cdot\infty$, we may find $\lim_{x\to\infty}f(x)g(x)$ by writing the product $f(x)g(x)$ as a quotient:
\[fg=\frac{f}{1/g},\quad\tx{or\ }fg=\frac{g}{1/f}\]
and use general form of L'Hôpital's rule.

Let $f(x)$ and $g(x)$ be functions differentiable on $(-\infty,a)$. If $\lim_{x\to -\infty}f(x)=0$ and $\abs{\lim_{x\to -\infty}g(x)}=\infty$, where $\lim_{x\to -\infty}f(x)g(x)$ is called indeterminate form of type $0\cdot\infty$, we may find $\lim_{x\to -\infty}f(x)g(x)$ by writing the product $f(x)g(x)$ as a quotient:
\[fg=\frac{f}{1/g},\quad\tx{or\ }fg=\frac{g}{1/f}\]
and use general form of L'Hôpital's rule.
\sssc{Indeterminate differences}
Let $I$ be an open interval and $a\in I$, and $f(x)$ and $g(x)$ be functions differentiable on $I\setminus\{a\}$. If $\lim_{x\to a}f(x)=\lim_{x\to a}g(x)\in\{\infty,-\infty\}$, where $\lim_{x\to a}\qty(f(x)-g(x))$ is called indeterminate form of type $\infty-\infty$, we may find $\lim_{x\to a}\qty(f(x)-g(x))$ by writing the difference $f(x)-g(x)$ as a quotient and use general form of L'Hôpital's rule.

Let $f(x)$ and $g(x)$ be functions differentiable on $(a,b)$ with $a<b$. If $\lim_{x\to a^+}f(x)=\lim_{x\to a^+}g(x)\in\{\infty,-\infty\}$, where $\lim_{x\to a^+}\qty(f(x)-g(x))$ is called indeterminate form of type $\infty-\infty$, we may find $\lim_{x\to a^+}\qty(f(x)-g(x))$ by writing the difference $f(x)-g(x)$ as a quotient and use general form of L'Hôpital's rule.

Let $f(x)$ and $g(x)$ be functions differentiable on $(b,a)$ with $a>b$. If $\lim_{x\to a^-}f(x)=\lim_{x\to a^-}g(x)\in\{\infty,-\infty\}$, where $\lim_{x\to a^-}\qty(f(x)-g(x))$ is called indeterminate form of type $\infty-\infty$, we may find $\lim_{x\to a^-}\qty(f(x)-g(x))$ by writing the difference $f(x)-g(x)$ as a quotient and use general form of L'Hôpital's rule.

Let $f(x)$ and $g(x)$ be functions differentiable on $(a,\infty)$. If $\lim_{x\to\infty}f(x)=\lim_{x\to\infty}g(x)\in\{\infty,-\infty\}$, where $\lim_{x\to\infty}\qty(f(x)-g(x))$ is called indeterminate form of type $\infty-\infty$, we may find $\lim_{x\to\infty}\qty(f(x)-g(x))$ by writing the difference $f(x)-g(x)$ as a quotient and use general form of L'Hôpital's rule.

Let $f(x)$ and $g(x)$ be functions differentiable on $(-\infty,a)$. If $\lim_{x\to -\infty}f(x)=\lim_{x\to -\infty}g(x)\in\{\infty,-\infty\}$, where $\lim_{x\to -\infty}\qty(f(x)-g(x))$ is called indeterminate form of type $\infty-\infty$, we may find $\lim_{x\to -\infty}\qty(f(x)-g(x))$ by writing the difference $f(x)-g(x)$ as a quotient and use general form of L'Hôpital's rule.
\sssc{Indeterminate powers/exponentials}
Let $I$ be an open interval and $a\in I$, and $f(x)$ and $g(x)$ be functions differentiable on $I\setminus\{a\}$. If $\lim_{x\to a}f(x)=\lim_{x\to a}g(x)=0$, where $\lim_{x\to a}f(x)^{g(x)}$ is called indeterminate form of type $0^0$, we may find $\lim_{x\to a}f(x)^{g(x)}$ by taking natural logarithm:
\[g(x)\ln(f(x)),\]
which is in indeterminate form of $0\cdot\infty$ because $\lim_{x\to a}\ln(f(x))=-\infty$.

Let $I$ be an open interval and $a\in I$, and $f(x)$ and $g(x)$ be functions differentiable on $I\setminus\{a\}$. If $\lim_{x\to a}f(x)=\infty$ and $\lim_{x\to a}g(x)=0$, where $\lim_{x\to a}f(x)^{g(x)}$ is called indeterminate form of type $\infty^0$, we may find $\lim_{x\to a}f(x)^{g(x)}$ by taking natural logarithm:
\[g(x)\ln(f(x)),\]
which is in indeterminate form of $0\cdot\infty$ because $\lim_{x\to a}\ln(f(x))=\infty$.

Let $I$ be an open interval and $a\in I$, and $f(x)$ and $g(x)$ be functions differentiable on $I\setminus\{a\}$. If $\lim_{x\to a}f(x)=1$ and $\lim_{x\to a}g(x)=\infty$, where $\lim_{x\to a}f(x)^{g(x)}$ is called indeterminate form of type $1^{\infty}$, we may find $\lim_{x\to a}f(x)^{g(x)}$ by taking natural logarithm:
\[g(x)\ln(f(x)),\]
which is in indeterminate form of $0\cdot\infty$ because $\lim_{x\to a}\ln(f(x))=0$.

Let $f(x)$ and $g(x)$ be functions differentiable on $(a,b)$ with $a<b$. If $\lim_{x\to a^+}f(x)=\lim_{x\to a^+}g(x)=0$, where $\lim_{x\to a^+}f(x)^{g(x)}$ is called indeterminate form of type $0^0$, we may find $\lim_{x\to a^+}f(x)^{g(x)}$ by taking natural logarithm:
\[g(x)\ln(f(x)),\]
which is in indeterminate form of $0\cdot\infty$ because $\lim_{x\to a^+}\ln(f(x))=-\infty$.

Let $f(x)$ and $g(x)$ be functions differentiable on $(a,b)$ with $a<b$. If $\lim_{x\to a^+}f(x)=\infty$ and $\lim_{x\to a^+}g(x)=0$, where $\lim_{x\to a^+}f(x)^{g(x)}$ is called indeterminate form of type $\infty^0$, we may find $\lim_{x\to a^+}f(x)^{g(x)}$ by taking natural logarithm:
\[g(x)\ln(f(x)),\]
which is in indeterminate form of $0\cdot\infty$ because $\lim_{x\to a^+}\ln(f(x))=\infty$.

Let $f(x)$ and $g(x)$ be functions differentiable on $(a,b)$ with $a<b$. If $\lim_{x\to a^+}f(x)=1$ and $\lim_{x\to a^+}g(x)=\infty$, where $\lim_{x\to a^+}f(x)^{g(x)}$ is called indeterminate form of type $1^{\infty}$, we may find $\lim_{x\to a^+}f(x)^{g(x)}$ by taking natural logarithm:
\[g(x)\ln(f(x)),\]
which is in indeterminate form of $0\cdot\infty$ because $\lim_{x\to a^+}\ln(f(x))=0$.

Let $f(x)$ and $g(x)$ be functions differentiable on $(b,a)$ with $a>b$. If $\lim_{x\to a^-}f(x)=\lim_{x\to a^-}g(x)=0$, where $\lim_{x\to a^-}f(x)^{g(x)}$ is called indeterminate form of type $0^0$, we may find $\lim_{x\to a^-}f(x)^{g(x)}$ by taking natural logarithm:
\[g(x)\ln(f(x)),\]
which is in indeterminate form of $0\cdot\infty$ because $\lim_{x\to a^-}\ln(f(x))=-\infty$.

Let $f(x)$ and $g(x)$ be functions differentiable on $(b,a)$ with $a>b$. If $\lim_{x\to a^-}f(x)=\infty$ and $\lim_{x\to a^-}g(x)=0$, where $\lim_{x\to a^-}f(x)^{g(x)}$ is called indeterminate form of type $\infty^0$, we may find $\lim_{x\to a^-}f(x)^{g(x)}$ by taking natural logarithm:
\[g(x)\ln(f(x)),\]
which is in indeterminate form of $0\cdot\infty$ because $\lim_{x\to a^-}\ln(f(x))=\infty$.

Let $f(x)$ and $g(x)$ be functions differentiable on $(b,a)$ with $a>b$. If $\lim_{x\to a^-}f(x)=1$ and $\lim_{x\to a^-}g(x)=\infty$, where $\lim_{x\to a^-}f(x)^{g(x)}$ is called indeterminate form of type $1^{\infty}$, we may find $\lim_{x\to a^-}f(x)^{g(x)}$ by taking natural logarithm:
\[g(x)\ln(f(x)),\]
which is in indeterminate form of $0\cdot\infty$ because $\lim_{x\to a^-}\ln(f(x))=0$.

Let $f(x)$ and $g(x)$ be functions differentiable on $(a,\infty)$. If $\lim_{x\to\infty}f(x)=\lim_{x\to\infty}g(x)=0$, where $\lim_{x\to\infty}f(x)^{g(x)}$ is called indeterminate form of type $0^0$, we may find $\lim_{x\to\infty}f(x)^{g(x)}$ by taking natural logarithm:
\[g(x)\ln(f(x)),\]
which is in indeterminate form of $0\cdot\infty$ because $\lim_{x\to\infty}\ln(f(x))=-\infty$.

Let $f(x)$ and $g(x)$ be functions differentiable on $(a,\infty)$. If $\lim_{x\to\infty}f(x)=\infty$ and $\lim_{x\to\infty}g(x)=0$, where $\lim_{x\to\infty}f(x)^{g(x)}$ is called indeterminate form of type $\infty^0$, we may find $\lim_{x\to\infty}f(x)^{g(x)}$ by taking natural logarithm:
\[g(x)\ln(f(x)),\]
which is in indeterminate form of $0\cdot\infty$ because $\lim_{x\to\infty}\ln(f(x))=\infty$.

Let $f(x)$ and $g(x)$ be functions differentiable on $(a,\infty)$. If $\lim_{x\to\infty}f(x)=1$ and $\lim_{x\to\infty}g(x)=\infty$, where $\lim_{x\to\infty}f(x)^{g(x)}$ is called indeterminate form of type $1^{\infty}$, we may find $\lim_{x\to\infty}f(x)^{g(x)}$ by taking natural logarithm:
\[g(x)\ln(f(x)),\]
which is in indeterminate form of $0\cdot\infty$ because $\lim_{x\to\infty}\ln(f(x))=0$.

Let $f(x)$ and $g(x)$ be functions differentiable on $(-\infty,a)$. If $\lim_{x\to -\infty}f(x)=\lim_{x\to -\infty}g(x)=0$, where $\lim_{x\to -\infty}f(x)^{g(x)}$ is called indeterminate form of type $0^0$, we may find $\lim_{x\to -\infty}f(x)^{g(x)}$ by taking natural logarithm:
\[g(x)\ln(f(x)),\]
which is in indeterminate form of $0\cdot\infty$ because $\lim_{x\to -\infty}\ln(f(x))=-\infty$.

Let $f(x)$ and $g(x)$ be functions differentiable on $(-\infty,a)$. If $\lim_{x\to -\infty}f(x)=\infty$ and $\lim_{x\to -\infty}g(x)=0$, where $\lim_{x\to -\infty}f(x)^{g(x)}$ is called indeterminate form of type $\infty^0$, we may find $\lim_{x\to -\infty}f(x)^{g(x)}$ by taking natural logarithm:
\[g(x)\ln(f(x)),\]
which is in indeterminate form of $0\cdot\infty$ because $\lim_{x\to -\infty}\ln(f(x))=\infty$.

Let $f(x)$ and $g(x)$ be functions differentiable on $(-\infty,a)$. If $\lim_{x\to -\infty}f(x)=1$ and $\lim_{x\to -\infty}g(x)=\infty$, where $\lim_{x\to -\infty}f(x)^{g(x)}$ is called indeterminate form of type $1^{\infty}$, we may find $\lim_{x\to -\infty}f(x)^{g(x)}$ by taking natural logarithm:
\[g(x)\ln(f(x)),\]
which is in indeterminate form of $0\cdot\infty$ because $\lim_{x\to -\infty}\ln(f(x))=0$.
\subsection{Lagrange multiplier (method) (拉格朗日乘數/乘子（法）)}
The Lagrange multiplier method is a method for finding the points where extremes occur of a differentiable function under constraints.
\sssc{Univariate form}
Let $f:\,\mathbb{R} \rightarrow \mathbb{R}$ and $g:\,\mathbb{R} \rightarrow \mathbb{R}$ . We want to find the points where extremes of \( f(x) \) under the constraint \( g(x) = \mathbf{0} \) occur. 

First, construct the Lagrangian function \( \mathcal{L}(x,\lambda) \):
\[\mathcal{L}(x,\lambda) = f(x) - \lambda \cdot g(x),\]
where \( \lambda\in\mathbb{R} \) is the Lagrange multiplier (拉格朗日乘數 or 乘子).

Find the derivative of $\mathcal{L}$ and set it to zero:
\[
\dv{\mathcal{L}}{x} = 0
\]
Solve the equation to find \( x \) and \( \lambda \) . 

\text{Statement:} Let $A$ be the set of all solutions for \( x \) such that $\dv{\mathcal{L}}{x} = 0$, and $B$ be the set of all points where extremes of \( f(x) \) under the constraint \( g(x) = \mathbf{0} \) occur. We claim that $B\subseteq A$.
\sssc{Multivariate form}
Let \( \mathbf{x} = (x_1, x_2, \dots, x_n) \) be the independent variable vector and $\mathbf{0}$ be the zero vector. Now we have $f:\,\mathbb{R}^n \rightarrow \mathbb{R}$ and $g:\,\mathbb{R}^n \rightarrow \mathbb{R}^c$. We want to find the points where extremes of \( f(\mathbf{x}) \) under the constraint \( g(\mathbf{x}) = \mathbf{0}\) occur. 

First, construct the Lagrangian function \( \mathcal{L}(\mathbf{x},\lambda) \):
\[
\mathcal{L}(\mathbf{x},\lambda) = f(\mathbf{x}) - \lambda \cdot g(\mathbf{x}),
\]
where \( \lambda\in\mathbb{R}^c \) is the Lagrange multiplier vector.

Find the gradient of $\mathcal{L}$ and set it to zero:
\[
\nabla \mathcal{L} = \mathbf{0}
\]
Solve the equation to find \( \mathbf{x} \) and \( \lambda \) . 

\text{Statement:} Let $A$ be the set of all solutions for \( \mathbf{x} \) such that $\nabla \mathcal{L} = \mathbf{0}$, and $B$ be the set of all points where extremes of \( f(\mathbf{x}) \) under the constraint \( g(\mathbf{x}) = \mathbf{0}\) occur. We claim that $B\subseteq A$.
\begin{proof}
Consider $\mathbf{x}^*\in B$. It must satisfy the constraint:
\[g(\mathbf{x}^*) = \mathbf{0}.\]
Any feasible point $\mathbf{x}$ near $\mathbf{x}^*$ must satisfy the constraint. We can represent $\mathbf{x}$ as:
\[\mathbf{x} = \mathbf{x}^* + \delta\mathbf{x},\]
where $\delta\mathbf{x}$ is a differential change tangent to the manifold defined by $g(\mathbf{x})$, that is, it lies in the kernel of $\nabla g(\mathbf{x}^*)$, that is,
\[g(\mathbf{x}^* + \delta\mathbf{x}) = \mathbf{0}.\]
Find the first-order approximation of $f$ at $\mathbf{x}^*$:
\[f(\mathbf{x}^*+ \delta\mathbf{x}) \approx f(\mathbf{x}^*) + \nabla f(\mathbf{x}^*) \cdot \delta\mathbf{x} + O(\|\delta\mathbf{x}\|^2)\]
Find the first-order approximation of $g$ at $\mathbf{x}^*$:
\[g(\mathbf{x}^*+ \delta\mathbf{x}) \approx g(\mathbf{x}^*) + \nabla g(\mathbf{x}^*) \cdot \delta\mathbf{x} + O(\|\delta\mathbf{x}\|^2)\]
Since $\mathbf{x}^*\in B$, for any feasible $\delta\mathbf{x}$ we must have:
\[\nabla f(\mathbf{x}^*) \cdot \delta\mathbf{x} = 0.\]
Since $g(\mathbf{x}^*) = \mathbf{0}$, we have
\[\nabla g(\mathbf{x}^*) \cdot \delta\mathbf{x} = O(\|\delta\mathbf{x}\|^2).\]
Because \( \delta\mathbf{x} \in \ker(\nabla g(\mathbf{x}^)) \), \( \nabla f(\mathbf{x}^) \) can be expressed as a linear combination of \( \nabla g(\mathbf{x}^) \) . This means that there exists a vector to $\lambda$ such that:
\[\nabla\mathcal{L} = \nabla \qty(f(\mathbf{x}) - \lambda \cdot g(\mathbf{x})) = \mathbf{0} \]
\end{proof}
\ssc{Generalized Schwarz's Theorem, Young's Theorem, or Clairaut's Theorem on equality or symmetry of mixed partial derivatives}
For a function $f\colon\Omega\subseteq\mathbb{R}^n\to\mathbb{R}^o$ and any $m$th derivative function $g$ of it given by
\[g=\frac{\partial^mf}{\prod_{k=1}^r\partial x_{i_k}^{\phantom{i_k}m_k}}\]
with $\sum_{k=1}^rm_k=m$ and $i_k\in\mathbb{N}\land i_k\leq n$ for all $k$. Define constants $t_q$ for all $q\in\mathbb{N}\land q\leq n$ as $t_q=\sum_{i_k=q}m_k$. 

If any such $g$ exists in a neighborhood of $\mathbf{p}\in\Omega$ and is continuous at $\mathbf{p}$, then all such $g$ with the same $t_q$ for all $q\in\mathbb{N}\land q\leq n$ are equal at $\mathbf{p}$.
\ssc{Numerical differentiation (數值微分)}
\sssc{Newton's Method (牛頓法) or Newton-Raphson Method (牛頓-拉普森法)}
Newton's method, also known as Newton-Raphson method, is an iterative technique used to approximate the roots of a real-valued function. Given a function $f(x)$ and an initial guess \( x_0 \), Newton's method refines this guess by repeatedly applying the formula:
\[
x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)},\quad n\in\mathbb{N}
\]
where:
\begin{itemize}
\item \( x_n \) is the current approximation,
\item \( f(x_n) \) is the value of the function at \( x_n \),
\item \( f'(x_n) \) is the derivative of \( f(x) \) evaluated at \( x_n \).
\end{itemize}
PLACEHOLDER: Newton's method converges quadratically or faster if and proof
PLACEHOLDER: Given convergence, suppose that we want the error to be less than a given value $v$, we can take $x_n$ such that $\abs{x_n-x_{n-1}}<v$?



\section{Integral theorems and methods}
\ssc{Linearity, or sum rule, difference rule, and constant multiple rule}
If functions $f$ and $g$ are integrable over an interval $I$ and $a,b\in\mathbb{R}$, then $af(x)+bg(x)$ is also integrable over $I$ and its integral is given by
\[\int_Iaf(x)+bg(x)\dd{x}=a\int_If(x)\dd{x}+b\int_Ig(x)\dd{x}.\]
\ssc{Integrals of Symmetric Functions}
Suppose real function $f$ is Riemann integrable on $[-a,a]$.
\bit
\item If $f$ is an even function, that is, $f(-x)=f(x)$, then $\int_{-a}^af(x)\dd{x}=2\int_0^af(x)\dd{x}$.
\item If $f$ is an of function, that is, $f(-x)=-f(x)$, then $\int_{-a}^af(x)\dd{x}=0$.
\eit
\ssc{Mean Value Theorem (MVT) for Integrals}
If a function $f\colon D\subseteq\bbR\to\bbR$ is continuous on a closed interval $[a,b]$ with $a<b$, then
\[\exists c\in (a, b)\text{\ s.t.\ }f(c)=\frac{1}{b-a}\int_a^bf(x)\dd{x}.\]
\begin{proof}
By EVT, $f$ must have maximum and minimum on $[a,b]$.

Let
\[M=\max_{x\in [a,b]}f(x),\quad m=\min_{x\in [a,b]}f(x).\]
Then for any $x\in[a,b]$:
\[m\leq f(x)\leq M.\]
Integrate it over $[a,b]$:
\[m(b-a)=\int_a^bm\dd{x}\leq\int_a^bf(x)\dd{x}\leq\int_a^bM\dd{x}=M(b-a).\]
\[m\leq\frac{1}{b-a}\int_a^bf(x)\dd{x}\leq M.\]
Since $f$ is continuous, by IVT, there exists $c\in[a,b]$ such that
\[f(c)=\frac{1}{b-a}\int_a^bf(x)\dd{x}.\]
\end{proof}
\ssc{Fundamental Theorem of Calculus (FTC) (微積分基本定理)}
\sssc{Fundamental Theorem of Calculus Part First or First Fundamental Theorem of Calculus}
Let function $f\colon D\subseteq\bbR\to\bbR$ be continuous on a closed interval $[a,b]$, and $F$ be the function defined, for all $x\in[a,b]$ by
\[F(x)=\int_a^xf(t)\dd{t}.\]
Then $F$ Lipschitz continuous on $[a,b]$ and differentiable on $(a,b)$ and
\[F'(x)=f(x)\]
for all $x\in (a,b)$.
\begin{proof}
Lipschitz continuity: Let $(x,y)\in(a,b)$ with $x<y$. Let
\[M=\max_{t\in[a,b]}\abs{f(t)}.\]
Then,
\[F(y)-F(x)=\int_a^yf(t)\dd{t}-\int_a^xf(t)\dd{t}=\int_x^yf(t)\dd{t}.\]
\[\abs{F(y)+F(x)}=\abs{\int_x^yf(t)\dd{t}}\leq\int_x^y\abs{f(t)}\dd{t}\leq\int_x^yM\dd{t}=M(y-x).\]
Thus $F$ is Lipschitz continuous with constant $M$.

Differentiability:
\[F'(x)=\lim_{h\to 0}\frac{\int_a^{x+h}f(t)\dd{t}-\int_a^xf(t)\dd{t}}{h}=\lim_{h\to 0}\frac{\int_x^{x+h}f(t)\dd{t}}{h}.\]
By MVT for integrals, there exists $c_h\in[x,x+h]$ (or $[x+h,x]$ for h<0) such that
\[f(c_h)=\frac{\int_x^{x+h}f(t)\dd{t}}{h}.\]
By continuity of $f$,
\[\lim_{h\to 0}c_h=x.\]
Hence,
\[\lim_{h\to 0}\frac{\int_x^{x+h}f(t)\dd{t}}{h}=f(x).\]
\end{proof}
\sssc{Fundamental Theorem of Calculus Part Second, Second Fundamental Theorem of Calculus, or Newton–Leibniz Theorem}
Let function $f\colon I\subseteq\bbR\to\bbR$ be Riemann integrable on a closed interval $[a,b]$, and $F\colon J\subseteq\bbR\to\bbR$ be a function continuous on $[a,b]$ and differentiable on $(a,b)$ such that
\[F'(x)=f(x)\]
for all $x\in (a,b)$.

Then
\[\int_a^bf(x)\dd{x}=F(b)-F(a).\]
\begin{proof}
Let $P(x,n)$ be a partition of $[a,b]$. By MVT, for each subinterval $[x_i,x_{i+1}]$, there exists $c_i\in[x_i,x_{i+1}]$ such that
\[F(x_{i+1})-F(x_i)=F'(c_i)(x_{i+1}-x_i)=f(c_i)(x_{i+1}-x_i).\]
So for any $n\in\bbN$:
\[\sum_{i=0}^{n-1}f(c_i)(x_{i+1}-x_i)=\sum_{i=0}^{n-1}(F(x_{i+1})-F(x_i))=F(x_n)-F(x_0)=F(b)-F(a).\]
Since $f$ is Riemann integrable
\[\int_a^bf(x)\dd{x}=\lim_{n\to\infty}\sum_{i=0}^{n-1}f(c_i)(x_{i+1}-x_i)\]
exists.
\end{proof}
\ssc{Integrability}
\sssc{Lebesgue-Vitali theorem (of characterization of the Riemann integrable functions)}
A function is Riemann integrable (i.e. Darboux integrable) over a closed interval $I$ iff it is bounded on $I$ and continuous a.e. in $I$.
\begin{proof}
PLACEHOLDER
\end{proof}
\sssc{Riemann–Stieltjes integrability}
The Riemann–Stieltjes integral
\[\int_{x=a}^bf(x)\dd{g(x)}\]
exists if $g$ is of a bounded variation on $[a,b]$, $f$ is bounded on $[a,b]$, $f$ is continuous a.e. on $[a,b]$, and there doesn't exist $x\in[a,b]$ such that $f$ and $g$ both have irremovable discontinuity at $x$.
\begin{proof}
PLACEHOLDER
\end{proof}
\sssc{PLACEHOLDER}
PLACEHOLDER
\subsection{Integration by substitution (代換積分法), integration by change of variables (換元積分法), u-substitution (u-代換), reverse chain rule, substitution theroem (代換定理), change of variables theorem (換元定理), or transformation theorem (變換定理)}
\subsubsection{Univariate form}
Let $g:\,I\subseteq\mathbb{R}\to\mathbb{R}$ be injective and differentiable on $[a,b]\subseteq I$, with $g'$ being integrable on $[a,b]$, and $f:\,K\supseteq g([a,b])\to\mathbb{R}$ be integrable on $g([a,b])$. Then:
\[\int_a^bf\circ g(x)\cdot g'(x)\dd{x}=\int_{g(a)}^{g(b)}f(u)\,\mathrm{d}u,\]
and
\[\int f\circ g(x)\cdot g'(x)\dd{x}=\int f(u)\,\mathrm{d}u.\]
Substitutions from RHS to LHS are also called inverse substitution.
\begin{proof}
Consider the interval \([a, b]\) partitioned as
\[P = \{a = x_0 < x_1 < \dots  < x_n = b\}.\]
For each subinterval \([x_{i-1}, x_i]\), let \(\xi_i \in [x_{i-1}, x_i]\) be a sample point. The Riemann sum for the left-hand side of the integral is:
\[S_P = \sum_{i=1}^n f(g(\xi_i)) g'(\xi_i) (x_i - x_{i-1}).\]
Since \(g\) is injective and differentiable, it is either strictly increasing or strictly decreasing on \([a, b]\). Assume \(g\) is strictly increasing (the proof for \(g\) strictly decreasing follows similarly).

Under this assumption, \(g\) maps \([a, b]\) to \([g(a), g(b)]\) with \(g(a) < g(b)\). Let \([g(a), g(b)]\) be partitioned as
\[Q = \{g(a) = u_0 < u_1 < \dots  < u_m = g(b)\},\]
where \(u_i = g(x_i)\).

The Riemann sum for the right-hand side of the integral is:
\[T_Q = \sum_{i=1}^n f(u_i) (u_i - u_{i-1}).\]
Since \(u_i = g(x_i)\) and \(g'(\xi_i) \approx \frac{g(x_i) - g(x_{i-1})}{x_i - x_{i-1}}\), we rewrite:
\[ g'(\xi_i) (x_i - x_{i-1}) \approx g(x_i) - g(x_{i-1}) = u_i - u_{i-1}. \]
Thus, the left-hand Riemann sum \(S_P\) becomes:
\[ S_P = \sum_{i=1}^n f(g(\xi_i)) (u_i - u_{i-1}),\]
which matches the structure of the right-hand Riemann sum \(T_Q\) if we let \(\xi_i = g^{-1}(u_i)\).

As the partition \(P\) of \([a, b]\) gets finer, the Riemann sum \(S_P\) converges to \(\int_a^b f(g(x)) g'(x) \, \mathrm{d}x\). Similarly, as the partition \(Q\) of \([g(a), g(b)]\) gets finer, the Riemann sum \(T_Q\) converges to \(\int_{g(a)}^{g(b)} f(u) \, \mathrm{d}u\).
\end{proof}
\subsubsection{Multivariate form}
Let $\mathbf{T}:\,I\subseteq\mathbb{R}^n\to\mathbb{R}^n$ be injective and differentiable on $D\subseteq I$, with all elements of its gradient (i.e. Jacobian matrix) $\nabla\mathbf{T}$ being continuous on $D$, and $f:\,K\supseteq\mathbf{T}(D)\to\mathbb{R}$ be integrable on $\mathbf{T}(D)$. Then:
\[\int_D f(u_1\,u_2\,\dots\,u_n)\abs{\det\left(\nabla\mathbf{T}\right)}\,\mathrm{d}u_1\,\mathrm{d}u_2\,\dots\,\mathrm{d}u_n=\int_{\mathbf{T}(D)}f(x_1\,x_2\,\dots\,x_n)\cdot\dd{x}_1\dd{x}_2\,\dots\dd{x}_n,\]
and
\[\int f(u_1\,u_2\,\dots\,u_n)\abs{\det\left(\nabla\mathbf{T}\right)}\,\mathrm{d}u_1\,\mathrm{d}u_2\,\dots\,\mathrm{d}u_n=\int f(x_1\,x_2\,\dots\,x_n)\cdot\dd{x}_1\dd{x}_2\,\dots\dd{x}_n.\]
Substitutions from RHS to LHS are also called inverse substitution.
\subsubsection{Measure theory form}
Let $X$ be a locally compact Hausdorff space equipped with a finite Radon measure $μ$, and let $Y$ be a \text{\textsigma}-compact Hausdorff space with a \text{\textsigma}-finite Radon measure $\rho$. Let $\phi:\,X\to Y$ be an absolutely continuous function, (which implies that $\mu(E)=0\implies\rho(\phi(E))=0$). Then there exists a real-valued Borel measurable function $w$ on $X$ such that for every Lebesgue integrable function $f:\,Y\to\mathbb{R}$, the function $(f\circ\phi)\cdot w$ is Lebesgue integrable on $X$, and for every open subset $U$ of $X$
\[\int_U(f\circ\phi)(x)\cdot w(x)\,\mathrm{d}\mu(x)=\int_{\phi(U)}f(y)\,\mathrm{d}\rho(y).\]
Substitutions from RHS to LHS are also called inverse substitution.

Furthermore, there exists some Borel measurable function $g$ such that 
\[w(x)=(g\circ\phi)(x).\]
\subsection{Integration by parts (IBP) (分部積分法) or partial integration (部分積分法)}
\subsubsection{Theorem}
\[\frac{\mathrm{d}}{\mathrm{d}x}\prod_{i=1}^nf_i(x)=\sum_{j=1}^n\left(\frac{\mathrm{d}f_j(x)}{\mathrm{d}x}\frac{\prod_{\substack{i=1\\i\neq j}}^n f_i(x)}{f_j(x)}\right)\]
For example,
\[\int_{\Omega} u\dd{v} = \qty(u v)\big\vert_{\Omega} - \int_{\Omega} v\dd{u}.\]
\subsubsection{Application}
Integration by parts is a heuristic rather than a purely mechanical process for solving integrals; given a single function to integrate, the typical strategy is to carefully separate this single function into a product of two functions such that the residual integral from the integration by parts formula is easier to evaluate than the single function.

The DETAIL rule or the LIATE rule is a rule of thumb for integration by parts. It involves choosing as u the function that comes first in the following list:
\begin{itemize}
\item L: Logarithmic function
\item I: Inverse trigonometric function
\item A: Algebraic function
\item T: Trigonometric function
\item E: Exponential function
\end{itemize}
\sssc{Notation for two parts}
We write the integration of
\[\int f(x)\dd{x}\]
by parts as:
\ben
\item Let
\[u=g(x),\quad\dd{v}=h(x)\dd{x}\]
with some functions $g(x)$ and $h(x)$ such that
\[f(x)\dd{x}=u\dd{v}.\]
\item Compute
\[\dd{u}=g'(x)\dd{x},\quad v=\int h(x)\dd{x}\]
with the constant of integration of $\int h(x)\dd{x}$ arbitrarily chosen to be assigned to $v$.
\item Integral by parts
\[\int f(x)\dd{x}=uv-\int v\dd{u}.\]
\item If $\int v\dd{u}$ is simplified as
\[\int v\dd{u}=k\int f(x)\dd{x}+I(x)+C\]
with some constant $k\notin\{-1,0\}$, we write
\[\ba
\int f(x)\dd{x}&=uv-\int v\dd{u}\\
&=uv-k\int f(x)\dd{x}-I(x)+C\\
&=\frac{1}{k+1}\qty(uv-I(x))+C.
\ea\]
\een
Take
\[\int e^{ax}\sin(bx)\dd{x}\]
for example.

Let:
\[u=\sin(bx),\quad\dd{v}=e^{ax}\dd{x}.\]
\[\dd{u}=b\cos(bx)\dd{x},\quad v=\int e^{ax}\dd{x}=\frac{1}{a}e^{ax}.\]
\[\ba
\int e^{ax}\sin(bx)\dd{x}&=\int u\dd{v}=uv-\int v\dd{u}\\
&=\frac{1}{a}e^{ax}\sin(bx)-\frac{b}{a}\int e^{ax}\cos(bx)\dd{x}.
\ea\]
\[w=\cos(bx).\]
\[\dd{w}=-b\sin(bx).\]
\[\ba
\int e^{ax}\cos(bx)\dd{x}&=\int w\dd{v}=wv-\int v\dd{w}\\
&=\frac{1}{a}e^{ax}\cos(bx)+\frac{b}{a}\int e^{ax}\sin(bx)\dd{x}.
\ea\]
\[\ba
\int e^{ax}\sin(bx)\dd{x}&=\frac{1}{a}e^{ax}\sin(bx)-\frac{b}{a}\qty(\frac{1}{a}e^{ax}\cos(bx)+\frac{b}{a}\int e^{ax}\sin(bx)\dd{x})\\
&=\frac{1}{a}e^{ax}\sin(bx)-\frac{b}{a^2}e^{ax}\cos(bx)-\frac{b^2}{a^2}\int e^{ax}\sin(bx)\dd{x}\\
&=\frac{a^2}{a^2+b^2}\qty(\frac{1}{a}e^{ax}\sin(bx)-\frac{b}{a^2}e^{ax}\cos(bx))+C\\
&=\frac{e^{ax}}{a^2+b^2}\qty(a\sin(bx)-b\cos(bx))+C.
\ea\]
\ssc{Riemann–Stieltjes integral theorems}
\sssc{Integration by parts (IBP) or partial integration of Riemann–Stieltjes integral}
\[\int_{x=a}^bf(x)\dd{g(x)}=f(b)g(b)-f(a)g(a)-\int_{x=a}^bg(x)\dd{f(x)}.\]
\begin{proof}
PLACEHOLDER
\end{proof}
\sssc{Riemann–Stieltjes integral with respect to differential function}
If $f(x)$ is bounded on $[a,b]$, $g(x)$ is monotonic on $[a,b]$, and $g'(x)$ exists and is Riemann integrable on $[a,b]$, then the Riemann–Stieltjes integral is related to the Riemann integral by
\[\int_{x=a}^bf(x)\dd{g(x)}=\int_a^bf(x)g'(x)\dd{x}.\]
\begin{proof}
PLACEHOLDER
\end{proof}
\sssc{Riemann–Stieltjes integral with respect to step function}
If $a<s<b$,
\[g(x)=\bcs 0,\quad&a\leq x\leq s\\
1,\quad&b\geq x>s\ecs,\]
and $f\colon X\supseteq[a,b]\to\bbR$ is continuous at $s$, then
\[\int_{x=a}^bf(x)\dd{g(x)}=f(s).\]
\begin{proof}
PLACEHOLDER
\end{proof}
\ssc{General Method of Integration of Rational Functions}
\sssc{$\frac{A}{x-a}$}
\[\int\frac{A}{x-a}\dd{x}=A\ln|x-a|+C,\quad a,A\in\bbR\]
\sssc{$\frac{A}{\qty(x-a)^g}$}
\[\int\frac{A}{\qty(x-a)^g}\dd{x}=-\frac{A}{(g-1)\qty(x-a)^{g-1}}+C,\quad a,A\in\bbR\land g\in\bbN_{>1}\]
\sssc{$\frac{Ax+B}{x^2+bx+c}$}
\[\int\frac{Ax+B}{x^2+bx+c}=\frac{A}{2}\ln|x^2+bx+c|+\frac{2B-bA}{\sqrt{4c-b^2}}\arctan(\frac{2x+b}{\sqrt{4c-b^2}})+C,\quad b,c,A,B\in\bbR\land b^2<4c\]
\begin{proof}
\[\ba
\int\frac{Ax+B}{x^2+bx+c}&=\int\frac{A}{2}\frac{2x+b}{x^2+bx+c}+\frac{B-\frac{bA}{2}}{\qty(x+\frac{b}{2})^2+\qty(c-\frac{b^2}{4})}\dd{x}\\
&=\frac{A}{2}\ln|x^2+bx+c|+\qty(B-\frac{bA}{2})\int\frac{1}{u^2+\qty(c-\frac{b^2}{4})}\dd{u},\quad u=x+\frac{b}{2}\\
&=\frac{A}{2}\ln|x^2+bx+c|+\frac{2B-bA}{\sqrt{4c-b^2}}\arctan(\frac{2x+b}{\sqrt{4c-b^2}})+C
\ea\]
\sssc{$\frac{1}{\qty(x^2+bx+c)^h}$}
\[\int\frac{1}{\qty(x^2+bx+c)^h}\dd{x}=\frac{1}{\qty(4c-b^2)(h-1)}\frac{2x+b}{\qty(x^2+bx+c)^{h-1}}+\frac{4h-6}{\qty(4c-b^2)(h-1)}\int\frac{1}{\qty(x^2+bx+c)^{h-1}}\dd{x},\quad b,c\in\bbR\land b^2<4c\land h\in\bbN_{>1}\]
\begin{proof}
\[u=x+\frac{b}{2},\quad\alpha=\sqrt{c-\frac{b^2}{4}}\]
\[\ba 
\int\frac{1}{\qty(x^2+bx+c)^h}\dd{x}&=\int\frac{1}{\qty(u^2+\alpha^2)^h}\dd{u}\\
&=\frac{1}{\alpha^2}\int\frac{u^2+\alpha^2-u^2}{\qty(u^2+\alpha^2)^h}\dd{u}\\
&=\frac{1}{\alpha^2}\int\frac{1}{\qty(u^2+\alpha^2)^{h-1}}\dd{u}-\frac{1}{\alpha^2}\int\frac{u^2}{\qty(u^2+\alpha^2)^h}\dd{u}
\ea\]
\[\ba
\dv{}{u}\qty(\frac{u}{\qty(u^2+\alpha^2)^{h-1}})&=\frac{\qty(u^2+\alpha^2)^{h-1}-u(h-1)\qty(u^2+\alpha^2)^{h-2}(2u)}{\qty(u^2+\alpha^2)^{2(h-1)}}\\
&=\frac{1}{\qty(u^2+\alpha^2)^{h-1}}-
2(h-1)\frac{u^2}{\qty(u^2+\alpha^2)^h}
\ea\]
\[\frac{u^2}{\qty(u^2+\alpha^2)^h}=\frac{1}{2(h-1)}\qty(\frac{1}{\qty(u^2+\alpha^2)^{h-1}}-\dv{}{u}\qty(\frac{u}{\qty(u^2+\alpha^2)^{h-1}}))\]
\[\int\frac{u^2}{\qty(u^2+\alpha^2)^h}\dd{u}=\frac{1}{2(h-1)}\qty(\int\frac{1}{\qty(u^2+\alpha^2)^{h-1}}\dd{u}-\frac{u}{\qty(u^2+\alpha^2)^{h-1}})\]
\[\ba  
\int\frac{1}{\qty(x^2+bx+c)^h}\dd{x}&=\frac{1}{\alpha^2}\int\frac{1}{\qty(u^2+\alpha^2)^{h-1}}\dd{u}-\frac{1}{\alpha^2}\int\frac{u^2}{\qty(u^2+\alpha^2)^h}\dd{u}\\
&=\frac{1}{\alpha^2}\int\frac{1}{\qty(u^2+\alpha^2)^{h-1}}\dd{u}-\frac{1}{2\alpha^2(h-1)}\qty(\int\frac{1}{\qty(u^2+\alpha^2)^{h-1}}\dd{u}-\frac{u}{\qty(u^2+\alpha^2)^{h-1}})\\
&=\frac{2h-3}{2\alpha^2(h-1)}\int\frac{1}{\qty(u^2+\alpha^2)^{h-1}}\dd{u}+\frac{1}{2\alpha^2(h-1)}\frac{u}{\qty(u^2+\alpha^2)^{h-1}}\\
&=\frac{4h-6}{\qty(4c-b^2)(h-1)}\int\frac{1}{\qty(x^2+bx+c)^{h-1}}\dd{x}+\frac{1}{\qty(4c-b^2)(h-1)}\frac{2x+b}{\qty(x^2+bx+c)^{h-1}}
\ea\]
\end{proof}
\sssc{$\frac{Ax+B}{\qty(x^2+bx+c)^h}$}
\[\int\frac{Ax+B}{\qty(x^2+bx+c)^h}\dd{x}=-\frac{A}{2(h-1)\qty(x^2+bx+c)^{h-1}}+\qty(B-\frac{bA}{2})\int\frac{1}{\qty(x^2+bx+c)^h}\dd{x},\quad b,c,A,B\in\bbR\land b^2<4c\land h\in\bbN_{>1}\]
\sssc{Integration of Rational Functions by Partial Fractions}
To compute the integral of any arbitrary rational function $f(x)$,
\ben
\item Express it as
\[f(x)=S(x)+\frac{P(x)}{Q(x)}\]
where $S(x),P(x),Q(x)$ are polynomials and $\deg(P)<\deg(Q)$.
\item Find $q,a_j,b_k,c_k\in\bbR$, $m,n\in\bbN_0$, $r_j,s_k\in\bbN$ and $b_k^{\pht{k}2}-4c_k<0$ for all $k$ such that
\[Q(x)=q\prod_{j=1}^m\qty(x-a_j)^{r_j}\prod_{k=1}^n\qty(x^2+b_kx+c_k)^{s_k}.\]
Note that all polynomials can be expressed as a product of linear factors and irreducible quadratic factors.
\item Express $\frac{P(x)}{Q(x)}$ as
\[\frac{P(x)}{Q(x)}=p\qty(\sum_{j=1}^m\sum_{g=1}^{r_j}\frac{A_{j_g}}{\qty(x-a_j)^g}+\sum_{k=1}^n\sum_{h=1}^{s_k}\frac{B_{k_h}x+C_{k_h}}{\qty(x^2+b_kx+c_k)^h})\]
where $p,A_{j_g},B_{k_h},C_{k_h}\in\bbR$.
\item Integrate $S(x)$ and each term of $\frac{A_{j_g}}{\qty(x-a_j)^g}$ and $\frac{B_{k_h}x+C_{k_h}}{\qty(x^2+b_kx+c_k)^h}$ respectively.
\een
\ssc{Substitution for irrational function integrand}
\sssc{Direct substitution}
When computing an integral of
\[R(x,\sqrt[n]{g(x)})\]
with respect to $x$ where $R$ and $g$ are rational functions, the substitution $u=\sqrt[n]{g(x)}$ may be effective.
\sssc{Square root of quadratic polynomial}
When computing an integral of
\[R\qty(x,\sqrt{ax^2+bx+c})\]
with respect to $x$ where $R$ is a rational function and $a\neq 0$, it may be effective to
\ben
\item let $h=\frac{b}{2|a|}$ and $k=-\frac{b^2}{4a^2}+\frac{c}{a}$, rewrite $\sqrt{ax^2+bx+c}$ as
\[\sqrt{ax^2+bx+c}=\sqrt{|ak|}\sqrt{\sgn(a)\qty(\frac{x}{\sqrt{|k|}}+\frac{h}{\sqrt{|k|}})^2+\sgn(k)},\]
\iten use substitution $u=\frac{x}{\sqrt{|k|}}+\frac{h}{\sqrt{|k|}}$, which makes the integrand,
\[\sqrt{|k|}R\qty(\sqrt{|k|}u-h,\sqrt{|ak|}\sqrt{\sgn(a)u^2+\sgn(k)}),\]
which is a rational function of $u$ and $\sqrt{\sgn(a)u^2+\sgn(k)}$, and,
\item depending on $\sgn(a)$ and $\sgn(k)$,
\bit
\item $k=0$: the integrand is a rational function of $u$,
\item $a>0$ and $k>0$: try the substitution $u=\tan(t)$, $u=\cot(t)$, $u=\sinh(t)$, or $u=\csch(t)$,
\item $a>0$ and $k<0$: try the substitution $u=\sec(t)$, $u=\csc(t)$, $u=\cosh(t)$, or $u=\coth(t),
\item $a<0$ and $k>0$: try the substitution $u=\sin(t)$, $u=\cos(t)$, $u=\tanh(t)$, or $u=\sech(t)$.
\eit
\een
\sssc{Euler substitutions}
When computing an integral of
\[R(x,\sqrt{ax^2+bx+c})\]
with respect to $x$ where $R$ is a rational function, the three Euler('s) substitutions may be effective.
\ben
\item First substitution: For $a\geq 0$, substitute
\[\sqrt{ax^2+bx+c}=\pm x\sqrt{a}+t\]
\[x=\frac{c-t^2}{\pm 2t\sqrt{a}-b}\]
where either the positive sign or the negative sign can be chosen.
\item Second substitution: For $c\geq 0$, substitute
\[\sqrt{ax^2+bx+c}=xt\pm\sqrt{c}\]
\[x=\pm 2t\sqrt{c}-b}\]
where either the positive sign or the negative sign can be chosen.
\item Third substitution: For $b^2-4ac\geq 0$, let
\[ax^2+bx+c=a(x-\alpha)(x-\beta),\]
substitute
\[\sqrt{ax^2+bx+c}=(x-\alpha)t\]
\[x=\frac{\alpha\beta-\alpha t^2}{a-t^2}\]
\een
\ssc{Function of trigonometric functions integral}
\sssc{Tangent half-angle substitution, Weierstrass substitution, or universal trigonometric substitution}
When computing an integral of
\[f(\sin(x),\cos(x))\]
with respect to $x$, the substitution
\[t=\tan(\frac{x}{2})\]
gives
\[\int f(\sin(x),\cos(x))=\int f\qty(\frac{2t}{1+t^2},\frac{1-t^2}{1+t^2})\frac{2}{1+t^2}\dd{t}.\]
\sssc{Product of sine and cosine functions}
\[\int\sin^m(x)\cos^n(x)\dd{x},\quad m,n\in\bbN.\]
\begin{itemize}
\item For odd $n$, use $\cos^2(x)=1-\sin^2(x)$ and then substitute $u=\sin(x),\quad\dd{u}=\cos(x)\dd{x}$.
\item For odd $m$, use $\sin^2(x)=1-\cos^2(x)$ and then substitute $u=\cos(x),\quad\dd{u}=-\sin(x)\dd{x}$.
\item For $m=n$, use $\sin(x)\cos(x)=\frac{1}{2}\sin(2x)$.
\item For $\frac{m-n}{2}\in\bbN$, use $\sin(x)\cos(x)=\frac{1}{2}\sin(2x)$ and then substitute $\sin^2(x)=\frac{1}{2}(1-\cos(2x))$.
\item For $\frac{n-m}{2}\in\bbN$, use $\sin(x)\cos(x)=\frac{1}{2}\sin(2x)$ and then substitute $\cos^2(x)=\frac{1}{2}(1+\cos(2x))$.
\end{itemize}
\sssc{Product of tangent and secant functions}
\[\int\tan^m(x)\sec^n(x)\dd{x},\quad m,n\in\bbN.\]
\begin{itemize}
\item For even $n$, save a factor of $\sec^2(x)$, use $\sec^2(x)=1+\tan^2(x)$ to express the remaining factors in terms of $\tan(x)$, and then substitute $u=\tan(x),\quad\dd{u}=\sec^2(x)\dd{x}$.
\item For odd $m$, save a factor of $\tan(x)\sec(x)$, use $\tan^2(x)=\sec^2(x)-1$ to express the remaining factors in terms of $\sec(x)$, and then substitute $u=\sec(x),\quad\dd{u}=\tan(x)\sec(x)\dd{x}$.
\item For even $m$, use $\tan^2(x)=\sec^2(x)-1$ to express the integrand in terms of $\sec(x)$, and then use reduction formula for secant function.
\end{itemize}
\sssc{Product of cotangent and cosecant functions}
\[\int\cot^m(x)\csc^n(x)\dd{x},\quad m,n\in\bbN.\]
\begin{itemize}
\item For even $n$, save a factor of $\csc^2(x)$, use $\csc^2(x)=1+\cot^2(x)$ to express the remaining factors in terms of $\cot(x)$, and then substitute $u=\cot(x),\quad\dd{u}=-\csc^2(x)\dd{x}$.
\item For odd $m$, save a factor of $\cot(x)\csc(x)$, use $\cot^2(x)=\csc^2(x)-1$ to express the remaining factors in terms of $\csc(x)$, and then substitute $u=\csc(x),\quad\dd{u}=-\cot(x)\csc(x)\dd{x}$.
\item For even $m$, use $\cot^2(x)=\csc^2(x)-1$ to express the integrand in terms of $\csc(x)$, and then use reduction formula for cosecant function.
\end{itemize}
\ssc{Leibniz integral rule (for differentiation under the integral sign) (（積分符號內取微分的）萊布尼茲積分法則)}
\sssc{Basic form for constant limits}
Let $a,b\in\mathbb{R}$, $f(x,t)$ be a function with domain $\mathbb{R}^2$, and the following integral exists. Then:
\[\begin{aligned}
&\dv{}{x}\qty(\int_a^bf(x,t)\dd{t})\\
=&\int_a^b\pdv{}{x}f(x,t)\dd{t}
\end{aligned}\]
\sssc{Basic form for variable limits}
Let $a(x),b(x)\in\mathbb{R}$, $f(x,t)$ be a function with domain $\mathbb{R}^2$, and the following integral exists. Then:
\[\begin{aligned}
&\dv{}{x}\qty(\int_{a(x)}^{b(x)}f(x,t)\dd{t})\\
=&f\qty(x,b(x))\cdot\dv{b(x)}{x}-f\qty(x,a(x))\cdot\dv{a(x)}{x}+\int_{a(x)}^{b(x)}\pdv{}{x}f(x,t)\dd{t}
\end{aligned}\]
\sssc{Measure theory form for const limits}
Let $X$ be an open subset of $\mathbb{R}$, and $\Omega$ be a measure space. Suppose $f\colon X\times\Omega\to\mathbb{R}$ satisfies the following conditions:
\ben
\item $f(x,\omega)$ is a Lebesgue-integrable function of $\omega$ for each $x\in X$.
\item For almost all $\omega\in\Omega$, the partial derivative $\pdv{f}{x}$ exists for all $x\in X$.
\item There is an integrable function $\theta\colon\Omega\to\mathbb{R}$ such that $\abs{\pdv{f}{x}\qty(x,\omega)}\leq\theta(\omega)$ for all $x\in X$ and almost all $\omega\in\Omega$.
\een
Then, for all $x\in X$,
\[\dv{}{x}\int_{\Omega}f(x,\omega)\dd{\omega}=\int_{\Omega}\pdv{f}{x}\qty(x,\omega)\dd{\omega}.\]
\ssc{Fubini's theorem (富比尼定理)}
If a function is Lebesgue integrable on $X\times Y$, then:
\[\iint_{X\times Y}f(x,y)\dd{(x,y)}=\int_X\qty(\int_Yf(x,y)\dd{y})\dd{x}=\int_Y\qty(\int_Xf(x,y)\dd{x})\dd{y}.\]
\ssc{(Lebesgue's) Dominated convergence theorem (DCT) (（勒貝格）控制/受制收斂定理)}
Let $\langle f_n\rangle_{n\in I}$ be a net of real or complex-valued measurable functions on a measure space $(S,\Sigma,\mu)$. If $f_n$ is almost everywhere pointwise convergent to a function $f$, and there is a Lebesgue-integrable function $g$ such that
\[\abs{f_n}\leq g\]
almost everywhere for all $n\in I$.

Then $f_n$ for all $n\in I$ and $f$ are in $L^1(\mu)$ and
\[\lim_n\int_Sf_n\dd{\mu}=\int_S\lim_nf_n\dd{\mu}=\int_Sf\dd{\mu},\]
and
\[\lim_n\int_S\abs{f_n-f}\dd{\mu}=0.\]
\ssc{Fundamental theorem of multivariable calculus (多變數微積分基本定理)}
\sssc{Gradient theorem (梯度定理)}
Suppose $r$ is a oriented differentiable curve that starts at a point $\mathbf{p}$ and ends at a point $\mathbf{q}$. If $\mathbf{F}$ is a differentiable tensor field defined on a neighborhood of $\mathbf{F}$, then,
\[\int_r(\nabla\mathbf{F})\cdot\mathrm{d}\mathbf{r}=\mathbf{F}\left(\mathbf{q}\right)-\mathbf{F}\left(\mathbf{p}\right).\]
Gradient theorem is a special case of generalized Stokes theorem.
\sssc{Divergence theorem, Gauss's theorem, or Ostrogradsky's theorem (高斯散度定理)}
Suppose $V\subseteq\mathbb{R}^n$ is compact and has a piecewise smooth boundary $S$ (also indicated with $\partial V=S$). The closed, measurable set $\partial V$ is oriented by outward-pointing normals. If $F$ is a continuously differentiable vector field defined on a neighborhood of $V$, then,
\[\iiint_V\left(\nabla\cdot\mathbf {F}\right)\,\mathrm{d}V=\oiint_S\mathbf{F}\cdot\mathrm{d}\mathbf{S}\]
Divergence theorem is a special case of generalized Stokes theorem.
\sssc{Stokes' theorem (斯托克斯定理) or Kelvin–Stokes theorem}
Let $S$ be a positively oriented, piecewise smooth surface in $\mathbb{R}^3$ with boundary $\partial S\equiv L$. If a vector field $\mathbf{F}:\,\mathbb{R}^3\rightarrow\mathbb{R}^3$ is defined and has continuous first order partial derivatives in a region containing $S$, then,
\[\iint_S(\nabla\times\mathbf{F})\cdot \mathrm{d}\mathbf{S}=\oint_{L}\mathbf{F}\cdot\mathrm{d}\mathbf{L}\]
Stokes' theorem is a special case of generalized Stokes theorem.
\sssc{Green's theorem (格林定理或綠定理)}
Let $S$ be a positively oriented, piecewise smooth surface in $\mathbb{R}^2$ with boundary $\partial S\equiv L$. If scalar function $P,(x,y)\,Q(x,y)$ are defined and has continuous first order partial derivatives in a region containing $S$, then,
\[\oint_L (P\mathrm{d}x+Q\mathrm{d}y)=\iint_S\left(\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y}\right)\mathrm{d}x\mathrm{d}y\]
where the path of integration along C is counterclockwise.

Green's theorem is a special case of Stokes' theorem.
\sssc{Generalized Stokes theorem, Stokes–Cartan theorem, or fundamental theorem of multivariable calculus}
The generalized Stokes theorem says that the integral of a differential form $\omega$ over the boundary $\partial\Omega$ of some orientable manifold $\Omega$ is equal to the integral of its exterior derivative $\mathrm{d}\boldsymbol{\omega}$ over the whole of $\Omega$, i.e.,
\[\int _{\partial\Omega}\omega=\int_{\Omega}\mathrm{d}\boldsymbol{\omega}\]
\ssc{Average value}
\sssc{Plane region}
The area $A$ and average $(\bar{x},\bar{y})$ of the plane region bounded by $y=f(x)$,$y=g(x)$, $x=a$, and $x=b$ with $a<b$ is given by
\[A=\int_a^b\abs{f(x)-g(x)}\dd{x},\]
\[\bar{x}=\frac{1}{A}\int_a^bx\abs{f(x)-g(x)}\dd{x},\]
\[\bar{y}=\frac{1}{2A}\int_a^b\abs{f(x)-g(x)}(f(x)+g(x))\dd{x}.\]
If $f(x)\geq g(x)$,
\[A=\int_a^bf(x)-g(x)\dd{x},\]
\[\bar{x}=\frac{1}{A}\int_a^bxf(x)-g(x)\dd{x},\]
\[\bar{y}=\frac{1}{2A}\int_a^b(f(x))^2-(g(x))^2\dd{x}.\]
\ssc{Arc Length}
\sssc{Definition}
Given a curve $\gamma(t)=(x_1(t),x_2(t),\quad,x_n(t)),\quad t\in[a,b]$. Let $P(t,k)$ be a partition of interval $[a,b]$. Define the polygonal length of $\gamma$ along $P(t,k)$ as
\[s(P(t,k))=\sum_{i=1}^k\|\gamma(i)-\gamma(i-1)\|.\]
The arc length of the curve is
\[s=\sup_{P\in\mathcal{P}}s(P),\]
where $\mathcal{P}$ is the set of all partitions of interval $[a,b]$.

The curve is called rectifiable iff $s$ is finite.

$s$ is finite iff all $x_i(t)$ is of bounded variation.
\begin{proof}
"If" direction:

By triangular inequality,
\[\|\gamma(i)-\gamma(i-1)\|\leq\sum_{j=1}^n\abs{x_j(i)-x_j(i-1)}.\]
\[\sum_{i=1}^k\|\gamma(i)-\gamma(i-1)\|\leq\sum_{i=1}^k\sum_{j=1}^n\abs{x_j(i)-x_j(i-1)}=\sum_{j=1}^n\sum_{i=1}^k\abs{x_j(i)-x_j(i-1)}<\infty.\]

"Only if" direction:

By triangular inequality, for every $j\in\bbN\land j\leq n$,
\[\abs{x_j(i)-x_j(i-1)}\leq\|\gamma(i)-\gamma(i-1)\|.\]
\[\sum_{i=1}^k\abs{x_j(i)-x_j(i-1)}\leq\sum_{i=1}^k\|\gamma(i)-\gamma(i-1)\|<\infty.\]
\end{proof}

The arc length function of the curve from $a$ is defined a function of $t$ that maps $t\geq a$ to the arc length of $\gamma$ between $a$ and $t$.
\sssc{For differentiable curve}
If $\gamma$ is differentiable, the arc length is
\[s=\int_a^b\|\dv{\gamma(t)}{t}\|\dd{t},\]
and the arc length function of it from $a$ is
\[s(t)=\int_a^t\|\dv{\gamma(u)}{u}\|\dd{u},\quad t\geq a.\]
\sssc{For differentiable function}
Given differentiable function $y=f(x),\quad x\in[a,b]$. The arc length of it is
\[s=\int_a^b\|1+f'(x)\|\dd{x}.\]
$s$ is finite iff $f(x)$ is of bounded variation.

The arc length function of it from $a$ is
\[s(x)=\int_a^x\|1+f'(t)\|\dd{t},\quad x\geq a.\]
\ssc{Surface of revolution}
\sssc{Definition}
The surface formed by rotating the curve $\gamma(t)=(x(t),y(t),z(t)),\quad t\in[a,b]$ about rotational axis $\mb{P}+\mb{k}s,\quad s\in\bbR$ with $\mb{P},\mb{k}\in\bbR^3$ and $\|\mb{k}\|=1$ is parameterized as
\[R(t,\theta)=\mb{P}+\qty(\gamma(t)-\mb{P})\cos\theta+(\mb{k}\times\qty(\gamma(t)-\mb{P}))\sin\theta+\mb{k}(\mb{k}\cdot\qty(\gamma(t)-\mb{P}))(1-\cos\theta),\quad t\in[a,b]\land\theta\in[0,2\pi].\]
And its area is
\[A=2\pi\int_{t=a}^b\norm{\gamma(t)-\mb{P}-\mb{k}(\mb{k}\cdot\qty(\gamma(t)-\mb{P}))}\dd{s(t)},\]
where $s(t)$ is the arc length function of $\gamma$ from $a$.

The area is called rectifiable iff $A$ is finite.

$A$ is finite iff $x(t)$, $y(t)$, and $z(t)$ are all of bounded variation iff $s(t)$ is of bounded variation.
\sssc{Two-dimensional curve about principal axis on the same plane}
The area of the surface formed by rotating the curve $\gamma(t)=(x(t),y(t)),\quad t\in[a,b]$ about $y=d$ is
\[A=2\pi\int_{t=a}^b\abs{y(t)-d}\dd{s(t)},\]
where $s(t)$ is the arc length function of $\gamma$ from $a$.
\sssc{Pappus's (centroid) theorem I or (Pappus–)Guldinus theorem I}
The area of the surface formed by rotating a two-dimensional curve with arc length $s$ and centroid $\mb{P}$ about a rotational axis on the same plane of the curve that doesn't cut the curve in a distance $d$ from $\mb{P}$ is
\[A=2\pi sd.\]
\begin{proof}
Let the curve be $\gamma(t)=(x(t),y(t)),\quad t\in[a,b]$, $s(t)$ be the arc length function of it, the centroid of it be the origin, that is, 
\[\int\gamma(t)\dd{s(t)}=(0,0),\]
and the rotational axis is $y=d$.
\[\ba
A&=2\pi\int_{t=a}^b\abs{y(t)-d}\dd{s(t)}\\
&=2\pi\abs{\int_{t=a}^by(t)\dd{s(t)}-\int_{t=a}^bd\dd{s(t)}}\\
&=2\pi sd
\ea\]
\end{proof}
\ssc{Solid of revolution}
\sssc{Disc method or disc integration}
The volume of the solid formed by rotating the area bounded by $y=f(x)$,$y=g(x)$, $x=a$, and $x=b$ with $a<b$ about the $x$-axis is given by 
\[V=\pi\int_a^b\abs{f(x)^2-g(x)^2}\dd{x},\]
aka Washer method.

If $g(x)=0$ (e.g. revolving an area between the curve and the y-axis), this reduces to: 
\[V=\pi\int_a^bf(x)^2\dd{x}.\]
\sssc{Shell method or shell integration}
The volume of the solid formed by rotating the area bounded by $y=f(x)$,$y=g(x)$, $x=a$, and $x=b$ with $a<b$ about the $y$-axis is given by 
\[V=2\pi\int_a^bx\abs{f(x)-g(x)}\dd{x}.\]
\sssc{Pappus's (centroid) theorem II or (Pappus–)Guldinus theorem II}
The volume of the solid formed by rotating a plane region with area $A$ and centroid $\mb{P}$ about a rotational axis on the same plane of the region that doesn't cut the region in a distance $d$ from $\mb{P}$ is
\[V=2\pi Ad.\]
\begin{proof}
Let the rotational axis be the $y$-axis. Split the region to subregions such that each subregion is bounded by $y=f(x)$,$y=g(x)$, $x=a$, and $x=b$, for some functions $f(x)$ and $g(x)$ and some constant $a<b$.

For each subregion,
\[V=2\pi\int_a^bx\abs{f(x)-g(x)}\dd{x}.\]
\[Ad=\int_a^bx\abs{f(x)-g(x)}\dd{x}.\]
\[V=2\pi Ad.\]

The sum of the volume of the solid formed by rotating the subregions is the volume of the solid formed by rotating the original region. The average of the centroids $\mb{P}_i=(d_i,y_i)$ of the subregions weighted by their areas $A_i$ is the centroid $\mb{P}=(d,p_y)$ of the original region.
\[\mb{P}=\frac{\sum_iA_i\mb{P}_i}{A}\]
\[V=\sum_iV_i=\sum_iA_id_i=A\frac{\sum_iA_id_i}{A}=Ad.\]
\end{proof}
\ssc{Numerical integration (數值積分)}
\sssc{Left and right endpoint rule}
Let $f$ be a continuous real-valued function on $[a,b]$. The left endpoint rule gives the approximation of $\int_a^bf(x)\dd{x}$
\[L_n=\frac{b-a}{n}\sum_{i=0}^{n-1}f\qty(a+\frac{i}{n}(b-a)).\]
The right endpoint rule gives the approximation of $\int_a^bf(x)\dd{x}$
\[R_n=\frac{b-a}{n}\sum_{i=1}^nf\qty(a+\frac{i}{n}(b-a)).\]
\sssc{Midpoint rule}
Let $f$ be a continuous real-valued function on $[a,b]$. The midpoint rule gives the approximation of $\int_a^bf(x)\dd{x}$
\[M_n=\frac{b-a}{n}\sum_{i=0}^{n-1}f\qty(a+\frac{2i+1}{2n}(b-a)).\]
The error is
\[E_M=\int_a^bf(x)\dd{x}-M_n.\]
If $f''$ exists a.e. on $[a,b]$ and $\abs{f''(x)}\leq K$ for all $x\in[a,b]$ such that $f''(x)$ exist, then
\[\abs{E_M}\leq\frac{K(b-a)^3}{24n^2}.\]
If $f\in C^2([a,b])$, then
\[E_M=\frac{(b-a)^3}{24n^2}f''(\xi)\]
for some $\xi\in[a,b]$.
\sssc{Trapezoidal rule}
Let $f$ be a continuous real-valued function on $[a,b]$. The trapezoidal rule gives the approximation of $\int_a^bf(x)\dd{x}$
\[T_n=\frac{b-a}{2n}\qty(f(a)+f(b)+2\sum_{i=1}^{n-1}f\qty(a+\frac{i}{n}(b-a))).\]
The error is
\[E_T=\int_a^bf(x)\dd{x}-T_n.\]
If $f''$ exists a.e. on $[a,b]$ and $\abs{f''(x)}\leq K$ for all $x\in[a,b]$ such that $f''(x)$ exist, then
\[\abs{E_T}\leq\frac{K(b-a)^3}{12n^2}.\]
If $f\in C^2([a,b])$, then
\[E_T=-\frac{(b-a)^3}{12n^2}f''(\xi)\]
for some $\xi\in[a,b]$.
\sssc{Simpson's rule or Simpson's 1/3 rule}
Let $f$ be a continuous real-valued function on $[a,b]$, the Simpson's rule gives the approximation of $\int_a^bf(x)\dd{x}$
\[S_n=\frac{b-a}{3n}\qty(f(a)+f(b)+2\sum_{i=1}^{n-1}f\qty(a+\frac{i(i\mod 2+1)}{n}(b-a)),\quad\frac{n}{2}\in\bbN.\]
The error is
\[E_S=\int_a^bf(x)\dd{x}-S_n.\]
If $f^{(4)}$ exists a.e. on $[a,b]$ and $\abs{f^{(4)}(x)}\leq K$ for all $x\in[a,b]$ such that $f^{(4)}(x)$ exist, then
\[\abs{E_S}\leq\frac{K(b-a)^5}{180n^4}.\]
If $f\in C^4([a,b])$, then
\[E_S=-\frac{(b-a)^5}{180n^4}f^{(4)}(\xi)\]
for some $\xi\in[a,b]$.
\ssc{Theorem of total variation of differentiable function}
\sssc{Theorem of total variation of differentiable real function}
Let $f\colon X\subseteq\bbR\to\bbR$ be a function. If $f$ is differentiable over $[a,b]\subseteq X$ and $f'$ is Riemann integrable over $[a,b]$, then the total variation of $f$ over $[a,b]$ is
\[V_a^b(f)=\int_a^b\abs{f'(x)}\dd{x}.\]
\sssc{Theorem of total variation of differentiable real fields}
PLACEHOLDER



\sct{Integral Transform}
PLACEHOLDER
Integral Transform
Linear transform
\ssc{(Unilateral or One-sided) Laplace transform (（單邊）拉普拉斯變換)}
\sssc{Introduction}
The (unilateral or one-sided) Laplace transform is an integral transform that converts a function of a real variable $t$, called time domain, to a complex function of a complex variable $s$, called (complex-valued) frequency domain, $s$-domain, or $s$-plane. The functions are often denoted in lowercase for the time-domain and uppercase for the frequency-domain.
\sssc{Definition as Lebesgue integral}
For any set $S$, for any complex-valued functions $g_j(t)$ defined on $D_j\superseteq\mathbb{R}_{\geq 0}$, for any indexed family $A_j\colon I_j\to\mathcal{A}_j\subseteq D_j;\;i\mapsto A_{j_i}$ with $n\in\bbN$ and $I_j=J_j\cap\bbN$ for some interval $J_j$, the Laplace transform of the extended complex-valued function
\[f(t)=\sum_{j\in S}g_j(t)\prod_{i\in I_j}\delta(A_{j_i}),\]
denoted as $\mathcal{L}\{f(t)\}(s)$ or $F(s)$, is defined as
\[\mathcal{L}\{f(t)\}(s)=F(s)=\int_0^{\infty}f(t)e^{-st}\dd{t},\]
with integrals involving Dirac detla functions defined via Dirac measures.

The convergence of a Laplace transform at a value of $s$ is defined as the existence of such Lebesgue integral.
\sssc{Definition as improper Riemann–Stieltjes integral}
For any set $S$, for any complex-valued functions $g_j(t)$ defined on $D_j\superseteq\mathbb{R}_{\geq 0}$, for any indexed family $A_j\colon I_j\to\mathcal{A}_j\subseteq D_j;\;i\mapsto A_{j_i}$ with $n\in\bbN$ and $I_j=J_j\cap\bbN$ for some interval $J_j$, the Laplace transform of the extended complex-valued function
\[f(t)=\sum_{j\in S}g_j(t)\prod_{i\in I_j}\delta(A_{j_i}),\]
denoted as $\mathcal{L}\{f(t)\}(s)$ or $F(s)$, is defined, with $\mathcal{f}(t)$, typically denoted simply as $f(t)$ defined as any function such that
\bit
\item its domain is a super set of an interval $[a,\infty)$ for some $a\in\bbR_{<0}$,
\item $\mathcal{f}(t)=f(t)$ for all $t\in\bbR_{\geq 0}$, and
\item it's continuous on some interval $[a,0)$ for some $a\in\bbR_{<0}$,
\eit
as,
\[\mathcal{L}\{f(t)\}(s)=F(s)=\lim_{\varepsilon\to 0^+}\int_{-\varepsilon}^{\infty}\mathcal{f}(t)e^{-st}\dd{t},\]
with integrals involving Dirac detla functions defined via improper Riemann–Stieltjes integral, where $\lim_{\varepsilon\to 0^+}\int_{-\varepsilon}^{\infty}$ is typically denoted as $\int_{0^-}^{\infty}$.

The convergence of a Laplace transform at a value of $s$ is defined as the absolute convergence of such improper Riemann–Stieltjes integral.
\sssc{Region of convergence (ROC)}
The set of values of $s$ for which $F(s)$ converges, called region of convergence (ROC), is a class of either $\Re(s) > a$ or $\Re(s) \geq a$ for some extended real constant $a$, called abscissa of convergence.
\sssc{Laplace transformability}
A such $f(t)$ is called Laplace-transformable iff there exists some real number $a$ such that $F(a)$ converges.
\sssc{Laplace transformability theorem}
A complex-valued function $f(t)$ defined on $[0,\infty)$ is Laplace-transformable iff it is piecewise continuous on all closed subintervals of $[0,\infty)$ and of exponential order.
\begin{proof}
Assume that a $f(t)$ is piecewise continuous on $[0,\infty)$ and there exists $M>0$ and $T>0$ such that:
\[|f(t)|\leq Me^{\alpha t}\quad \forall t>T.\]

For $s>\alpha$, since $f(t)$ is piecewise continuous on $[0,\infty)$, there exist a locally finite indexed family $A=\{[a_i,b_i]\mid i\in I\}$ such that for each $i\in I\setminus\{j\}$, the integral
\[\int_{a_i}^{b_i} |f(t)| e^{-st}\dd{t}\]
exists and is finite.

Split the integral:
\[\int_0^{\infty}f(t)e^{-st}\dd{t}=\int_0^Tf(t)e^{-st}\dd{t}+\int_T^{\infty}f(t)e^{-st}\dd{t}.\]
For the first integral, by local finiteness, there exists a finite cover of $[0,T]$ that is a subset of $A$. The sum over finitely many finite integral is finite.

For the second integral, since $|f(t)| \le M e^{\alpha t}$, we have
\[\int_T^\infty |f(t)| e^{-st}\dd{t}\le \int_T^\infty M e^{\alpha t} e^{-st}\dd{t} = M \int_T^\infty e^{-(s-\alpha)t}\dd{t},\]
which converges since $\Re(s)>\alpha$.
\end{proof}
For any complex function $g(t)$ defined on $D\superseteq\mathbb{R}_{\geq 0}$, for any indexed family $A\colon I\to\mathcal{A}\subseteq D;\;i\mapsto A_i$ with $n\in\bbN$ and $I=J\cap\bbN$ for some interval $J\ni 0$, the function
\[f(t)=g(t)\prod_{i\in I}\delta(A_i)\]
is Laplace-transformable iff $g(t)$ is Laplace-transformable and that $\sum_{a\in\mathcal{A}}a$ converges.

If $f(t)$ and $g(t)$ are Laplace-transformable, then $f(t)+g(t)$ is Laplace-transformable.
\sssc{Abscissa of convergence theorem}
PLACEHOLDER
\sssc{Linearity}
\[\mathcal{L}\{af(t)+bg(t)\}=a\mathcal{L}\{f(t)\}+b\mathcal{L}\{g(t)\},\quad a,b\in\bbC.\]
\sssc{First shifting theorem or Frequency shift}
\[\mathcal{L}\{e^{at} f(t)\}(s) = F(s-a),\]
ROC shifts right by $\Re(a)$.
\begin{proof}
\[\mathcal{L}\{e^{at} f(t)\}(s)=\int_0^{\infty}e^{-(s-a)t}f(t)=F(s-a)\]
\end{proof}
\sssc{Second shifting theorem, Time delay, or Time shift}
\[\mathcal{L}\{f(t-a)u(t-a)\}=e^{-as}F(s), \quad a > 0,\]
where $u(t)$ is the unit step function.
\begin{proof}
\[\ba
\mathcal{L}\{f(t-a)u(t-a)\}(s)&=\int_a^{\infty} e^{-st}f(t-a)\dd{t}\\
&=\int_0^{\infty}e^{-s\tau}e^{-as}f(\tau)\dd{\tau}\\
&=e^{-as}F(s)
\ea\]
\end{proof}
\sssc{Differentiation in Time Domain}
\[\mathcal{L}\{f'(t)\}(s) = sF(s) - f(0).\]
\[\mathcal{L}\{f^{(n)}(t)\}(s) = s^n F(s) - \sum_{i=0}^{n-1}s^{n-1-i}f^{(i)}(0).\]
\begin{proof}
\[u = e^{-st} \quad \Rightarrow \quad \dd{u} = -s e^{-st} \dd{t}.\]
\[dv = f'(t)\dd{t} \quad \Rightarrow \quad v = f(t).\]
\[\ba
\mathcal{L}\{f'(t)\}(s)&=\int_0^\infty e^{-st} f'(t)\dd{t}\\
&=\qty(e^{-st}f(t))\big\vert_0^\infty+\int_0^\infty f(t)se^{-st}\dd{t}\\
&=s\mathcal{L}\{f(t)\}(s)-f(0)
\ea\]
Nota that in the case where $f'(t)$ contains $\delta(0)$, using $f(0)$ holds while $f\qty(0^+)$ not.
\end{proof}
\sssc{Integration in Time Domain}
\[\mathcal{L}\left\{\int_0^t f(\tau)\dd{\tau}\right\}(s) = \frac{1}{s} F(s).\]
\begin{proof}
\bma
\mathcal{L}\{\int_0^t f(\tau)\dd{\tau}\}(s) &= \int_0^{\infty} e^{-st} \int_0^t f(\tau)\dd{\tau}\dd{t}\\
&=\qty(-\frac{1}{s}e^{-st}\int_0^t f(\tau)\dd{\tau})\big\vert_0^\infty+\int_0^{\infty} \frac{1}{s}e^{-st}f(t)\dd{t}\\
&=\frac{1}{s}\int_0^{\infty} e^{-st}f(t)\dd{t}.
\eam
\end{proof}
\sssc{Differentiation in Frequency Domain}
\[\mathcal{L}\{t f(t)\}(s) = -\dv{}{s} F(s).\]
\[\mathcal{L}\{t^n f(t)\}(s) = (-1)^n \dv[n]{}{s} F(s).\]
\begin{proof}
By Leibniz integral rule,
\bma
-\dv{}{s} F(s)&=-\dv{}{s}\int_0^{\infty} e^{-st} f(t)\,\mathrm{d}t\\
&=-\int_0^{\infty} \pdv{}{s}\qty(e^{-st} f(t))\,\mathrm{d}t\\
&=-\int_0^{\infty} -te^{-st} f(t)\,\mathrm{d}t\\
&=\int_0^{\infty} te^{-st} f(t)\,\mathrm{d}t\\
&=\mathcal{L}\{t f(t)\}(s)
\eam
\end{proof}
\sssc{Scaling in Time Domain}
\[\mathcal{L}\{f(at)\}(s) = \frac{1}{a} F\left(\frac{s}{a}\right), \quad a>0.\]
\sssc{Convolution Theorem}
If $h(t) = (f * g)(t) = \int_0^t f(\tau)g(t-\tau)\dd{\tau}$, then
\[\mathcal{L}\{h(t)\}(s) = F(s)G(s).\]
\begin{proof}
\[\mathcal{L}\{h(t)\}(s)=\int_0^{\infty} e^{-st} \qty(\int_0^t f(\tau)g(t-\tau)\dd{\tau})\dd{t}\]
By Fubini's theorem,
\[\mathcal{L}\{h(t)\}(s)=\int_0^\infty\int_\tau^\infty e^{-st} f(\tau)g(t-\tau)\dd{t}\dd{\tau}\]
Let $u=t-\tau$. $\dd{t}=\dd{u}$.
\[\begin{aligned}
\mathcal{L}\{h(t)\}(s)&=\int_0^\infty f(\tau)\int_0^\infty e^{-s(u+\tau)} g(u)\dd{u}\dd{\tau}\\
&=\int_0^\infty f(\tau)e^{-s\tau}\int_0^\infty e^{-su} g(u)\dd{u}\dd{\tau}\\
&=F(s)G(s)
\end{aligned}\]
\end{proof}
\sssc{Initial Value Theorem}
If $f(t)$ and $f'(t)$ are Laplace-transformable:
\[\lim_{t \to 0^+} f(t) = \lim_{s \to \infty} s F(s).\]
\begin{proof}
\[s F(s) = \int_0^\infty s f(t) e^{-st} \dd{t}.\]
Let $u = st$, $\dd{t} = \frac{\dd{u}}{s}$.
\[s F(s) = \int_0^\infty f\qty(\frac{u}{s}) e^{-u} \dd{u}.\]
\[\lim_{s \to \infty}s F(s)=\int_0^\infty f\qty(\frac{u}{s}) e^{-u} \dd{u}.\]

We define a net of functions $\langle f_s\rangle_{s\in\mathbb{R}_{>s_0}}$, where $s_0$ is such that $F(s)$ converges for all $\Re(s)>s_0$.

For fixed $u \in\mathbb{R}_{>0}$, $\lim_{s\to\infty}\frac{u}{s} \to 0^+$, so $f_n\qty(\frac{u}{s})$ pointwise converges to $f(0^+)$.

For dominated convergence theorem, we require an integrable function $g(u)$ such that
\[\abs{f\qty(\frac{u}{s}) e^{-u}} \le g(u), \quad \forall s > 0.\]

Since $f(t)$ is Laplace-transformable, it is of exponential order, that is, there exists $\alpha>0$, $M>0$, and $T>0$ such that:
\[|f(t)|\leq Me^{\alpha t}\quad \forall t>T.\]
\[M e^{\alpha \frac{u}{s}} e^{-u} = M e^{-u\qty(1 - \frac{\alpha}{s})}\le M e^{-\frac{u}{2}}, \quad \forall s > 2\alpha.\]

By dominated convergence theorem, we obtain:
\[\lim_{s \to \infty}s F(s)=\lim_{n\to\infty}
\int_0^\infty f(0^+) e^{-u} \dd{u}.\]

Evaluate the integral:
\[\int_0^\infty f(0^+) e^{-u} \dd{u} = f(0^+) \int_0^\infty e^{-u}\dd{u} = f(0^+).\]
\end{proof}
\ssc{Mellin's inverse formula, Bromwich integral, or Fourier–Mellin integral of Inverse Laplace transform (反拉普拉斯變換)}
The inverse Laplace transform of a complex function $F(s)$, denoted as $\mathcal{L}^{-1}\{F(s)\}(t)$ or $f(t)$, is defined as the function such that
\[\mathcal{L}\{f(t)\}(s) = F(s).\]
Mellin's inverse formula, Bromwich integral, or Fourier–Mellin integral states that, the inverse Laplace transform of a complex function $F(s)$ is given by the line integral:
\[\mathcal{L}^{-1}\{F(s)\}(t)=f(t)=\frac{1}{2\pi i}\lim_{T\to\infty}\int_{\gamma-iT}^{\gamma+iT}e^{st}F(s)\dd{s},\]
where $\gamma$ is any real number such that it is greater than the real part of all singularities of $F$ and that $F$ is bounded on the line $s=\gamma$.
\ssc{(Bilateral or Two-sided) Laplace Transform (（雙邊）拉普拉斯變換)}
PLACEHOLDER
The (bilateral or two-sided) Laplace transform is an integral transform that converts a function of a real variable (usually $t$, in the time domain) to a function of a complex variable (usually $s$, in the complex-valued angular frequency domain, also known as $s$-domain or $s$-plane). The functions are often denoted in lowercase for the time-domain representation and uppercase for the frequency-domain.

The Laplace transform of a real function $f(t)$, denoted as $\mathcal{B}\{f(t)\}(s)$, is defined by the improper integral
\[\mathcal{B}\{f(t)\}(s) = \int_{-\infty}^{\infty} e^{-st} f(t)\,\mathrm{d}t.\]
\ssc{Fourier Transform (FT) (傅立葉變換)}
PLACEHOLDER: as Laplace tranform special case
\sssc{Fourier Transform (FT)}
Fourier transform is an integral transform that converts a function of a real variable (usually $t$, in the time domain) to a function of another real variable (usually $\omega$, in the real-valued angular frequency domain). The functions are often denoted in lowercase for the time-domain representation and uppercase for the frequency-domain.

The Fourier transform, denoted as $\mathcal{F}\{f(t)\}(\omega)$ or $F(\omega)$, is defined by the improper integral
\[\mathcal{F}\{f(t)\}(\omega) = F(\omega) = \int_{-\infty}^{\infty} e^{-i\omega t} f(t)\,\mathrm{d}t.\]
\sssc{Inverse Fourier Transform (反傅立葉變換)}
The inverse Fourier transform of a complex function $F(s)$, denoted as $\mathcal{F}^{-1}\{F(s)\}(t)$ or $f(t)$, is defined as a real function such that
\[\mathcal{F}\{f(t)\}(s) = F(s),\]
where $\mathcal {F}$ denotes the Fourier transform.

The inverse Laplace transform of a complex function $F(s)$ is given by the line integral:
\[f(t) = \frac{1}{2\pi}\int_{-\infty}^{\infty} F(\omega) e^{i\omega t}\dd{\omega} .\]



\sct{Lists}
\ssc{List of Sequences}
\sssc{Arithmetic progression or sequence (等差數列)}
An arithmetic sequence is a sequence $\langle a_n\rangle=\langle a_1+(n-1)d\rangle$. 

Given $a$ and $b$, $\frac{a+b}{2}$ is called the median of an arithmetic sequence (等差中項).

\[\nexists\lim_{n\to\infty}a_n,\quad d\neq 0\]
\[\lim_{n\to\infty}a_n=a_1,\quad d=0\]
\sssc{Geometric progression or sequence (等比 or 幾何數列)}
A geometric sequence is a sequence $\langle a_n\rangle=\langle a_1\cdot r^{n-1}\rangle$, where $a_1r\neq 0$.

Given $a$ and $b$, $\pm\sqrt{ab}$ is called the median of an geometric sequence (等比中項).
\[\nexists\lim_{n\to\infty}a_n,\quad |d|\geq 1\land d\neq 1\]
\[\lim_{n\to\infty}a_n=a_1,\quad d=1\]
\[\lim_{n\to\infty}a_n=0,\quad |d|<1\]
\ssc{List of Series}
\sssc{Arithmetic series (等差級數)}
An arithmetic series is a series $S_n=\sum_{i=1}^na_i$, where $\langle a_n\rangle$ is an arithmetic sequence.
\[S_n=\frac{n}{2}\qty(a_1+a_n)=\frac{n}{2}\qty(2a_1+(n-1)d)=na_1+\frac{n(n-1)d}{2}\]
\[\nexists\lim_{n\to\infty}S_n,\quad a_1\neq 0\lor d\neq 0\]
\[\lim_{n\to\infty}S_n=0,\quad a_1=0\land d=0\]
\sssc{Geometric series (等比 or 幾何級數)}
A geometric series is a series $S_n=\sum_{i=1}^na_i$, where $\langle a_n\rangle$ is a geometric sequence.

\[S_n=\frac{a_1\qty(1-r^n)}{1-r},\quad r\neq 1\]
\[S_n=na_1,\quad r=1\]
\[\lim_{n\to\infty}S_n=\frac{a_1}{1-r},\quad \abs{r}<1\]
\[\nexists\lim_{n\to\infty}S_n,\quad \abs{r}\geq 1\]
\sssc{Riemann zeta function (黎曼 zeta 函數)}
\[\begin{aligned}
\zeta(s) &= \sum_{n=1}^\infty\frac{1}{n^s}\\
&= \frac{1}{\Gamma (s)}\int _0^\infty \frac {x^{s-1}}{e^x-1}\,\mathrm {d} x
\eam

Harmonic Series (調和級數):
\[S_n=\sum_{n=1}^n\frac{1}{n}\]
\[\nexists\sum_{n=1}^\infty\frac{1}{n}\]

Basel Problem (巴塞爾問題):
\[\zeta(2)=\frac{\pi^2}{6}\]

Other Even Positive Integers:
\[\zeta(4)=\frac{\pi^4}{90}\]
\[\zeta(6)=\frac{\pi^6}{945}\]
\[\zeta(8)=\frac{\pi^8}{9450}\]
\[\zeta(10)=\frac{\pi^{10}}{93555}\]
\[\zeta(12)=\frac{691\pi^{12}}{638512875}\]
\[\zeta(14)=\frac{2\pi^{14}}{18243225}\]

Infinity:
\[\lim_{n\to\infty}\zeta(n)=1\]
\sssc{Euler–Mascheroni constant (歐拉–馬斯克若尼常數)}
\[\begin{aligned}
\gamma &= \lim _{n\to \infty }\left(\left(\sum _{k=1}^n\frac {1}{k}\right)-\ln(n)\right)\\
&= \int _1^\infty \left(\frac{1}{\lfloor x\rfloor}-\frac{1}{x}\right)\,\mathrm{d}x
\end{aligned}\]
\sssc{Power series (冪級數)}
\[\begin{aligned}
\sum_{i=1}^ni &= \frac{n\qty(n+1)}{2}\\
\sum_{i=1}^ni^2 &= \frac{n\qty(n+1)\qty(2n+1)}{6}\\
\sum_{i=1}^ni^3 &= \qty(\frac{n(n+1)}{2})^2\\
\sum_{i=1}^ni^r &= n + \sum_{k=1}^{n-1} (n-k)((k+1)^r - k^r)\\
&= n + \sum_{k=1}^{n-1} (n-k)\sum_{j=0}^{r-1}\binom{r}{j}k^{j}
\end{aligned}\]
\ssc{List of Limits of Real Functions}
\sssc{Limit of sine function over independent variable at zero}
\[\lim_{h\to 0}\frac{\sin h}{h}=1.\]
\begin{proof}
On a unit circle with center $O$, consider the arc $\arc{AB}=h$ subtended by acute angle $h$ (i.e. $\frac{\pi}{2}>h>0$), the chord length $\ol{BC}=\sin(h)$ with $C$ be the intersection of the chord and $\ora{OA}$, and the tangent length $\ol{AD}=\tan(h)$ with $D$ be the intersection of the tangent and $\ora{OB}$.

We can observe that
\[\ol{BC}<\arc{AB}.\]

Take tangent of the circle at $B$. Let it intersects $\ol{AD}$ at $E$. We can observe that the adjacent $\ol{BE}$ is less than the hypothenuse $\ol{DE}$. Thus
\[\arc{AB}<\ol{BE}+\ol{AE}<\ol{DE}+\ol{AE}=\ol{AD}.\]

Thus,
\[\sin h<h<\tan h.\]
\[1<\frac{h}{\sin h}<\frac{1}{\cos h}.\]
\[\cos h<\frac{\sin h}{h}<1.\]
\[\lim_{h\to 0}\cos h=1.\]

By the squeeze theorem:
\[\lim_{h\to 0}\frac{\sin h}{h}=1.\]
\end{proof}
\ssc{List of Derivatives of Real Functions and Real Functions as Definite Integrals}
\sssc{Power function}
\[\dv{x^n}{x}=nx^{n-1}.\]
\[x^n=n\int_0^xt^{n-1}\dd{t}.\]
\begin{proof}
\[\dv{x^n}{x}=\lim_{h\to 0}\frac{(x+h)^n-x^n}{h}=\lim_{h\to 0}\frac{\sum_{k=1}^{\infty}\binom{n}{k}x^{n-k}h^k}{h}=nx^{n-1}.\]
\end{proof}
\sssc{Absolute value function}
\[\dv{|x|}{x}=\sgn(x),\quad x\neq 0.\]
\sssc{Logarithmic function}
\[\dv{\ln(x)}{x}=\frac{1}{x}.\]
\[\ln(x)=\int_1^x\frac{1}{t}\dd{t},\quad x>0.\]
\sssc{Exponential function}
\[\dv{a^x}{x}=\ln(a)a^x.\]
\[a^x=1+\int_0^x\ln(a)a^t\dd{t}.\]
\begin{proof}
\[\ba
\dv{a^x}{x}&=\lim_{h\to 0}\frac{a^{x+h}-a^x}{h}\\
&=a^x\lim_{h\to 0}\frac{a^h-1}{h}\\
&=a^x\lim_{h\to 0}\frac{e^{\ln(a)h}-1}{h}\\
&=a^x\lim_{h\to 0}\frac{\lim_{n\to\infty}\sum_{k=0}^n\frac{\qty(\ln(a)h)^k}{k!}-1}{h}\\
&=a^x\lim_{h\to 0}\frac{\lim_{n\to\infty}\sum_{k=1}^n\frac{\qty(\ln(a)h)^k}{k!}}{h}\\
&=\ln(a)a^x
\ea\]
\end{proof}
\sssc{Sine function}
\[\dv{\sin(x)}{x}=\cos(x).\]
\[\sin(x)=\int_0^x\cos(t)\dd{t}.\]
\begin{proof}
\[\begin{aligned}
\dv{\sin(x)}{x}&=\lim_{h\to 0}\frac{\sin(x+h)-\sin(x)}{h}\\
&=\lim_{h\to 0}\frac{\sin(x)(\cos (h)-1)+\cos(x)\sin(h)}{h}
\end{aligned}\]
\[\cos(h)-1=-2\sin^2\qty(\frac{h}{2}),\]
\[\frac{\sin^2\qty(\frac{h}{2})}{h}=\frac{\sin\qty(\frac{h}{2})}{\frac{h}{2}}\cdot\frac{\sin\qty(\frac{h}{2})}{2}.\]
By
\[\lim_{h\to 0}\frac{\sin(h)}{h}=1.\]
we have:
\[\lim_{h\to 0}\frac{\cos(h)-1}{h}=0.\]
\[\begin{aligned}
&=\lim_{h\to 0}\sin(x)\cdot 0+\cos(x)\cdot 1\\
&=\cos(x).
\end{aligned}\]
\end{proof}
\sssc{Cosine function}
\[\dv{\cos(x)}{x}=-\sin(x).\]
\[\cos(x)=1-\int_0^x\sin(t)\dd{t}.\]
\sssc{Tangent function}
\[\dv{\tan(x)}{x}=\sec^2(x).\]
\[\tan(x)=\int_{\operatorname{round}\qty(\frac{x}{\pi})\pi}^x\sec^2(t)\dd{t},\quad x\in\bbR\setminus\{\frac{\pi}{2}+k\pi\mid k\in\bbZ\},\]
in which $\operatorname{round}(x)=\left\lfloor x+\frac{1}{2}\right\rfloor$.
\begin{proof}
\[\begin{aligned}
\dv{\tan(x)}{x}&=\dv{}{x}\frac{\sin(x)}{\cos(x)}\\
&=\frac{\cos^2(x)+\sin^2(x)}{\cos^2(x)}\\
&=\sec^2(x).
\end{aligned}\]
\end{proof}
\sssc{Cotangent function}
\[\dv{\cot(x)}{x}=-\csc^2(x).\]
\[\cot(x)=-\int_{\frac{\pi}{2}+\operatorname{round}\qty(\frac{x}{\pi}-\frac{1}{2})\pi}^x\csc^2(t)\dd{t},\quad x\in\bbR\setminus\{k\pi\mid k\in\bbZ\},\]
in which $\operatorname{round}(x)=\left\lfloor x+\frac{1}{2}\right\rfloor$.
\begin{proof}
\[\cot(x)=\frac{\cos(x)}{\sin(x)}.\]
\[\begin{aligned}
\dv{\cot(x)}{x}&=\dv{}{x}\frac{\cos(x)}{\sin(x)}\\
&=\frac{-\sin^2(x)-\cos^2(x)}{\sin^2(x)}\\
&=-\csc^2(x).
\end{aligned}\]
\end{proof}
\sssc{Secant function}
\[\dv{\sec(x)}{x}=\tan(x)\sec(x).\]
\[\sec(x)=\int_{\operatorname{round}\qty(\frac{x}{\pi})\pi}^x\tan(t)\sec(t)\dd{t},\quad x\in\bbR\setminus\{\frac{\pi}{2}+k\pi\mid k\in\bbZ\},\]
in which $\operatorname{round}(x)=\left\lfloor x+\frac{1}{2}\right\rfloor$.
\begin{proof}
\[\ba
\dv{\sec(x)}{x}&=\dv{}{x}\frac{1}{\cos(x)}\\
&=\frac{\sin(x)}{\cos^2(x)}\\
&=\tan(x)\sec(x).
\ea\]
\end{proof}
\sssc{Cosecant function}
\[\dv{\csc(x)}{x}=-\cot(x)\csc(x).\]
\[\csc(x)=-\int_{\frac{\pi}{2}+\operatorname{round}\qty(\frac{x}{\pi}-\frac{1}{2})\pi}^x\cot(t)\csc(t)\dd{t},\]
in which $\operatorname{round}(x)=\left\lfloor x+\frac{1}{2}\right\rfloor$.
\begin{proof}
\[\ba
\dv{\csc(x)}{x}&=\dv{}{x}\frac{1}{\sin(x)}\\
&=\frac{-\cos(x)}{\sin^2(x)}\\
&=-\cot(x)\csc(x).
\ea\]
\end{proof}
\sssc{Inverse sine function}
\[\dv{\arcsin(x)}{x}=\frac{1}{\sqrt{1-x^2}}.\]
\[\arcsin(x)=\int_0^x\frac{1}{\sqrt{1-t^2}}\dd{t},\quad\abs{x}\leq 1.\]
\begin{proof}
Let $y=\arcsin(x)$. $\sin(y)=x$.
\[\dv{}{x}\sin(y)=\dv{}{x}(x).\]
Using the chain rule on the left:
\[\cos(y)\dv{y}{x}=1.\]
\[\dv{y}{x}=\frac{1}{\cos(y)}=\frac{1}{\sqrt{1-x^2}}.\]
\end{proof}
\sssc{Inverse cosine function}
\[\dv{\arccos(x)}{x}=-\frac{1}{\sqrt{1-x^2}}.\]
\[\arccos(x)=\int_x^1\frac{1}{\sqrt{1-t^2}}\dd{t},\quad\abs{x}\leq 1.\]
\begin{proof}
Let $y=\arccos(x)$. $\cos(y)=x$.
\[\dv{}{x}\cos(y)=\dv{}{x}(x).\]
Using the chain rule on the left:
\[-\sin(y)\dv{y}{x}=1.\]
\[\dv{y}{x}=-\frac{1}{\cos(y)}=-\frac{1}{\sqrt{1-x^2}}.\]
\end{proof}
\sssc{Inverse tangent function}
\[\dv{\arctan(x)}{x}=\frac{1}{1+x^2}.\]
\[\arctan(x)=\int_0^x\frac{1}{1+t^2}\dd{t}.\]
\begin{proof}
Let $y=\arctan(x)$. $\tan(y)=x$.
\[\dv{}{x}\tan(y)=\dv{}{x}(x).\]
Using the chain rule on the left:
\[\sec^2(y)\dv{y}{x}=1.\]
\[\dv{y}{x}=\cos^2(y)=\frac{1}{1+x^2}.\]
\end{proof}
\sssc{Inverse cotangent function}
\[\dv{\arccot(x)}{x}=-\frac{1}{1+x^2}.\]
\[\arccot(x)=\int_x^{\infty}\frac{1}{1+t^2}\dd{t}.\]
\begin{proof}
Let $y=\arccot(x)$. $\cot(y)=x$.
\[\dv{}{x}\cot(y)=\dv{}{x}(x).\]
Using the chain rule on the left:
\[-\csc^2(y)\dv{y}{x}=1.\]
\[\dv{y}{x}=-\sin^2(y)=-\frac{1}{1+x^2}.\]
\end{proof}
\sssc{Inverse secant function}
\[\dv{\arcsec(x)}{x}=\frac{1}{|x|\sqrt{x^2-1}}.\]
\[\arcsec(x)=\sgn(x)\int_1^{\abs{x}}\frac{1}{t\sqrt{t^2-1}}\dd{t}+(1-\sgn(x))\frac{\pi}{2},\quad\abs{x}\geq 1.\]
\begin{proof}
\[\ba
\dv{\arcsec(x)}{x}&=\dv{\arccos(\frac{1}{x})}{x}\\
&=-\frac{1}{\sqrt{1-x^{-2}}}\qty(-x^{-2})\\
&=\frac{1}{|x|\sqrt{x^2-1}}
\ea\]
\end{proof}
\sssc{Inverse cosecant function}
\[\dv{\arccsc(x)}{x}=-\frac{1}{|x|\sqrt{x^2-1}}.\]
\[\arccsc(x)=\sgn(x)\int_{\abs{x}}^{\infty}\frac{1}{t\sqrt{t^2-1}}\dd{t},\quad\abs{x}\geq 1.\]
\begin{proof}
\[\ba
\dv{\arccsc(x)}{x}&=\dv{\arcsin(\frac{1}{x})}{x}\\
&=\frac{1}{\sqrt{1-x^{-2}}}\qty(-x^{-2})\\
&=-\frac{1}{|x|\sqrt{x^2-1}}
\ea\]
\end{proof}
\sssc{Hyperbolic sine function}
\[\dv{\sinh(x)}{x}=\cosh(x).\]
\begin{proof}
\[\ba
\dv{\sinh(x)}{x}&=\dv{}{x}\qty(\frac{e^x-e^{-x}}{2})\\
&=\frac{e^x+e^{-x}}{2}=\cosh(x)
\ea\]
\end{proof}
\sssc{Hyperbolic cosine function}
\[\dv{\cosh(x)}{x}=\sinh(x).\]
\begin{proof}
\[\ba
\dv{\cosh(x)}{x}&=\dv{}{x}\qty(\frac{e^x+e^{-x}}{2})\\
&=\frac{e^x-e^{-x}}{2}=\sinh(x)
\ea\]
\end{proof}
\sssc{Hyperbolic tangent function}
\[\dv{\tanh(x)}{x}=\sech^2(x).\]
\begin{proof}
\[\ba
\dv{\tanh(x)}{x}&=\dv{}{x}\qty(\frac{e^{2x}-1}{e^{2x}+1})\\
&=\frac{2e^{2x}\qty(e^{2x}+1)-\qty(e^{2x}-1)2e^{2x}}{\qty(e^{2x}+1)^2}\\
&=\frac{4e^{2x}}{\qty(e^{2x}+1)^2}\\
&=\qty((\frac{2}{e^x+e^{-x}})^2\\
&=\sech^2(x)
\ea\]
\end{proof}
\sssc{Hyperbolic cotangent function}
\[\dv{\coth(x)}{x}=-\csch^2(x).\]
\begin{proof}
\[\ba
\dv{\coth(x)}{x}&=\dv{}{x}\qty(\frac{e^{2x}+1}{e^{2x}-1})\\
&=\frac{2e^{2x}\qty(e^{2x}-1)-\qty(e^{2x}+1)2e^{2x}}{\qty(e^{2x}-1)^2}\\
&=\frac{-4e^{2x}}{\qty(e^{2x}-1)^2}\\
&=-\qty((\frac{2}{e^x-e^{-x}})^2\\
&=-\csch^2(x)
\ea\]
\end{proof}
\sssc{Hyperbolic secant function}
\[\dv{\sech(x)}{x}=-\tanh(x)\sech(x).\]
\begin{proof}
\[\ba
\dv{\sech(x)}{x}&=\dv{}{x}\qty(\frac{2}{e^x+e^{-x}})\\
&=\dv{}{x}\qty(\frac{-2\qty(e^x-e^{-x})}{\qty(e^x+e^{-x})^2})\\
&=-\tanh(x)\sech(x)
\ea\]
\end{proof}
\sssc{Hyperbolic cosecant function}
\[\dv{\csch(x)}{x}=-\coth(x)\csch(x).\]
\begin{proof}
\[\ba
\dv{\csch(x)}{x}&=\dv{}{x}\qty(\frac{2}{e^x-e^{-x}})\\
&=\dv{}{x}\qty(\frac{-2\qty(e^x+e^{-x})}{\qty(e^x-e^{-x})^2})\\
&=-\coth(x)\csch(x)
\ea\]
\end{proof}
\sssc{Inverse hyperbolic sine function}
\[\dv{\arcsinh(x)}{x}=\frac{1}{\sqrt{x^2+1}}.\]
\begin{proof}
\[\ba
\dv{\arcsinh(x)}{x}&=\dv{}{x}\ln(x+\sqrt{x^2+1})\\
&=\frac{1+\frac{x}{\sqrt{x^2+1}}}{x+\sqrt{x^2+1}}\\
&=\frac{1}{\sqrt{x^2+1}}
\ea\]
\end{proof}
\sssc{Inverse hyperbolic cosine function}
\[\dv{\arccosh(x)}{x}=\frac{1}{\sqrt{x^2-1}}.\]
\begin{proof}
\[\ba
\dv{\arccosh(x)}{x}&=\dv{}{x}\ln(x+\sqrt{x^2-1})\\
&=\frac{1+\frac{x}{\sqrt{x^2-1}}}{x+\sqrt{x^2-1}}\\
&=\frac{1}{\sqrt{x^2-1}}
\ea\]
\end{proof}
\sssc{Inverse hyperbolic tangent function}
\[\dv{\arctanh(x)}{x}=\frac{1}{1-x^2},\quad|x|<1.\]
\begin{proof}
\[\ba
\dv{\arctanh(x)}{x}&=\frac{1}{2}\dv{}{x}\ln(\frac{1+x}{1-x})\\
&=\frac{1}{2}\frac{1-x}{1+x}\frac{(1-x)-(-1)(1+x)}{(1-x)^2}\\
&=\frac{1}{2}\frac{1}{1+x}\frac{2}{1-x}\\
&=\frac{1}{1-x^2}
\ea\]
\end{proof}
\sssc{Inverse hyperbolic cotangent function}
\[\dv{\arccoth(x)}{x}=\frac{1}{1-x^2},\quad|x|>1.\]
\begin{proof}
\[\ba
\dv{\arccoth(x)}{x}&=\frac{1}{2}\dv{}{x}\ln(\frac{x+1}{x-1})\\
&=\frac{1}{2}\frac{x-1}{x+1}\frac{(x-1)-(x+1)}{(x-1)^2}\\
&=\frac{1}{2}\frac{1}{x+1}\frac{-2}{x-1}\\
&=\frac{1}{1-x^2}
\ea\]
\end{proof}
\sssc{Inverse hyperbolic secant function}
\[\dv{\arcsech(x)}{x}=-\frac{1}{x\sqrt{1-x^2}}.\]
\begin{proof}
\[\ba
\dv{\arcsech(x)}{x}&=\dv{}{x}\ln(\frac{1}{x}+\frac{\sqrt{1-x^2}}{x})\\
&=\frac{x}{1+\sqrt{1-x^2}}\frac{\frac{-x}{\sqrt{1-x^2}}x-\qty(1+\sqrt{1-x^2})}{x^2}\\
&=\frac{1}{1+\sqrt{1-x^2}}\frac{-x^2-\sqrt{1-x^2}-1+x^2}{x\sqrt{1-x^2}}\\
&=-\frac{1}{x\sqrt{1-x^2}}
\ea\]
\end{proof}
\sssc{Inverse hyperbolic cosecant function}
\[\dv{\arccsch(x)}{x}=-\frac{1}{|x|\sqrt{1+x^2}}.\]
\begin{proof}
\[\ba
\dv{\arccsch(x)}{x}&=\dv{}{x}\ln(\frac{1}{x}+\frac{\sqrt{1+x^2}}{|x|})\\
&=\dv{}{x}\ln(\frac{1+\sgn(x)\sqrt{1+x^2}}{x})\\
&=\frac{x}{1+\sgn(x)\sqrt{1+x^2}}\frac{\frac{\sgn(x)x}{\sqrt{1+x^2}}x-\qty(1+\sgn(x)\sqrt{1+x^2})}{x^2}\\
&=\frac{1}{1+\sgn(x)\sqrt{1+x^2}}\frac{-\sqrt{1+x^2}-\sgn(x)}{x\sqrt{1+x^2}}\\
&=\frac{-\sgn(x)}{x\sqrt{1+x^2}}\\
&=-\frac{1}{|x|\sqrt{1+x^2}}
\ea\]
\end{proof}
\ssc{List of Integrals of Real Functions}
\sssc{Power function}
\[\int x^{-1}\dd{x}=\ln|x|+C.\]
\[\int x^n\dd{x}=\frac{1}{n+1}x^{n+1}+C,\quad n\neq -1\]
\sssc{Logarithmic function}
\[\int\ln(x)\dd{x}=x\ln(x)-x+C.\]
\begin{proof}
    \[\int\ln(x)\dd{x}=x\ln(x)-\int x\frac{1}{x}\dd{x}=x\ln(x)-x+C.\]
\end{proof}
\[\int\qty(\ln(x))^n\dd{x}=x\qty(\ln(x))^n-n\int\qty(\ln(x))^{n-1}\dd{x},\quad n\in\bbN.\]
\sssc{Exponential function}
\[\int e^{nx}\dd{x}=\frac{1}{n}e^{nx}+C,\quad n\neq 0.\]
\sssc{Sine function}
\[\int\sin(x)\dd{x}=-\cos(x)+C.\]
\[\int\sin^2(x)\dd{x}=\frac{x}{2}-\frac{\sin(2x)}{4}+C.\]
\begin{proof}
    \[\sin^2(x)=\frac{1}{2}\qty(1-\cos(2x)).\]
    \[\int\sin^2(x)\dd{x}=\frac{x}{2}-\frac{1}{2}\int\cos(2x)\dd{x}=\frac{x}{2}-\frac{\sin(2x)}{4}+C.\]
\end{proof}
\[\int\sin^n(x)\dd{x}=-\frac{1}{n}\sin^{n-1}(x)\cos(x)+\frac{n-1}{n}\int\sin^{n-2}(x)\dd{x},\quad n\in\bbN_{>2}.\]
\begin{proof}
\[\ba
\int\sin^n(x)\dd{x}&=-\sin^{n-1}(x)\cos(x)-(n-1)\int\sin^{n-2}(x)\cos^2(x)\dd{x}\\
&=-\sin^{n-1}(x)\cos(x)-(n-1)\int\sin^{n-2}(x)\dd{x}+(n-1)\int\sin^n(x)\dd{x}\\
&=-\frac{1}{n}\sin^{n-1}(x)\cos(x)+\frac{n-1}{n}\int\sin^{n-2}(x)\dd{x}
\ea\]
\end{proof}
\sssc{Cosine function}
\[\int\cos(x)\dd{x}=\sin(x)+C.\]
\[\int\cos^2(x)\dd{x}=\frac{x}{2}+\frac{\sin(2x)}{4}+C.\]
\begin{proof}
    \[\sin^2(x)=\frac{1}{2}\qty(1+\cos(2x)).\]
    \[\int\sin^2(x)\dd{x}=\frac{x}{2}+\frac{1}{2}\int\cos(2x)\dd{x}=\frac{x}{2}+\frac{\sin(2x)}{4}+C.\]
\end{proof}
\[\int\cos^n(x)\dd{x}=\frac{1}{n}\cos^{n-1}(x)\sin(x)+\frac{n-1}{n}\int\cos^{n-2}(x)\dd{x},\quad n\in\bbN_{>2}.\]
\begin{proof}
\[\ba
\int\cos^n(x)\dd{x}&=\cos^{n-1}(x)\sin(x)+(n-1)\int\cos^{n-2}(x)\sin^2(x)\dd{x}\\
&=\cos^{n-1}(x)\sin(x)+(n-1)\int\cos^{n-2}(x)\dd{x}-(n-1)\int\cos^n(x)\dd{x}\\
&=\frac{1}{n}\cos^{n-1}(x)\sin(x)+\frac{n-1}{n}\int\cos^{n-2}(x)\dd{x}
\ea\]
\end{proof}
\sssc{Tangent function}
\[\int\tan(x)\dd{x}=-\ln\abs{\cos(x)}+C=\ln\abs{\sec(x)}+C.\]
\begin{proof}
\[\ba
\int\tan(x)\dd{x}&=-\int\frac{-\sin(x)}{\cos(x)}\dd{x}\\
&=-\ln\abs{\cos(x)}+C=\ln\abs{\sec(x)}+C
\ea\]
\end{proof}
\[\int\tan^2(x)\dd{x}=\tan(x)-x+C.\]
\begin{proof}
\[\ba
\int\tan^2(x)\dd{x}&=\int\sec^2(x)-1\dd{x}\\
&=\tan(x)-x+C
\ea\]
\end{proof}
\[\int\tan^n(x)\dd{x}=\frac{1}{n-1}\tan^{n-1}(x)-\int\tan^{n-2}(x)\dd{x},\quad n\in\bbN_{>2}.\]
\begin{proof}
\[\int\tan^n(x)\dd{x}=\int\tan^{n-2}(x)\sec^2(x)\dd{x}-\int\tan^{n-2}(x)\dd{x}\]
\[u=\tan^{n-2}(x),\quad\dd{v}=\sec^2(x)\dd{x},\dd{u}=(n-2)\tan^{n-3}(x)\sec^2(x),\quad v=\tan(x).\]
\[\ba
\int\tan^{n-2}(x)\sec^2(x)\dd{x}&=\tan^{n-1}(x)-(n-2)\int\tan^{n-2}(x)\sec^2(x)\dd{x}\\
&=\frac{1}{n-1}\tan^{n-1}(x)
\ea\]
\[\int\tan^n(x)\dd{x}=\frac{1}{n-1}\tan^{n-1}(x)-\int\tan^{n-2}(x)\dd{x}.\]
\end{proof}
\sssc{Cotangent function}
\[\int\cot(x)\dd{x}=\ln\abs{\sin(x)}+C.\]
\begin{proof}
\[\ba
\int\cot(x)\dd{x}&=\int\frac{-\cos(x)}{\sin(x)}\dd{x}\\
&=\ln\abs{\sin(x)}+C
\ea\]
\end{proof}
\[\int\cot^2(x)\dd{x}=-\cot(x)-x+C.\]
\begin{proof}
\[\ba
\int\cot^2(x)\dd{x}&=\int\csc^2(x)-1\dd{x}\\
&=-\cot(x)-x+C
\ea\]
\end{proof}
\[\int\cot^n(x)\dd{x}=-\frac{1}{n-1}\cot^{n-1}(x)-\int\cot^{n-2}(x)\dd{x},\quad n\in\bbN_{>2}.\]
\begin{proof}
\[\int\cot^n(x)\dd{x}=\int\cot^{n-2}(x)\csc^2(x)\dd{x}-\int\cot^{n-2}(x)\dd{x}\]
\[u=\cot^{n-2}(x),\quad\dd{v}=\csc^2(x)\dd{x},\dd{u}=-(n-2)\cot^{n-3}(x)\csc^2(x),\quad v=-\cot(x).\]
\[\ba
\int\cot^{n-2}(x)\csc^2(x)\dd{x}&=-\cot^{n-1}(x)+(n-2)\int\cot^{n-2}(x)\csc^2(x)\dd{x}\\
&=\frac{1}{n-1}\cot^{n-1}(x)
\[\int\cot^n(x)\dd{x}=-\frac{1}{n-1}\cot^{n-1}(x)-\int\cot^{n-2}(x)\dd{x}.\]
\ea\]
\end{proof}
\sssc{Secant function}
\[\int\sec(x)\dd{x}=\ln\abs{\tan(x)+\sec(x)}+C=\ln\abs{\tan(\frac{x}{2}+\frac{\pi}{4})}+C.\]
\begin{proof}
\[\ba
\int\sec(x)\dd{x}&=\int\sec(x)\frac{\tan(x)+\sec(x)}{\tan(x)+\sec(x)}\dd{x}\\
&=\int u^{-1}\dd{u},\quad u=\tan(x)+\sec(x),\quad\dd{u}=\sec(x)\qty(\tan(x)+\sec(x))\dd{x}\\
&=\ln|u|+C=\ln\abs{\tan(x)+\sec(x)}+C\\
&=\ln|\tan(\frac{x}{2}+\frac{\pi}{4})+C
\ea\]
\end{proof}
\[\int\sec^2(x)\dd{x}=\tan(x)+C.\]
\[\int\sec^n(x)\dd{x}=\frac{1}{n-1}\tan(x)\sec^{n-2}(x)+\frac{n-2}{n-1}\int\sec^{n-2}(x)\dd{x},\quad n\in\bbN_{>2}.\]
\begin{proof}
\[\ba
\int\sec^n(x)\dd{x}&=\tan(x)\sec^{n-2}(x)-\int\tan(x)(n-2)\sec^{n-3}(x)\tan(x)\sec(x)\dd{x}\\
&=\tan(x)\sec^{n-2}(x)-(n-2)\int\sec^n(x)-\sec^{n-2}(x)\dd{x}\\
&=\frac{1}{n-1}\tan(x)\sec^{n-2}(x)+\frac{n-2}{n-1}\int\sec^{n-2}(x)\dd{x}\\
\ea\]
\end{proof}
\sssc{Cosecant function}
\[\int\csc(x)\dd{x}=-\ln\abs{\cot(x)+\csc(x)}+C=-\ln\abs{\cot(\frac{x}{2})}+C.\]
\begin{proof}
\[\ba
\int\csc(x)\dd{x}&=\int\csc(x)\frac{\cot(x)+\csc(x)}{\cot(x)+\csc(x)}\dd{x}\\
&=-\int u^{-1}\dd{u},\quad u=\cot(x)+\csc(x),\quad\dd{u}=-\cot(x)\qty(\cot(x)+\csc(x))\dd{x}\\
&=-\ln|u|+C=\ln\abs{\cot(x)+\csc(x)}+C\\
&=-\ln\abs{\cot(\frac{x}{2})}+C
\ea\]
\end{proof}
\[\int\csc^2(x)\dd{x}=-\cot(x)+C.\]
\[\int\csc^n(x)\dd{x}=-\frac{1}{n-1}\cot(x)\csc^{n-2}(x)+\frac{n-2}{n-1}\int\csc^{n-2}(x)\dd{x},\quad n\in\bbN_{>2}.\]
\begin{proof}
\[\ba
\int\csc^n(x)\dd{x}&=-\cot(x)\csc^{n-2}(x)+\int\cot(x)(n-2)\csc^{n-3}(x)(-1)\cot(x)\csc(x)\dd{x}\\
&=-\cot(x)\csc^{n-2}(x)-(n-2)\int\csc^n(x)-\csc^{n-2}(x)\dd{x}\\
&=-\frac{1}{n-1}\cot(x)\csc^{n-2}(x)+\frac{n-2}{n-1}\int\csc^{n-2}(x)\dd{x}\\
\ea\]
\end{proof}
\sssc{Inverse sine function}
\[\int\arcsin(x)\dd{x}=x\arcsin(x)+\sqrt{1-x^2}+C.\]
\sssc{Inverse cosine function}
\[\int\arccos(x)\dd{x}=x\arccos(x)-\sqrt{1-x^2}+C.\]
\sssc{Inverse tangent function}
\[\int\arctan(x)\dd{x}=x\arctan(x)-\frac{1}{2}\ln(1+x^2)+C.\]
\sssc{Inverse cotangent function}
\[\int\arccot(x)\dd{x}=x\arccot(x)+\frac{1}{2}\ln(1+x^2)+C.\]
\sssc{Inverse secant function}
\[\int\arcsec(x)\dd{x}=x\arcsec(x)-\sgn(x)\ln\abs{x+\sqrt{x^2-1}}+C,\quad|x|\geq 1.\]
\sssc{Inverse cosecant function}
\[\int\arccsc(x)\dd{x}=x\arccsc(x)+\sgn(x)\ln\abs{x+\sqrt{x^2-1}}+C,\quad|x|\geq 1.\]
\sssc{Hyperbolic sine function}
\[\int\sinh(x)\dd{x}=\cosh(x)+C.\]
\[\int\sinh^2(x)\dd{x}=-\frac{x}{2}+\frac{\sinh(2x)}{4}+C.\]
\begin{proof}
PLACEHOLDER
\end{proof}
\[\int\sinh^n(x)\dd{x}=\frac{1}{n}\sinh^{n-1}(x)\cosh(x)-\frac{n-1}{n}\int\sinh^{n-2}(x)\dd{x},\quad n\in\bbN_{>2}.\]
\begin{proof}
PLACEHOLDER
\end{proof}
\sssc{Hyperbolic cosine function}
\[\int\cosh(x)\dd{x}=\sinh(x)+C.\]
\[\int\cosh^2(x)\dd{x}=\frac{x}{2}+\frac{\sinh(2x)}{4}+C.\]
\begin{proof}
PLACEHOLDER
\end{proof}
\[\int\cosh^n(x)\dd{x}=\frac{1}{n}\cosh^{n-1}(x)\sinh(x)+\frac{n-1}{n}\int\cosh^{n-2}(x)\dd{x},\quad n\in\bbN_{>2}.\]
\begin{proof}
PLACEHOLDER
\end{proof}
\sssc{Hyperbolic tangent function}
\[\int\tanh(x)\dd{x}=\ln(\cosh(x))+C.\]
\begin{proof}
\[\ba
\int\tanh(x)\dd{x}&=\int\frac{\sinh(x)}{\cosh(x)}\dd{x}\\
&=\ln(\cosh(x))+C
\ea\]
\end{proof}
\[\int\tanh^2(x)\dd{x}=x-\tanh(x)+C.\]
\begin{proof}
PLACEHOLDER
\end{proof}
\[\int\tanh^n(x)\dd{x}=\frac{1}{n-1}\tanh^{n-1}(x)-\int\tanh^{n-2}(x)\dd{x},\quad n\in\bbN_{>2}.\]
\begin{proof}
PLACEHOLDER
\end{proof}
\sssc{Hyperbolic cotangent function}
\[\int\coth(x)\dd{x}=\ln\abs{\sinh(x)}+C.\]
\begin{proof}
\[\ba
\int\coth(x)\dd{x}&=\int\frac{\cosh(x)}{\sinh(x)}\dd{x}\\
&=\ln\abs{\sinh(x)}+C
\ea\]
\end{proof}
\[\int\coth^2(x)\dd{x}=x-\coth(x)+C.\]
\begin{proof}
PLACEHOLDER
\end{proof}
\[\int\coth^n(x)\dd{x}=-\frac{1}{n-1}\coth^{n-1}(x)-\int\coth^{n-2}(x)\dd{x},\quad n\in\bbN_{>2}.\]
\begin{proof}
PLACEHOLDER
\end{proof}
\sssc{Hyperbolic secant function}
\[\int\sech(x)\dd{x}=2\arctan(\tanh(\frac{x}{2}))+C=\arctan(\sinh(x))+C=\arcsin(\tanh(x))+C.\]
\begin{proof}
\[\ba
\int\sech(x)\dd{x}&=\int\frac{1-t^2}{1+t^2}\dd{x},\quad t=\tanh(\frac{x}{2})\\
&=2\int\frac{1}{1+t^2}\dd{t},\quad\dd{t}=\frac{1}{2}\sech^2\qty(\frac{x}{2})\dd{x}=\frac{1}{2}\qty(1-\tanh^2\qty(\frac{x}{2}))\dd{x}\\
&=2\arctan(\tanh(\frac{x}{2}))+C\\
&=\arctan(\sinh(x))+C\\
&=\arcsin(\tanh(x))+C
\ea\]
\end{proof}
\[\int\sech^2(x)\dd{x}=\tanh(x)+C.\]
\[\int\sech^n(x)\dd{x}=\frac{1}{n-1}\tanh(x)\sech^{n-1}(x)+\frac{n-2}{n-1}\int\sech^{n-2}(x)\dd{x},\quad n\in\bbN_{>2}.\]
\begin{proof}
PLACEHOLDER
\end{proof}
\sssc{Hyperbolic cosecant function}
\[\int\csch(x)\dd{x}=\ln\abs{\tanh(\frac{x}{2})}+C=\ln\abs{\coth(x)-\csch(x)}+C.\]
\begin{proof}
\[\ba
\int\csch(x)\dd{x}&=\int\frac{1-t^2}{2t}\dd{x},\quad t=\tanh(\frac{x}{2})\\
&=\int\frac{1}{t}\dd{t},\quad\dd{t}=\frac{1}{2}\sech^2\qty(\frac{x}{2})\dd{x}=\frac{1}{2}\qty(1-\tanh^2\qty(\frac{x}{2}))\dd{x}\\
&=\ln\abs{\tanh(\frac{x}{2})}+C\\
&=\ln\abs{\coth(x)-\csch(x)}+C
\ea\]
\end{proof}
\[\int\csch^2(x)\dd{x}=-\coth(x)+C.\]
\[\int\csch^n(x)\dd{x}=-\frac{1}{n-1}\coth(x)\csch^{n-1}(x)+\frac{n-2}{n-1}\int\csch^{n-2}(x)\dd{x},\quad n\in\bbN_{>2}.\]
\begin{proof}
PLACEHOLDER
\end{proof}
\sssc{Inverse hyperbolic sine function}
\[\int\arcsinh(x)\dd{x}=x\arcsinh(x)-\sqrt{x^2+1}+C.\]
\sssc{Inverse hyperbolic cosine function}
\[\int\arccosh(x)\dd{x}=x\arccosh(x)-\sqrt{x^2-1}+C.\]
\sssc{Inverse hyperbolic tangent function}
\[\int\arctanh(x)\dd{x}=x\arctanh(x)+\frac{1}{2}\ln(1-x^2)+C.\]
\sssc{Inverse hyperbolic cotangent function}
\[\int\arccoth(x)\dd{x}=x\arccoth(x)+\frac{1}{2}\ln(x^2-1)+C.\]
\sssc{Inverse hyperbolic secant function}
\[\int\arcsech(x)\dd{x}=x\arcsech(x)+\arctan\qty(\frac{\sqrt{1-x^2}}{x})+C.\]
\sssc{Inverse hyperbolic cosecant function}
\[\int\arccsch(x)\dd{x}=x\arccsch(x)+\ln\abs{x+\sqrt{x^2+1}}+C.\]
\sssc{Derivative over function}
\[\int\frac{f'(x)}{f(x)}\dd{x}=\ln|f(x)|+C,\quad f(x)\neq 0.\]
\sssc{$\frac{1}{x^2+a^2}$}
\[\int\frac{1}{x^2+a^2}\dd{x}=\frac{1}{a}\arctan(\frac{x}{a})+C,\quad a>0.\]
\begin{proof}
\[\ba
\int\frac{1}{x^2+a^2}\dd{x}&=\frac{1}{a}\int\frac{1}{u^2+1^2}\dd{u},\quad u=\frac{x}{a},\quad\dd{u}=\frac{1}{a}\dd{x}\\
&=\frac{1}{a}\arctan(\frac{x}{a})+C
\ea\]
\end{proof}
\sssc{$\frac{1}{x^2-a^2}$}
\[\int\frac{1}{x^2-a^2}\dd{x}=\frac{1}{2a}\ln(\frac{x-a}{x+a})+C=\frac{1}{a}\arccoth(\frac{x}{a})+C,\quad a>0\land x^2-a^2>0.\]
\begin{proof}
\[\ba
\int\frac{1}{x^2-a^2}\dd{x}&=\int\frac{1}{2a}\qty(\frac{1}{x-a}-\frac{1}{x+a})\dd{x}\\
&=\frac{1}{2a}\ln(\frac{x-a}{x+a})+C
\ea\]
\end{proof}
\sssc{$\frac{1}{a^2-x^2}$}
\[\int\frac{1}{a^2-x^2}\dd{x}=\frac{1}{2a}\ln(\frac{a-x}{a+x})+C=\frac{1}{a}\arctanh(\frac{x}{a})+C,\quad a>0\land a^2-x^2>0.\]
\begin{proof}
\[\ba
\int\frac{1}{a^2-x^2}\dd{x}&=\int\frac{1}{2a}\qty(\frac{1}{a-x}-\frac{1}{a+x})\dd{x}\\
&=\frac{1}{2a}\ln(\frac{a-x}{a+x})+C
\ea\]
\end{proof}
\sssc{$ax+b$}
\[\int\frac{1}{ax+b}\dd{x}=\frac{1}{a}\ln\abs{ax+b}+C,\quad a>0.\]
\begin{proof}
\[\ba
\int\frac{1}{ax+b}\dd{x}&=\frac{1}{a}\int\frac{1}{u}\dd{u},\quad u=ax+b,\quad\dd{u}=a\dd{x}\\
&=\frac{1}{a}\ln\abs{ax+b}+C
\ea\]
\end{proof}
\[\int(ax+b)^n\dd{x}=\frac{1}{a(n+1)}(ax+b)^{n+1}+C,\quad a\neq 0\land n\neq -1.\]
\begin{proof}
\[\ba
\int(ax+b)^n\dd{x}&=\frac{1}{a}\int u^n\dd{u},\quad u=ax+b,\quad \dd{u}=a\dd{x}\\
&=\frac{1}{a}u^{n+1}+C\\
&=\frac{1}{a(n+1)}(ax+b)^{n+1}+C
\ea\]
\end{proof}
\[\int\frac{x}{ax+b}\dd{x}=\frac{x}{a}-\frac{b}{a^2}\ln\abs{ax+b}+C,\quad a>0.\]
\begin{proof}
\[\ba
\int\frac{x}{ax+b}\dd{x}&=\int\frac{u-b}{a^2u}\dd{u},\quad u=ax+b,\quad \dd{u}=a\dd{x}\\
&=\frac{ax+b}{a^2}-\frac{b}{a^2}\ln\abs{ax+b}+C\\
&=\frac{x}{a}-\frac{b}{a^2}\ln\abs{ax+b}+C
\ea\]
\end{proof}
\[\int\frac{x}{(ax+b)^2}\dd{x}=\frac{1}{a^2}\ln\abs{ax+b}+\frac{b}{a^2(ax+b)}+C,\quad a>0.\]
\begin{proof}
\[\ba
\int\frac{x}{(ax+b)^2}\dd{x}&=\int\frac{u-b}{a^2u^2}\dd{u},\quad u=ax+b,\quad \dd{u}=a\dd{x}\\
&=\frac{1}{a^2}\ln\abs{ax+b}+\frac{b}{a^2(ax+b)}
\ea\]
\end{proof}
\[\int x(ax+b)^n\dd{x}=\frac{a(n+1)x-b}{a^2(n+1)(n+2)}(ax+b)^{n+1}+C,\quad a\neq 0\land n\notin\{-1,-2\}.\]
\begin{proof}
\[\ba
\int x(ax+b)^n\dd{x}&=\int\frac{u-b}{a^2}u^n\dd{u},\quad u=ax+b,\quad \dd{u}=a\dd{x}\\
&=\frac{(ax+b)^{n+2}}{a^2(n+2)}-\frac{b(ax+b)^{n+1}}{a^2(n+1)}\\
&=\frac{(ax+b)(n+1)-b(n+2)}{a^2(n+1)(n+2)}(ax+b)^{n+1}+C\\
&=\frac{a(n+1)x-b}{a^2(n+1)(n+2)}(ax+b)^{n+1}+C
\ea\]
\end{proof}
\sssc{$\sqrt{a^2+x^2}$}
Let $r=\sqrt{a^2+x^2}$.
\[\int r\dd{x}=\frac{1}{2}\qty(xr+a^2\ln(x+r))+C.\]
\begin{proof}
\[\ba
\int r\dd{x}&=a^2\int\sqrt{1+u^2}\dd{u},\quad u=\frac{x}{|a|},\quad\dd{u}=\frac{1}{|a|}\dd{x}\\
&=a^2\int\sqrt{1+\sinh^2t}\cosh t\dd{t},\quad u=\sinh t,\quad\dd{u}=\cosh t\dd{t}\\
&=a^2\int\cosh^2t\dd{t}\\
&=a^2\int\frac{\cosh(2t)+1}{2}\dd{t}\\
&=\frac{a^2\sinh(2t)}{4}+\frac{a^2t}{2}+C\\
&=\frac{a^2u\sqrt{1+u^2}}{2}+\frac{a^2}{2}\ln(u+\sqrt{1+u^2})+C\\
&=\frac{xr}{2}+\frac{a^2}{2}\ln(\frac{x}{|a|}+\frac{1}{|a|}r)+C\\
&=\frac{xr}{2}+\frac{a^2}{2}\ln(x+r)+C\\
&=\frac{1}{2}\qty(xr+a^2\ln(x+r))+C
\ea\]
Alternatively,
\[\ba
\int r\dd{x}&=xr-\int\frac{x^2}{r}\dd{x}\\
&=xr-a^2\int\frac{u^2}{\sqrt{1+u^2}}\dd{u},\quad u=\frac{x}{|a|},\quad\dd{u}=\frac{1}{|a|}\dd{x}\\
&=xr-a^2\int\tan^2t\sec t\dd{t},\quad u=\tan t,\quad\dd{u}=\sec^2t\dd{t}\\
&=xr-a^2\int\sec^3t-\sec t\dd{t}\\
&=xr-\frac{a^2}{2}\tan(t)\sec(t)-\frac{a^2}{2}\ln|\tan t+\sec t|+a^2\ln|\tan t+\sec t|+C\\
&=xr-\frac{a^2}{2}u\sqrt{1+u^2}+\frac{a^2}{2}\ln|u+\sqrt{1+u^2}|+C\\
&=\frac{xr}{2}+\frac{a^2}{2}\ln(\frac{x}{|a|}+\frac{1}{|a|}r)+C\\
&=\frac{xr}{2}+\frac{a^2}{2}\ln(x+r)+C\\
&=\frac{1}{2}\qty(xr+a^2\ln(x+r))+C
\ea\]
\end{proof}
\[\int xr\dd{x}=\frac{1}{3}r^3+C.\]
\begin{proof}
\[\ba
\int xr\dd{x}&=\int r^2\dd{r},\quad\dd{r}=\frac{x}{r}\dd{x}\\
&=\frac{1}{3}r^3+C\\
\ea\]
\end{proof}
\[\int\frac{1}{r}\dd{x}=\arcsinh(\frac{x}{|a|})+C=\ln(x+r)+C.\]
\begin{proof}
\[\ba
\int\frac{1}{r}\dd{x}&=\int\frac{1}{\sqrt{1+u^2}}\dd{x},\quad u=\frac{x}{|a|},\quad\dd{u}=\frac{1}{|a|}\dd{x}\\
&=\int 1\dd{t},\quad u=\sinh t,\quad\dd{u}=\cosh t\dd{t}\\
&=t+C=\arcsinh u+C=\arcsinh(\frac{x}{|a|})+C\\
&=\ln(\frac{x}{|a|}+\sqrt{1+\qty(\frac{x}{|a|})^2})\\
&=\ln(x+r)+C
\ea\]
\end{proof}
\[\int\frac{x}{r}\dd{x}=r+C.\]
\sssc{$\sqrt{x^2-a^2}$}
Let $s=\sqrt{x^2-a^2},\quad x^2>a^2$.
\[\int s\dd{x}=\frac{1}{2}\qty(xs-a^2\ln(x+s))+C.\]
\begin{proof}
\[\ba
\int s\dd{x}&=a^2\int\sqrt{u^2-1}\dd{u},\quad u=\frac{x}{|a|},\quad\dd{u}=\frac{1}{|a|}\dd{x}\\
&=a^2\int\sinh^2t\dd{t},\quad u=\cosh t,\quad\dd{u}=\sinh t\dd{t}\\
&=a^2\int\frac{\cosh(2t)-1}{2}\dd{t}\\
&=\frac{a^2\sinh(2t)}{4}-\frac{a^2t}{2}+C\\
&=\frac{a^2u\sqrt{u^2-1}}{2}-\frac{a^2}{2}\ln(u+\sqrt{u^2-1})+C\\
&=\frac{xs}{2}+\frac{a^2}{2}\ln(\frac{x}{|a|}+\frac{1}{|a|}s)+C\\
&=\frac{xs}{2}-\frac{a^2}{2}\ln(x+s)+C\\
&=\frac{1}{2}\qty(xs-a^2\ln(x+s))+C
\ea\]
\end{proof}
\[\int xs\dd{x}=\frac{1}{3}s^3+C.\]
\begin{proof}
\[\ba
\int xs\dd{x}&=\int s^2\dd{s},\quad\dd{s}=\frac{x}{s}\dd{x}\\
&=\frac{1}{3}s^3+C
\ea\]
\end{proof}
\[\int\frac{1}{s}\dd{x}=\arcsin(\frac{x}{|a|})+C.\]
\begin{proof}
\[\ba
\int\frac{1}{s}\dd{x}&=\int\frac{1}{\sqrt{u^2-1}}\dd{x},\quad u=\frac{x}{|a|},\quad\dd{u}=\frac{1}{|a|}\dd{x}\\
&=\int 1\dd{t},\quad u=\cosh t,\quad\dd{u}=\sinh t\dd{t}\\
&=t+C=\sgn(u)\arccosh u+C\\
&=\sgn(x)\arccosh\abs{\frac{x}{a}}+C\\
&=\ln\abs{\frac{x}{a}+\sqrt{\qty(\frac{x}{a})^2-1}}+C
&=\ln\abs{x+s}+C
\ea\]
\end{proof}
\[\int\frac{x}{s}\dd{x}=-s+C.\]
\sssc{$\sqrt{a^2-x^2}$}
Let $q=\sqrt{a^2-x^2},\quad a^2\geq x^2$.
\[\int q\dd{x}=\frac{1}{2}\qty(q+a^2\arcsin(\frac{x}{|a|}))+C.\]
\begin{proof}
\[\ba
\int q\dd{x}&=a^2\int\sqrt{1-u^2}\dd{u},\quad u=\frac{x}{|a|},\quad\dd{u}=\frac{1}{|a|}\dd{x}\\
&=a^2\int\cos^2t\dd{t},\quad u=\sin t,\quad\dd{u}=\cos t\dd{t}\\
&=a^2\int\frac{\cos(2t)+1}{2}\dd{t}\\
&=\frac{a^2\sin(2t)}{4}+\frac{a^2t}{2}+C\\
&=\frac{a^2}{2}\sqrt{1-u^2}+\frac{a^2}{2}\arcsin(\frac{x}{|a|})+C\\
&=\frac{1}{2}\qty(q+a^2\arcsin(\frac{x}{|a|}))+C
\ea\]
\end{proof}
\[\int xq\dd{x}=\frac{1}{3}q^3+C.\]
\begin{proof}
\[\ba
\int xq\dd{x}&=\int q^2\dd{q},\quad\dd{q}=\frac{x}{q}\dd{x}\\
&=\frac{1}{3}q^3+C
\ea\]
\end{proof}
\[\int\frac{1}{q}\dd{x}=\arcsin(\frac{x}{|a|})+C.\]
\begin{proof}
\[\ba
\int\frac{1}{q}\dd{x}&=\int\frac{1}{\sqrt{1-u^2}}\dd{x},\quad u=\frac{x}{|a|},\quad\dd{u}=\frac{1}{|a|}\dd{x}\\
&=\int 1\dd{t},\quad u=\sin t,\quad\dd{u}=\cos t\dd{t}\\
&=t+C=\arccos u+C\\
&=\arccos(\frac{x}{|a|})+C
\ea\]
\end{proof}
\[\int\frac{x}{q}\dd{x}=q+C.\]
\sssc{$\sqrt{ax+b}$}
Let $R=\sqrt{ax+b},\quad a\neq 0$.
\[\int R\dd{x}=\frac{2}{3a}R^3+C.\]
\begin{proof}
\[\ba
\int R\dd{x}&=\frac{2}{a}\int R^2\dd{R},\quad\dd{R}=\frac{a}{2R}\dd{x}\\
&=\frac{2}{3a}R^3+C
\ea\]
\end{proof}
\[\int x^nR\dd{x}=\frac{2}{a(2n+3)}\qty(x^nR^3-bn\int x^{n-1}R\dd{x}),\quad n\in\bbN.\]
\begin{proof}
\[\ba
\int x^nR\dd{x}&=\frac{2}{3a}x^nR^3-\frac{2n}{3a}\int x^{n-1}R^3\dd{x}\\
&=\frac{2}{3a}x^nR^3-\frac{2n}{3}\int x^nR\dd{x}-\frac{2bn}{3a}\int x^{n-1}R\dd{x}\\
&=\frac{2}{a(2n+3)}\qty(x^nR^3-bn\int x^{n-1}R\dd{x})
\ea\]
\end{proof}
\[\int\frac{1}{R}\dd{x}=\frac{2R}{a}+C.\]
\begin{proof}
\[\ba
\int\frac{1}{R}\dd{x}&=\frac{2}{a}\int 1\dd{R},\quad\dd{R}=\frac{a}{2R}\dd{x}\\
&=\frac{2R}{a}+C
\ea\]
\end{proof}
\[\int\frac{x^n}{R}\dd{x}=\frac{2}{a}\qty(x^nR-n\int x^{n-1}R\dd{x})=\frac{2}{a(2n+1)}\qty(x^nR-bn\int\frac{x^{n-1}}{R}\dd{x}),\quad n\in\bbN.\]
\begin{proof}
\[\ba
\int\frac{x^n}{R}\dd{x}&=x^n\frac{2R}{a}-\frac{2n}{a}\int x^{n-1}R\dd{x}\\
&=\frac{2}{a}\qty(x^nR-n\int x^{n-1}R\dd{x})\\
&=\frac{2}{a}x^nR-2n\int\frac{x^n}{R}\dd{x})-\frac{2bn}{a}\int\frac{x^{n-1}}{R}\dd{x})\\
&=\frac{2}{a(2n+1)\qty(x^nR-bn\int \frac{x^{n-1}}{R}\dd{x})
\ea\]
\end{proof}
\sssc{Gaussian integral (高斯積分) or Euler–Poisson integral}
\[\int_{-\infty}^{\infty}e^{-t^2}\dd{t}=\sqrt{\pi}.\]
\[\int_0^{\infty}e^{-t^2}\dd{t}=\frac{\sqrt{\pi}}{2}.\]
\begin{proof}
Let
\[I=\int_0^{\infty}e^{-t^2}\dd{t}.\]
\[\ba
I^2&=\qty(\int_0^{\infty}e^{-x^2}\dd{x})\qty(\int_0^{\infty}e^{-y^2}\dd{y})\\
&=\int_0^{\infty}\int_0^{\infty}e^{-x^2}e^{-y^2}\dd{x}\dd{y}\\
&=\int_0^{\pi/2}\int_0^{\infty}e^{-r^2}r\dd{r}\dd{\theta}\\
&=\frac{1}{2}\int_0^{\pi/2}\int_0^{\infty}e^{-u}\dd{u}\dd{\theta},\quad u=r^2\\
&=\frac{1}{2}\int_0^{\pi/2}1\dd{\theta}\\
&=\frac{\pi}{4}
\ea\]
\end{proof}
\sssc{Euler's constant or Euler–Mascheroni constant}
PLACEHOLDER
\ssc{List of Maclaurin Series and Taylor Series of Real Functions}
\sssc{Power function}
\[x^n=\sum_{k=0}^{\infty}\binom{n}{k}a^{n-k}(x-a)^k,\quad |x-a|<|a|.\]
\sssc{$\frac{1}{1-x}$}
\[\frac{1}{1-x}=\sum_{n=0}^{\infty}x^n,\quad |x|<1.\]
\[\frac{1}{1-x}=\frac{1}{1-a}\sum_{n=0}^{\infty}\qty(\frac{x-a}{1-a})^n,\quad |x-a|<|1-a|.\]
\begin{proof}
\[\dv{}{x}\qty(\frac{1}{1-x})=(1-x)^{-2}\]
\[\dv{}{x}\qty((1-x)^{-n})=n(1-x)^{-n-1},\quad n\neq 0\]
\[\dv[n]{}{x}\qty(\frac{1}{1-x})=\frac{n}{1-x}\dv[n-1]{}{x}\qty(\frac{1}{1-x}),\quad n\in\bbN\]
\[\dv[n]{}{x}\qty(\frac{1}{1-x})=\frac{n!}{(1-x)^{n+1}},\quad n\in\bbN_0\]
\end{proof}
\sssc{$\frac{1}{1+x}$}
\[\frac{1}{1+x}=\sum_{n=0}^{\infty}(-1)^nx^n,\quad |x|<1.\]
\[\frac{1}{1+x}=\frac{1}{1+a}\sum_{n=0}^{\infty}\qty(\frac{-(x-a)}{1+a})^n,\quad |x-a|<|1+a|.\]
\begin{proof}
\[\dv{}{x}\qty(\frac{1}{1+x})=-(1+x)^{-2}\]
\[\dv{}{x}\qty((1+x)^{-n})=-n(1+x)^{-n-1},\quad n\neq 0\]
\[\dv[n]{}{x}\qty(\frac{1}{1+x})=-\frac{n}{1+x}\dv[n-1]{}{x}\qty(\frac{1}{1+x}),\quad n\in\bbN\]
\[\dv[n]{}{x}\qty(\frac{1}{1+x})=\frac{(-1)^nn!}{(1+x)^{n+1}},\quad n\in\bbN_0\]
\end{proof}
\sssc{Logarithmic function}
\[\ln(x)=\ln(a)+\sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{na^n}(x-a)^n,\quad x\leq a.\]
\begin{proof}
\[\dv{\ln(x)}{x}=x^{-1}.\]
Thus for $n\in\mathbb{N}$:
\[\ba
\dv[n]{\ln(x)}{x}&=\prod_{j=1}^{n-1}(-j)x^{-n}\\
&=(-1)^{n-1}\frac{(n-1)!}{x^n}
\ea\]
The series converges iff $-1<\frac{(x-a)^n}{a^n}\leq 1$ ($\leq 1$ since alternating harmonic series converges) iff $0<x\leq a$.
\end{proof}
\[\ln(1+x)=\sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{n}x^n,\quad x\leq 1.\]
\[\ln(1+x)=\ln(1+a)+\sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{n(1+a)^n}(x-a)^n,\quad x\leq 1+a.\]
\sssc{Exponential function}
\[e^x=\sum_{n=0}^{\infty}\frac{x^n}{n!}.\]
\[e^x=e^a\sum_{n=0}^{\infty}\frac{(x-a)^n}{n!}.\]
\[b^x=\sum_{n=0}^{\infty}\frac{(\ln b)^n}{n!}x^n,\quad b>0.\]
\[b^x=b^a\sum_{n=0}^{\infty}\frac{(\ln b)^n}{n!}(x-a)^n,\quad b>0.\]
\sssc{Sine function}
\[\sin(x)=\sum_{n=0}^{\infty}\frac{(-1)^n}{(2n+1)!}x^{2n+1}.\]
\[\sin(x)=\sum_{n=0}^{\infty}\frac{\sin\qty(a+\frac{n\pi}{2})}{n!}(x-a)^n.\]
\sssc{Cosine function}
\[\cos(x)=\sum_{n=0}^{\infty}\frac{(-1)^n}{(2n)!}x^{2n}.\]
\[\cos(x)=\sum_{n=0}^{\infty}\frac{\cos\qty(a+\frac{n\pi}{2})}{n!}(x-a)^n.\]
\sssc{Tangent function}
Define the derivative polynomials $P_n$ such that $P_n\qty(\tan(x))=\tan^{(n)}(x)$ with recursion as:
\[\begin{cases}
&P_0(y)=y,\\
&P_n(y)=(1+y^2)P_{n-1}'(y),\quad n\in\mathbb{N}.
\end{cases}\]

The Taylor expansion of the tangent function at $a$ is:
\[\tan(x)=\sum_{n=0}^{\infty}\frac{P_n\qty(\tan(x))(a)}{n!}(x-a)^n.\]
\begin{proof}
Let $y=\tan(x)$.
\[y'=1+y^2.\]
Prove by mathematical induction. When $n=0$,
\[P_0(y)=y.\]
Assume:
\[P_{n-1}(y)=y^{(n-1)}.\]
Differentiate both side:
\[y'P_{n-1}'(y)=y^{(n)}=(1+y^2)P_{n-1}'(y)=P_n(y).\]
\end{proof}
\sssc{Cotangent function}
Define the derivative polynomials $P_n$ such that $P_n\qty(\cot(x))=\cot^{(n)}(x)$ with recursion as:
\[\begin{cases}
&P_0(y)=y,\\
&P_n(y)=-(1+y^2)P_{n-1}'(y),\quad n\in\mathbb{N}.
\end{cases}\]

The Taylor expansion of the cotangent function at $a$ is:
\[\cot(x)=\sum_{n=0}^{\infty}\frac{P_n\qty(\cot(x))(a)}{n!}(x-a)^n.\]
\begin{proof}
Let $y=\cot(x)$.
\[y'=-(1+y^2).\]
Prove by mathematical induction. When $n=0$,
\[P_0(y)=y.\]
Assume:
\[P_{n-1}(y)=y^{(n-1)}.\]
Differentiate both side:
\[y'P_{n-1}'(y)=y^{(n)}=-(1+y^2)P_{n-1}'(y)=P_n(y).\]
\end{proof}
\ssc{Lists of Laplace Transform}
PLACEHOLDER
\ssc{Lists Fourier Transform}
PLACEHOLDER
\ssc{List of Counterexamples}
\sssc{Dirichlet function (狄利克雷函數)}
The Dirichlet function is a function $f\colon\mathbb{R}\to\mathbb{R};$
\[f(x)=\begin{cases}1,\quad & x\in\mathbb{Q}\\
0,\quad & x\in\mathbb{R}\setminus\mathbb{Q}
\end{cases},\]
which is discontinuous everywhere and measurable.
\sssc{Weierstrass function (魏爾施特拉斯函數)}
The Weierstrass function is a function $f\colon\mathbb{R}\to\mathbb{R};$
\[f(x)=\sum_{n=0}^{\infty}a^n\cos\left(b^n\pi x\right),\]
in which $0<a<1$, $b$ is a positive odd integer, and $ab>1+\frac{3}{2}\pi$, which is continuous everywhere and differentiable nowhere.
\sssc{Differentiable but derivative not continuous}
The function $f\colon\mathbb{R}\to\mathbb{R};$
\[f(x)=\begin{cases}x^2\sin\qty(\frac{1}{x}),\quad&x\neq 0\\0,\quad&x=0\end{cases},\]
is differentiable but its derivative is not continuous at $0$. (Note that because $\{0\}$ has Lebesgue measure $0$, $f'\colon\mathbb{R}\to\mathbb{R}$ is continuous almost everywhere, that is, $f'$ is Riemann integrable on any closed interval.)
\begin{proof}
\[f'(x)=2x\sin\qty(\frac{1}{x})-x^2\cos\qty(\frac{1}{x}),\quad x\neq 0\]
\bma
f'(0)&=\lim_{h\to 0}\frac{f(h)}{h}\\
&=\lim_{h\to 0}h\sin\qty(\frac{1}{h})
\eam
For any $|h|>0$, we have $-|h|\leq h\sin\qty(\frac{1}{h})\leq |h|$. By the squeeze theorem, $\lim_{h\to 0}-|h|=\lim_{h\to 0}|h|=0$ implies $\lim_{h\to 0}h\sin\qty(\frac{1}{h})=0$.
\bma
\lim_{x\to 0}f'(x)&=2\lim_{x\to 0}x\sin\qty(\frac{1}{x})-\lim_{x\to 0}\cos\qty(\frac{1}{x})\\
&=-\lim_{x\to 0}\cos\qty(\frac{1}{x})\\
\eam
$\lim_{x\to 0}\cos\qty(\frac{1}{x})$ doesn't exist, so $\lim_{x\to 0}f'(x)$ doesn't exist.
\end{proof}
\sssc{Differentiable at one point and discontinuous everywhere else}
The function $f\colon\mathbb{R}\to\mathbb{R};$
\[f(x)=\begin{cases}1,\quad & x^2\in\mathbb{Q}\\
0,\quad & x\in\mathbb{R}\setminus\mathbb{Q}
\end{cases}\]
which is differentiable at $0$ with $f'(0)=0$ and discontinuous everywhere else.
\sssc{Derivative being zero at a point where no local extreme occurs}
\[f(x)=x^3,\quad f'(x)=3x^2.\]
\[f'(0)=0\]
$f(x)$ has no local extreme at $0$.
\ssc{List of implicitly defined functions}
\ssc{Lambert W function, omega function, or product logarithm}
Lambert W function, omega function, or product logarithm $W(z)$ is defined implicitly by
\[W(z)e^{W(z)}=z,\quad z\in\bbC.\]
Each branch $k$, starting from $0$ as the principal branch, is denoted as $W_k(z)$.

In the reals, there are two branches: $W_0(x)\colon[-\frac{1}{e},\infty)\to\bbR$ is the inverse of
\[xe^x,\quad x\geq-1.\]
$W_{-1}(x)\colon[-\frac{1}{e},0)\to\bbR$ is the inverse of
\[xe^x,\quad x\leq-1.\]

Derivative:
\[\dv{W_0(x)}{x}=\begin{cases}
\frac{W_0(x)}{x(1+W_0(x))},\quad&x\neq 0,-\frac{1}{e}\\
1,\quad&x=0
\end{cases}.\]
\[\lim_{x\to-\frac{1}{e}^+}\dv{W_0(x)}{x}=\infty.\]
\[\dv{W_{-1}(x)}{x}=\frac{W_{-1}(x)}{x(1+W_{-1}(x))},\quad x\neq -\frac{1}{e}.\]
\[\lim_{x\to-\frac{1}{e}^+}\dv{W_{-1}(x)}{x}=-\infty.\]
\[\lim_{x\to 0^-}\dv{W_{-1}(x)}{x}=-\infty.\]
\begin{proof}
\[W(x)e^{W(x)}=x\]
\[\dv{W(x)}{x}e^{W(x)}+W(x)\dv{W(x)}{x}e^{W(x)}=1\]
\[\dv{W(x)}{x}e^{W(x)}(1+W(x))=1\]
\[\dv{W(x)}{x}W(x)e^{W(x)}(1+W(x))=W(x)\]
\[\dv{W(x)}{x}x(1+W(x))=W(x)\]
\[\dv{W_0(0)}{x}e^{W_0(0)}(1+W_0(0))=1\]
\[\dv{W_0(0)}{x}1(1+0)=1\]
\[\dv{W_0(0)}{x}=1\]
\[W\qty(-\frac{1}{e})=-1\]
Solve below equation for $\varepsilon$:
\[\qty(-1+\varepsilon)e^{-1+\varepsilon}=-\frac{1}{e}+\detla.\]
\[\qty(-1+\varepsilon)e^{\varepsilon}=-1+e\detla\]
\[\qty(-1+\varepsilon)\sum_{i=0}^{\infty}\frac{\varepsilon^i}{i!}=-1+e\detla\]
\[-\sum_{i=0}^{\infty}\frac{\varepsilon^i}{i!}+\sum_{i=1}^{\infty}\frac{\varepsilon^i}{(i-1)!}=-1+e\detla\]
\[\sum_{i=2}^{\infty}\frac{\varepsilon^i}{(i-2)!i!}=e\detla\]
\[\frac{\varepsilon^2}{2}+O(\varepsilon^3)=e\delta\]
\[\varepsilon=O(\sqrt{\delta})\]
\[W_0\qty(-\frac{1}{e}+\detla)=-1+\varepsilon=-1+O(\sqrt{\delta})\]
\[\frac{W\qty(-\frac{1}{e}+\detla)-W\qty(-\frac{1}{e})}{\delta}=O\qty((\delta)^{-1/2})\]
\[\lim_{\delta\to 0}\dv{W(x)}{x}=\lim_{\delta\to 0}O\qty((\delta)^{-1/2})=\pm\infty\]
\[\lim_{x\to 0^-}W_{-1}(x)=-\infty\]
\[\ba
\lim_{x\to 0^-}xW_{-1}(x)&=\lim_{x\to 0^-}\frac{W_{-1}(x)}{x^{-1}}\\
&=\lim_{x\to 0^-}\frac{\frac{W_{-1}(x)}{x(1+W_{-1}(x))}}{-x^{-2}}\\
&=-\lim_{x\to 0^-}\frac{xW_{-1}(x)}{1+W_{-1}(x)}
\ea\]
Let
\[L=\lim_{x\to 0^-}xW_{-1}(x).\]
\[L=-\frac{L}{-\infty}\]
\[L=-\infty\]
\end{proof}

Integral:
\[\int W(x)\dd{x}=x(W(x)-1)+e^{W(x)}+C.\]
\begin{proof}
\[\ba
\int W(x)\dd{x}&=xW(x)-\int\frac{W(x)}{1+W(x)}\dd{x}\\
&=xW(x)-x+\int\frac{1}{1+W(x)}\frac{W(x)}{x}\frac{x}{W(x)}\dd{x}\\
&=x(W(x)-1)+\int\dv{W(x)}{x}\frac{W(x)e^{W(x)}}{W(x)}\dd{x}\\
&=x(W(x)-1)+\int e^W\dd{W}\\
&=x(W(x)-1)+e^{W(x)}+C
\ea\]
\end{proof}



\sct{Integral Defined Functions}
\ssc{Error function}
\sssc{Error funcction (誤差函數) or Gauss error function (高斯誤差函數)}
The error function or Gauss error function $\erf\colon\bbC\to\bbC$ or $\erf\colon\bbR\to\bbR$ is defined as:
\[\erf(z)=\frac{2}{\sqrt{\pi}}\int_0^ze^{-t^2}\dd{t}.\]
\sssc{Complementary error function (互補誤差函數)}
The complementary error function $\erfc\colon\bbC\to\bbC$ or $\erfc\colon\bbR\to\bbR$ is defined as:
\[\erfc(z)=1-\erf(z)=\int_z^{\infty}e^{-t^2}\dd{t}.\]
\sssc{Imaginary error function (虛誤差函數)}
The imaginary error function $\erfi\colon\bbC\to\bbC$ or $\erfi\colon\bbR\to\bbR$ is defined as:
\[\erfi(z)=-i\erf(iz).\]
\ssc{Fresnel Integrals}
Fresnel integrals $S(x)$ and $C(x)$, and their auxiliary functions $F(x)$ and $G(x)$ are defined as
\[S(x)=\int_0^x\sin(t^2)\dd{t},\]
\[C(x)=\int_0^x\cos(t^2)\dd{t},\]
\[F(x)=\qty(\frac{1}{2}-S(x))\cos(x^2)-\qty(\frac{1}{2}-C(x))\sin(x^2),\]
\[G(x)=\qty(\frac{1}{2}-S(x))\sin(x^2)+\qty(\frac{1}{2}-C(x))\cos(x^2).\]

The Auxiliary functions $F(x)$ and $G(x)$ provide monotonic bounds for the Fresnel Integrals:
\[\frac{1}{2}-F(x)-G(x)\leq S(x)\leq\frac{1}{2}+F(x)+G(x),\]
\[\frac{1}{2}-F(x)-G(x)\leq C(x)\leq\frac{1}{2}+F(x)+G(x).\]
\begin{proof}
PLACEHOLDER
\end{proof}
\ssc{Trigonometric and Hyperbolic Integrals}
\sssc{Sine Integral}
The two different sine integral definitions are
\[\operatorname{Si}(x)=\int_0^x\frac{\sin(t)}{t}\dd{t},\]
\[\operatorname{si}(x)=-\int_x^\infty\frac{\sin(t)}{t}\dd{t}.\]
Their difference is
\[\operatorname{Si}(x)-\operatorname{si}(x)=\int_0^\infty\frac{\sin(t)}{t}\dd{t}=\frac{\pi}{2}.\]
\begin{proof}
PLACEHOLDER
\end{proof}
\sssc{Cosine Integral}
The two different cosine integral definitions are
\[\operatorname{Cin}(x)=\int_0^x\frac{1-\cos(t)}{t}\dd{t},\]
\[\operatorname{Ci}(x)=-\int_x^\infty\frac{\cos(t)}{t}\dd{t}.\]
Their sum is
\[\operatorname{Cin}(x)+\operatorname{Ci}(x)=\ln(x)+\gamma.\]
where $\gamma$ is the Euler–Mascheroni constant.
\begin{proof}
PLACEHOLDER
\end{proof}
\sssc{Hyperbolic Sine Integral}
The hyperbolic sine integral is defined as:
\[\operatorname{Shi}(x)=\int_0^x\frac{\sinh(t)}{t}\dd{t}.\]
It is related to the sine integral by
\[\operatorname{Si}(ix)=i\operatorname{Shi}(x).\]
\begin{proof}
PLACEHOLDER
\end{proof}
\sssc{Hyperbolic Cosine Integral}
The hyperbolic cosine integral is defined as
\[\operatorname{Chi}(x)=\gamma+\ln(x)+\int_0^x\frac{\cosh(t)-1}{t}\dd{t},\]
where $\gamma$ is the Euler–Mascheroni constant.

It is related to the cosine integral by
\[\operatorname{Ci}(ix)=i\operatorname{Chi}(x)-\frac{\pi}{2}.\]
\begin{proof}
PLACEHOLDER
\end{proof}
\end{document}

