\documentclass[a4paper,12pt]{report}
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{3}
\input{/usr/share/LaTeX-ToolKit/template.tex}
\begin{document}
\title{Ordinary Differential Equations, Dynamical Systems, and Control Theory}
\author{沈威宇}
\date{\temtoday}
\titletocdoc
\ch{Ordinary Differential Equations (常微分方程), Dynamical Systems (動態系統 or 動力系統), and Control Theory (控制理論)}
\sct{Ordinary Differential Equations}
\ssc{Definitions}
\sssc{Normal form}
The normal form of an $n$th-order ODE of a dependent variable $y$ in codomain $Y$ with respect to an independent variable $x$ in domain $X$ is
\[\dv[n]{y}{x}=F(x,y,y',y'',\dots y^{(n-1)}),\]
in which $F$ is a function of $(n+1)$ variables with codomain $Y$.
\sssc{System of ODEs (常微分方程組)}
A system of ODEs is two or more equations involving the derivatives of two or more unknown functions or dependent variables of a single independent variable.
\sssc{Initial-value problem (IVP) (初值問題)}
An $n$th-order initial-value problem is an $n$th-order ODE with $n$ conditions for $y$ and all $k$th derivative functions with $k\in\bbN\land k<n$ of $y$ at the same point $x=x_0$, that is,
\[\left\{y^{(k)}(x_0)=y_k\middle| k\in\bbN\land k<n\right\},\]
called initial conditions (ICs) (初始條件).

A solution of an IVP is a solution of the ODE that complies with all the ICs.

The interval of existence of an IVP is the largest open interval containing $x_0$ where a solution of the IVP exists; the interval of existence of an IVP is the largest open interval containing $x_0$ where a unique solution of the IVP exists.
\sssc{Rectangle}
A rectangle in $\mathbb{R}\times\mathbb{R}^n$ is a subset $D$ of it in the form:
\[D=\{(t,y)\mid|t-T|\leq a\land\forall\tx{\ integer\ }1\leq i\leq n\colon |y_i-Y_i|\leq b_i\}\]
where $t,T\in\mathbb{R}$, $y=(y_1, y_2,\dots  y_n)\in\mathbb{R}^n$, $Y=(Y_1, Y_2,\dots  Y_n)\in\mathbb{R}^n$, and constant $a,b_i\in\mathbb{R}_{>0}$.
\sssc{Boundary-value problem (BVP) (邊值問題)}
An $n$th-order boundary-value problem is an $n$th-order ODE with some conditions called boundary conditions (BCs) (邊界條件).

A solution of an BVP is a solution of the ODE that complies with all the BCs.
\ssc{Solutions of ODEs}
\sssc{Solution or flow of an ODE}
Any function $f$ that is defined on an interval $I$, called interval of definition, the interval of existence, the interval of validity, or the domain of the solution, and of class $C^n$ on $I$, and when substituted into an $n$th-order ordinary differential equation reduces the equation to an identity, is said to be a solution (aka flow) of the equation on $I$.

An ODE does not necessarily have to possess a solution.
\sssc{Solution curve or trajectory}
The graph of a solution $f$ on its interval of definition of an ODE is called a solution curve or a trajectory.
\sssc{Explicit solution}
An explicit solution of an ODE of a dependent variable $y$ with respect to an independent variable $x$ is in the form $y=f(x)$, where $f(x)$ is a function of $x$.
\sssc{Implicit solution}
A relation $G(x, y) = 0$ is said to be an implicit solution of an ODE on an interval $I$ if there exists at least one function $f$ that satisfes the relation $G(x, y) = 0$ as well as the ODE on $I$.
\sssc{Parametric family or parameterized family}
A parametric family or a parameterized family is a family of objects whose differences depend only on the chosen values for a set of parameters.
\sssc{Degrees of freedom}
The degrees of freedom of a system is the number of parameters of the system that may vary independently.
\sssc{Parametric family of solutions}
An $n$-parameter family of solutions of an ODE of a dependent variable $y$ with respect to an independent variable $x$ is in the form $y=f(x,c_1,c_2,\dots c_n)$ (explicit) or $G(x,y,c_1,c_2,\dots c_n)=0$ (implicit), in which $c_1,c_2,\dots c_n$ are parameters that are arbitrary given that the solution obtained is a solution of the ODE. The arbitrary parameters are usually denoted as $A,B,\ldots$.
\sssc{General solution (通解)}
If every solution of an ODE on an interval $I$ can be obtained from an $n$-parameter family of solutions by appropriate choices of the parameters, we then say that that family of solutions is the general solution of the ODE.
\sssc{Particular solution (特解)}
A particular solution of an ODE that is free of parameters is called a particular solution.

If a system given by an ODE have $n$ degrees of freedom, one may obtain a determined particular solution by imposing $n-1$ non contradictory constraints, leaving one degree of freedom determined by the ODE.
\sssc{Singular solution (奇異解)}
Sometimes a differential equation possesses a solution that is not a member of a family of solutions of the equation, that is, a solution that cannot be obtained by specializing any of the parameters in the family of solutions. Such an extra solution is called a singular solution.
\sssc{Solutions by substitutions or solutions by change of variables}
When solving an ODE, we often replace dependent variables with functions of the independent variable and new dependent variables where the new dependent variables are functions of the independent variable and old dependent variables to transform it into another ODE of the new dependent variables that is easier to solve.
\sssc{Solution of System of ODEs}
A solution of a system of ODEs involving the derivatives of $n$ unknown functions or dependent variables, $y_1,y_2,\dots y_n$ of a single independent variable $x$ is a $n$-tuple of sufficiently smooth functions of $x$ defined on a common interval of definition that satisfy all equations in the system.

A system of ODEs does not necessarily have to possess a solution.
\sssc{Orthogonal trajectory and isogonal trajectory}
An orthogonal trajectory of a family of curves is a curve that intersects each curve of the family orthogonally.

An isogonal trajectory of a family of curves is a curve that intersects each curve of the family at a same angle $\alpha$.
\ssc{Conversion of order to variable}
Any $n$th-order system of ODEs of $m$ variables $x_1,x_2,\ldots,x_m$ can be converted to a first-order system of ODEs of $m\cdot n$ variables by, for each variable $x$, assigning $(n-1)$ new variables defined as the first to $(n-1)$th derivatives of $x$.
\sct{First-order ODEs}
Unless otherwise specified, the variables and functions are in $\mathbb{R}$.
\ssc{Differential form}
The differential form of a first-order ODE $M(x,y)+N(x,y)\dv{y}{x}=0$ is
\[M(x,y)\dd{x}+N(x,y)\dd{y}=0.\]
\ssc{Slope}
\sssc{Slope function or rate function}
In a first-order ODE in the form $\dv{y}{x}=f(x,y)$, $f$ is called the slope function or rate function.
\sssc{Direction field or slope field (斜率場)}
In a first-order ODE in the form $\dv{y}{x}=f(x,y)$, if we evaluate $f$ over a rectangle grid of points and draw a lineal element at each point $(x,y)$ of the grid with slope $f(x,y)$, then the collection of all these lineal elements is called a direction field or a slope field of the ODE.
\sssc{Isocline}
In a first-order ODE in the form $\dv{y}{x}=f(x,y)$, the isocline for slope $m$ is defined as the family of points $\{(x,y)\mid f(x,y)=m\}$. In the method of isocline, we draw a lineal element at each point in the isocline for slope $m$ of $f$ with slope $m$.
\sssc{Euler method or forward Euler method}
Approximate values for the solution of the initial-value problem $y'=f(x,y)$, $y(x_0)=y_0$, with step size $h$, at $x_n=x_{n-1}+h$, are
\[y_n=y_{n-1}+hf(x_{n-1},y_{n-1}),\quad n\in\bbN.\]
\sssc{Backward Euler method}
Approximate values for the solution of the initial-value problem $y'=f(x,y)$, $y(x_0)=y_0$, with step size $h$, at $x_n=x_{n-1}+h$, are the solutions of the equations
\[y_n=y_{n-1}+hf(x_n,y_n),\quad n\in\bbN.\]
\ssc{Autonomous System}
\sssc{Autonomous system (自治系統)}
A system of $n$th-order ODEs is called autonomous if it can be written in the form
\[\dv[n]{x}{t}=f\qty(x,\dv{x}{t},\ldots,\dv[n-1]{x}{t}).\]
\sssc{Critical point (臨界點), equilibrium, equilibrium point (平衡點), or stationary point (駐點) of autonomous systems of ODEs}
For an autonomous systems of ODEs, we say that a point $c$ in the domain of $f$ is a critical point, equilibrium, equilibrium point, or stationary point if $f(c)=0$.

If $c$ is a critical point, then $y(x)=c$ is a constant solution of the system of autonomous first-order ODEs, also called an equilibrium solution (平衡解).

If $c$ is a critical point and $f$ is locally Lipschitz at $c$, then $y(x)=c$ is the unique solution of the system of autonomous first-order ODEs through $c$.
\sssc{Translation property or shift property of solutions of autonomous systems of ODEs}
Let function $\Phi(t,y)$ denotes the solution of an autonomous system of ODEs with IC $x(0)=y$. The translation property or shift property states that
\[\forall s\in\mathbb{R}\colon\Phi(t+s,y)=\Phi(t,\Phi(s,y)).\]
\ssc{Orthogonal trajectories}
The family of the orthogonal trajectories of the family of solutions of the first-order ODE
\[M(x,y)\dd{x}+N(x,y)\dd{y}=0,\]
is the family of solutions of the first-order ODE
\[N(x,y)\dd{x}-M(x,y)\dd{y}=0.\]
\ssc{Separable equation}
\sssc{Definition}
A first-order ODE in the form
\[\dv{y}{x}=g(x)h(y)\]
is said to be separable or have separable variables.
\sssc{Solutions by direct integration}
The solutions of
\[\dv{y}{x}=g(x)h(y)\]
are the family of solutions
\[\int\frac{1}{h(y)}\dd{y}=\int g(x)\dd{x}+C\]
and the constant solution
\[h(y)=0.\]
\sssc{Example: law of natural growth}
IVP:
\[\dv{P}{t}=kP,\quad P(0)=P_0.\]
Solutions:
\[P=P_0e^{kt}.\]
\begin{proof}
\[P^{-1}\dd{P}=k\dd{t}\]
\[\int P^{-1}\dd{P}=\int k\dd{t}=kt+A=\ln(P).\]
\[P=Ae^{kt}.\]
\[P_0=A.\]
\end{proof}
\sssc{Example: logistic differential equation}
IVP:
\[\dv{P}{t}=kP\qty(1-\frac{P}{M}),\quad P(0)=P_0.\]
Solutions:
\[P=\frac{M}{1+\frac{M-P_0}{P_0}e^{-kt}}.\]
\begin{proof}
\[\frac{1}{P\qty(1-\frac{P}{M})}\dd{P}=k\dd{t}\]
\[\int\frac{1}{P\qty(1-\frac{P}{M})}\dd{P}=\int k\dd{t}=kt+A\]
\[\frac{1}{P\qty(1-\frac{P}{M})}=\frac{M}{P(M-P)}=\frac{A}{P}+\frac{B}{M-P}\]
\[AM-AP+BP=M,\quad A=1,\quad B=1\]
\[\int\frac{1}{P\qty(1-\frac{P}{M})}\dd{P}=\int\frac{1}{P}+\frac{1}{M-P}\dd{P}=\ln\abs{P}-\ln\abs{M-P}+C\]
\[\ln\abs{P}-\ln\abs{M-P}=kt+A=\ln\abs{\frac{P}{M-P}}\]
\[\frac{P}{M-P}=Ae^{kt}\]
\[P=\frac{AMe^{kt}}{1+Ae^{kt}}\]
\[P_0=\frac{AM}{1+A}\]
\[A=\frac{P_0}{M-P_0}\]
\[P=\frac{\frac{P_0}{M-P_0}Me^{kt}}{1+\frac{P_0}{M-P_0}e^{kt}}=\frac{M}{1+\frac{M-P_0}{P_0}e^{-kt}}\]
\end{proof}
\sssc{Example: Lotka–Volterra equations or predator–prey equations}
ODE:
\[\dv{x}{t}=x(\alpha-\beta y),\]
\[\dv{y}{t}=-y(\gamma-\delta x).\]

Implicit solutions:
\[\delta x-\gamma\ln(x)+\beta y-\alpha\ln(y)=C.\]
Equilibrium solutions:
\[x=0,\quad y=0,\]
and
\[x=\frac{\gamma}{\delta},\quad y=\frac{\alpha}{\beta}.\]
\begin{proof}
\[\dv{y}{t}=\dv{y}{x}\dv{x}{t}\]
\[\dv{y}{x}=-\frac{y}{x}\frac{\gamma-\delta x}{\alpha-\beta y}\]
\[\frac{\delta x-\gamma}{x}\dd{x}=-\frac{\beta y-\alpha}{y}\dd{y}\]
\[\delta x-\gamma\ln(x)+\beta y-\alpha\ln(y)=C\]
\end{proof}
\ssc{Linear equation}
\sssc{Definition}
A first-order ODE in the form
\[\dv{y}{x}+P(x)y=Q(x)\]
is said to be linear.
\sssc{Solutions by integrating factor}
Use the integrating factor:
\[\mu(x)=e^{\int P(x)\dd{x}}.\]
Multiply both sides with $\mu(x)$:
\[\mu(x)\dv{y}{x}+\mu(x)P(x)y=\mu(x)Q(x).\]
The left-hand side is exactly a derivative:
\[\dv{}{x}\qty(\mu(x)y(x))=\mu(x)Q(x).\]
Integrate:
\[\mu(x)y(x)=\int\mu(x)Q(x)\dd{x}+C.\]
\[y(x)=\frac{1}{\mu(x)}\qty(\int\mu(x)Q(x)\dd{x}+C).\]
\sssc{Remarks}
Occasionally, a first-order differential equation is not linear in one variable but is linear in the other variable. If a first-order ODE that can be wriiten in the form
\[\dv{y}{x}=\frac{1}{P(y)x+Q(y)}.\]
We can take its reciprocal as
\[\dv{x}{y}-P(y)x=Q(y),\]
which is recognized as linear in the variable $x$.
\sssc{Example: constant voltage series RL filter circuit}
IVP:
\[L\dv{I(t)}{t}+RI(t)=V,\quad I(0)=I_0.\]
Solutions:
\[I(t)=\frac{V}{R}\qty(1-e^{-Rt/L})+I_0e^{-Rt/L}.\]
Equilibrium solution:
\[I(t)=\frac{V}{R}.\]
\begin{proof}
\[\dv{I(t)}{t}+\frac{R}{L}I(t)=\frac{V}{L}\]
\[\mu(t)=\exp(\int\frac{R}{L}\dd{t})=e^{Rt/L}\]
\[e^{Rt/L}\dv{I(t)}{t}+e^{Rt/L}\frac{R}{L}I(t)=\dv{u}{t},\quad u=e^{Rt/L}I(t)\]
\[\int 1\dd{u}=\int e^{Rt/L}\frac{V}{L}\dd{t}=u+A=\frac{V}{R}e^{Rt/L}+B\]
\[u=e^{Rt/L}I(t)=\frac{V}{R}e^{Rt/L}+A\]
\[I(t)=\frac{V}{R}+Ae^{-Rt/L}\]
\[I_0=\frac{V}{R}+A\]
\[A=I_0-\frac{V}{R}\]
\[I(t)=\frac{V}{R}\qty(1-e^{-Rt/L})+I_0e^{-Rt/L}\]
\end{proof}
\sssc{Example: constant current parallel RC filter circuit}
IVP:
\[C\dv{V(t)}{t}+\frac{1}{R}V(t)=I,\quad V(0)=V_0.\]
Solutions:
\[V(t)=IR\qty(1-e^{-t/(RC)})+V_0e^{-t/(RC)}.\]
Equilibrium solution:
\[V(t)=IR.\]
\begin{proof}
\[\dv{V(t)}{t}+\frac{1}{RC}V(t)=\frac{I}{C}\]
\[\mu(t)=\exp(\int\frac{1}{RC}\dd{t})=e^{t/(RC)}\]
\[e^{t/(RC)}\dv{V(t)}{t}+e^{t/(RC)}\frac{1}{RC}V(t)=e^{t/(RC)}\frac{I}{C}=\dv{u}{t},\quad u=e^{t/(RC)}V(t)\]
\[\int 1\dd{u}=\int e^{t/(RC)}\frac{I}{C}\dd{t}=u+A=IRe^{t/(RC)}+B\]
\[u=e^{t/(RC)}V(t)=IRe^{t/(RC)}+A\]
\[V(t)=IR+Ae^{-t/(RC)}\]
\[V_0=IR+A\]
\[A=V_0-IR\]
\[V(t)=IR\qty(1-e^{-t/(RC)})+V_0e^{-t/(RC)}\]
\end{proof}
\sssc{Example: Falling with drag force complying with Stokes' law}
IVP:
\[m\dv{v}{t}=-kv-mg,\quad v(0)=v_0.\]
Solutions:
\[v=\frac{mg}{k}\qty(1-e^{-kt/m})+v_0e^{-kt/m}.\]
Equilibrium solution:
\[v=\frac{mg}{k}.\]
\begin{proof}
\[\dv{v}{t}+\frac{k}{m}v=-g\]
\[\mu(t)=\exp(\int\frac{k}{m}\dd{t})=e^{kt/m}\]
\[\dv{}{t}\qty(e^{kt/m}v)=-e^{kt/m}g\]
\[e^{kt/m}v=\int-e^{kt/m}g\dd{t}=\frac{mg}{k}e^{kt/m}+C\]
\[v=\frac{mg}{k}+Ce^{-kt/m}\]
\[v_0=\frac{mg}{k}+C\]
\[v=\frac{mg}{k}+\qty(v_0-\frac{mg}{k})e^{-kt/m}.\]
\end{proof}
\ssc{Exact equation}
\sssc{Definition}
A first-order ODE in the form
\[M(x,y)\dd{x}+N(x,y)\dd{y}=0\]
where $\frac{\partial^2M}{\partial x\partial y}$ and $\frac{\partial^2N}{\partial x\partial y}$ is continuous and
\[\pdv{M}{y}=\pdv{N}{x}\]
is said to be exact.

By Schwarz's Theorem, the criterion holds iff there exists a function $F\colon R\to\bbR$ such that
\[\pdv{F}{x}=M,\quad\pdv{F}{y}=N,\]
and $\frac{\partial^2F}{\partial x\partial y}$ is continuous. Such $F$ is called the potential function.
\sssc{Solutions by integration and then differentiation with respect to different variables}
First, integrate $M(x,y)$ with respect to $x$:
\[F(x,y)=\int M(x,y)\dd{x}+\phi(y),\]
where $\phi(y)$ is an arbitrary constant of integration that may depend on $y$.

Second, differentiate with respect to $y$:
\[\pdv{F}{y}(x,y)=N(x,y)=\pdv{}{y}\qty(\int M(x,y)\dd{x})+\phi'(y).\]

Third, integrate $\phi'(y)$ with respect to $y$ to find $\phi(y)$:
\[\phi(y)=\int\phi'(y)\dd{y}=\int N(x,y)-\pdv{}{y}\qty(\int M(x,y)\dd{x})\dd{y}.\]

Fourth, substitute $\phi(y)$ back to find the potential function $F(x,y)$. The implicit solutions is given by
\[F(x,y)=C,\]
where $C$ is an arbitrary constant.

Alternatively, first, integrate $N(x,y)$ with respect to $y$:
\[F(x,y)=\int N(x,y)\dd{y}+\phi(x),\]
where $\phi(x)$ is an arbitrary constant of integration that may depend on $x$.

Second, differentiate with respect to $x$:
\[\pdv{F}{x}(x,y)=M(x,y)=\pdv{}{x}\qty(\int N(x,y)\dd{y})+\phi'(x).\]

Third, integrate $\phi(x)$ with respect to $x$ to find $\phi(x)$:
\[\phi(x)=\int\phi'(x)\dd{x}=\int M(x,y)-\pdv{}{x}\qty(\int N(x,y)\dd{y})\dd{x}.\]

Fourth, substitute $\phi(x)$ back to find the potential function $F(x,y)$. The implicit solutions is given by
\[F(x,y)=C,\]
where $C$ is an arbitrary constant.
\sssc{Example: $(4x^3+3y^2+\cos(x))\dd{x}+(6xy+2)\dd{y}=0$}
ODE:
\[(4x^3+3y^2+\cos(x))\dd{x}+(6xy+2)\dd{y}=0.\]
Solutions:
\[x^4+3xy^2+\sin(x)+2y=C.\]
\begin{proof}
\[\pdv{}{y}(4x^3+3y^2+\cos(x))=6y\]
\[\pdv{}{x}(6xy+2)=6y\]
\[\ba
F(x,y)&=\int 4x^3+3y^2+\cos(x)\dd{x}+\phi(y)\\
&=x^4+3xy^2+\sin(x)+\phi(y)
\ea\]
\[\pdv{F}{y}=6xy+\phi'(y)=6xy+2\]
\[\phi'(y)=2,\quad\phi(y)=2y+C\]
\[F(x,y)=x^4+3xy^2+\sin(x)+2y+C\]
\end{proof}
\ssc{Integration factors to make inexact equations exact}
\sssc{General case}
Given a first-order ODE in the form
\[M(x,y)\dd{x}+N(x,y)\dd{y}=0,\]
we define the integration factor $\mu(x,y)$ such that
\[\mu(x,y)M(x,y)\dd{x}+\mu(x,y)N(x,y)\dd{y}=0\]
is exact and with potential function $F$ such that
\[\pdv{F}{x}=\mu(x,y)M(x,y),\quad\pdv{F}{y}=\mu(x,y)N(x,y),\]
that is,
\[\pdv{\mu M}{y}=\pdv{\mu N}{x}.\]
Solve the PDE to get $\mu$.
\sssc{Separable case}
If
\[\frac{\pdv{M}{y}-\pdv{N}{x}}{N}\]
depends only on $x$, we can construct integration factor $\mu(x)$:
\[\mu(x)=e^{\int\frac{\pdv{M}{y}-\pdv{N}{x}}{N}\dd{x}}\]
such that
\[\pdv{\mu M}{y}=\pdv{\mu N}{x}=\mu\pdv{M}{y}.\]

Similarly, if
\[\frac{\pdv{N}{x}-\pdv{M}{y}}{M}\]
depends only on $y$, we can construct integration factor $\mu(y)$:
\[\mu(y)=e^{\int\frac{\pdv{N}{x}-\pdv{M}{y}}{M}\dd{x}}\]
such that
\[\pdv{\mu M}{y}=\pdv{\mu N}{x}=\mu\pdv{N}{x}.\]
\begin{proof}
\[\frac{\mu'(x)}{\mu(x)}=\frac{\pdv{M}{y}-\pdv{N}{x}}{N}.\]
This is a separable ODE of $\mu$ with repect to $x$.

Let
\[P(x)=\frac{\pdv{M}{y}-\pdv{N}{x}}{N}.\]
\[\mu^{-1}\dd{\mu}=P(x)\dd{x}.\]
\[\ln|\mu|=\int P(x)\dd{x}.\]
\[\mu=e^{\int P(x)\dd{x}}.\]

Similarly,
\[\frac{\mu'(y)}{\mu(y)}=\frac{\pdv{N}{x}-\pdv{M}{y}}{M}\]
for the second case.
\end{proof}
\ssc{Example: $(5xy+4y^2+1)\dd{x}+(x^2+2xy)\dd{y}=0$}
ODE:
\[(5xy+4y^2+1)\dd{x}+(x^2+2xy)\dd{y}=0.\]
Solutions:
\[x^5y+x^4y^2+\frac{x^4}{4}=C.\]
\begin{proof}
\[\pdv{}{y}(5xy+4y^2+1)=5x+8y\]
\[\pdv{}{x}(x^2+2xy)=2x+2y\]
\[\frac{\pdv{}{y}(5xy+4y^2+1)-\pdv{}{x}(x^2+2xy)}{x^2+2xy}=\frac{3x+6y}{x^2+2xy}=\frac{3}{x}\]
\[\mu(x)=\exp(\int\frac{3}{x}\dd{x})=x^3\]
\[x^3(5xy+4y^2+1)\dd{x}+x^3(x^2+2xy)\dd{y}=0\]
\[\ba
F(x,y)&=\int x^3(5xy+4y^2+1)\dd{x}+\phi(y)\\
&=\int 5x^4y+4x^3y^2+x^3\dd{x}+\phi(y)\\
&=x^5y+x^4y^2+\frac{x^4}{4}+\phi(y)
\ea\]
\[\pdv{F}{y}=x^5+2x^4y+\phi'(y)=x^3(x^2+2xy)=x^5+2x^4y\]
\[\phi'(y)=0,\quad\phi(y)=C\]
\[F(x,y)=x^5y+x^4y^2+\frac{x^4}{4}+C\]
\end{proof}
\sssc{Example: $(2xy+y)\dd{x}+x^2\dd{y}=0$}
ODE:
\[(2xy+y)\dd{x}+x^2\dd{y}=0.\]
Solutions:
\[y=Ce^{1/x}x^{-2}.\]
\begin{proof}
\[\pdv{}{y}(2xy+y)=2x+1\]
\[\pdv{}{x}(x^2)=2x\]
\[\frac{\pdv{}{y}(2xy+y)-\pdv{}{x}(x^2)}{x^2}=\frac{1}{x^2}\]
\[\mu(x)=\exp(\int\frac{1}{x^2}\dd{x})=e^{-1/x}\]
\[e^{-1/x}(2xy+y)\dd{x}+e^{-1/x}x^2\dd{y}=0.\]
\[F(x,y)=\int e^{-1/x}x^2\dd{y}+\phi(x)=e^{-1/x}x^2y+\phi(x)\]
\[\pdv{F}{x}=\qty(x^{-2}e^{-1/x}x^2+e^{-1/x}2x)y+\phi'(x)=e^{-1/x}(2x+1)y+\phi'(x)\]
\[\phi'(x)=0\]
\[F(x,y)=e^{-1/x}x^2y+C\]
\[e^{-1/x}x^2y=C\]
\[y=Ce^{1/x}x^{-2}\]
\end{proof}
\ssc{Homogeneous equation}
\sssc{Definition}
A first-order ODE in the form
\[\dv{y}{x}=F(x,y)\]
with $F(x,y)$ be a homogeneous function of degree $0$ is said to be homogeneous. 

For first-order ODE in the form
\[M(x,y)\dd{x}+N(x,y)\dd{y}=0,\]
if $M(x,y)$ and $N(x,y)$ are homogeneous functions of the same degree, $F(x,y)=-\frac{M(x,y)}{N(x,y)}$ is a homogeneous function of degree $0$.
\sssc{Solutions by substitutions}
For any homogeneous function $F(x,y)$ of $2$ variables, there exists a function $f$ of $1$ variable such that $F(x,y)=f\qty(\frac{y}{x})$ for all $x\neq 0$ such that $(x,y)$ is in the domain of $F$.

Introduce the substitution $v=\frac{y}{x}$.
\[\dv{y}{x}=\dv{(xv)}{x}=v+x\dv{v}{x}=f(v),\]
which is a separable ODE.
\[\frac{\dd{v}}{f(v)-v}=\frac{\dd{x}}{x}.\]
\[\int\frac{\dd{v}}{f(v)-v}=\ln|x|+C.\]
Substituting $v=\frac{y}{x}$ back gives the solutions.

If $F$ is defined when $x=0$, we also have a implicit constant solution
\[F(0,y)=0.\]
\sssc{Example: $(x^2+y^2)\dd{x}-2xy\dd{y}=0$}
ODE:
\[(x^2+y^2)\dd{x}-2xy\dd{y}=0.\]
Implicit solutions:
\[y^2=x^2+Cx.\]
\begin{proof}
\[\dv{y}{x}=\frac{x^2+y^2}{2xy}=F(x,y)\]
\[F(tx,ty)=F(x,y)\]
\[v=\frac{y}{x}\]
\[F(x,y)=f(v)=\frac{1+v^2}{2v}\]
\[\dv{y}{x}=v+x\dv{v}{x}=f(v)\]
\[\frac{1}{f(v)-v}\dd{v}=\frac{\dd{x}}{x}\]
\[\ba
\int\frac{1}{f(v)-v}\dd{v}&=\ln|x|+C\\
&=\int\frac{2v}{1-v^2}\dd{v}\\
&=-\ln|u|,\quad u=1-v^2\\
&=-\ln|1-v^2|
\ea\]
\[C|x|=\frac{1}{|1-v^2|}\]
\[v^2=1+\frac{C}{x}\]
\[y^2=x^2+Cx\]
\end{proof}
\sssc{Example: $(x^2+y^2)\dd{x}+y^2\dd{y}=0$}
ODE:
\[(x^2+y^2)\dd{x}+y^2\dd{y}=0.\]
Implicit solutions:
\[\arctan(\frac{2\sqrt{3}}{3}\qty(\frac{y}{x}+\frac{1}{2}))=\frac{\sqrt{3}}{2}\ln\abs{\frac{x^2}{y}}+C.\]
Constant solution:
\[x=0,\quad y=0.\]
\begin{proof}
\[\dv{y}{x}=-\frac{y^2}{x^2+y^2}=F(x,y)\]
\[F(tx,ty)=F(x,y)\]
\[v=\frac{y}{x}\]
\[F(x,y)=f(v)=-\frac{v^2}{1+v^2},\quad x\neq 0\]
\[\frac{1}{f(v)-v}\dd{v}=\frac{\dd{x}}{x}\]
\[\int\frac{1}{f(v)-v}\dd{v}=\ln|x|+C\]
\[\frac{1}{f(v)-v}=-\frac{1+v^2}{v(1+v+v^2)}=-\frac{A}{v}-\frac{Bv+C}{1+v+v^2}\]
\[A+Av+Av^2+Bv^2+Cv=1+v^2\]
\[A=1,\quad B=0,\quad C=-1\]
\[\ba
\int\frac{1}{f(v)-v}\dd{v}&=-\int\frac{1}{v}\dd{v}+\int\frac{1}{1+v+v^2}\dd{v}\\
&=\ln|v|+\int\frac{1}{\qty(v+\frac{1}{2})^2+\frac{3}{4}}\dd{v},\quad u=\frac{2}{\sqrt{3}}\qty(v+\frac{1}{2})\\
&=\ln|v|+\frac{\sqrt{3}}{2}\frac{4}{3}\int\frac{1}{u^2+1}\dd{u}\\
&=\ln|v|+\frac{2\sqrt{3}}{3}\arctan(u)+C\\
&=\ln|v|+\frac{2\sqrt{3}}{3}\arctan(\frac{2\sqrt{3}}{3}\qty(v+\frac{1}{2}))+C
\ea\]
\[\ln|v|+\frac{2\sqrt{3}}{3}\arctan(\frac{2\sqrt{3}}{3}\qty(v+\frac{1}{2}))=\ln|x|+C\]
\[\ln|y|-\ln|x|+\frac{2\sqrt{3}}{3}\arctan(\frac{2\sqrt{3}}{3}\qty(\frac{y}{x}+\frac{1}{2}))=\ln|x|+C\]
\[\arctan(\frac{2\sqrt{3}}{3}\qty(\frac{y}{x}+\frac{1}{2}))=\frac{\sqrt{3}}{2}\ln\abs{\frac{x^2}{y}}+C\]
\[\arctan(\frac{2\sqrt{3}}{3}\qty(\frac{y}{x}+\frac{1}{2}))=\frac{\sqrt{3}}{2}\ln\abs{\frac{x^2}{y}}+C\]
\[F(0,y)=0,\quad y=0\]
\end{proof}
\ssc{Bernoulli differential equation}
\sssc{Definition}
A first-order ODE in the form
\[\dv{y}{x}+P(x)y=Q(x)y^n,\quad n\in\mathbb{R}\setminus\{0,1\}\]
is called a Bernoulli differential equation.

Remark: When $n=0$ or $1$, it is a first-order linear equation.
\sssc{Solutions by substitutions}
Divide both sides by $y^n$:
\[y^{-n}\dv{y}{x}+P(x)y^{1-n}=Q(x).\]
Introduce the substitution $v=y^{1-n}$.
\[\dv{v}{x}=(1-n)y^{-n}\dv{y}{x}.\]
Substitute into the equation:
\[\frac{1}{1-n}\dv{v}{x}+P(x)v=Q(x).\]
\[\dv{v}{x}+(1-n)P(x)v=(1-n)Q(x),\]
which is linear.

Use the integrating factor:
\[\mu(x)=e^{\int (1-n)P(x)\dd{x}}.\]
Multiply both sides with $\mu(x)$:
\[\mu(x)\dv{v}{x}+\mu(x)(1-n)P(x)v=\mu(x)(1-n)Q(x).\]
The left-hand side is exactly a derivative:
\[\dv{}{x}\qty(\mu(x)v(x))=\mu(x)(1-n)Q(x).\]
Integrate:
\[\mu(x)v(x)=\int\mu(x)(1-n)Q(x)\dd{x}+C.\]
\[v(x)=\frac{1}{\mu(x)}\qty(\int\mu(x)(1-n)Q(x)\dd{x}+C).\]
Recall $v=y^{1-n}$, we obtain the family of general solutions.
\sssc{Example: $\dv{y}{x}+\cos(x)y=\sin(2x)y^{3/2}$}
ODE:
\[\dv{y}{x}+\cos(x)y=\sin(2x)y^{3/2}.\]
Solutions:
\[y=\qty(2\sin(x)+4+Ce^{\sin(x)/2})^{-2}.\]
\begin{proof}
\[y^{-3/2}\dv{y}{x}+\cos(x)y^{-1/2}=2\sin(x)\cos(x)\]
\[v=y^{-1/2},\quad\dv{v}{x}=-\frac{1}{2}y^{-3/2}\dv{y}{x}.\]
\[\dv{v}{x}-\frac{1}{2}\cos(x)v=-\sin(x)\cos(x)\]
\[\mu(x)=\exp(\int-\frac{1}{2}\cos(x)\dd{x})=e^{-\sin(x)/2}\]
\[\dv{}{x}\qty(e^{-\sin(x)/2}v)=-\sin(x)\cos(x)e^{-\sin(x)/2}\]
\[\ba
e^{-\sin(x)/2}v&=\int-\sin(x)\cos(x)e^{-\sin(x)/2}\dd{x},\quad u=\frac{\sin(x)}{2}\\
&=-4\int ue^{-u}\dd{u}\\
&=-4\qty(-ue^{-u}-\int -e^{-u}\dd{u})\\
&=-4\qty(-ue^{-u}-e^{-u}+C)\\
&=2\sin(x)e^{-\sin(x)/2}+4e^{-\sin(x)/2}+C
\ea\]
\[v=2\sin(x)+4+Ce^{\sin(x)/2}\]
\[y=v^{-2}=\qty(2\sin(x)+4+Ce^{\sin(x)/2})^{-2}\]
\end{proof}
\ssc{Slope being function of linear function}
ODE:
\[\dv{y}{x}=f(u),\quad u=ax+by+c.\]
Solutions:
\[\int\frac{1}{a+bf(u)}\dd{u}=x+C.\]
\begin{proof}
\[\dv{u}{x}=a+b\dv{y}{x}=a+bf(u)\]
This is separable.
\[\int\frac{1}{a+bf(u)}\dd{u}=x+C\]
\end{proof}
\ssc{Slope being function of linear function over linear function}
ODE:
\[\dv{y}{x}=F\qty(\frac{ax+by+c}{px+qy+r}),\quad aq-bp\neq 0.\]
We can find a unique solution of $ax+by+c=px+qy+r=0$ for $x$ and $y$, let it be $x=\alpha$, $y=\beta$, let
\[f(t)=F\qty(\frac{a+bt}{p+qt}),\]
and we can rewrite it as:
\[\dv{y}{x}=f(u),\quad u=\frac{y-\beta}{x-\alpha}.\]
\begin{proof}
\[y=u(x-\alpha)+\beta\]
\[ax+by+c=(a+bu)(x-\alpha)+a\alpha+b\beta+c=(a+bu)(x-\alpha)\]
\[px+qy+r=(p+qu)(x-\alpha)+p\alpha+q\beta+r=(p+qu)(x-\alpha)\]
\[\frac{ax+by+c}{px+qy+r}=\frac{a+bu}{p+qu}\]
\end{proof}
Solutions:
\[\int\frac{1}{f(u)-u}\dd{u}=\ln|x-\alpha|+C,\]
and possibe constant or singular solutions:
\[f(u)=u.\]
\begin{proof}
\[y=(x-\alpha)u+\beta\]
\[\dv{y}{x}=\pdv{}{x}\qty((x-\alpha)u+\beta)+\pdv{}{u}\qty((x-\alpha)u+\beta)\dv{u}{x}=u+(x-\alpha)\dv{u}{x}\]
\[u+(x-\alpha)\dv{u}{x}=f(u)\]
\[\frac{1}{f(u)-u}\dd{u}=\frac{1}{x-\alpha}\dd{x}\]
This is separable.
\[\int\frac{1}{f(u)-u}\dd{u}=\ln|x-\alpha|+C\]
\end{proof}
\sct{Linear ODE}
Unless otherwise specified, the variables and functions are in $\mathbb{R}$.
\ssc{Definition}
An $n$th-order ODE of a dependent variable $y$ with respect to an independent variable $x$ is linear iff it can be written in the form
\[\sum_{i=0}^np_i(x)y^{(i)}=q(x),\]
where $p_0(x),\dots p_n(x)$, called the coefficients, and $q(x)$, called the forcing term, are functions of $x$, and $p_n(x)$ is nontrivial.

An ODE is nonlinear if it is not linear.
\ssc{Linearity}
Let $L[y]=\sum_{i=0}^np_i(x)y^{(i)}$ denotes the left-hand side, then $L[\alpha y_1+\beta y_2]=\alpha L[y_1]+\beta L[y_2]$. That's why it's called to be linear.
\ssc{Homogeneity}
A linear ODE is called a linear homgeneous ODE iff the forcing term is 0 for all $x$; otherwise, it is called a linear nonhomogeneous ODE.
\ssc{Superposition principle}
If $y_1(x)$ and $y_2(x)$ are both solutions of a linear homgeneous ODE on an interval, then $c_1y_1(x)+c_2y_2(x)$ is also a solution of the ODE on the interval for any constants $c_1,c_2$.
\ssc{Linear independence}
$n$ functions of the same domain and codomain $y_1(x),y_2(x),\ldots y_n(x)$ are said to be linearly independent iff
\[\sum_{i=1}^nc_iy_i(x)=0\implies\forall i\colon c_i=0.\]
\ssc{Solutions of linear homogenous ODE as vector space}
The general solutions of an $n$th-order linear homogenous ODE is a vector space of dimension $n$.
\ssc{Basis of solutions of linear homogenous ODE}
If $y_1(x),y_2(x),\ldots y_n(x)$ are $n$ linearly independent solutions of an $n$th-order linear homgeneous ODE on an interval, then they are a basis of the vector space of the general solutions of the ODE on the interval, and $\sum_{i=1}^nc_iy_i(x)$ is the family general solutions of the ODE on the interval with $n$ parameter $c_1,c_2,\ldots c_n$.
\ssc{Complementary equation and particularly solution}
Given an $n$th-order linear nonhomogeneous ODE
\[y^{(n)}+\sum_{i=0}^{n-1}p_i(x)y^{(i)}=q(x),\]
the $n$th-order linear homogeneous ODE,
\[y^{(n)}+\sum_{i=0}^{n-1}p_i(x)y^{(i)}=0,\]
is called its complementary equation, and the general solutions of the original equation is the sum of the general solutions $y_c$ of the complementary equation, also called natural solution or homogeneous solution, and a particular solution $y_p$.
\ssc{Solutions of linear nonhomogenous ODE as affine space}
The general solutions of a linear nonhomogenous ODE is an affine space whose associated vector space is the general solutions of its complementary equation.
\ssc{Characteristic equation or auxiliary equation for constant coefficient linear homogeneous ODE}
\sssc{Method}
Consider an $n$th-order constant coefficient linear homogeneous ODE
\[\sum_{j=0}^na_jy^{(j)}=0,\quad a_n\neq 0.\]
The formation of its general solutions using the characteristic equation (also called auxiliary equation) is as follows:
\ben
\item The characteristic equation is
\[\sum_{j=0}^na_jr^j=0.\]
\item Suppose there are $k$ distinct real roots $r_1,r_2,\ldots,r_k$, each $r_j$ with multiplicity $m_j$, and $h$ distinct pairs of conjugate imaginary roots $\alpha_1\pm\beta_1i,\alpha_2\pm\beta_2i,\ldots,\alpha_h\pm\beta_hi$ ($\beta_j\neq 0$), each $\alpha_j\pm\beta_ji$ with multiplicity $\omega_j$. (Thus, $\sum_{j=1}^km_j+2\sum_{j=1}^h\omega_j=n$.)
\item The $n$-parameter family of general solutions of the ODE is
\[\sum_{j=1}^k\sum_{u=0}^{m_j-1}A_{ju}x^ue^{r_jx}+\sum_{j=1}^h\sum_{u=0}^{\omega_j-1}\qty(B_{ju}\cos(\beta_jx)+C_{ju}\sin(\beta_jx))x^ue^{\alpha_jx},\]
with parameters $A_{ju},B_{ju},C_{ju}$.
\een
\sssc{Exponential order}
For any solution $f(t)$ of any linear nonhomogenous ODE of one variable $t$, there exists some $M,T\geq 0$ and $\alpha\in\bbR$ such that for all $t>T$ $\abs{f(t)}\leq e^{M\alpha t}$, and the smallest such $\alpha$ is the largest real part among all roots of its characteristic equation.
\sssc{Example: simple harmonic motion}
ODE:
\[\ddot{x}=-\omega^2x,\quad\omega\in\bbR_{>0}.\]
Solutions:
\[x=A\sin(\omega t+\phi),\quad A,\phi\in\bbR.\]
\begin{proof}
\[\ddot{x}+\omega^2x=0\]
\[r^2+\omega^2=0\]
\[r=\pm\omega i\]
\[x(t)=A\sin(\omega t)+B\cos(\omega t)=A\sin(\omega t+\phi)\]
\end{proof}
\sssc{Example: linearly damped simple harmonic motion}
ODE:
\[\ddot{x}=-k(x-C)-b\dot{x},\quad k,b\in\bbR_{>0}\land C\in\bbR.\]
Solutions:
\begin{itemize}
\item Case $b^2<4k$ called underdamped:
\[x=Ae^{\frac{-b}{2}t}\sin(\frac{\sqrt{4k-b^2}}{2}t+\phi)+C.\]
\item Case $b^2=4k$ called critically damped:
\[x=A(1+Bt)e^{\frac{-b}{2}t}+C\]
\item Case $b^2>4k$ called overdamped:
\[x=Ae^{\frac{-b}{2}t}\qty(e^{\frac{\sqrt{b^2-4k}}{2}t}+Be^{\frac{-\sqrt{b^2-4k}}{2}t})+C\]
\end{itemize}
\begin{proof}
\[\lambda^2+b\lambda+k=0\]
\[\lambda=\frac{-b\pm\sqrt{b^2-4k}}{2}\]
Case $b^2<4k$:
\[\lambda=\frac{-b\pm\sqrt{4k-b^2}i}{2}\]
\[x-C=D\qty(e^{\frac{-b+\sqrt{4k-b^2}i}{2}t}+Ee^{\frac{-b-\sqrt{4k-b^2}i}{2}t})=Ae^{\frac{-b}{2}t}\sin(\frac{\sqrt{4k-b^2}}{2}t+\phi)\]
Case $b^2=4k$:
\[\lambda=\frac{-b}{2}\]
\[x-C=A(1+Bt)e^{\frac{-b}{2}t}\]
Case $b^2>4k$:
\[\lambda=\frac{-b\pm\sqrt{b^2-4k}}{2}\]
\[x-C=A\qty(e^{\frac{-b+\sqrt{b^2-4k}}{2}t}+Be^{\frac{-b-\sqrt{b^2-4k}}{2}t})=Ae^{\frac{-b}{2}t}\qty(e^{\frac{\sqrt{b^2-4k}}{2}t}+Be^{\frac{-\sqrt{b^2-4k}}{2}t})\]
\end{proof}
\ssc{Method of undetermined coefficients (MUC) for constant coefficient linear nonhomogeneous ODE}
\sssc{Method}
Consider an $n$th-order constant coefficient linear nonhomogeneous ODE
\[\sum_{j=0}^na_jy^{(j)}=g(x),\quad a_n\neq 0,\]
with $g(x)$ being able to be written in the form
\[g(x)=\sum_{j=1}^pk_jx^{m_j}e^{\alpha_jx}+\sum_{j=p+1}^{p+q}x^{m_j}e^{\alpha_jx}\qty(k_j\cos(\beta_jx)+l_j\sin(\beta_jx)),\]
for some constants $p,q,m_j\in\bbN_0$ and $\alpha_j,\beta_j,k_j,l_j\in\bbR$.

The formation of its general solutions using the method of undetermined coefficients is as follows:
\ben
\item Solve the complementary equation
\[\sum_{j=0}^na_jy^{(j)}=0,\quad a_n\neq 0\]
using characteristic equation to obtain its general solutions $y_c$.
\item For each term $k_jx^{m_j}e^{\alpha_jx}$ of $g(x)$ for $j\in\bbN\land j\leq p$, construct a particular solution $y_j$:
\ben
\item If $\alpha_j$ is not a root of the characteristic equation of the complementary equation, let $s_j=0$; otherwise, let $s_j$ be the multiplicity of $\alpha_j$ as a root of the characteristic equation of the complementary equation.
\item The ansatz is
\[y_j=x^{s_j}e^{\alpha_jx}\sum_{k=0}^{m_j}C_{jk}x^k,\]
with constants $C_{jk}\in\bbR$.
\item Solve for $C_{jk}$ such that $y_j$ is a particular solution of the constant coefficient linear nonhomogeneous ODE
\[\sum_{j=0}^na_jy^{(j)}=k_jx^{m_j}e^{\alpha_jx}.\]
\een
\item For each term $x^{m_j}e^{\alpha_jx}\qty(k_j\cos(\beta_jx)+l_j\sin(\beta_jx))$ of $g(x)$ for $j\in\bbN\land p<j\leq p+q$, construct a particular solution $y_j$:
\ben
\item If $\alpha_j\pm\beta_ji$ is not a pair of conjugate imaginary roots of the characteristic equation of the complementary equation, let $s_j=0$; otherwise, let $s_j$ be the multiplicity of $\alpha_j\pm\beta_ji$ as a pair of conjugate imaginary roots of the characteristic equation of the complementary equation.
\item The ansatz is
\[y_j=x^{s_j}e^{\alpha_jx}\sum_{k=0}^{m_j}\qty(C_{jk}\cos(\beta_jx)+D_{jk}\sin(\beta_jx))x^k,\]
with constants $C_{jk},D_{jk}\in\bbR$.
\item Solve for $C_{jk},D_{jk}$ such that $y_j$ is a particular solution of the constant coefficient linear nonhomogeneous ODE
\[\sum_{j=0}^na_jy^{(j)}=x^{m_j}e^{\alpha_jx}\qty(k_j\cos(\beta_jx)+l_j\sin(\beta_jx)).\]
\een
\item A particular solution of the origin ODE is
\[y_p=\sum_{j=1}^{p+q}y_j,\]
and the general solutions of the origin ODE is
\[y=y_c+y_p.\]
\een
\sssc{Example: Forced oscillation and resonance}
PLACEHOLDER
\ssc{Formation of solutions of linear nonhomogeneous equation}
\sssc{Wrońskian or Wronskian}
For $n$ functions $f_1,f_2,\ldots,f_n$ that are $(n-1)$ times differentiable on an interval $I$, the Wrońskian (also called Wronskian) of them, $W(f_1,f_2,\ldots,f_n)$, is a function on $I$ defined by
\[W(f_1,f_2,\ldots,f_n)(x)=\det\begin{bmatrix}
f_1(x) & f_2(x) & \cdots & f_n(x) \\
f_1'(x) & f_2(x) & \cdots & f_n'(x) \\
\vdots & \vdots & \ddots & \vdots \\
f_1^{(n-1)}(x) & f_2^{(n-1)}(x) & \cdots & f_n^{(n-1)}(x)
\end{bmatrix}.\]
If $f_1,f_2,\ldots,f_n$ are not linearly independent, then $W=0$.
\sssc{Second-order Abel's (differential equation) identity/formula}
A second-order linear homogeneous ODE
\[y''+p(x)y'+q(x)y=0\]
on an interval $I$ with continuous function $p$ and $q$. The Wrońskian $W(y_1,y_2)$ of two solutions $y_1,y_2$ of it satisfies
\[W(y_1,y_2)(x)=W(y_1,y_2)(x_0)\cdot\exp(-\int_{x_0}^xp(t)\dd{t}),\quad x\in I,\]
for any $x_0\in I$.
\begin{proof}
\[\ba
W'&=(y_1y_2'-y_1'y_2)'\\
&=y_1'y_2'+y_1y_2''-y_1'y_2'-y_1''y_2\\
&=y_1y_2''-y_1''y_2
\ea\]
\[y''=-(py'+qy).\]
\[W'=-y_1(py_2'+qy_2)+y_2(py_2'+qy_2)=-pW\]
$W'+p(x)W=0$ is a first-order linear homogenous ODE that can be solved by the integrating factor
\[\mu(x)=\exp(\int p(x)\dd{x})\]
and initial condition $W(x_0)$:
\[\qty(W\exp(\int_a^xp(t)\dd{t}))'=0\]
\[W\exp(\int_a^xp(t)\dd{t})=C\]
\[W(x_0)\exp(\int_a^{x_0}p(t)\dd{t})=C\]
\[W(x)=W(x_0)\cdot\exp(\int_a^{x_0}p(t)\dd{t}-\int_a^xp(t)\dd{t})=W(x_0)\cdot\exp(-\int_{x_0}^xp(t)\dd{t}).\]
\end{proof}
\sssc{General Abel's (differential equation) identity/formula}
A linear homogeneous ODE
\[\sum_{i=0}^{n-1}p_i(x)y^{(i)}+y^{(n)}=0\]
on an interval $I$ with continuous functions $p_i$. The Wrońskian $W(y_1,y_2,\ldots,y_n)$ of $n$ solutions $y_1,y_2,\ldots,y_n$ of it satisfies
\[W(y_1,y_2,\ldots,y_n)(x)=W(y_1,y_2,\ldots,y_n)(x_0)\cdot\exp(-\int_{x_0}^xp_{n-1}(t)\dd{t}),\quad x\in I,\]
for any $x_0\in I$.
\begin{proof}
Differentiate row by row:
\[\ba
W'&=\dv{}{x}\qty(\det\begin{bmatrix}
y_1 & y_2 & \cdots & y_n \\
y_1' & y_2' & \cdots & y_n' \\
\vdots & \vdots & \ddots & \vdots \\
y_1^{(n-1)} & y_2^{(n-1)} & \cdots & y_n^{(n-1)}
\end{bmatrix})\\
&=\det\begin{bmatrix}
y_1' & y_2' & \cdots & y_n' \\
y_1' & y_2' & \cdots & y_n' \\
\vdots & \vdots & \ddots & \vdots \\
y_1^{(n-1)} & y_2^{(n-1)} & \cdots & y_n^{(n-1)}
\end{bmatrix}+\det\begin{bmatrix}
y_1 & y_2 & \cdots & y_n \\
y_1'' & y_2'' & \cdots & y_n'' \\
\vdots & \vdots & \ddots & \vdots \\
y_1^{(n-1)} & y_2^{(n-1)} & \cdots & y_n^{(n-1)}
\end{bmatrix}+\ldots+\det\begin{bmatrix}
y_1 & y_2 & \cdots & y_n \\
y_1' & y_2' & \cdots & y_n' \\
\vdots & \vdots & \ddots & \vdots \\
y_1^{(n)} & y_2^{(n)} & \cdots & y_n^{(n)}
\end{bmatrix}
\ea\]
All these determinants except the last one contain linearly dependent rows and thus equal to 0.
\[W'=\det\begin{bmatrix}
y_1 & y_2 & \cdots & y_n \\
y_1' & y_2' & \cdots & y_n' \\
\vdots & \vdots & \ddots & \vdots \\
y_1^{(n)} & y_2^{(n)} & \cdots & y_n^{(n)}
\end{bmatrix}.\]
For all $i\in\bbN\land i\leq n$:
\[y_i^{(n)}+\sum_{i=0}^{n-2}p_i(x)y^{(i)}=-p_{n-1}(x)y^{(n-1)}.\]
Hence, we can add to the last row of the above determinant $p_i$ times its $(i+1)$th row for all $i\in\bbN_0\land i<n-1$, the value of the determinant is unchanged, and we get
\[W'=\det\begin{bmatrix}
y_1 & y_2 & \cdots & y_n \\
y_1' & y_2' & \cdots & y_n' \\
\vdots & \vdots & \ddots & \vdots \\
-p_{n-1}(x)y_1^{(n-1)} & -p_{n-1}(x)y_2^{(n-1)} & \cdots & -p_{n-1}(x)y_n^{(n-1)}
\end{bmatrix}=-p_{n-1}(x)W.\]
$W'+p_{n-1}(x)W=0$ is a first-order linear homogenous ODE that can be solved by the integrating factor
\[\mu(x)=\exp(\int p_{n-1}(x)\dd{x})\]
and initial condition $W(x_0)$:
\[\qty(W\exp(\int_a^xp_{n-1}(t)\dd{t}))'=0\]
\[W\exp(\int_a^xp_{n-1}(t)\dd{t})=C\]
\[W(x_0)\exp(\int_a^{x_0}p_{n-1}(t)\dd{t})=C\]
\[W(x)=W(x_0)\cdot\exp(\int_a^{x_0}p_{n-1}(t)\dd{t}-\int_a^xp_{n-1}(t)\dd{t})=W(x_0)\cdot\exp(-\int_{x_0}^xp_{n-1}(t)\dd{t}).\]
\end{proof}
\sssc{Variation of parameters or variation of constants}
Given an $n$th-order linear nonhomogeneous ODE
\[y^{(n)}+\sum_{i=0}^{n-1}p_i(x)y^{(i)}=q(x),\]
let $y_1(x),y_2(x),\ldots,y_n(x)$ be a basis of the vector space of the solutions of the complementary equation,
\[y^{(n)}+\sum_{i=0}^{n-1}p_i(x)y^{(i)}=0,\]
which can be obtained by variation of parameters of the family of the solutions of the complementary equation. The particular solution of the original ODE (or family of general solutions with the integral constants being parameters) is given by:
\[y_p=\sum_{i=1}^ny_i(x)\int\frac{W_i(x)}{W(x)}\dd{x},\]
where
\bit
\item $W(x)$ is the Wrońskian of $y_1(x),y_2(x),\ldots,y_n(x)$,
\item $W_i(x)$ is the Wrońskian of $W(x)$ but with the $i$th column replaced by $(0,0,\ldots,0,q(x))$.
\eit
For second-order equation
\[y''+p_1(x)y'+p_0(x)y=q(x),\]
let $y_1(x),y_2(x)$ be two linearly independent solutions of its complementary equation
\[y''+p_1(x)y'+p_0(x)y=0,\]
the particular solution (or family of general solutions with the integral constants being parameters) is given by
\[y_p(x)=-y_1(x)\int\frac{y_2(x)q(x)}{y_1(x)y_2'(x)-y_2(x)y_1'(x)}\dd{x}+y_2(x)\int\frac{y_1(x)q(x)}{y_1(x)y_2'(x)-y_2(x)y_1'(x)}\dd{x}.\]
\begin{proof}
The particular solution is given by
\[y_p=\sum_{i=1}^nc_i(x)y_i(x),\]
where $c_i(x)$ are differentiable functions which are assumed to satisfy the $n-1$ conditions
\[\sum_{i=1}^nc_i'(x)y_i^{(j)}(x)=0\]
for all $j\in\bbN_0\land j\leq n-2$.

By repeated differentiation, we obtain:
\[y_p^{(j)}=\sum_{i=1}^nc_i(x)y_i^{(j)}(x)\]
for all $j\in\bbN_0\land j\leq n-1$.

One last differentiation gives
\[y_p^{(n)}=\sum_{i=1}^nc_i(x)y_i^{(n)}(x)+\sum_{i=1}^nc_i'(x)y_i^{(n-1)}(x).\]

Substituting $y_p$ into the original ODE gives:
\[y_p^{(n)}+\sum_{i=0}^{n-1}p_i(x)y_p^{(i)}=q(x),\]
\[\sum_{i=1}^nc_i(x)y_i^{(n)}(x)+\sum_{i=1}^nc_i'(x)y_i^{(n-1)}(x)+\sum_{i=0}^{n-1}p_i(x)\sum_{i=1}^nc_i(x)y_i^{(j)}(x)=q(x),\]
\[\sum_{i=1}^nc_i'(x)y_i^{(n-1)}(x)+\sum_{i=1}^nc_i(x)\qty(y_i^{(n)}(x)+\sum_{i=0}^{n-1}p_i(x)y_i^{(j)}(x))=q(x),\]
\[\sum_{i=1}^nc_i'(x)y_i^{(n-1)}(x)=q(x).\]
We obtain a system of linear equations
\[\sum_{i=1}^nc_i'(x)y_i^{(j)}(x)=0\]
for all $j\in\bbN_0\land j\leq n-2$, and
\[\sum_{i=1}^nc_i'(x)y_i^{(n-1)}(x)=q(x).\]
By Cramer Rule, we have
\[c_i'(x)=\frac{W_i(x)}{W(x)},\quad i\in\bbN\land i\leq n.\]
\end{proof}
\ssc{Reduction of order}
\sssc{Method}
Given an $n$th-order linear homogeneous ODE
\[\sum_{i=0}^np_i(x)y^{(i)}=0,\]
if a nontrivial particular solution $y_1(x)$ has been known, we can reduce the order of the ODE by 1 by the substitution
\[y=vy_1\]
and then the substitution
\[u=v'\]
to an $(n-1)$th-order linear ODE.
\sssc{Closed-form formula for second-order linear homogeneous ODEs}
Given a second-order linear homogeneous ODE
\[y''+p(x)y'+q(x)y=0,\]
if a nontrivial particular solution $y_1(x)$ that has been known, then the general solutions of the ODE is
\[y=y_1\int\frac{e^{-\int p(x)\dd{x}}}{y_1(x)^2}\dd{x}.\]
\begin{proof}
Substitute
\[y=vy_1,\]
\[y'=v'y_1+vy_1',\]
\[y''=v''y_1+2v'y_1'+vy_1'',\]
\[y_1''=-py_1'-qy_1,\]
\[y''=-py'-qy=,\]
\[-pv'y_1-pvy_1'-qvy_1=v''y_1+2v'y_1'-pvy_1'-qvy_1,\]
\[y_1v''+(2y_1'+py_1)v'=0,\]
Substitute
\[u=v',\]
\[y_1u'+(2y_1'+py_1)u=0,\]
\[u'+\qty(\frac{2y_1'}{y_1}+p)u=0,\]
\[\mu(x)=\exp(\int\frac{y_1'}{y_1}+p\dd{x})=y_1(x)^2e^{\int p(x)\dd{x}},\]
\[(u\mu(x))'=0,\]
\[u=\frac{C}{\mu(x)}=C\frac{e^{-\int p(x)\dd{x}}}{y_1(x)^2}=\frac{e^{-\int p(x)\dd{x}}}{y_1(x)^2},\]
\[v=\int u\dd{x}=\int\frac{e^{-\int p(x)\dd{x}}}{y_1(x)^2}\dd{x},\]
\[y=vy_1=y_1\int\frac{e^{-\int p(x)\dd{x}}}{y_1(x)^2}\dd{x}.\]
\end{proof}
\sssc{Example:}
PLACEHOLDER
\ssc{Power series solutions and Frobenius method for second-order linear homogenous ODE}
\sssc{Power series solutions}
Consider a second-order linear homogenous ODE
\[f(x)y''+g(x)y'+h(x)y=0.\]
Let
\[p(x)=\frac{g(x)}{f(x)},\quad q(x)=\frac{h(x)}{f(x)}.\]
For any $a$ in the intersection of the domain of $p$ and the domain of $q$, $a$ is called an ordinary point iff $p$ and $q$ are both analytic at $a$.
\ben
\item The power series method seeks a solution in the form:
\[y=\sum_{n=0}^{\infty}a_n(x-x_0)^n,\]
where $x_0$ is a fixed point called expansion point and $a_n$ are constants to be determined, called power series.
\item Differentiate the series term by term:
\[y'=\sum_{n=0}^{\infty}a_nn(x-x_0)^{n-1}=\sum_{n=0}^{\infty}a_{n+1}(n+1)(x-x_0)^n,\]
\[y''=\sum_{n=0}^{\infty}a_nn(n-1)(x-x_0)^{n-2}=\sum_{n=0}^{\infty}a_{n+2}(n+2)(n+1)(x-x_0)^n.\]
\item Substitute into the ODE, rewrite $p(x)$ and $q(x)$ into Taylor expansion at $x_0$, rewrite the infinite series products (if any) into Cauchy products, and rewrite the LHS as a power series in $x^n$.
\item Solve for the recurrence relation of $a_n$. We may set $a_0$ as any nonzero constant, typically 1.
\item The two-parameter family of general solutions for all $0<|x-x_0|<R$ where $R$ is the distance between $x_0$ and the nearest to $x_0$ singular point of $p(x)$ or $q(x)$ with parameters $a_0,a_1$ is:
\[y=\sum_{n=0}^{\infty}a_n(x-x_0)^n.\]
\een
\sssc{Frobenius method}
Consider a second-order linear homogenous ODE
\[f(x)y''+g(x)y'+h(x)y=0.\]
Let
\[p(x)=\frac{g(x)}{f(x)},\quad q(x)=\frac{h(x)}{f(x)}.\]
For any $x_0$ in the intersection of the domain of $p$ and the domain of $q$, $x_0$ is called a regular singular point iff it is not an ordinary point and $(x-x_0)p(x)$ and $(x-x_0)^2q(x)$ are both analytic at $a$.
\ben
\item The Frobenius method seeks a solution in the form:
\[y=\sum_{n=0}^{\infty}a_n(x-x_0)^{n+r},\quad a_0\neq 0,\]
where $x_0$ is called expansion point and $a_n$ are constants to be determined, called Frobenius series.
\item Differentiate the series term by term:
\[y'=\sum_{n=0}^{\infty}a_n(n+r)(x-x_0)^{n+r-1},\]
\[y''=\sum_{n=0}^{\infty}a_n(n+r)(n+r-1)(x-x_0)^{n+r-2}.\]
\item Substitute into $(x-x_0)^2y''$, $(x-x_0)^2p(x)y'$, and $(x-x_0)^2q(x)y$ respectively, rewrite $(x-x_0)^2p(x)$ and $(x-x_0)^2q(x)$ into Taylor expansion at $x_0$, rewrite the infinite series products (if any) into Cauchy products, and let the sum of all terms involving $a_0$ of the three be $L$.
\item The indicial polynomial $I(r)$ is defined as the coefficient of the lowest power term of $L$, and the indicial equation is defined as
\[I(r)=0,\]
which is a quadratic equation for $r$.
\item Solve the indicial equation for $r$. Let the roots be $r_1\geq r_2$.
\item Depending on the relation of $r_1$ and $r_2$:
\bit
\item Case $r_1-r_2\notin\bbZ\land r_1,r_2\in\bbR$: Two linearly independent solutions for all $0<|x-x_0|<R$ where $R$ is the distance between $x_0$ and the nearest to $x_0$ regular singular point of $(x-x_0)p(x)$ or $(x-x_0)^2q(x)$ are:
\[y_1(x)=(x-x_0)^{r_1}\sum_{n=0}^{\infty}A_n(x-x_0)^n,\quad A_0\neq 0\land A_n\in\bbR,\]
\[y_2(x)=(x-x_0)^{r_2}\sum_{n=0}^{\infty}B_n(x-x_0)^n,\quad B_0\neq 0\land B_n\in\bbR.\]
\item Case $r_1,r_2$ are conjugate imaginary roots: Let $r_1,r_2=\alpha\pm\beta i$. Two linearly independent solutions for all $0<|x-x_0|<R$ where $R$ is the distance between $x_0$ and the nearest to $x_0$ regular singular point of $(x-x_0)p(x)$ or $(x-x_0)^2q(x)$ are:
\[y_1(x)=(x-x_0)^{\alpha}\cos(\beta\ln|x-x_0|)\sum_{n=0}^{\infty}A_n(x-x_0)^n,\quad A_0\neq 0\land A_n\in\bbR,\]
\[y_2(x)=(x-x_0)^{\alpha}\sin(\beta\ln|x-x_0|)\sum_{n=0}^{\infty}B_n(x-x_0)^n,\quad B_0\neq 0\land B_n\in\bbR.\]
\item Case $r_1-r_2\in\bbN_0$: Two solutions for all $0<|x-x_0|<R$ where $R$ is the distance between $x_0$ and the nearest to $x_0$ regular singular point of $(x-x_0)p(x)$ or $(x-x_0)^2q(x)$ are:
\[y_1(x)=(x-x_0)^{r_1}\sum_{n=0}^{\infty}A_n(x-x_0)^n,\quad A_0\neq 0\land A_n\in\bbR,\]
\[y_2(x)=(x-x_0)^{r_2}\sum_{n=0}^{\infty}B_n(x-x_0)^n,\quad B_0\neq 0\land B_n\in\bbR.\]
If they both exist and are linearly independent, no modification is needed; otherwise, $y_2$ is modified to
\[y_2(x)=\ln|x-x_0|y_1(x)+(x-x_0)^{r_2}\sum_{n=0}^{\infty}B_n(x-x_0)^n,\quad B_0\neq 0\land B_n\in\bbR.\]
\eit 
\item Substitute $y_1,y_1',y_1''$ and $y_2,y_2',y_2''$ into the ODE respectively, rewrite $p(x)$ and $q(x)$ into Taylor expansion at $x_0$, rewrite the products into Cauchy products, and rewrite LHSs as power series in $x^n$.
\item Solve for the recurrence relations of $A_n$ and $B_n$.
\bit
\item Case $r_1-r_2\notin\bbZ\land r_1,r_2\in\bbR$ and Case $r_1,r_2$ are conjugate imaginary roots: We may set $A_0$ and $B_0$ as any nonzero constants (typically 1).
\item Case $r_1-r_2\in\bbN_0$: The terms multiplied by $\ln|x-x_0|$ in the substitution of $y_2(x)$ yield the same recurrence relation for $A_n$ as that obtained from the substitution of $y_1(x)$, and therefore need not be solved again. We may set $A_0$ as any nonzero constant (typically 1). The lowest-two-order equations in the substitution of $y_2(x)$ may determine $B_0$ and/or $B_1$, or relation of $B_0$ and $B_1$. If one of them remains free after applying this constraint, it may be chosen arbitrarily except that $B_0\neq 0$, with the remaining determined uniquely by the recurrence relation.
\eit
\item The two-parameter family of general solutions for all $0<|x-x_0|<R$ where $R$ is the distance between $x_0$ and the nearest to $x_0$ regular singular point of $(x-x_0)p(x)$ or $(x-x_0)^2q(x)$ is:
\[y=C_1y_1(x)+C_2y_2(x),\quad C_1,C_2\in\bbR.\]
\een
\begin{proof}
PLACEHOLDER
\end{proof}
\sssc{Example: $y''-2xy'+y=0$}
ODE:
\[y''-2xy'+y=0.\]
Solutions:
\[y=\sum_{n=0}^{\infty}a_nx^n,\]
\[a_0,a_1\in\bbR,\quad a_{n+2}=\frac{n-1}{(n+2)(n+1)}a_n.\]
\begin{proof}
\[y=\sum_{n=0}^{\infty}a_nx^n\]
\[y'=\sum_{n=0}^{\infty}a_{n+1}(n+1)x^n\]
\[y''=\sum_{n=0}^{\infty}a_{n+2}(n+2)(n+1)x^n\]
\[a_{n+2}(n+2)(n+1)-a_nn+a_n=0\]
\[a_{n+2}=\frac{n-1}{(n+2)(n+1)}a_n\]
\end{proof}
\sssc{Example: $y''+\sin(x)y'+x^2y=0$}
ODE:
\[y''+\sin(x)y'+x^2y=0.\]
Solutions:
\[y=\sum_{n=0}^{\infty}a_nx^n,\]
where:
\[a_{-1}=a_{-2}=0,\quad a_0,a_1\in\bbR,\]
\[a_{n+2}(n+2)(n+1)+\sum_{k=0}^{\left\lfloor\frac{n-1}{2}\right\rfloor}\frac{(-1)^k}{(2k+1)!}a_{n-2k}(n-2k)+a_{n-2}=0.\]
\begin{proof}
\[y=\sum_{n=0}^{\infty}a_nx^n\]
\[y'=\sum_{n=0}^{\infty}a_{n+1}(n+1)x^n\]
\[y''=\sum_{n=0}^{\infty}a_{n+2}(n+2)(n+1)x^n\]
\[\sin(x)=\sum_{n=0}^{\infty}\frac{(-1)^n}{(2n+1)!}x^{2n+1}\]
\[\sum_{n=0}^{\infty}a_{n+2}(n+2)(n+1)x^n+\sum_{n=0}^{\infty}\frac{(-1)^n}{(2n+1)!}x^{2n+1}\sum_{n=0}^{\infty}a_{n+1}(n+1)x^n+x^2\sum_{n=0}^{\infty}a_nx^n=0.\]
\[\ba
\sum_{n=0}^{\infty}\frac{(-1)^n}{(2n+1)!}x^{2n+1}\sum_{n=0}^{\infty}a_{n+1}(n+1)x^n&=\sum_{n=0)^{\infty}\sum_{k=0}^n\frac{(-1)^k}{(2k+1)!}x^{2k+1}a_{n-k+1}(n-k+1)x^{n-k}\\
&=\sum_{n=0)^{\infty}\sum_{k=0}^n\frac{(-1)^k}{(2k+1)!}a_{n-k+1}(n-k+1)x^{n+k+1}\\
&=\sum_{n=0}^{\infty}\sum_{k=0}^{\left\lfloor\frac{n-1}{2}\right\rfloor}\frac{(-1)^k}{(2k+1)!}a_{n-2k}(n-2k)x^n
\ea\]
\[\sum_{n=0}^{\infty}\qty(a_{n+2}(n+2)(n+1)+\sum_{k=0}^{\left\lfloor\frac{n-1}{2}\right\rfloor}\frac{(-1)^k}{(2k+1)!}a_{n-2k}(n-2k)+a_{n-2})x^n=0,\quad a_{-1}=a_{-2}=0\]
\[a_{n+2}(n+2)(n+1)+\sum_{k=0}^{\left\lfloor\frac{n-1}{2}\right\rfloor}\frac{(-1)^k}{(2k+1)!}a_{n-2k}(n-2k)+a_{n-2}=0\]
\end{proof}
\sssc{Example: $(x-x_0)^2y''+(x-x_0)y'-y=0$}
ODE:
\[(x-x_0)^2y''+(x-x_0)y'-y=0.\]
Solutions:
\[y(x)=A(x-x_0)+B(x-x_0)^{-1},\quad A,B\in\bbR.\]
\begin{proof}
\[y=\sum_{n=0}^{\infty}a_n(x-x_0)^{n+r}\]
\[y'=\sum_{n=0}^{\infty}a_n(n+r)(x-x_0)^{n+r-1}\]
\[y''=\sum_{n=0}^{\infty}a_n(n+r)(n+r-1)(x-x_0)^{n+r-2}\]
\[(x-x_0)^2y''=\sum_{n=0}^{\infty}a_n(n+r)(n+r-1)(x-x_0)^{n+r}\]
\[(x-x_0)y'=\sum_{n=0}^{\infty}a_n(n+r)(x-x_0)^{n+r}\]
\[L=a_0r(r-1)(x-x_0)^r+a_0r(x-x_0)^r-a_0(x-x_0)^r\]
\[I(r)=a_0r(r-1)+a_0r-a_0=a_0(r^2-1)=0\]
\[r=\pm 1\]
\[y_1(x)=\sum_{n=0}^{\infty}A_n(x-x_0)^{n+1}\]
\[y_1'(x)=\sum_{n=0}^{\infty}A_n(n+1)(x-x_0)^n\]
\[y_1''(x)=\sum_{n=0}^{\infty}A_n(n+1)n(x-x_0)^{n-1}\]
\[(x-x_0)y_1'(x)=\sum_{n=0}^{\infty}A_n(n+1)(x-x_0)^{n+1}\]
\[(x-x_0)^2y_1''(x)=\sum_{n=0}^{\infty}A_n(n+1)n(x-x_0)^{n+1}\]
\[A_n(n+1)n+A_n(n+1)-A_n=0.\]
\[A_n=0,\quad\forall n\in\bbN\]
\[y_2(x)=\sum_{n=0}^{\infty}B_n(x-x_0)^{n-1}\]
\[y_2'(x)=\sum_{n=0}^{\infty}B_n(n-1)(x-x_0)^{n-2}\]
\[y_2''(x)=\sum_{n=0}^{\infty}B_n(n-1)(n-2)(x-x_0)^{n-3}\]
\[\sum_{n=0}^{\infty}B_n(n-1)(n-2)(x-x_0)^{n-1}+B_n(n-1)(x-x_0)^{n-1}-B_n(x-x_0)^{n-1}=0\]
\[\sum_{n=0}^{\infty}B_n(n+1)(n-1)(x-x_0)^n=0\]
\[B_n(n+1)(n-1)=0\]
\[B_n=0,\quad\forall n\in\bbN\land n\neq 2\]
\[y_2(x)=B_0(x-x_0)^{-1}+B_2(x-x_0)\]
\[y(x)=C_1y_1(x)+C_2y_2(x)=A(x-x_0)+B(x-x_0)^{-1},\quad A,B\in\bbR\]
\end{proof}
\sssc{Example: $xy''+(x-1)^2y'+y=0$}
ODE:
\[xy''+(x-1)^2y'+y=0.\]
Solutions:
\[y(x)=\sum_{n=0}^{\infty}\qty(C_1A_n+C_2B_n)x^n+C_2\ln|x|\sum_{n=0}^{\infty}A_nx^n,\]
\[A_0=1,\quad A_1=-1,\quad B_0=4,\quad B_1=0,\quad C_1,C_2\in\bbR,\]
\[A_{n+2}(n+2)^2-A_{n+1}(2n+1)+A_nn=0,\]
\[2A_{n+2}(n+2)+B_{n+2}(n+2)^2-2A_{n+1}-B_{n+1}(2n+1)+A_n+B_nn=0.\]
\begin{proof}
\[y=\sum_{n=0}^{\infty}a_nx^{n+r}\]
\[y'=\sum_{n=0}^{\infty}a_n(n+r)x^{n+r-1}\]
\[y''=\sum_{n=0}^{\infty}a_n(n+r)(n+r-1)x^{n+r-2}\]
\[xy''=\sum_{n=0}^{\infty}a_n(n+r)(n+r-1)x^{n+r-1}\]
\[(x-1)^2y'=\sum_{n=0}^{\infty}a_n(n+r)x^{n+r+1}-2\sum_{n=0}^{\infty}a_n(n+r)x^{n+r}+\sum_{n=0}^{\infty}a_n(n+r)x^{n+r-1}\]
\[L=a_0r(r-1)x^{r-1}+a_0rx^{r+1}-2a_0rx^r+a_0rx^{r-1}\]
\[I(r)=a_0r(r-1)+a_0r=0\]
\[r_1=r_2=0\]
\[y_1(x)=\sum_{n=0}^{\infty}A_nx^n\]
\[\sum_{n=0}^{\infty}A_nn(n-1)x^{n-1}+\sum_{n=0}^{\infty}A_nnx^{n+1}-2\sum_{n=0}^{\infty}A_nnx^n+\sum_{n=0}^{\infty}A_nnx^{n-1}+\sum_{n=0}^{\infty}A_nx^n=0\]
\[\sum_{n=0}^{\infty}A_{n+1}(n+1)nx^n+\sum_{n=0}^{\infty}A_{n-1}(n-1)x^n-2\sum_{n=0}^{\infty}A_nnx^n+\sum_{n=0}^{\infty}A_{n+1}(n+1)x^n+\sum_{n=0}^{\infty}A_nx^n=0\]
\[A_{n+1}(n+1)^2-A_n(2n-1)+A_{n-1}(n-1)=0\]
\[A_1-A_0(-1)=0,\quad A_1=-A_0\]
\[A_{n+2}(n+2)^2-A_{n+1}(2n+1)+A_nn=0\]
\[y_2(x)=\ln|x|\sum_{n=0}^{\infty}A_nx^n+\sum_{n=0}^{\infty}B_nx^n\]
\[y_2'(x)=\ln|x|\sum_{n=0}^{\infty}A_nnx^{n-1}+\sum_{n=0}^{\infty}A_nx^{n-1}+\sum_{n=0}^{\infty}B_nnx^{n-1}\]
\[y_2''(x)=\ln|x|\sum_{n=0}^{\infty}A_nn(n-1)x^{n-2}+\sum_{n=0}^{\infty}A_nnx^{n-2}+\sum_{n=0}^{\infty}A_n(n-1)x^{n-2}+\sum_{n=0}^{\infty}B_nn(n-1)x^{n-2}\]
\[xy_2''(x)=\ln|x|\sum_{n=0}^{\infty}A_nn(n-1)x^{n-1}+\sum_{n=0}^{\infty}A_n(2n-1)x^{n-1}+\sum_{n=0}^{\infty}B_nn(n-1)x^{n-1}\]
\[x^2y_2'(x)=\ln|x|\sum_{n=0}^{\infty}A_nnx^{n+1}+\sum_{n=0}^{\infty}A_nx^{n+1}+\sum_{n=0}^{\infty}B_nnx^{n+1}\]
\[xy_2'(x)=\ln|x|\sum_{n=0}^{\infty}A_nnx^n+\sum_{n=0}^{\infty}A_nx^n+\sum_{n=0}^{\infty}B_nnx^n\]
\[\sum_{n=0}^{\infty}A_n(2n-1)x^{n-1}+\sum_{n=0}^{\infty}B_nn(n-1)x^{n-1}+\sum_{n=0}^{\infty}A_nx^{n+1}+\sum_{n=0}^{\infty}B_nnx^{n+1}-2\sum_{n=0}^{\infty}A_nx^n-2\sum_{n=0}^{\infty}B_nnx^n+\sum_{n=0}^{\infty}A_nx^{n-1}+\sum_{n=0}^{\infty}B_nnx^{n-1}+\sum_{n=0}^{\infty}B_nx^n=0\]
\[\sum_{n=0}^{\infty}A_n2nx^{n-1}+B_nn^2x^{n-1}-2A_nx^n-B_n(2n-1)x^n+A_nx^{n+1}+B_nnx^{n+1}=0\]
\[-2A_0+B_0+2A_1+B_1=0,\quad B_0+B_1=4A_0\]
\[2A_{n+2}(n+2)+B_{n+2}(n+2)^2-2A_{n+1}-B_{n+1}(2n+1)+A_n+B_nn=0\]
Set
\[A_0=1,\quad A_1=-1,\quad B_0=4,\quad B_1=0\]
\[y(x)=C_1y_1(x)+C_2y_2(x)=\sum_{n=0}^{\infty}\qty(C_1A_n+C_2B_n)x^n+C_2\ln|x|\sum_{n=0}^{\infty}A_nx^n\]
\end{proof}
\sssc{Example for complex roots: PLACEHOLDER}
PLACEHOLDER
\sct{Classical theory}
PLACEHOLDER
: below waiting for change to "Ordinary Differential Equations and Dynamical Systems" version.
: above things e.g. solutions as vector space etc. mb need conditions or assumptions of existence and/or uniqueness.
\ssc{Existence of Solution}
\sssc{Peano existence theorem (皮亞諾存在性定理), Peano theorem (皮亞諾定理), or Cauchy–Peano theorem (柯西-皮亞諾定理)}
Let $D$ be an open subset of $\mathbb{R}\times\mathbb{R}^n$ and $f\colon D\to \mathbb {R}$ be a continuous function, then every initial value problem given by explicit first-order ODE $y'(t)=f\left(t,y(t)\right)$ defined on $D$ and initial condition $y\left(t_{0}\right)=y_{0}$ with $(t_{0},y_{0})\in D$ has a local solution $z\colon I\to \mathbb {R}^n$ where $I$ is a neighbourhood of $t_0$ in $\mathbb {R} $.
\sssc{Carathéodory's existence theorem}
Let
\[D=\{(t,y)\mid|t-T|\leq a\land\forall\tx{\ integer\ }1\leq i\leq n\colon |y_i-Y_i|\leq b_i\}\]
be a rectangle in $\mathbb{R}\times\mathbb{R}^n$ where $t,T\in\mathbb{R}$, $y=(y_1, y_2,\dots  y_n)\in\mathbb{R}^n$, $Y=(Y_1, Y_2,\dots  Y_n)\in\mathbb{R}^n$, and constant $a,b_i\in\mathbb{R}_{>0}$, and $f(t,y)\colon D\to \mathbb {R}$ be a function that is:
\bit
\item continuous in $y$ for each fixed $t$,
\item Lebesgue-measurable in $t$ for each fixed $y$, and
\item such that there is a Lebesgue-integrable function $m\colon [T-a,T+a]\to [0,\infty )$ such that $|f(t,y)|\leq m(t)$ for all $(t,y)\in D$,
\end{itemize}
then every initial value problem given by explicit first-order ODE $y'(t)=f\left(t,y(t)\right)$ defined on $D$ and initial condition $y\left(t_{0}\right)=y_{0}$ with $(t_{0},y_{0})\in D$ has a local solution $z\colon I\to \mathbb {R}^n$ where $I$ is a neighbourhood of $t_0$ in $\mathbb{R}$.

Let $I$ be an open interval of $\mathbb{R}$ and $f(t,y)\colon I\times\mathbb{R}^n\to\mathbb{R}$ where $t\in\mathbb{R}$, $y=(y_1, y_2,\dots  y_n)\in\mathbb{R}^n$ be a function that is:
\bit
\item continuous in $y$ for each fixed $t$,
\item Lebesgue-measurable in $t$ for each fixed $y$, and
\item such that there is a Lebesgue-integrable function $m\colon I\to [0,\infty )$ such that $|f(t,y)|\leq m(t)$ for all $(t,y)\in I\times\mathbb{R}^n$,
\end{itemize}
then every initial value problem given by explicit first-order ODE $y'(t)=f\left(t,y(t)\right)$ defined on $I\times\mathbb{R}^n$ and initial condition $y\left(t_{0}\right)=y_{0}$ with $(t_{0},y_{0})\in I\times\mathbb{R}^n$ has a local solution $z\colon I\to \mathbb {R}^n$ where $I$ is a neighbourhood of $t_0$ in $\mathbb{R}$.
\ssc{Uniqueness of Solution}
\sssc{Picard–Lindelöf theorem (皮卡-林德勒夫定理) or Cauchy–Lipschitz theorem (柯西-利普希茨定理) local version}
Let
\[D=\{(t,y)\mid|t-T|\leq a\land\forall\tx{\ integer\ }1\leq i\leq n\colon |y_i-Y_i|\leq b_i\}\]
be a rectangle in $\mathbb{R}\times\mathbb{R}^n$ where $t,T\in\mathbb{R}$, $y=(y_1, y_2,\dots  y_n)\in\mathbb{R}^n$, $Y=(Y_1, Y_2,\dots  Y_n)\in\mathbb{R}^n$, and constant $a,b_i\in\mathbb{R}_{>0}$, and $f(t,y)\colon D\to \mathbb {R}$ be a function that is continuous in $t$ andi locally Lipschitz on $D$ in all $y_i$, then every initial value problem given by explicit first-order ODE $y'(t)=f\left(t,y(t)\right)$ defined on $D$ and initial condition $y\left(t_{0}\right)=y_{0}$ with $(t_{0},y_{0})\in D$ has a unique local solution $z\colon I\to \mathbb {R}^n$ where $I$ is a neighbourhood of $t_0$ in $\mathbb {R} $, that is, let $I_1,I_2$ be two neighbourhoods of $t_0$ in $\mathbb{R}$ and $z_i\colon I_i\to\mathbb{R}^n$ for $i\in\{1,2\}$ be two differentiable functions such that $z_i'(t)=f\left(t,z_i(t)\right)$ for all $t\in I_i$, for $i\in\{1,2\}$, then $\exists t_0\in I_1\cap I_2\text{\ s.t.\ }z_1(t_0)=z_2(t_0)\implies\forall t\in I_1\cap I_2\colon z_1(t)=z_2(t)$.

Let $I$ be an open interval of $\mathbb{R}$ and $f(t,y)\colon I\times\mathbb{R}^n\to\mathbb{R}$ where $t\in\mathbb{R}$, $y=(y_1, y_2,\dots  y_n)\in\mathbb{R}^n$ be a function that is continuous in $t$ and locally Lipschitz in all $y_i$, then every initial value problem given by explicit first-order ODE $y'(t)=f\left(t,y(t)\right)$ defined on $I\times\mathbb{R}^n$ and initial condition $y\left(t_{0}\right)=y_{0}$ with $(t_{0},y_{0})\in I\times\mathbb{R}^n$ has a unique solution $z\colon I\to\mathbb {R}^n$, that is, let $I_1,I_2\subseteq\mathbb{R}$ and $z_i\colon I_i\to\mathbb{R}^n$ for $i\in\{1,2\}$ be two differentiable functions such that $z_i'(t)=f\left(t,z_i(t)\right)$ for all $t\in I_i$, for $i\in\{1,2\}$, then $\exists t_0\in I_1\cap I_2\text{\ s.t.\ }z_1(t_0)=z_2(t_0)\implies\forall t\in I_1\cap I_2\colon z_1(t)=z_2(t)$.
PLACEHOLDER: end
\sct{Dynamical system (動態系統 or 動力系統)}
\ssc{Dynamical system (DS)}
\sssc{Dynamical system}
A dynamical system, or simply system, is a tuple $(T, X, \Phi)$ where $T$ is a monoid, written additively and with the independent variable $t$ in it called evolution parameter (演化參數) or time, $X$ is a non-empty set, called the phase space (相空間) or state space (狀態空間) with the independent variable $x$ in it called (system) phase (相) or state (狀態), and $\Phi$ is a function, called the evolution function (演化函數) or flow (map),
\[\Phi(t,x)\colon U\subseteq(T\times X)\to X\]
where $U$ is such that the second projection map $\pi_2$ for $T\times X$ satisfies
\[\pi_2(U)=X,\]
and for any $x \in X$, $\Phi (0,x)=x$.
\sssc{Time-invariant or autonomous dynamical system}
A dynamic system $(T, X, \Phi)$ is called time-invariant or autonomous iff it satisfies the semigroup property, translation property, shift property, time-invariance, or autonomy that
\[\Phi (t_{2},\Phi (t_{1},x))=\Phi (t_{2}+t_{1},x)\]
for any $t_{1},t_{2}+t_{1}\in I(x)$ and $t_{2}\in I(\Phi (t_{1},x))$, in which
\[I(x)\coloneq\{t\in T\mid(t,x)\in U\}\]
for any $x\in X$.

Otherwise, it is called time-variant or non-autonomous.
\sssc{Orbit (軌道)}
Given a dynamical system $(T, X, \Phi)$ with
\[\Phi(t,x)\colon U\subseteq(T\times X)\to X\]
and
\[I(x)\coloneq\{t\in T\mid(t,x)\in U\}.\]
The set
\[\gamma(x_0)\coloneq\{\Phi (t,x)\colon t\in I(x)\}\subset X\]
is called the orbit through $x$.

An orbit which consists of a single point is called constant orbit. A non-constant orbit is called closed or periodic if there exists $t\neq 0\in I(x)$ such that $\Phi (t,x)=x$.
\sssc{(Phase) trajectory (function)}
Given a dynamical system $(T, X, \Phi)$, for any $x_0\in X$, the (phase) trajectory (function) starting at $x_0$ is a function
\[x\colon t\to\gamma(x_0);\;t\mapsto\Phi(t,x_0).\]
\sssc{Phase portrait (相圖)}
A phase portrait is a geometric representation of a collection of phase trajectories of an autonomous dynamical system, typically all phase trajectories starting at any $x\in X$.
\sssc{Attractor (吸引子)}
For a dynamical system $(\mathbb{R}, X, \Phi)$ with $D\subseteq X$ and $\Phi(t,x)\colon \mathbb{R}_{\geq 0}\times D\to X$, a non-empty subset $A$ of $D$ is called an attractor if and only if it satisfies the following three conditions:
\bit
\item Forward invariance:
    \[\forall a\in A\colon\forall t>0\colon\Phi(t,a)\in A.\]
\item Attraction: There exists a neighborhood of $A$, called the basin of attraction for $A$ and denoted $B(A)$, such that for any $b\in B(A)$ and any open neighborhood $N$ of $A$, there is a positive constant $T$ such that $\forall t>T\colon\Phi(t,b)\in N$.
\item Minimality: There is no non-empty proper subset of $A$ that satisfies the above two conditions.
\eit
A point $a$ in $D$ is called an attractor iff $\{a\}$ is an attractor.
\sssc{Repeller}
For a dynamical system $(\mathbb{R}, X, \Phi)$ with $D\subseteq X$ and $\Phi(t,x)\colon \mathbb{R}_{\geq 0}\times D\to X$, a non-empty subset $R$ of $X$ is called a repeller if and only if it satisfies the following three conditions:
\bit
\item Forward invariance:
    \[\forall r\in R\colon\forall t>0\colon\Phi(t,r)\in R.\]
\item Repulsion: There exists a neighborhood of $R$, called the basin of repulsion for $R$ and denoted $B(R)$, such that for any $b\in B(R)\setminus R$ and any open neighborhood $N$ of $R$, there is a positive constant $T$ such that $\forall t>T\colon\Phi(t,b)\notin N$.
\item Minimality: There is no non-empty proper subset of $R$ that satisfies the above two conditions.
\eit
A point $r$ in $D$ is called a repeller iff $\{r\}$ is a repeller.
\sssc{Continuous-time dynamical system}
A continuous-time dynamical system is a dynamical system $(\mathbb{R}, X, \Phi)$ with $X$ being a manifold locally diffeomorphic to a Banach space and $\Phi(t,x)\colon A\times X\to X$ with $\mathbb{R}_{\geq 0}\subseteq A\subseteq\mathbb{R}$ such that $\pdv{\Phi}{t}\big\vert_{t=0}$ exists for all $x\in X$.
\sssc{Discrete-time dynamical system}
A discrete-time dynamical system is a dynamical system $(\mathbb{Z}, X, \Phi)$ with $X$ being a manifold locally diffeomorphic to a Banach space and $\Phi(t,x)\colon A\times X\to X$ with $\mathbb{N}_0\subseteq A\subseteq\mathbb{Z}$.
\ssc{Continuous-time dynamical systems}
Below, we will discuss continuous-time dynamical systems in Euclidean vector spaces, that are, continuous-time dynamical systems whose phase space is $\bbR^n$ for some $n\in\bbN$.
\sssc{Systems of first-order ODEs}
Consider a system of first-order ODEs:
\[\dv{x}{t}=f(t,x), \quad x\in\mathbb{R}^n\land f\colon\mathbb{R}\times\mathbb{R}^n\to\mathbb{R}^n.\]
Let $U\subseteq\mathbb{R}\times\mathbb{R}^n$ be the set such that for any $(t_0,x_0)$ in $U$, $t_0$ is in the interval of definition of the solution of it with the initial condition $x(0)=x_0$ and that the solution is unique, and $x(t;x_0)$ be the solution of it with the initial condition $x(0)=x_0$.

Then the dynamical system represented by it has phase space $\mathbb{R}^n$, evolution parameter $t$, phase $x$, and evolution function $\Phi\colon U\to\mathbb{R}^n;\Phi(t,x_0)=x(t;x_0)$. The system of ODEs is called the evolution rule of the dynamical system, and the dynamical system is called to be defined by the system of ODEs. Each solution of the system of ODEs is a phase trajectory of the dynamical system.
\ssc{Autonomous continuous-time dynamical systems}
Below, we will discuss autonomous continuous-time dynamical systems in Euclidean vector spaces, that are, autonomous continuous-time dynamical systems whose phase space is $\bbR^n$ for some $n\in\bbN$.
\sssc{Equilibria, fixed points, or fixpoints of autonomous continuous-time dynamical systems}
An equilibrium, fixed point, or fixpoint of an autonomous continuous-time dynamical system $(T, X, \Phi)$ is a point $x^*\in X$ such that the vector field $f(x)=\pdv{\Phi}{t}\big\vert_{t=0}$ vanishes there, that is, $f(x^*)=0$.
\sssc{Autonomous system of ODEs}
An autonomous system of ODEs defines an autonomous continuous-time dynamical system, and the equilibria of the dynamical system are the critical points of the system of ODEs.
\sssc{Phase portrait}
For an autonomous continuous-time dynamical system, one usually plots $X$, marks equilibria, and draw arrows at each point $x$ in a grid indicating $f(x)$ at it. When $X=\mathbb{R}$, a phase potrait is also called a phase line.
\sssc{Linear autonomous continuous-time dynamical system}
An autonomous continuous-time dynamical system $(\mathbb{R}, \mathbb{R}^n, \Phi(t,x))$ is called linear iff its evolution rule is a system of linear ODEs. Let the forcing term be $q(x)=Cx^\top$ where $C$ is a constant matrix in $\mathbb{R}^{n\times n}$, then $C$ is called the dynamics matrix of the system, and the eigenvalues and eigen vectors of $C$ are called the eigenvalues and eigen vectors of the system.
\ssc{Stability of equilibria}
Let $x^*$ be an equilibrium of an autonomous continuous-time dynamical system and $A$ be the domain of the evolution function.
\sssc{(Lyapunov) stable (（李亞普諾夫）穩定)}
$x^*$ is called to be (Lyapunov) stable iff    \[\forall\varepsilon>0\colon\exists\delta>0\text{\ s.t.\ }\|x(0)-x^*\|<\delta\implies\forall t\in A\colon\|x(t)-x^*\|<\varepsilon.\]
\sssc{Asymptotically stable (漸近穩定)}
$x^*$ is called to be asymptotically stable iff
\[\exists\delta>0\text{\ s.t.\ }\|x(0)-x^*\|<\delta\implies\lim_{t\to\infty}x(t)=x^*.\]
An asymptotically stable equilibrium is necessarily (Lyapunov) stable and an attractor.
\sssc{Exponentially stable (指數穩定)}
$x^*$ is called to be exponentially stable iff
\[\exists M>0,\alpha>0,\delta>0\text{\ s.t.\ }\|x(0)-x^*\|<\delta\implies\forall t\in A\|x(t)-x^*\|\leq\|x(0)-x^*\|e^{-\alpha t}.\]
An exponentially stable equilibrium is necessarily asymptotically stable.
\sssc{Semi-stable or semistable (半穩定)}
$x^*$ is called to be semi-stable or semistable iff it is (Lyapunov) stable and
\[(\exists\delta>0\text{\ s.t.\ }x(0)-x^*<\delta\implies\lim_{t\to\infty}x(t)=x^*)\lor (\exists\delta>0\text{\ s.t.\ }x^*-x(0)<\delta\implies\lim_{t\to\infty}x(t)=x^*).\]
\sssc{Marginally stable (臨界穩定)}
For linear autonomous continuous-time dynamical system, $x^*$ is called to be marginally stable iff it is (Lyapunov) stable but not asymptotically stable,
\sssc{Unstable (不穩定)}
$x^*$ is called to be unstable iff it is not (Lyapunov) stable.

An equilibrium that is in a repeller is necessarily unstable.
\sct{Control Theory (控制理論)}
\ssc{Continuous-time linear time-invariant (LTI) system}
\sssc{Causal (因果的) continuous-time linear time-invariant (LTI) system}
A causal continuous-time linear time-invariant (LTI) system of a variable $t\in\bbR$ is a system that accept an input (distribution) (often called function) $x(t)$ and produces a response (distribution) (often called function) $y(t)$ that is the solution of a linear autonomous ODE whose forcing term is $x(t)$. It can be completely characterized by a homogeneous solution $y_c(t)$ given an initial condition (also called initial state) $y(0^-)$, a distribution called impulse response (function) $h(t)$ that map all $t<0$ to $0$, which is the output when the input is the Dirac delta function $\detla(t)$, that
\[y(t)=(x*h)(t)+y_c(t),\]
where
\[(x*h)(t)\coloneq\int_0^tx(\tau)h(t-\tau)\dd{\tau}.\]
Applying unilateral Laplace transform \[Y(s)=X(s)\cdot H(s)+Y_c(s),\]
where $Y_c(s)=\mathcal{L}\{y_c(t)\}$ and $H(s)$ is called transfer function or gain.
\sssc{Non-causal continuous-time linear time-invariant (LTI) system}
A non-causal continuous-time linear time-invariant (LTI) system of a variable $t\in\bbR$ is a system that accept an input (distribution) (often called function) $x(t)$ and produces a response (distribution) (often called function) $y(t)$ that is the solution of a linear autonomous ODE whose forcing term is $x(t)$. It can be completely characterized by a distribution called impulse response (function) $h(t)$, which is the output when the input is the Dirac delta function $\detla(t)$, that
\[y(t)=(x*h)(t)\coloneq\int_{-\infty}^{\infty} x(\tau)h(t-\tau)\dd{\tau}.\]
Applying bilateral Laplace transform \[Y(s)=X(s)\cdot H(s),\]
where $H(s)$ is called transfer function or gain.
\sssc{Types of responses}
\bit
\item\tb{Natural, zero-input, homogeneous, or unforced response (ZIR)}: Response when $x(t)=0$.
\item\tb{Forced, zero-state, or zero IC response}: Response when $y(0)=0$ for causal system.
\item\tb{(Total) response}: For causal system, the sum of natural response and forced response is the total response.
\item\tb{Transient response}: A response that converges to a constant.
\eit
\sssc{Time constant}
For a response function in the form $y(t)=y_0e^{-\alpha t}$ with constants $y_0\neq 0$ and $\alpha>0$, the time constant $\tau$ is defined as $\frac{1}{\alpha}$, that is, $y(\tau)=e^{-1}$.

For the smallest positive integer (or rational number to a number of decimals) $k$ such that $\frac{y(k\tau)}{y_0}<0.01$ (or other designated number), we typically call that $y(t)$ decays to $0$ about $k$ times time constants.
\sssc{Filter}
A continuous-time linear time-invariant system is a low-pass filter iff $H(i\omega)$ where $i=\sqrt{-1}$ as a function of a real variable $\omega$ is such that
\[\lim_{\omega\to 0}\abs{H(i\omega)}=1\]
and
\[\lim_{\omega\to\infty}\abs{H(i\omega)}=0.\]
A continuous-time linear time-invariant system is a high-pass filter iff $H(i\omega)$ where $i=\sqrt{-1}$ as a function of a real variable $\omega$ is such that
\[\lim_{\omega\to 0}\abs{H(i\omega)}=0\]
and
\[\lim_{\omega\to\infty}\abs{H(i\omega)}=1.\]



\end{document}
